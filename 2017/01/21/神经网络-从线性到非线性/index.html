<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />













  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Deep learning,激活函数," />





  <link rel="alternate" href="/atom.xml" title="徐阿衡" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.3" />






<meta name="description" content="这一篇讨论常用的非线性激励函数。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习-从线性到非线性">
<meta property="og:url" content="http://www.shuang0420.com/2017/01/21/神经网络-从线性到非线性/index.html">
<meta property="og:site_name" content="徐阿衡">
<meta property="og:description" content="这一篇讨论常用的非线性激励函数。">
<meta property="og:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/shallow.jpg">
<meta property="og:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/sigmoid.jpg">
<meta property="og:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/tanh.jpg">
<meta property="og:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/relu.jpg">
<meta property="og:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/leakyrelu.jpg">
<meta property="og:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/activationF.jpg">
<meta property="og:updated_time" content="2018-09-17T11:14:29.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习-从线性到非线性">
<meta name="twitter:description" content="这一篇讨论常用的非线性激励函数。">
<meta name="twitter:image" content="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/shallow.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '6294135991397516000',
      author: '阿衡'
    }
  };
</script>




  <link rel="canonical" href="http://www.shuang0420.com/2017/01/21/神经网络-从线性到非线性/"/>


  <title> 深度学习-从线性到非线性 | 徐阿衡 </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="en">

  










  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">徐阿衡</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Shuang</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-works">
          <a href="/works" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Works
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/aboutme" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input" placeholder="search my blog...">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
         
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                深度学习-从线性到非线性
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-01-21T12:20:02+08:00" content="2017-01-21">
              2017-01-21
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Deep-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/01/21/神经网络-从线性到非线性/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/01/21/神经网络-从线性到非线性/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这一篇讨论常用的非线性激励函数。<br><a id="more"></a></p>
<h1 id="全连接神经网络"><a href="#全连接神经网络" class="headerlink" title="全连接神经网络"></a>全连接神经网络</h1><p>一个浅层的神经网络，如下图其实就可以看作一个 logistic regression 模型加上非线性激励函数。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/shallow.jpg" class="ful-image" alt="shallow.jpg"></p>
<p>一个神经元的组成：</p>
<ul>
<li>输入：n 维向量</li>
<li>线性加权：$z=\sum^n_{i=1}w_ix_i+b$</li>
<li>激活函数：a=h(z)，要求非线性，容易求导</li>
<li>输出值：a(标量)</li>
</ul>
<p>当然我们可以加 z2, z3, a2, a3… 输入是 x1,x2…xn，输出是 a1,a2…am，如果给一个神经元，就是或 0 或 1 的输出，如果给多个，就从 logistic 回归变成了 softmax 回归。</p>
<p>一个输入，若干个中间层(可能是全连接／非全连接网络)，最后输出层，如果要做分类，就可以给一个或多个全连接网络（可以看作是 softmax）。</p>
<h1 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h1><p>如果不用激活函数，或者说激活函数是f(x) = x，那么在这种情况下你每一层输出都是上层输入的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，来个例子，假设<br>X1=W0*X0<br>X2=W1*X1<br>Y=W2*X2<br>那么，线性矩阵相乘，可以直接简化为一层：Y=W2*W1*W0*X0=W3*X0，为什么还要用网络？</p>
<p>所以，<strong>有线性回归网络吗？没有！</strong></p>
<p>正因为上面的原因，我们才要引入非线性函数作为激励函数，这样深层神经网络就有意义了（不再是输入的线性组合，可以逼近任意函数）。最早的想法是 sigmoid 函数或者 tanh 函数，输出有界，很容易充当下一层输入。</p>
<h1 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h1><p>激活函数通常有如下一些性质：</p>
<blockquote>
<p><strong>非线性：</strong> 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。<br><strong>可微性：</strong> 当优化方法是基于梯度的时候，这个性质是必须的。<br><strong>单调性：</strong> 当激活函数是单调的时候，单层网络能够保证是凸函数。<br><strong>f(x)≈x：</strong> 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。<br><strong>输出值的范围：</strong> 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate.</p>
</blockquote>
<p>这些性质，也正是我们使用激活函数的原因。</p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/sigmoid.jpg" class="ful-image" alt="sigmoid.jpg">
<p>公式：<br>$$f(x)=sigmoid(x)={1 \over 1+e^{-x}}$$</p>
<p>对其求导<br>$$<br>  \begin{aligned}<br>  {df \over dx} &amp; = -{1 \over (1+e^{-x})^2}(-e^{-x}) \\<br>  &amp; =  {1 \over 1+e^{-x}} {e^{-x} \over 1+e^{-x}} \\<br>   &amp; = {1 \over 1+e^{-x}} {1+e^{-x}-1 \over 1+e^{-x}} \\<br>   &amp; = f(x)(1-f(x))<br>  \end{aligned}<br>$$</p>
<p>Sigmoid 将数据映射到 [0,1]</p>
<p><strong>缺点：</strong></p>
<blockquote>
<p>Sigmoids saturate and kill gradients.</p>
</blockquote>
<ol>
<li>梯度下降非常明显，且两头过于平坦，容易出现梯度消失的情况<br>当输入非常大或者非常小的时候(saturation)，神经元的梯度是接近于0的，从图中可以看出梯度的趋势。所以，你需要尤其注意参数的初始值来避免 saturation 的情况。如果初始值很大的话，大部分神经元可能都会处在 saturation 的状态而把 gradient kill 掉，这会导致网络变的很难学习。</li>
<li>输出值域不对称（非0均值）<br>后一层的神经元将得到上一层输出的非 0 均值的信号作为输入，产生的一个结果就是：如果数据进入神经元的时候是正的(e.g. x&gt;0 elementwise in f=wTx+b)，那么 w 计算出的梯度也会始终都是正的。</li>
</ol>
<h2 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/tanh.jpg" class="ful-image" alt="tanh.jpg">
<p>公式：<br>$$f(x)=tanh(x)={2 \over 1+e^{-2x}}-1$$</p>
<p>对其求导<br>我们知道 $tanh(x)={sinh(x) \over cosh(x)}$，所以对 f(x) 求导也就是对 ${sinh(x) \over cosh(x)}$ 求导。<br>$$<br>  \begin{aligned}<br>  {df \over dx} &amp; = {cosh^2(x)-sinh^2(x) \over cosh^2(x)} \\<br>  &amp; =  1-tanh^2(x) \\<br>   &amp; = 1-f(x)^2<br>  \end{aligned}<br>$$</p>
<p>tanh 将数据映射到 [-1,1]，解决了 sigmoid 输出值域不对称问题，然而两头依旧过于平坦，梯度损失仍然明显。</p>
<h2 id="ReLU-Rectified-linear-unit"><a href="#ReLU-Rectified-linear-unit" class="headerlink" title="ReLU(Rectified linear unit)"></a>ReLU(Rectified linear unit)</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/relu.jpg" class="ful-image" alt="relu.jpg">
<p>$$f(x)=max(0,x)$$</p>
<p>也就是 x&lt;0 取0，否则取本身。</p>
<p><strong>优点：</strong></p>
<ol>
<li>收敛速度比 sigmoid/tanh 更快<br> 可能是因为它是linear，而且 non-saturating</li>
<li>计算高效简单<br> 相比于 sigmoid/tanh，ReLU 只需要一个阈值就可以得到激活值，ReLU具有所希望的特性，不需要输入归一化来防止它们达到饱和，也不用去算一大堆复杂的运算。</li>
<li>反向梯度没有损失</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>正向截断负值，损失大量特征</li>
<li>训练时很“脆弱”，有 dead area<br> 如，太高的 learning rate 配合上非常大的梯度流过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了。如果这个情况发生了，那么这个神经元的梯度就永远都会是 0.<br> 实际操作中，如果 learning rate 很大，那么很有可能网络中的 40% 的神经元都”dead”了。<br> 当然，如果你设置了一个合适的较小的 learning rate，这个问题发生的情况其实也不会太频繁。另外可以配合 Xavier 权重初始化方法，使用 adagrad 等方法自动调节 learning rate 来防止这种问题。</li>
</ol>
<blockquote>
<p>(-) Unfortunately, ReLU units can be fragile during training and can “die”. For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold. For example, you may find that as much as 40% of your network can be “dead” (i.e. neurons that never activate across the entire training dataset) if the learning rate is set too high. With a proper setting of the learning rate this is less frequently an issue.</p>
</blockquote>
<p>有实验说，大概 80%-90%的特征都会被截断，然而 ReLU 仍然是非常常用的激励函数，因为特征足够多。</p>
<h2 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/leakyrelu.jpg" class="ful-image" alt="leakyrelu.jpg">
<p>对 ReLU 的改进，解决 dying ReLU 的问题。x&lt;0 时乘上一个 a 取较小的值，一般 a=0.01，可以保留更多的参数，反向梯度有部分损失。</p>
<p>为什么不变成 y=x？那不就回到了线性回归了嘛。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>一般现在都直接取 ReLU，然而如果使用 ReLU，一定要小心设置 learning rate，要注意不要让你的网络出现很多 “dead” 神经元，如果这个问题不好解决，那么可以试试 Leaky ReLU、PReLU、random ReLU 或者 Maxout。另外，现在主流的做法，会多做一步batch normalization，尽可能保证每一层网络的输入具有相同的分布，见<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="external">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%88%B0%E9%9D%9E%E7%BA%BF%E6%80%A7/activationF.jpg" class="ful-image" alt="activationF.jpg">
<p><strong>sigmoid 缺点：</strong></p>
<ol>
<li>两头过于平坦</li>
<li>输出值域不对称（非0均值）</li>
</ol>
<p><strong>tanh 缺点:</strong></p>
<ol>
<li>两头依旧过于平坦</li>
</ol>
<p><strong>ReLU:</strong></p>
<ol>
<li>收敛速度比 sigmoid/tanh 更快</li>
<li>计算高效简单</li>
<li>Dead Area 中权重不更新(leaky ReLU 不存在 dead area)</li>
</ol>
<blockquote>
<p>参考链接<br><a href="http://blog.csdn.net/u013146742/article/details/51986575" target="_blank" rel="external">RELU 激活函数及其他相关的函数</a></p>
</blockquote>

      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/wechat.jpg" alt="徐阿衡 wechat" style="width: 200px; max-width: 100%;"/>
    <div>欢迎关注：徐阿衡的微信公众号</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>客官，打个赏呗~</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="http://7xu83c.com1.z0.glb.clouddn.com/1.pic.jpg" alt="徐阿衡 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-learning/" rel="tag">#Deep learning</a>
          
            <a href="/tags/激活函数/" rel="tag">#激活函数</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/01/20/卷积神经网络 CNN 笔记/" rel="next" title="卷积神经网络 CNN 笔记">
                <i class="fa fa-chevron-left"></i> 卷积神经网络 CNN 笔记
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/01/23/推荐系统--开坑/" rel="prev" title="推荐系统--开坑">
                推荐系统--开坑 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      



    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
     
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xu83c.com1.z0.glb.clouddn.com/2.pic.jpg"
               alt="徐阿衡" />
          <p class="site-author-name" itemprop="name">徐阿衡</p>
          <p class="site-description motion-element" itemprop="description">读万卷书，行万里路 @SYSU @CMU</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/">
              <span class="site-state-item-count">160</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">123</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Shuang0420" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.linkedin.com/in/shuang-xu-7008b894?trk=nav_responsive_tab_profile_pic" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://zhuanlan.zhihu.com/c_136690664" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://starllap.space" title="Star" target="_blank">Star</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://liam0205.me" title="Liam Huang" target="_blank">Liam Huang</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.libinx.com" title="Li Bin" target="_blank">Li Bin</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#全连接神经网络"><span class="nav-number">1.</span> <span class="nav-text">全连接神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#激活函数"><span class="nav-number">2.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#性质"><span class="nav-number">3.</span> <span class="nav-text">性质</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类"><span class="nav-number">4.</span> <span class="nav-text">分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Sigmoid"><span class="nav-number">4.1.</span> <span class="nav-text">Sigmoid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tanh"><span class="nav-number">4.2.</span> <span class="nav-text">tanh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ReLU-Rectified-linear-unit"><span class="nav-number">4.3.</span> <span class="nav-text">ReLU(Rectified linear unit)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Leaky-ReLU"><span class="nav-number">4.4.</span> <span class="nav-text">Leaky ReLU</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#小结"><span class="nav-number">5.</span> <span class="nav-text">小结</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <!-- Other code may be here -->
<div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">徐阿衡</span>
  <a href="http://www.miitbeian.gov.cn/">粤ICP备17129486号</a>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>


<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'httpshuang0420githubio';
      var disqus_identifier = '2017/01/21/神经网络-从线性到非线性/';
      var disqus_title = "深度学习-从线性到非线性";
      var disqus_url = 'http://www.shuang0420.com/2017/01/21/神经网络-从线性到非线性/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
