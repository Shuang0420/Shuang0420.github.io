<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />













  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Deep learning,RNN," />





  <link rel="alternate" href="/atom.xml" title="徐阿衡" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.3" />






<meta name="description" content="关于如何用 2-Component 共享词向量来优化 RNN。">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks">
<meta property="og:url" content="http://www.shuang0420.cn/2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/index.html">
<meta property="og:site_name" content="徐阿衡">
<meta property="og:description" content="关于如何用 2-Component 共享词向量来优化 RNN。">
<meta property="og:image" content="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/1.jpg">
<meta property="og:image" content="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/4.jpg">
<meta property="og:image" content="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/2.jpg">
<meta property="og:image" content="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/5.jpg">
<meta property="og:image" content="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/6.jpg">
<meta property="og:updated_time" content="2020-09-10T12:26:31.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks">
<meta name="twitter:description" content="关于如何用 2-Component 共享词向量来优化 RNN。">
<meta name="twitter:image" content="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/1.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '6294135991397516000',
      author: '阿衡'
    }
  };
</script>

<script async src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6146435155426457",
    enable_page_level_ads: true
  });
</script>




  <link rel="canonical" href="http://www.shuang0420.cn/2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/"/>


  <title> 论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks | 徐阿衡 </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="en">

  










  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">徐阿衡</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Shuang</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-works">
          <a href="/works" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Works
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/aboutme" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input" placeholder="search my blog...">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
         
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-03-14T09:02:27+08:00" content="2017-03-14">
              2017-03-14
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  , 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/Meaning-Representation/" itemprop="url" rel="index">
                    <span itemprop="name">Meaning Representation</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>关于如何用 2-Component 共享词向量来优化 RNN。<br><a id="more"></a></p>
<p><strong>原文：</strong><a href="https://arxiv.org/pdf/1610.09893v1.pdf" target="_blank" rel="external">LightRNN: Memory and Computation-Efficient Recurrent Neural Networks</a><br><strong>部分译文：</strong> <a href="http://www.tuicool.com/articles/2QjeMzn" target="_blank" rel="external">微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络</a></p>
<p>这里只是稍微总结一下。</p>
<h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><p>LightRNN 解决的问题是在 perplexity 差不多的情况下 <strong>减少模型大小(model size) + 加快训练速度(computational complexity)</strong>。论文在多个基准数据集进行语言建模任务来评价 LightRNN，实验表明，在困惑度（perplexity）上面，LightRNN 实现了可与最先进的语言模型媲美或更好的准确度，同时还减少了模型大小高达百倍，加快了训练过程两倍。这带来的意义无疑是深远的，它使得先前昂贵的 RNN 算法变得非常经济且规模化了，RNN 模型运用到 GPU 甚至是移动设备成为了可能，另外，如果训练数据很大，需要分布式平行训练时，聚合本地工作器（worker）的模型所需要的交流成本也会大大降低。</p>
<h1 id="主要思路"><a href="#主要思路" class="headerlink" title="主要思路"></a>主要思路</h1><h2 id="单词表示-Word-Representation"><a href="#单词表示-Word-Representation" class="headerlink" title="单词表示(Word Representation)"></a>单词表示(Word Representation)</h2><p>主要思路是使用 <strong>二分量（2-Component）</strong> 来共享 embeddings。</p>
<p>将词汇表中的每一个词都分配(或者说填入)到一个二维表格中，然后每一行关联一个向量，每一列关联另一个向量。根据一个词在表中的位置，该词可由行向量和列向量两个维度联合表示。表格中每一行的单词共享一个行向量，每一列的单词共享一个列向量，所以我们仅需要 $2 \sqrt |V|$ 个向量来表示带有|V|个词的词汇表，远少于现有的方法所需要的向量数|V|。<br><img src="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/1.jpg" class="ful-image" alt="1.jpg"></p>
<p>$x^r_i$: 第 i 行<br>$x^c_j$: 第 j 列</p>
<h2 id="引入-RNN"><a href="#引入-RNN" class="headerlink" title="引入 RNN"></a>引入 RNN</h2><p>知道了怎么用两个向量来表示一个词语，下一步就是如何将这种表示方法引入到 RNN 中。论文的做法非常简单，将一个词的行向量和列向量按顺序分别送入 RNN 中，以语言模型(Language Model, LM)为例，要计算下一个词是 $w_t$ 的概率，先根据前文计算下一个词的行向量是 $w_t$ 的概率，在根据前文和  $w_t$ 的行向量来计算下一个词的列向量是 $w_t$ 的概率，行向量和列向量的概率乘积就是下一个词是  $w_t$ 的概率。</p>
<img src="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/4.jpg" class="ful-image" alt="4.jpg">
<h2 id="单词分配"><a href="#单词分配" class="headerlink" title="单词分配"></a>单词分配</h2><p>怎么来分配单词形成这个表格呢？</p>
<ol>
<li>对冷启动(cold start)来说，随机初始化分配单词</li>
<li>对给定的 allocation 训练 embedding vectors 直到收敛(convergence)<br> 停止条件(stopping criterion)可以是训练时间或者是 perplexity(for LM model)</li>
<li>固定上一步中学习到的 embedding vectors，重新分配单词(refine allocation)，标准当然是最小化损失函数了</li>
</ol>
<h2 id="损失函数-优化问题"><a href="#损失函数-优化问题" class="headerlink" title="损失函数/优化问题"></a>损失函数/优化问题</h2><p><strong>损失函数：</strong><br>交叉熵(corss-entropy)<br>给定 T 个单词，损失函数 NNL(negative log-likelihood) 为：<br>$$NNL = \sum^T_{t=1}-logP(w_t)=\sum^T_{t=1}-logP_r{w_t}-logP_c(w_t)$$</p>
<p>扩展一下，$NNL=\sum^{|V|}_{w=1}NLL_w$，而单词 w 的损失函数 $NNL_w$ 为：<br>$$<br>  \begin{aligned}<br>  NNL_w &amp; = \sum_{t \in S_w} -logP(w_t) = l(w,r(w),c(w))\\<br>  &amp; = \sum_{t \in S_w} -logP_r(w_t)+ \sum_{t \in S_w} -logP_c(w_t) = l_r(w,r(w)) + l_c(w,c(w)) \\<br>  \end{aligned}<br>$$</p>
<ul>
<li>$S_w$: 单词 w 的所有可能出现的位置的集合</li>
<li>$(r(w),c(w))$: 单词 w 在 allocation table 的位置</li>
<li>$l_r(w,r(w))$: 单词 w 的行损失(row loss)</li>
<li>$l_c(w,c(w))$: 单词 w 的列损失(column loss)</li>
</ul>
<p>假定 $l(w,i,j)=l(w,i)+l(w,j)$ 的情况下，计算 $l(w,i,j)$ 的复杂度是 $O(|V|^2)$，而事实上，所有的 $l_r(w,i)$ 和  $l_c(w,j)$ 都在 LightRNN 训练的前向传播中计算过了。对所有的 $w,i,j$ 计算 $l(w,i,j)$ 后，我们可以把 reallocation 的问题看做下面的优化问题：</p>
<img src="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/2.jpg" class="ful-image" alt="2.jpg">
<p>这个优化问题又可以等价为一个标准的 <strong>最小权完美匹配(minimum weight perfect matching problem)</strong>，可以用 <a href="https://dspace.mit.edu/bitstream/handle/1721.1/49424/networkflows00ahuj.pdf?sequence=1" target="_blank" rel="external">minimum cost maximum flow(MCMF)</a> 算法来实现，复杂度为 $O(|V|^3)$，主要思路大概如下图，论文的实验中用的是一个最小权完美匹配的近似算法 <a href="https://link.springer.com/chapter/10.1007/3-540-49116-3_24" target="_blank" rel="external">1/2-approximation algorithm</a>，复杂度为 $O(|V|^2)$，这和整个 LightRNN 的训练复杂度(约为 $O(|V|KT)$，K 是训练过程的 epoch 数，T 是训练集中的 token 总数)比起来不算什么。</p>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><img src="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/5.jpg" class="ful-image" alt="5.jpg">
<img src="http://images.shuang0420.cn/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20LightRNN%20-%20Memory%20and%20Computation-Efficient%20Recurrent%20Neural%20Networks/6.jpg" class="ful-image" alt="6.jpg">
<p>[1] Ravindra K Ahuja, Thomas L Magnanti, and James B Orlin. Network flows. Technical report, DTIC Document, 1988.<br>[2] Jeremy Appleyard, Tomas Kocisky, and Phil Blunsom. Optimizing performance of recurrent neural networks on gpus. arXiv preprint arXiv:1604.01946, 2016.<br>[3] Yoshua Bengio, Jean-Sébastien Senécal, et al. Quick training of probabilistic neural nets by importance sampling. In AISTATS, 2003.<br>[4] Jan A Botha and Phil Blunsom. Compositional morphology for word representations and language modelling. arXiv preprint arXiv:1405.4273, 2014.<br>[5] Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robinson. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint arXiv:1312.3005, 2013.<br>[6] Welin Chen, David Grangier, and Michael Auli. Strategies for training large vocabulary neural language models. arXiv preprint arXiv:1512.04906, 2015.<br>[7] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.<br>[8] Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. Learning to forget: Continual prediction with lstm. Neural computation, 12(10):2451–2471, 2000.<br>[9] Joshua Goodman. Classes for fast maximum entropy training. In Acoustics, Speech, and Signal Processing, 2001. Proceedings.(ICASSP’01). 2001 IEEE International Conference on, volume 1, pages 561–564. IEEE, 2001.<br>[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.<br>[11] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.<br>[12] Shihao Ji, SVN Vishwanathan, Nadathur Satish, Michael J Anderson, and Pradeep Dubey. Blackout: Speeding up recurrent neural network language models with very large vocabularies. arXiv preprint arXiv:1511.06909, 2015.<br>[13] Yoon Kim, Yacine Jernite, David Sontag, and Alexander M Rush. Character-aware neural language models. arXiv preprint arXiv:1508.06615, 2015.<br>[14] Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan Cernock<code>y, and Sanjeev Khudanpur. Recurrent neural network based language model. In INTERSPEECH, volume 2, page 3, 2010.
[15] TomášMikolov, Stefan Kombrink, Lukáš Burget, Jan Honza Cˇ ernocky</code>, and Sanjeev Khudanpur. Extensions of recurrent neural network language model. In Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pages 5528–5531. IEEE, 2011.<br>[16] Andriy Mnih and Geoffrey E Hinton. A scalable hierarchical distributed language model. In Advances in neural information processing systems, pages 1081–1088, 2009.<br>[17] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In Aistats, volume 5, pages 246–252. Citeseer, 2005.<br>[18] Christos H Papadimitriou and Kenneth Steiglitz. Combinatorial optimization: algorithms and complexity. Courier Corporation, 1982.<br>[19] Jan Pomikálek, Milos Jakubícek, and Pavel Rychl`y. Building a 70 billion word corpus of english from clueweb. In LREC, pages 502–506, 2012.<br>[20] Robert Preis. Linear time 1/2-approximation algorithm for maximum weighted matching in general graphs. In STACS 99, pages 259–269. Springer, 1999.<br>[21] Ha¸sim Sak, Andrew Senior, and Françoise Beaufays. Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition. arXiv preprint arXiv:1402.1128, 2014.<br>[22] Martin Sundermeyer, Ralf Schlüter, and Hermann Ney. Lstm neural networks for language modeling. In INTERSPEECH, pages 194–197, 2012.<br>[23] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104–3112, 2014.<br>[24] Duyu Tang, Bing Qin, and Ting Liu. Document modeling with gated recurrent neural network for sentiment classification. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1422–1432, 2015.<br>[25] Paul J Werbos. Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, 78(10):1550–1560, 1990.<br>[26] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. arXiv preprint arXiv:1410.3916, 2014.<br>[27] Dong Yu, Adam Eversole, Mike Seltzer, Kaisheng Yao, Zhiheng Huang, Brian Guenter, Oleksii Kuchaiev, Yu Zhang, Frank Seide, Huaming Wang, et al. An introduction to computational networks and the computational network toolkit. Technical report, Technical report, Tech. Rep. MSR, Microsoft Research, 2014, 2014. research. microsoft. com/apps/pubs, 2014.<br>[28] Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. Recurrent neural network regularization. arXiv preprint arXiv:1409.2329, 2014.</p>

      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/wechat.jpg" alt="徐阿衡 wechat" style="width: 200px; max-width: 100%;"/>
    <div>欢迎关注：徐阿衡的微信公众号</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>客官，打个赏呗~</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="http://7xu83c.com1.z0.glb.clouddn.com/1.pic.jpg" alt="徐阿衡 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-learning/" rel="tag">#Deep learning</a>
          
            <a href="/tags/RNN/" rel="tag">#RNN</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/13/论文笔记 - Wide and Deep Learning for Recommender Systems/" rel="next" title="论文笔记 - Wide and Deep Learning for Recommender Systems">
                <i class="fa fa-chevron-left"></i> 论文笔记 - Wide and Deep Learning for Recommender Systems
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/03/17/会议笔记 - Nuts and Bolts of Applying Deep Learning/" rel="prev" title="会议笔记 - Nuts and Bolts of Applying Deep Learning">
                会议笔记 - Nuts and Bolts of Applying Deep Learning <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      



    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
     
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xu83c.com1.z0.glb.clouddn.com/2.pic.jpg"
               alt="徐阿衡" />
          <p class="site-author-name" itemprop="name">徐阿衡</p>
          <p class="site-description motion-element" itemprop="description">读万卷书，行万里路 @SYSU @CMU</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/">
              <span class="site-state-item-count">167</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">126</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Shuang0420" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.linkedin.com/in/shuang-xu-7008b894?trk=nav_responsive_tab_profile_pic" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://zhuanlan.zhihu.com/c_136690664" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://starllap.space" title="Star" target="_blank">Star</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://liam0205.me" title="Liam Huang" target="_blank">Liam Huang</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.libinx.com" title="Li Bin" target="_blank">Li Bin</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#研究问题"><span class="nav-number">1.</span> <span class="nav-text">研究问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#主要思路"><span class="nav-number">2.</span> <span class="nav-text">主要思路</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#单词表示-Word-Representation"><span class="nav-number">2.1.</span> <span class="nav-text">单词表示(Word Representation)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#引入-RNN"><span class="nav-number">2.2.</span> <span class="nav-text">引入 RNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#单词分配"><span class="nav-number">2.3.</span> <span class="nav-text">单词分配</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#损失函数-优化问题"><span class="nav-number">2.4.</span> <span class="nav-text">损失函数/优化问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#相关工作"><span class="nav-number">3.</span> <span class="nav-text">相关工作</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <!-- Other code may be here -->
<div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">徐阿衡</span>
  <a href="http://www.miitbeian.gov.cn/">粤ICP备17129486号</a>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>


<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'httpshuang0420githubio';
      var disqus_identifier = '2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/';
      var disqus_title = "论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks";
      var disqus_url = 'http://www.shuang0420.cn/2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
