<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>徐阿衡</title>
  <subtitle>Shuang</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.shuang0420.com/"/>
  <updated>2018-11-25T09:48:43.000Z</updated>
  <id>http://www.shuang0420.com/</id>
  
  <author>
    <name>徐阿衡</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>知识抽取-事件抽取</title>
    <link href="http://www.shuang0420.com/2018/10/15/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/"/>
    <id>http://www.shuang0420.com/2018/10/15/知识抽取-事件抽取/</id>
    <published>2018-10-15T11:02:27.000Z</published>
    <updated>2018-11-25T09:48:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>接上一篇知识抽取-实体及关系抽取，前置知识在这一篇不多做解释啦。<br><a id="more"></a></p>
<p>事件是促使事情状态和关系改变的条件[Dong et.al., 2010]。目前已存在的知识资源（如维基百科等） 所描述实体及实体间的关系大多是静态的，而事件能描述粒度更大的、动态的、 结构化的知识，是现有知识资源的重要补充。</p>
<p>与<a href="http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取/">关系抽取</a>相比，事件抽取同样需要从文本中抽取 predicate 和对应的 arguments，但不同的是，关系抽取的问题是 binary 的，且两个 arguments 通常都会在同一个句子中出现，而事件抽取的难点在于，有多个 arguments 和 modifiers，且有些 arguments 不是必须的（some of which are omitted in any given instance of an event），这使得 bootstrapping/distant learning/coreference 都变得非常困难。</p>
<p>事件抽取的任务可以分两大类：</p>
<ul>
<li><strong>事件识别和抽取</strong><br>从描述事件信息的文本中识别并抽取出事件信息并以结构化的形式呈现出来，包括发生的时间、地点、参与角色以及与之相关的动作或者状态的改变。</li>
<li><strong>事件检测和追踪</strong><br>事件检测与追踪旨在将文本新闻流按照其报道的事件进行组织，为传统媒体多种来源的新闻监控提供核心技术，以便让用户了解新闻及其发展。具体而言，事件发现与跟踪包括三个主要任务：<strong>分割，发现和跟踪</strong>，将新闻文本分解为事件， 发现新的（不可预见的）事件，并跟踪以前报道事件的发展。<br>事件发现任务又可细分为<strong>历史事件发现</strong>和<strong>在线事件发现</strong>两种形式，前者目标是从按时间排序的新闻文档中发现以前没有识别的事件，后者则是从实时新闻流中实时发现新的事件。</li>
</ul>
<p>本文的重点在于事件识别与抽取。首先看一下相关的核心概念：</p>
<ul>
<li><strong>事件描述（Event Mention）</strong><br>描述事件的词组/句子/句群，包含一个 trigger 以及任意数量的 arguments</li>
<li><strong>事件触发（Event Trigger）</strong><br>事件描述中最能代表事件发生的词汇，决定事件类别的重要特征，一般是动词或者名词</li>
<li><strong>事件元素（Event Argument）</strong><br>事件的重要信息，或者说是实体描述（entity mention），主要由实体、属性值等表达完整语义的细粒度单位组成</li>
<li><strong>元素角色（Argument Role）</strong><br>事件元素在事件中扮演的角色，事件元素与事件的语义关系，可以理解为 slot</li>
<li><strong>事件类型（Event Type）</strong></li>
</ul>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/general.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/general.png">
<p>其实也可以把事件抽取理解成从文本中找到特定类别的事件，然后进行填表的过程。</p>
<h1 id="事件识别和抽取"><a href="#事件识别和抽取" class="headerlink" title="事件识别和抽取"></a>事件识别和抽取</h1><p>事件识别和抽取的任务定义：</p>
<blockquote>
<p>Given a text document, an event extraction system should <strong>predict event triggers</strong> with specific <strong>sub-types</strong> and <strong>their arguments for each sentence</strong>.</p>
</blockquote>
<p>也就是说，事件抽取任务最基础的部分包括：</p>
<ul>
<li>识别事件触发词及事件类型 </li>
<li>抽取事件元素（Event Argument）同时判断其角色（Argument Role）</li>
<li>抽出描述事件的词组或句子</li>
</ul>
<p>当然还有一些其他的子任务包括事件属性标注、事件共指消解等。</p>
<p>事件抽取大多是分阶段进行，通常由 trigger classifier 开始，如果有 trigger，把 trigger 以及它的上下文作为特征进行分类判断事件类型，再进行下一步的 argument classifier，对句子中的每个 entity mention 进行分类，判断是否是 argument，如果是，判定它的角色。</p>
<h2 id="基于模式匹配的方法"><a href="#基于模式匹配的方法" class="headerlink" title="基于模式匹配的方法"></a>基于模式匹配的方法</h2><p>MUCs 最开始，事件抽取的系统都是基于人工编写的规则，基于语法树或者正则表达式，如 CIRCUS (Lehnert 1991), RAPIER (Califf &amp; Mooney 1997), SRV (Freitag 1998), AutoSlog (Riloff 1993), LIEP (Huffman 1995), PALKA (Kim &amp; Moldovan 1995), CRYSTAL (Soderland et al. 1995), HASTEN (Krupka 1995) 等等，后来，慢慢的有了监督学习的模型，在 ACE 的阶段，大多数系统都是基于监督学习了，但由于标注一致性的问题，系统的效果普遍较差，ACE 事件抽取只举行了一次，在 2005 年。</p>
<p>下面先来看一下基于模板的抽取方法，基本都是通过句法（syntactic）和语义约束（semantic constraints）来进行识别。</p>
<h3 id="基于人工标注语料"><a href="#基于人工标注语料" class="headerlink" title="基于人工标注语料"></a>基于人工标注语料</h3><p>在早期，模板创建过程通常从一个大的标注集开始，模板的产生完全基于人工标注语料，学习效果高度依赖于人工标注质量。</p>
<ul>
<li><strong>AutoSlog</strong>（Riloff）<br>基本假设：<ol>
<li>事件元素首次提及之处即可确定该元素与事件间的关系</li>
<li>事件元素周围的语句中包含了事件元素在事件中的角色描述<br>通过监督学习和人工审查来建立抽取规则。通过训练数据中已经填充好的槽（filled slot），AutoSlog 解析 slot 附近的句法结构，来自动形成抽取规则，由于这个过程产生的模板 too-general，所以需要人工来审核。本质上形成的是一个字典。<br>举个例子<br><em>Ricardo Castellar, the mayor, was kidnapped yesterday by the FMLN.</em><br>假设 Ricardo Castellar 被标注成了 victim，AutoSlog 根据句法分析判断出 Ricardo Castellar 是主语，然后触发了主语的相关规则 \<subj\> passive-verb，将句子中相关的单词填充进去就得到了规则 \<victim\> was kidnapped，所以在之后的文本中，只要 kidnapped 在一个被动结构中出现，它对应的主语就会被标记为 victim。</victim\></subj\></li>
</ol>
</li>
<li><strong>PALKA</strong><br>基本假设：特定领域中高频出现的语言表达方式是可数的<br>用语义框架和短语模式结构来表示特定领域中的抽取模式，通过融入 WordNet 的语义信息，PALKA 在特定领域可取得接近纯人工抽取的效果。</li>
</ul>
<h3 id="弱监督"><a href="#弱监督" class="headerlink" title="弱监督"></a>弱监督</h3><p>不需要对语料进行完全标注，只需人工对语料进行一定的预分类或者制定种子模板，由机器根据预分类语料或种子模板自动进行模式学习。</p>
<p>一些系统：</p>
<ul>
<li><strong>AutoSlog-TS</strong><br>Riloff and Shoen, 1995<br>AutoSlog-TS 不需要进行文本的标注，只需要一个预先分类好的训练语料，类别是与该领域相关还是不相关。过程是先过一遍语料库，对每一个名词短语（根据句法分析识别）都产生对应的抽取规则，然后再整体过一遍语料库，产生每个规则的一些相关统计数据，基本的 idea 是与不相关文本相比，<strong>在相关文本中更常出现的抽取规则更有可能是好的抽取规则</strong>。假设训练语料中相关与不相关的文本比例是 1:1，对产生的每条抽取规则计算相关比率 relevance rate，相关文档中出现规则的实例数/整个语料库中出现规则的实例数，那么 relevance rate &lt; 50% 的抽取规则就被丢弃了，剩下的规则会按照 relevance_rate * log(frequency) 的形式从高到低进行排序，然后由人工进行审核。</li>
<li><strong>TIMES</strong><br>Chai and Biermann, 1998<br>引入了领域无关的概念知识库 WordNet，提升模式学习的泛化能力，并通过人工或规则进行词义消歧，使最终的模式更加准确</li>
<li><strong>NEXUS</strong><br>Piskorski et.al., 2001; Tanev et.al., 2008<br>用聚类对语料进行预处理</li>
<li><strong>GenPAM</strong><br>Jiang, 2005<br>在由特例生成泛化模式的学习过程中，有效利用模式间的相似性实现词义消歧，最大限度地减少了人工的工作量和对系统的干预</li>
</ul>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>基于模式匹配的方法在特定领域中性能较好，知识表示简洁，便于理解和后续应用，但对于语言、领域和文档形式都有不同程度的依赖，覆盖度和可移植性较差。</p>
<p>模式匹配的方法中，模板准确性是影响整个方法性能的重要因素。在实际应用中，模式匹配方法应用非常广泛，主要特点是高准确率低召回率，要提高召回率，一是要建立更完整的模板库，二是可以用半监督的方法来建 trigger 字典。</p>
<h2 id="基于统计-传统机器学习"><a href="#基于统计-传统机器学习" class="headerlink" title="基于统计 - 传统机器学习"></a>基于统计 - 传统机器学习</h2><p>建立在统计模型基础上，分为 pipeline 和 joint model 两大类。</p>
<h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p>将事件抽取任务转化为多阶段的分类问题（管道抽取），需要顺序执行下面的分类器：</p>
<ol>
<li><strong>事件触发词分类器（Trigger Classifier）</strong><br>判断词汇是否是事件触发词，以及事件类别</li>
<li><strong>元素分类器（Argument Classifier）</strong><br>词组是否是事件元素</li>
<li><strong>元素角色分类器（Role Classifier）</strong><br>判定元素的角色类别</li>
<li><strong>属性分类器（Attribute Classifier）</strong><br>判定事件属性</li>
<li><strong>可报告性分类器（Reportable-Event Classifier）</strong><br>判定是否存在值得报告的事件实例</li>
</ol>
<p>分类器可以用 MaxEnt, SVM。重点还是在于提取和集成有区分性的特征，包括 <strong>句子级信息</strong> 和 <strong>篇章级信息</strong>。</p>
<p><strong>句子级信息：</strong>与候选词相关的词法特征、上下文特征、实体特征、句法特征、语言学特征等，如：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/features.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/features.png"><br><strong>篇章级特征：</strong><br>跨文档利用全局信息。对于一个句子级的抽取结果不仅要考虑当前的置信度，还要考虑与待抽取文本相关的文本对它的影响，以及全局信息如事件与话题的关系，事件与事件的共现信息等，主要工作有：</p>
<ul>
<li>Ji and Grishman, 2008</li>
<li>Liao and Grishman, 2010</li>
<li>Hong et.al., 2011</li>
<li>Liu et.al., 2016a</li>
</ul>
<p>Pipeline 方法的问题也很明显：</p>
<ul>
<li>误差传递，导致性能衰减</li>
<li>各环节预测任务独立，缺少互动，如忽略了事件触发词和事件元素之间的相互影响</li>
<li>无法处理全局的依赖关系</li>
</ul>
<h4 id="Joint-Model"><a href="#Joint-Model" class="headerlink" title="Joint Model"></a>Joint Model</h4><p>又分为 Joint Inference 和 Joint Modeling 两种。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/joint_inference.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/joint_inference.png"><br><strong>Joint Inference</strong> 使用集成学习的思路，将各模型通过整体优化目标整合起来，可以通过整数规划等方法进行优化。<br><strong>Joint Modeling (Structured)</strong> 又可以称为基于结构的方法，将事件结构看作依存树，抽取任务相应转化为依存树结构预测问题，触发词识别和元素抽取可以同时完成，共享隐层特征，使用搜索进行求解，避免了误差传播导致的性能下降，另外，全局特征也可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。相关工作有：</p>
<ul>
<li>Li et.al., 2013a<br>Li 提出基于结构感知机的联合模型同时完成事件触发词识别和事件元素识别两个子任务，并通过 beam search 缩小搜索解空间</li>
<li>Li et.al., 2014<br>为了利用更多的句子级信息，Li 等提出利用结构预测模型将实体、关系和事件进行联合抽取</li>
</ul>
<p>尽管 Li 等人的联合系统优势明显，但在未见词和特征上缺乏泛化，人工提取的特征集是离散表达，能力有限。</p>
<p>几种方法的 trigger 和 argument 抽取结果，可以看出，实体之间协同消歧对效果提升非常明显<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/perf1.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/perf1.png"></p>
<h3 id="基于统计-深度学习"><a href="#基于统计-深度学习" class="headerlink" title="基于统计 - 深度学习"></a>基于统计 - 深度学习</h3><p>上面的方法在特征提取过程中还是会依赖依存分析、句法分析、词性标注等传统的外部 NLP 工具，还是会造成误差积累，另外有些语言和领域并没有这类处理工具，加之特征也需要人工设定，2015 年起基于深度学习的事件抽取方法逐渐成为研究热点，相比于传统机器学习，深度学习方法优势明显：</p>
<ol>
<li>减少对外部 NLP 工具的依赖 ， 甚至不依赖 NLP 工具 ， 建立成端对端的系统</li>
<li>使用词向量作为输入，蕴含更为丰富的语言特征</li>
<li>自动提取句子特征， 避免了人工特征设计的繁琐工作</li>
</ol>
<h4 id="DMCNN-Pipeline"><a href="#DMCNN-Pipeline" class="headerlink" title="DMCNN - Pipeline"></a>DMCNN - Pipeline</h4><p><a href="https://pdfs.semanticscholar.org/ca70/480f908ec60438e91a914c1075b9954e7834.pdf" target="_blank" rel="external">Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks Yubo Chen et. al., ACL 2015</a></p>
<p>自然语言处理中，传统 CNN 使用的最大池化对一个 feature map 只能得到一个最大值，这对事件抽取并不适用，因为事件抽取中一个句子中可能会包含多个事件，一个 argument candidate 在不同的 trigger 下也会扮演不同的角色，传统的最大池化只保留“最重要”的信息，而丢失的信息会导致 multiple-event sentence 下的事件漏分。DMCNN 使用动态多池化卷积能实现对一个句子中不同部分的最大值获取，以保留更多有价值的信息，逻辑和 PCNN 相似。</p>
<p>DMCNN 作者把事件抽取看做两个阶段的多分类任务，第一步是<strong>触发词分类（trigger classification）</strong>，利用 DMCNN 对句子中每个词进行分类，判断是否是触发词，如果句子中存在触发词，执行第二步<strong>论元分类（argument classification）</strong>，同样使用 DMCNN，给 trigger 分配 arguments，同时匹配 arguments 到 role，以第二个任务为例介绍一下过程。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn.png">
<p>主要包括四个部分，以 argument classification 为例：</p>
<ol>
<li><strong>词向量学习；</strong></li>
<li><strong>Lexical-level   词汇级别特征提取；</strong><ul>
<li>候选论元/触发词及其前后单词的词向量 </li>
</ul>
</li>
<li><strong>Sentence-level  句子级别特征提取；</strong><ul>
<li>输入特征：<ul>
<li>Context-word feature(CWF)</li>
<li>Position feature(PF)<ul>
<li>当前词语和候选论元/触发词之间的相对距离，距离值用向量表示，随机初始化</li>
</ul>
</li>
<li>Event-type feature(EF)<ul>
<li>当前 trigger 对应的事件类型特征</li>
</ul>
</li>
<li>CWF, PF, EF 拼接作为卷积的输入</li>
</ul>
</li>
<li>卷积后，根据 candidate argument 和 predicted trigger 将 feature map 分成三部分，分别对各部分进行最大池化</li>
</ul>
</li>
<li><strong>Output 分类输出</strong><ul>
<li>拼接词汇级别和句子级别的特征 F=[L, P]</li>
<li>O = WF+b 算分，进行 softmax，得到 argument role 的类别</li>
</ul>
</li>
</ol>
<p><strong>Trigger classification 阶段：</strong></p>
<ul>
<li><strong>Lexical-level</strong><ul>
<li>只使用候选触发词和其左右token</li>
</ul>
</li>
<li><strong>Sentence-level</strong><ul>
<li>CWF + PF，PF 只使用候选触发词的位置作为嵌入位置特征</li>
<li>句子由触发词分割成两部分</li>
</ul>
</li>
</ul>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn2.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn2.png">
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn3.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn3.png">
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn4.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/dynamic_cnn4.png">
<p>DMCNN 的效果是突破性的，但分两个阶段的预测仍有误差传递的问题，也没有利用好 trigger 和 argument 之间的依赖关系。</p>
<h4 id="Joint-Model-BiRNN"><a href="#Joint-Model-BiRNN" class="headerlink" title="Joint Model(BiRNN)"></a>Joint Model(BiRNN)</h4><p><a href="http://www.aclweb.org/anthology/N16-1034" target="_blank" rel="external">JRNN: Joint Event Extraction via Recurrent Neural Networks, ACL 2016</a></p>
<p>Nguyen et.al., 2016 通过 RNN 用联合方法解决时间抽取的问题，继承了 Li (2013) 和 Chen (2015) 的优点，并克服了它们的一些缺陷。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/JRNN1.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/JRNN1.png">
<ul>
<li><strong>Encoding phase</strong><ul>
<li>word embedding + entity type embedding + dependency tree relation<br>dependency tree relation 是 binary 的，个人理解应该是维度对应依存树中单词间所有可能的关系（如 conj_and, advcl 等），只有在依存树 W 中存在与 w_i 连接的一条对应边（如 conj_and 连接了 w_i 与 w_j）时，该维度（conj_and 对应维度）的值才设为 1，这个向量在 Li et al., 2013 的研究中是有用的。<br>没有用到位置特征，因为同时预测 trigger 和 argument roles，没有固定的锚点。</li>
<li>双向 GRU 进行编码</li>
</ul>
</li>
<li><strong>Prediction phase</strong><ul>
<li>对 W 对应的 trigger 和 argument role 分别维护了一个 binary memory vector $G^{trg}_i$ , binary memory matrices $G^{arg}_i$ 以及  $G^{arg/trg}_i$ </li>
<li>每个时间点 i，或者说对 $w_i$<ul>
<li>对 $w_i$ 进行 trigger 预测</li>
<li>如果 trigger 预测结果 $t<em>i$ 是 other，那么 $a\</em>{ij}$  j 从 1-k 都设为 other，然后进行下一步，否则对所有的 entity mention e1, e2,…,ek 进行 argument role 预测</li>
<li>利用上一步的记忆向量以及之前步骤的预测来计算 $G^{trg}_i$,  $G^{arg}_i$ and $G^{arg/trg}_i$ </li>
</ul>
</li>
<li><strong>Output:</strong><ul>
<li>trigger subtype $t_i$ for $w_i$</li>
<li>predicted argument roles $a_{i1}$, $a_{i2}$,…$a_{ik}$</li>
<li>memory vector/matrics  $G^{trg}_i$,  $G^{arg}_i$ and $G^{arg/trg}_i$ </li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Memory 向量代表的是同一个句子中 trigger 和 argument role 的相互关系，$G^{trg}_i$  代表的是 trigger subtypes 之间的关系，表示在 i 之前已经识别出哪些子事件，比如说句子中检测到了 Die 事件，那么很有可能下面会同时会出现 Attack 事件；</p>
<p>$G^{arg}_i$ 代表的是 argument role 之间的关系，总结了 entity mention 在过去扮演的 arugment roles 信息；$G^{arg/trg}_i$ 对应的是 arugment roles 和 trigger subtypes 之间的关系，表示 entity mention 在之前特定 event subtypes 扮演过 argument，$G^{arg/trg}_i[j][t]=1$ 代表 $e_j$ 在之前的 subtype t 中被认为是 argument。 实验表明，$G^{trg}$ 并没有帮助反而会导致整体性能下降，而 $G^{arg/trg}$ 还是很有效的。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/JRNN2.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/JRNN2.png">
<p>当输入句子包含多个事件时（1/N），JRNN 明显优于其他方法。特别是，JRNN在触发标记方面比DMCNN好13.9％，而参数角色标记的相应改进为6.5％，从而进一步表明 JRNN 具有记忆功能的好处。在单事件句子（1/1）的表现上，JRNN在 trigger 分类上仍然是最好的系统，尽管在 argument role 上比 DMCNN 要差一些。</p>
<h3 id="弱监督-语料扩充"><a href="#弱监督-语料扩充" class="headerlink" title="弱监督/语料扩充"></a>弱监督/语料扩充</h3><p>有监督的方法需要大量的标注样本，人工标注耗时耗力，一致性差，因此弱监督方法也是事件抽取的一个重要分支。Chen 等提出利用部分高质量的标注语料训练分类器，然后利用初步训练好的分类器判断未标注的数据，选取高置信度的分类样本作为训练样本，通过迭代自动扩充训练样本[Chen and Ji, 2009]。Liao 等在相关文档中使用自训练的（Self-Training）的半监督学习方法扩展标注语料，并利用全局推理的方法考虑样例的多样性进而完成事件抽取；进一步提出同时针对词汇和句子两个粒度训练最大熵分类器，并用协同训练（Co-training）的方法扩展标注数据，进而对分类器进行更充分的训练[Liao and Grishman, 2011a; 2011b]。</p>
<p>而目前，弱监督/训练数据生成方面比较流行的方向有下面几类，利用外部资源，通过远程监督，以及跨语料迁移的方法。</p>
<h4 id="外部资源"><a href="#外部资源" class="headerlink" title="外部资源"></a>外部资源</h4><p><a href="http://www.aclweb.org/anthology/P16-1201" target="_blank" rel="external">Leveraging FrameNet to Improve Automatic Event Detection</a></p>
<p>FrameNet 是语言学家定义及标注的语义框架资源，采用层级的组织结构，有1000+框架、1000+词法单元、150000+标注例句。在结构上，FrameNet 和事件抽取有着很高的相似性，一个框架由一个词法单元和若干框架元素组成，一个事件有触发词和若干事件角色组成。另外，Framenet 中很多 frame 其实也能够表示某些事件，如<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/framenet.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/framenet.png"><br>因此，Liu 等利用 ACE 语料训练的分类器去判定 FrameNet 中句子的事件类别，再利用全局推断将 FrameNet 的语义框架和 ACE 中的事件类别进行映射，进而利用 FrameNet 中人工标注的事件样例扩展训练数据以提升事件检测性能 [Liu et.al., 2016b]。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/framenet1.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/framenet1.png"></p>
<h4 id="远程监督"><a href="#远程监督" class="headerlink" title="远程监督"></a>远程监督</h4><p><a href="http://www.nlpr.ia.ac.cn/cip/~liukang/liukangPageFile/ACL2017-Chen.pdf" target="_blank" rel="external">Automatically Labeled Data Generation for Large Scale Event Extraction</a></p>
<p>Yubo Chen, ACL 2017 提出运用结构化的知识库来以及远程监督的方法来自动生成大规模事件语料。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/event_relation.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/event_relation.png">
<p>当把关系抽取中常用的远程监督方法用到事件抽取中时，会发现有下面的两个问题，一是<strong>现有事件知识库（如 Freebase）中缺乏触发词信息</strong>，如上图，在关系抽取中，我们可以用两个元素 Barack Obama, Michelle Obama 进行回标，但是在事件抽取中，结婚这一事件类型在 Freebase 中被表示为 m.02nqglv，所以我们不能直接用事件类型和元素来进行回标，在用 DS 前，必须先检测触发词。</p>
<p>根据 DS 在 RE 中的应用，可以假设如果一个句子中出现了所有的元素，那么这个句子就可以被作为是一个事件，句子中的动词就可以作为触发词。然而<strong>一个事件中的元素可能出现在多个句子中</strong>，如果用所有元素来进行句子的回标，那么能抽出的训练数据就非常少了，所以应该对元素进行排序，选择有代表性的元素进行回标。</p>
<p>整个流程如下，首先对 Freebase 中的核心元素进行检测，考虑<strong>角色显著性（role saliency）、事件相关性（ event relevance）和核心率（key rate）</strong>，接着利用所有的核心元素去 Wikipeida 中回标，根据<strong>触发率（trigger rate）、触发词频率（ trigger candidate frequency）、触发词事件频率（trigger event type frequency）</strong>来进行触发词检测，这一阶段得到的触发词表中只有动词，缺少名词，也存在噪声，于是再利用 FrameNet 过滤动词性触发词中的噪声，同时扩展名词性触发词，最后利用 Soft Distant Supervision 来自动生成标注数据。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/Yubo.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/Yubo.png">
<p>还有方法如 Karthik Narasimhan et al., EMNLP 2016，从网络获取同一事件的不同报道，再使用强化学习方法，做信息融合的决策（互补信息的融合、冗余信息的选择）。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/karthik.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/karthik.png">
<h4 id="跨语料迁移"><a href="#跨语料迁移" class="headerlink" title="跨语料迁移"></a>跨语料迁移</h4><p>由于目前中文事件抽取缺少公认语料，很多学者尝试利用现有大量的高质量英文标注语料辅助中文事件抽取。Chen 等首次提出该想法并利用跨语言协同训练的 Bootstrap 方法进行事件抽取[Chen and Ji, 2009]。Ji 提出基于中英文单语事件抽取系统和基于并行语料两种构建跨语言同义谓词集合的方法辅助进行中文事件抽取[Ji, 2009]，Zhu 等利用机器翻译同时扩大中文和英文训练语料，联合利用两种语料进行事件抽取[Zhu et.al., 2014]。Hsi 等联合利用符号特征和分布式特征的方法，利用英文事件语料提升中文事件抽取的性能[Hsi et.al., 2016]。</p>
<p><a href="http://www.nlpr.ia.ac.cn/cip/~liukang/liukangPageFile/Liu_aaai2018.pdf" target="_blank" rel="external">Event Detection via Gated Multilingual Attention Mechanism, AAAI2018</a></p>
<p>Motivation 是：</p>
<ol>
<li>多语言一致性，不同语言中表达了相同含义的句子往往包含相同的语义成分<br>如 MeiGuo TanKe 和 American tank 表达了相同含义，都是武器</li>
<li>多语言互补，某个词在一种语言中有歧义，但在另一种语言中缺没有歧义<br>如英文 fire，因为有开火和解雇两种意思，所以对应事件可能是 Attack 也可能是 End-Position，然而在中文中开火，Attach 类型，解雇就是 End-Position 类型，两个词没有相同语义</li>
</ol>
<p>所以文章提出了两种 attention 机制，一是利用多语言一致性，分别对每种语言进行单语语境的关注，对每个候选触发词，对其上下文进行注意力机制，注意力权重表示句子中不同单词对预测事件类型的重要性，二是利用互补信息，用 gated cross-lingual attention 来模拟其他语言的可信度，gate 来控制目标语言流向源语言的信息，集成多语言的信息。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/GMLATT.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/GMLATT.png">
<h3 id="中文事件抽取"><a href="#中文事件抽取" class="headerlink" title="中文事件抽取"></a>中文事件抽取</h3><p>目前事件抽取的相关研究大部分是面向英文文本，中文文本的工作才刚起步，一方面，中文的自身特点（需要分词、缺少时态和形态的变换）有一定挑战，另一方面，数据集上也缺乏统一、公认的语料资源和相关评测。尽管如此，近年来中文事件抽取在公开评测、领域扩展及上述的跨语料迁移方面也都取得了一些进展。</p>
<p>公开评测方面，除了在模型方面的创新[Chen and Ng, 2012;Li et.al., 2012a;2013b]，在中文语言特性的利用方面，Li 等通过中文词语的形态结构、同义词等信息捕获更多的未知触发词，进而解决中文事件抽取面临的分词错误和训练数据稀疏等问题； 进一步细分中文事件触发词内部的组合语义（复合、附加和转化），进而提高系统的性能[Li et.al., 2012b]。Ding 等利用聚类的方法自动生成新事件类型的语料， 在抽取过程中特别地考虑了待抽取文本的 HowNet 相似度[Ding et.al., 2013]。</p>
<p>特定领域方面，国内很多机构均面向实际应用展开特定领域的事件抽取研究， 覆盖突发灾难、金融、军事、体育、音乐等多个领域。例如，Zhou 等针对金融领域事件中的收购、分红和贷款三个典型事件，提出自动构建抽取规则集的方法进行中文金融领域事件抽取 [Zhou, 2003]；Liang 等利用事件框架的归纳和继承特性实现对灾难事件的抽取[Liang and Wu, 2006]。</p>
<p>还有其他一些其他方向的 Paper:<br><strong>特征表示：</strong><br>– Argument Attention: Exploiting Argument Information to Improve Event Detection via Supervised Attention Mechanisms  (ACL2017)<br><strong>多事件抽取：</strong><br>– HBTNGMA: Collective Event Detection via a Hierarchical and Bias Tagging Networks with Gated<br> Multi-level Attention (EMNLP-2018)<br><strong>篇章级事件抽取：</strong><br>– DCFEE: A Document-level Chinese Financial Event Extraction System based on Automatically Labeled<br> Training Data (ACL 2018)<br><strong>事件关系抽取：</strong><br>– ATT-ERNN: Attention-based Event Relevance Model for Stock Price Movement Prediction (CCKS-2017 Best Paper Award)<br>– MLNN: Event Coreference Resolution via Multi-loss Neural Network without Arguments （CCKS-2018）</p>
<h1 id="事件监测和追踪"><a href="#事件监测和追踪" class="headerlink" title="事件监测和追踪"></a>事件监测和追踪</h1><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/general2.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/general2.png">
<p>主流方法包括基于相似度聚类和基于概率统计两类。在这不多做介绍。</p>
<p>参考文献：<br>知识图谱发展报告 2018<br>事件抽取与金融事件图谱构建</p>
<p>关注公众号回复事件抽取获得下载地址</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接上一篇知识抽取-实体及关系抽取，前置知识在这一篇不多做解释啦。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Knowledge Graph" scheme="http://www.shuang0420.com/categories/NLP/Knowledge-Graph/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="Relation Extraction" scheme="http://www.shuang0420.com/tags/Relation-Extraction/"/>
    
      <category term="Information Extraction" scheme="http://www.shuang0420.com/tags/Information-Extraction/"/>
    
      <category term="Event Extraction" scheme="http://www.shuang0420.com/tags/Event-Extraction/"/>
    
  </entry>
  
  <entry>
    <title>知识抽取-实体及关系抽取</title>
    <link href="http://www.shuang0420.com/2018/09/15/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/"/>
    <id>http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取/</id>
    <published>2018-09-15T11:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 <a href="http://www.shuang0420.com/2017/03/18/NLP%20笔记%20-Information%20Extraction/">NLP笔记 - Information Extraction</a> 和 <a href="http://www.shuang0420.com/2017/04/10/NLP笔记%20-%20Relation%20Extraction/">NLP笔记 - Relation Extraction</a>，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。</p>
<a id="more"></a>
<p>知识抽取涉及的“知识”通常是 <strong>清楚的、事实性的信息</strong>，这些信息来自不同的来源和结构，而对不同数据源进行的知识抽取的方法各有不同，从结构化数据中获取知识用 D2R，其难点在于复杂表数据的处理，包括嵌套表、多列、外键关联等，从链接数据中获取知识用图映射，难点在于数据对齐，从半结构化数据中获取知识用包装器，难点在于 wrapper 的自动生成、更新和维护，这一篇主要讲从文本中获取知识，也就是我们广义上说的信息抽取。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/general.png">
<p>信息抽取三个最重要/最受关注的子任务：</p>
<ul>
<li><strong>实体抽取</strong><br>也就是命名实体识别，包括实体的检测（find）和分类（classify）</li>
<li><strong>关系抽取</strong><br>通常我们说的<strong>三元组（triple）</strong> 抽取，一个谓词（predicate）带 2 个形参（argument），如 Founding-location(IBM,New York) </li>
<li><strong>事件抽取</strong><br>相当于一种多元关系的抽取</li>
</ul>
<p>篇幅限制，这一篇主要整理实体抽取和关系抽取，下一篇再上事件抽取。</p>
<h1 id="相关竞赛与数据集"><a href="#相关竞赛与数据集" class="headerlink" title="相关竞赛与数据集"></a>相关竞赛与数据集</h1><p>信息抽取相关的会议/数据集有 <strong>MUC、ACE、KBP、SemEval</strong> 等。其中，<strong>ACE(Automated Content Extraction)</strong> 对 MUC 定义的任务进行了融合、分类和细化，<strong><a href="https://tac.nist.gov/2017/KBP/" target="_blank" rel="external">KBP(Knowledge Base Population)</a></strong> 对 ACE 定义的任务进一步修订，分了四个独立任务和一个整合任务，包括</p>
<ul>
<li><strong>Cold Start KB (CSKB)</strong><br>端到端的冷启动知识构建</li>
<li><strong>Entity Discovery and Linking (EDL)</strong><br>实体发现与链接</li>
<li><strong>Slot Filling (SF)</strong><br>槽填充</li>
<li><strong>Event</strong><br>事件抽取</li>
<li><strong>Belief/Sentiment (BeSt)</strong><br>信念和情感</li>
</ul>
<p>至于 SemEval 主要是词义消歧评测，目的是增加人们对词义、多义现象的理解。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/SemEval.png"></p>
<p>ACE 的 17 类关系<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/2.jpg" class="ful-image" alt="2.jpg"></p>
<p>具体的应用实例<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/3.jpg" class="ful-image" alt="3.jpg"></p>
<p>常用的 Freebase relations<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">people/person/nationality,</div><div class="line">people/person/profession,</div><div class="line">biology/organism_higher_classification,</div><div class="line">location/location/contains</div><div class="line">people/person/place-of-birth</div><div class="line">film/film/genre</div></pre></td></tr></table></figure></p>
<p>还有的一些世界范围内知名的高质量大规模开放知识图谱，如包括 DBpedia、Yago、Wikidata、BabelNet、ConceptNet 以及 Microsoft Concept Graph等，中文的有开放知识图谱平台 OpenKG……</p>
<h1 id="实体抽取"><a href="#实体抽取" class="headerlink" title="实体抽取"></a>实体抽取</h1><p>实体抽取或者说命名实体识别（NER）在信息抽取中扮演着重要角色，主要抽取的是文本中的原子信息元素，如<strong>人名、组织/机构名、地理位置、事件/日期、字符值、金额值</strong>等。实体抽取任务有两个关键词：<strong>find &amp; classify</strong>，找到命名实体，并进行分类。<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/2.jpg" class="ful-image" alt="2.jpg"></p>
<p><strong>主要应用：</strong></p>
<ul>
<li>命名实体作为索引和超链接</li>
<li>情感分析的准备步骤，在情感分析的文本中需要识别公司和产品，才能进一步为情感词归类</li>
<li>关系抽取（Relation Extraction）的准备步骤</li>
<li>QA 系统，大多数答案都是命名实体</li>
</ul>
<h2 id="传统机器学习方法"><a href="#传统机器学习方法" class="headerlink" title="传统机器学习方法"></a>传统机器学习方法</h2><p>标准流程：<br><strong>Training:</strong></p>
<ol>
<li>收集代表性的训练文档</li>
<li>为每个 token 标记命名实体(不属于任何实体就标 Others O)</li>
<li>设计适合该文本和类别的特征提取方法</li>
<li>训练一个 sequence classifier 来预测数据的 label</li>
</ol>
<p><strong>Testing:</strong></p>
<ol>
<li>收集测试文档</li>
<li>运行 sequence classifier 给每个 token 做标记</li>
<li>输出命名实体</li>
</ol>
<h3 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h3><p>看一下最常用的两种 sequence labeling 的编码方式，<strong>IO encoding</strong> 简单的为每个 token 标注，如果不是 NE 就标为 O(other)，所以一共需要 C+1 个类别(label)。而 <strong>IOB encoding</strong> 需要 2C+1 个类别(label)，因为它标了 NE boundary，B 代表 begining，NE 开始的位置，I 代表 continue，承接上一个 NE，如果连续出现两个 B，自然就表示上一个 B 已经结束了。<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/3.jpg" class="ful-image" alt="3.jpg"></p>
<p>在 Stanford NER 里，用的其实是 IO encoding，有两个原因，一是 IO encoding 运行速度更快，二是在实践中，两种编码方式的效果差不多。IO encoding 确定 boundary 的依据是，如果有连续的 token 类别不为 O，那么类别相同，同属一个 NE；类别不相同，就分割，相同的 sequence 属同一个 NE。而实际上，两个 NE 是相同类别这样的现象出现的很少，如上面的例子，Sue，Mengqiu Huang 两个同是 PER 类别，并不多见，更重要的是，在实践中，虽然 IOB encoding 能规定 boundary，而实际上它也很少能做对，它也会把 Sue Mengqiu Huang 分为同一个 PER，这主要是因为更多的类别会带来数据的稀疏。</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>Features for sequence labeling:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">• Words</div><div class="line">    Current word (essentially like a learned dictionary)</div><div class="line">    Previous/next word (context)</div><div class="line">• Other kinds of inferred linguistic classification</div><div class="line">    Part of speech tags</div><div class="line">    Dependency relations</div><div class="line">• Label context</div><div class="line">    Previous (and perhaps next) label</div></pre></td></tr></table></figure></p>
<p>再来看两个比较重要的 feature</p>
<p><strong>Word substrings</strong><br>Word substrings (包括前后缀)的作用是很大的，以下面的例子为例，NE 中间有 ‘oxa’ 的十有八九是 drug，NE 中间有 ‘:’ 的则大多都是 movie，而以 field 结尾的 NE 往往是 place。<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/4.jpg" class="ful-image" alt="4.jpg"></p>
<p><strong>Word shapes</strong><br>可以做一个 mapping，把 <strong>单词长度(length)、大写(capitalization)、数字(numerals)、希腊字母(Greek eltters)、单词内部标点(internal punctuation)</strong> 这些字本身的特征都考虑进去。<br>如下表，把所有大写字母映射为 X，小写字母映射为 x，数字映射为 d…<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/5.jpg" class="ful-image" alt="5.jpg"></p>
<h3 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h3><p>NLP 的很多数据都是序列类型，像 sequence of characters, words, phrases, lines, sentences，我们可以把这些任务当做是给每一个 item 打标签，如下图：<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/6.jpg" class="ful-image" alt="6.jpg"></p>
<p>常见的序列模型有 <strong>有向图模型</strong> 如 HMM，假设特征之间相互独立，找到使得 P(X,Y) 最大的参数，生成式模型；<strong>无向图模型</strong> 如 CRF，没有特征独立的假设，找到使得 P(Y|X) 最大的参数，判别式模型。相对而言，CRF 优化的是联合概率（整个序列，实际就是最终目标），而不是每个时刻最优点的拼接，一般而言性能比 CRF 要好，在小数据上拟合也会更好。</p>
<p>整个流程如图所示：<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/7.jpg" class="ful-image" alt="7.jpg"></p>
<p>讨论下最后的 inference<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/8.jpg" class="ful-image" alt="8.jpg"></p>
<p>最基础的是 “decide one sequence at a time and move on”，也就是一个 <strong>greedy inference</strong>，比如在词性标注中，可能模型在位置 2 的时候挑了当前最好的 PoS tag，但是到了位置 4 的时候，其实发现位置 2 应该有更好的选择，然而，greedy inference 并不会 care 这些。因为它是贪婪的，只要当前最好就行了。除了 greedy inference，比较常见的还有 beam inference 和 viterbi inference。</p>
<h4 id="Greedy-Inference"><a href="#Greedy-Inference" class="headerlink" title="Greedy Inference"></a>Greedy Inference</h4><p><strong>优点:</strong></p>
<ol>
<li>速度快，没有额外的内存要求</li>
<li>非常易于实现</li>
<li>有很丰富的特征，表现不错</li>
</ol>
<p><strong>缺点:</strong></p>
<ol>
<li>贪婪</li>
</ol>
<h4 id="Beam-Inference"><a href="#Beam-Inference" class="headerlink" title="Beam Inference"></a>Beam Inference</h4><ul>
<li>在每一个位置，都保留 top k 种可能(当前的完整序列)</li>
<li>在每个状态下，考虑上一步保存的序列来进行推进</li>
</ul>
<p><strong>优点:</strong></p>
<ol>
<li>速度快，没有额外的内存要求</li>
<li>易于实现(不用动态规划)</li>
</ol>
<p><strong>缺点:</strong></p>
<ol>
<li>不精确，不能保证找到全局最优</li>
</ol>
<h4 id="Viterbi-Inference"><a href="#Viterbi-Inference" class="headerlink" title="Viterbi Inference"></a>Viterbi Inference</h4><ul>
<li>动态规划</li>
<li>需要维护一个 fix small window</li>
</ul>
<p><strong>优点:</strong></p>
<ol>
<li>非常精确，能保证找到全局最优序列</li>
</ol>
<p><strong>缺点:</strong></p>
<ol>
<li>难以实现远距离的 state-state interaction</li>
</ol>
<h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><h3 id="LSTM-CRF"><a href="#LSTM-CRF" class="headerlink" title="LSTM+CRF"></a>LSTM+CRF</h3><p>最经典的 <a href="hiheng Huang, Wei Xu, Kai Yu. Bidirectional LSTM-CRF Models for Sequence Tagging. CoRR. 2015">LSTM+CRF</a>，端到端的判别式模型，LSTM 利用过去的输入特征，CRF 利用句子级的标注信息，可以有效地使用过去和未来的标注来预测当前的标注。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/LSTM%2BCRF.png">
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p>评估 IR 系统或者文本分类的任务，我们通常会用到 precision，recall，F1 这种 set-based metrics，见<a href="http://www.shuang0420.com/2016/09/20/Search%20Engines%E7%AC%94%E8%AE%B0%20-%20Evaluating%20Search%20Effectiveness/">信息检索评价的 Unranked Boolean Retrieval Model 部分</a>，但是在这里对 NER 这种 sequence 类型任务的评估，如果用这些 metrics，可能出现 boundary error 之类的问题。因为 NER 的评估是按每个 entity 而不是每个 token 来计算的，我们需要看 entity 的 boundary。</p>
<p>以下面一句话为例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">First Bank of Chicago announced earnings...</div></pre></td></tr></table></figure></p>
<p>正确的 NE 应该是 First Bank of Chicago，类别是 ORG，然而系统识别了 Bank of Chicago，类别 ORG，也就是说，右边界(right boundary)是对的，但是左边界(left boundary)是错误的，这其实是一个常见的错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">正确的标注：</div><div class="line">ORG - (1,4)</div><div class="line"></div><div class="line">系统：</div><div class="line">ORG - (2,4)</div></pre></td></tr></table></figure>
<p>而计算 precision，recall 的时候，我们会发现，对 ORG - (1,4) 而言，系统产生了一个 false negative，对 ORG - (2,4) 而言，系统产生了一个 false positive！所以系统有了 2 个错误。<strong>F1 measure</strong> 对 precision，recall 进行加权平均，结果会更好一些，所以经常用来作为 NER 任务的评估手段。另外，专家提出了别的建议，比如说给出 partial credit，如 MUC scorer metric，然而，对哪种 case 给多少的 credit，也需要精心设计。</p>
<h2 id="其他-实体链接"><a href="#其他-实体链接" class="headerlink" title="其他-实体链接"></a>其他-实体链接</h2><p>实体识别完成之后还需要进行归一化，比如万达集团、大连万达集团、万达集团有限公司这些实体其实是可以融合的。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.png" class="ful-image" alt="%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.png"></p>
<p>主要步骤如下：</p>
<ol>
<li><strong>实体识别</strong><br>命名实体识别，词典匹配</li>
<li><strong>候选实体生成</strong><br>表层名字扩展，搜索引擎，查询实体引用表</li>
<li><strong>候选实体消歧</strong><br>图方法，概率生成模型，主题模型，深度学习</li>
</ol>
<p>补充一些开源系统：</p>
<ul>
<li><a href="http://acube.di.unipi.it/tagme" target="_blank" rel="external">http://acube.di.unipi.it/tagme</a></li>
<li><a href="https://github.com/parthatalukdar/junto" target="_blank" rel="external">https://github.com/parthatalukdar/junto</a></li>
<li><a href="http://orion.tw.rpi.edu/~zhengj3/wod/wikify.php" target="_blank" rel="external">http://orion.tw.rpi.edu/~zhengj3/wod/wikify.php</a></li>
<li><a href="https://github.com/yahoo/FEL" target="_blank" rel="external">https://github.com/yahoo/FEL</a></li>
<li><a href="https://github.com/yago-naga/aida" target="_blank" rel="external">https://github.com/yago-naga/aida</a></li>
<li><a href="http://www.nzdl.org/wikification/about.html" target="_blank" rel="external">http://www.nzdl.org/wikification/about.html</a></li>
<li><a href="http://aksw.org/Projects/AGDISTIS.html" target="_blank" rel="external">http://aksw.org/Projects/AGDISTIS.html</a></li>
<li><a href="https://github.com/dalab/pboh-entity-linking" target="_blank" rel="external">https://github.com/dalab/pboh-entity-linking</a></li>
</ul>
<h1 id="关系抽取"><a href="#关系抽取" class="headerlink" title="关系抽取"></a>关系抽取</h1><p><strong>关系抽取</strong> 需要从文本中抽取两个或多个实体之间的语义关系，主要方法有下面几类：</p>
<ul>
<li><strong>基于模板的方法(hand-written patterns)</strong><ul>
<li>基于触发词/字符串</li>
<li>基于依存句法</li>
</ul>
</li>
<li><strong>监督学习(supervised machine learning)</strong><ul>
<li>机器学习</li>
<li>深度学习（Pipeline vs Joint Model）</li>
</ul>
</li>
<li><strong>半监督/无监督学习(semi-supervised and unsupervised)</strong><ul>
<li>Bootstrapping</li>
<li>Distant supervision</li>
<li>Unsupervised learning from the web</li>
</ul>
</li>
</ul>
<h2 id="基于模板的方法"><a href="#基于模板的方法" class="headerlink" title="基于模板的方法"></a>基于模板的方法</h2><h3 id="基于触发词-字符串"><a href="#基于触发词-字符串" class="headerlink" title="基于触发词/字符串"></a>基于触发词/字符串</h3><p>首先是基于字符串的 pattern，举一个 IS-A 的关系</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Agar is a substance prepared from a mixture of red algae, **such as** Gelidium, for laboratory or industrial use</div></pre></td></tr></table></figure>
<p>通过 such as 可以判断这是一种 IS-A 的关系，由此可以写的规则是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">“Y such as X ((, X)* (, and|or) X)”</div><div class="line">“such Y as X”</div><div class="line">“X or other Y”</div><div class="line">“X and other Y”</div><div class="line">“Y including X”</div><div class="line">“Y, especially X”</div></pre></td></tr></table></figure></p>
<p>另一个直觉是，更多的关系是在特定实体之间的，所以可以用 NER 标签来帮助关系抽取，如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">•  located-in (ORGANIZATION, LOCATION)</div><div class="line">•  founded (PERSON, ORGANIZATION)</div><div class="line">•  cures (DRUG, DISEASE)</div></pre></td></tr></table></figure></p>
<p>也就是说我们可以把基于字符串的 pattern 和基于 NER 的 pattern 结合起来，就有了下面的例子。<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/5.jpg" class="ful-image" alt="5.jpg"></p>
<p>对应的工具有 Stanford CoreNLP 的 tokensRegex。</p>
<h3 id="基于依存句法"><a href="#基于依存句法" class="headerlink" title="基于依存句法"></a>基于依存句法</h3><p>通常可以以动词为起点构建规则，对节点上的词性和边上的依存关系进行限定。流程为:<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DT.png" class="ful-image" alt="DT.png"><br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DT2.png" class="ful-image" alt="DT2.png"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>手写规则的 <strong>优点</strong> 是：</p>
<ul>
<li>人工规则有高准确率(high-precision)</li>
<li>可以为特定领域定制(tailor)</li>
<li>在小规模数据集上容易实现，构建简单</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>低召回率(low-recall)</li>
<li>特定领域的模板需要专家构建，要考虑周全所有可能的 pattern 很难，也很费时间精力</li>
<li>需要为每条关系来定义 pattern</li>
<li>难以维护</li>
<li>可移植性差</li>
</ul>
<h2 id="监督学习-传统机器学习"><a href="#监督学习-传统机器学习" class="headerlink" title="监督学习-传统机器学习"></a>监督学习-传统机器学习</h2><h3 id="研究综述"><a href="#研究综述" class="headerlink" title="研究综述"></a>研究综述</h3><p>漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025</p>
<blockquote>
<p>Zhou[13] 在 Kambhatla 的基础上加入了基本词组块信息和 WordNet，使用 SVM 作为分类器，在实体关系识别的准确率达到了 55.5%，实验表明实体类别信息的特征有助于提高关系抽取性能； Zelenko[14] 等人使用浅层句法分析树上最小公共子树来表达关系实例，计算两颗子树之间的核函数，通过训练例如 SVM 模型的分类器来对实例进行分。但基于核函数的方法的问题是召回率普遍较低，这是由于相似度计算过程匹配约束比较严格，因此在后续研究对基于核函数改进中，大部分是围绕改进召回率。但随着时间的推移，语料的增多、深度学习在图像和语音领域获得成功，信息抽取逐渐转向了基于神经模型的研究，相关的语料被提出作为测试标准，如 SemEval-2010 task 8[15]。基于神经网络方法的研究有，Hashimoto[16] 等人利用 Word Embedding 方法从标注语料中学习特定的名词对的上下文特征，然后将该特征加入到神经网络分类器中，在 SemEval-2010 task 8 上取得了 F1 值 82.8% 的效果。基于神经网络模型显著的特点是不需要加入太多的特征，一般可用的特征有词向量、位置等，因此有人提出利用基于联合抽取模型，这种模型可以同时抽取实体和其之间的关系。联合抽取模型的优点是可以避免流水线模型存在的错误累积[17-22]。其中比较有代表性的工作是[20]，该方法通过提出全新的全局特征作为算法的软约束，进而同时提高关系抽取和实体抽取的准确率，该方法在 ACE 语料上比传统的流水线方法 F1 提高了 1.5%，；另一项工作是 [22]，利用双层的 LSTM-RNN 模型训练分类模型，第一层 LSTM 输入的是词向量、位置特征和词性来识别实体的类型。训练得到的 LSTM 中隐藏层的分布式表达和实体的分类标签信息作为第二层 RNN 模型的输入，第二层的输入实体之间的依存路径，第二层训练对关系的分类，通过神经网络同时优化 LSTM 和 RNN 的模型参数，实验与另一个采用神经网络的联合抽取模型[21]相比在关系分类上有一定的提升。但无论是流水线方法还是联合抽取方法，都属于有监督学习，因此需要大量的训练语料，尤其是对基于神经网络的方法，需要大量的语料进行模型训练，因此这些方法都不适用于构建大规模的 Knowledge Base。</p>
</blockquote>
<p>[13] Guodong Z, Jian S, Jie Z, et al. ExploringVarious Knowledge in relation Extraction.[c]// acl2005, Meeting of the Association for ComputationalLinguistics, Proceedings of the Conference, 25-30 June, 2005, University of Michigan, USA. DBLP.2005:419-444.<br>[14] Zelenko D, Aone C, Richardella A. KernelMethods for relation Extraction[J]. the Journal ofMachine Learning Research, 2003, 1083-1106.<br>[15] Hendrickx I, Kim S N, Kozareva Z, et al.semEval-2010 task 8: Multi-way classification ofsemantic relations between Pairs of nominals[c]//the Workshop on semantic Evaluations: recentachievements and Future Directions. association forComputational Linguistics, 2009:94-99.<br>[16] Hashimoto K, Stenetorp P, Miwa M, et al. Task-oriented learning of Word Embeddings for semanticRelation Classification[J], Computer Science,2015:268-278.<br>[17] Singh S, Riedel S, Martin B, et al. JointInference of Entities, Relations, and Coreference[C]//the Workshop on automated Knowledge baseConstruction ,San Francisco, CA, USA, October27-november 1. 2013:1-6.<br>[18] Miwa M, Sasaki Y. Modeling Joint Entity andrelation Extraction with table representation[c]//conference on Empirical Methods in naturalLanguage Processing. 2014:944-948.<br>[19] Lu W, Dan R. Joint Mention Extraction andclassification with Mention Hypergraphs[c]//conference on Empirical Methods in naturallanguage Processing. 2015:857-867.<br>[20] Li Q, Ji H. Incremental Joint Extraction of EntityMentions and relations[c]// annual Meeting of theAssociation for Computational Linguistics. 2014:402-412.<br>[21] Kate R J, Mooney R J. Joint Entity andrelation Extraction using card-pyramid Parsing[c]//conference on computational natural languagelearning. 2010:203-212.<br>[22] Miwa M, Bansal M. End-to-End Relation Extraction using lstMs on sequences and tree structures[c]// annual Meeting of the association for computational linguistics. 2016:1105-1116.</p>
<h3 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h3><p>标准流程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">- 预先定义好想提取的关系集合</div><div class="line">- 选择相关的命名实体集合</div><div class="line">- 寻找并标注数据</div><div class="line"> 选择有代表性的语料库</div><div class="line"> 标记命名实体</div><div class="line"> 人工标注实体间的关系</div><div class="line"> 分成训练、开发、测试集</div><div class="line">- 设计特征</div><div class="line">- 选择并训练分类器</div><div class="line">- 评估结果</div></pre></td></tr></table></figure></p>
<p>为了提高 efficiency，通常我们会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用 task-specific feature-set。</p>
<p>可以采用的分类器可以是 <strong>MaxEnt、Naive Bayes、SVM</strong> 等。</p>
<h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><p>直接上例子：<br>E.g., <strong>American Airlines</strong>, a unit of AMR, immediately matched the move, spokesman <strong>Tim Wagner</strong> said</p>
<p><strong>Mention 1:</strong> American Airlines<br><strong>Mention 2:</strong> Tim Wagner</p>
<p>用到的特征可以有：<br><strong>Word features</strong></p>
<ul>
<li>Headwords of M1 and M2, and combination<ul>
<li>M1: Airlines,  M2: Wagner, Combination: Airlines-Wagner</li>
</ul>
</li>
<li>Bag of words and bigrams in M1 and M2<ul>
<li>{American, Airlines, Tim, Wagner, American Airlines, Tim Wagner}</li>
</ul>
</li>
<li>Words or bigrams in particular positions left and right of M1/M2<ul>
<li>M2: -1 spokesman</li>
<li>M2: +1 said</li>
</ul>
</li>
<li>Bag of words or bigrams between the two entities<ul>
<li>{a, AMR, of, immediately, matched, move, spokesman, the, unit}</li>
</ul>
</li>
</ul>
<p><strong>Named Entities Type and Mention Level Features</strong></p>
<ul>
<li>Named-entities types<br>M1: ORG<br>M2: PERSON</li>
<li>Concatenation of the two named-entities types<br>ORG-PERSON</li>
<li>Entity Level of M1 and M2 (NAME, NOMINAL, PRONOUN)<br>M1: NAME     [it or he would be PRONOUN]<br>M2: NAME     [the company would be NOMINAL]</li>
</ul>
<p><strong>Parse Features</strong></p>
<ul>
<li>Base syntactic chunk sequence from one to the other<br>NP NP PP VP NP NP</li>
<li>Constituent path through the tree from one to the other<br>NP ↑ NP ↑ S ↑ S ↓ NP</li>
<li>Dependency path<br>Airlines matched Wagner said</li>
</ul>
<p><strong>Gazetteer and trigger word features</strong></p>
<ul>
<li>Trigger list for family: kinship terms<br>parent, wife, husband, grandparent, etc. [from WordNet]</li>
<li>Gazetteer:<br>List of useful geo or geopolitical words<br>  Country name list<br>  Other sub-entities</li>
</ul>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/7.jpg" class="ful-image" alt="7.jpg">
<p>或者从另一个角度考虑，可以分为</p>
<ul>
<li><strong>轻量级</strong><br>实体的特征，包括实体前后的词，实体类型，实体之间的距离等</li>
<li><strong>中等量级</strong><br>考虑 chunk，如 NP，VP，PP 这类短语</li>
<li><strong>重量级</strong><br>考虑实体间的依存关系，实体间树结构的距离，及其他特定的结构信息</li>
</ul>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/features2.png" class="ful-image" alt="features2.png">
<h2 id="监督学习-深度学习"><a href="#监督学习-深度学习" class="headerlink" title="监督学习-深度学习"></a>监督学习-深度学习</h2><p>深度学习方法又分为两大类，pipeline 和 joint model</p>
<ul>
<li><strong>Pipeline</strong><br>把实体识别和关系分类作为两个完全独立的过程，不会相互影响，关系的识别依赖于实体识别的效果</li>
<li><strong>Joint Model</strong><br>实体识别和关系分类的过程共同优化</li>
</ul>
<p>深度学习用到的特征通常有：</p>
<ul>
<li>Position embeddings</li>
<li>Word embeddings</li>
<li>Knowledge embeddings</li>
</ul>
<p>模型通常有 CNN/RNN + attention，损失函数 ranking loss 要优于交叉熵。</p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><h4 id="CR-CNN"><a href="#CR-CNN" class="headerlink" title="CR-CNN"></a>CR-CNN</h4><p><a href="https://arxiv.org/pdf/1504.06580.pdf" target="_blank" rel="external">Santos et. al Computer Science 2015</a><br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/CR-CNN.png" class="ful-image" alt="CR-CNN.png"></p>
<p>输入层 word embedding + position embedding，用 6 个卷积核 + max pooling 生成句子向量表示，与关系（类别）向量做点积求相似度，作为关系分类的结果。<br>损失函数用的是  <strong>pairwise ranking loss function</strong></p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/CR-CNN_loss.png" class="ful-image" alt="CR-CNN_loss.png">
<p>训练时每个样本有两个标签，正确标签 y+ 和错误标签 c-，m+ 和 m- 对应了两个 margin，$\gamma$ 用来缩放，希望 $s(x)_{y+}$ 越大越好，$s(x)_{c-}$ 越小越好。</p>
<p>另外还有一些 tips：</p>
<ul>
<li>负样本选择 $s(x)_c$ 最大的标签，便于更好地将比较类似的两种 label 分开</li>
<li>加了一个 Artifical Class，表示两个实体没有任何关系，可以理解为 Other/拒识，训练时不考虑这一类，损失函数的第一项直接置 0，预测时如果其他 actual classes 的分数都为负，那么就分为 Other，对于整体的 performance 有提升</li>
<li>position feature 是每个 word 与两个 entity 的相对距离，强调了两个实体的作用，认为距离实体近的单词更重要，PE 对效果的提升明显，但实际上只用两个实体间的 word embedding 作为输入代替整个句子的 word embedding+position embedding，也有相近效果，且输入更少实现更简单。</li>
</ul>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/PE.png" class="ful-image" alt="PE.png">
<h4 id="Att-CNN"><a href="#Att-CNN" class="headerlink" title="Att-CNN"></a>Att-CNN</h4><p><a href="http://iiis.tsinghua.edu.cn/~weblt/papers/relation-classification.pdf" target="_blank" rel="external">Relation Classification via Multi-Level Attention CNNs</a></p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCNN.png" class="ful-image" alt="AttCNN.png">
<p>用了两个层面的 Attention，一个是输入层对两个 entity 的注意力，另一个是在卷积后的 pooling 阶段，用 attention pooling 代替 max pooling 来加强相关性强的词的权重。</p>
<p>输入特征还是 word embedding 和 position embedding，另外做了 n-gram 的操作，取每个词前后 k/2 个词作为上下文信息，每个词的 embedding size 就是 $(d_w + 2d_p)*k$。这个滑动窗口的效果其实和卷积一样，但因为输入层后直接接了 attention，所以这里先做了 n-gram。</p>
<p>第一层 input attention 用两个对角矩阵分别对应两个 entity，对角线各元素是输入位置对应词与实体间的相关性分数 $A^j_{i,i}=f(e_j, w_i)$，通过词向量內积衡量相关性，然后 softmax 归一化，每个词对两个实体各有一个权重 $\alpha_1, \alpha_2$，然后进行加权把权重与输入 $z_i$ 融合，有三种融合方法， <strong>求平均、拼接、相减</strong>（类似 transE 操作，把 relation 看做两个权重的差）。这一层的 attention 捕捉的是句中单词与实体的词向量距离，但其实有些线索词如 caused 与实体的相似度不高但很重要。</p>
<p>接着做正常卷积，然后第二层用 attention pooling 代替 max-pooling，bilinear 方法计算相关度，然后归一化，再做 max pooling 得到模型最后的输出 $w^O$。</p>
<p>另外，这篇 paper 还改进了 Santos 提出的 Ranking loss，Ranking loss 里的 distance function 直接用了网络的输出，而这里定义了新的 distance function 来衡量模型输出 $w^O$ 和正确标签对应的向量 relation embedding $W^L_y$ 的距离：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCnn_loss.png" class="ful-image" alt="AttCnn_loss.png"></p>
<p>用了 L2 正则，然后基于这一距离定义了目标函数：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCNN_loss2.png" class="ful-image" alt="AttCNN_loss2.png"></p>
<p>两个距离分别为网络输出与正例和与负例的距离，负例照例用了所有错误类别中与输出最接近的，margin 设置的 1。</p>
<p><strong>这应该是目前最好的方法，SemEval-2010 Task 8 上的 F1 值到了 88。</strong></p>
<h4 id="Att-BLSTM"><a href="#Att-BLSTM" class="headerlink" title="Att-BLSTM"></a>Att-BLSTM</h4><p><a href="http://www.aclweb.org/anthology/P16-2034" target="_blank" rel="external">Peng Zhou et. al ACL 2016</a></p>
<p>CNN 可以处理文本较短的输入，但是长距离的依赖还是需要 LSTM，这一篇就是中规中矩的 BiLSTM+Attn 来做关系分类任务。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttBLSM.png" class="ful-image" alt="AttBLSM.png"></p>
<h4 id="评测"><a href="#评测" class="headerlink" title="评测"></a>评测</h4><p>各方法在 SemEval-2010 Task 8 上的评测：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/pipeline_perf.png" class="ful-image" alt="pipeline_perf.png"></p>
<h3 id="Joint-Model"><a href="#Joint-Model" class="headerlink" title="Joint Model"></a>Joint Model</h3><p>Pipeline 的方法会导致误差的传递，端到端的方法直觉上会更优。</p>
<h4 id="LSTM-RNNs"><a href="#LSTM-RNNs" class="headerlink" title="LSTM-RNNs"></a>LSTM-RNNs</h4><p><a href="https://arxiv.org/pdf/1601.00770.pdf" target="_blank" rel="external">Miwa et. al ACL 2016</a></p>
<p>用端到端的方式进行抽取，实体识别和关系分类的参数共享，不过判断过程并没有进行交互。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/joint_model.png" class="ful-image" alt="joint_model.png"></p>
<p>三个表示层</p>
<ul>
<li><strong>Embedding layer (word embeddings layer)</strong><br>用到了词向量 $v_w$、词性 POS tags $v_p$、依存句法标签 Dependency types $v_d$、实体标签 entity labels $v_e$</li>
<li><strong>Sequence layer (word sequence based LSTM-RNN layer)</strong><br>负责实体识别<br>BiLSTM 对句子进行编码，输入是 word embedding 和 POS embedding 的拼接，输出是两个方向的隐层单元输出的拼接 $s_t$<br>然后进行实体识别，还是序列标注任务，两层 NN 加一个 softmax 输出标签。打标签的方法用 BILOU(Begin, Inside, Last, Outside, Unit)，解码时考虑到当前标签依赖于上一个标签的问题，输入在 sequence layer 层的输出上还加了上一时刻的 label embedding，用 schedule sampling 的方式来决定用 gold label 还是 predict label<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/entity_detection.png" class="ful-image" alt="entity_detection.png"></li>
<li><p><strong>Dependency layer (dependency subtree based LSTM-RNN layer )</strong><br>负责关系分类<br>用 tree-structured BiLSTM-RNNs 来表示 relation candidate，捕捉了 top-down 和 bottom-up 双向的关系，输入是 sequence layer 的输出 $s_t$，dependency type embedding $v_d$，以及 label embedding $v_e$，输出是 $d_p$<br>关系分类主要还是利用了依存树中两个实体之间的最短路径（shortest path）。主要过程是找到 sequence layer 识别出的所有实体，对每个实体的最后一个单词进行排列组合，再经过 dependency layer 得到每个组合的 $d_p$，然后同样用两层 NN + softmax 对该组合进行分类，输出这对实体的关系类别。<br>$d_p$ 第一项是 bottom-up LSTM-RNN 的 top LSTM unit，代表实体对的最低公共父节点（the lowest common ancestor of the target word pair p），第二、三项分别是两个实体对应的 top-down LSTM-RNN 的 hidden state。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/dp.png" class="ful-image" alt="dp.png">
<p>​</p>
</li>
</ul>
<p>不同模型在 SemEval-2010 Task 8 数据集上的效果比较：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/joint_perf.png" class="ful-image" alt="joint_perf.png"></p>
<p>与我们的直觉相反，joint model 不一定能起正作用。不过上面的比较能得到的另一个结论是：<strong>外部资源可以来优化模型</strong>。</p>
<h2 id="监督学习-评价指标"><a href="#监督学习-评价指标" class="headerlink" title="监督学习-评价指标"></a>监督学习-评价指标</h2><p>最常用的 Precision, Recall, F1</p>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/8.jpg" class="ful-image" alt="8.jpg">
<h2 id="监督学习-小结"><a href="#监督学习-小结" class="headerlink" title="监督学习-小结"></a>监督学习-小结</h2><p>如果测试集和训练集很相似，那么监督学习的准确率会很高，然而，它对不同 genre 的泛化能力有限，模型比较脆弱，也很难扩展新的关系；另一方面，获取这么大的训练集代价也是昂贵的。</p>
<h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><h3 id="研究综述-1"><a href="#研究综述-1" class="headerlink" title="研究综述"></a>研究综述</h3><p>漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025</p>
<blockquote>
<p>Brin[23]等人通过少量的实例学习种子模板，从网络上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，其主要贡献是构建了 DIPRE 系统；Agichtein[24]在 Brin 的基础上对新抽取的实例进行可信度的评分和完善关系描述的模式，设计实现了 Snowball 抽取系统；此后的一些系统都沿着 Bootstrap 的方法，但会加入更合理的对 pattern 描述、更加合理的限制条件和评分策略，或者基于先前系统抽取结果上构建大规模 pattern；如 NELL（Never-EndingLanguage Learner）系统[25-26]，NELL 初始化一个本体和种子 pattern，从大规模的 Web 文本中学习，通过对学习到的内容进行打分来提高准确率，目前已经获得了 280 万个事实。</p>
</blockquote>
<p>[23] brin s. Extracting Patterns and relations fromthe World Wide Web[J]. lecture notes in computerScience, 1998, 1590:172-183.<br>[24] Agichtein E, Gravano L. Snowball : Extractingrelations from large Plain-text collections[c]// acMConference on Digital Libraries. ACM, 2000:85-94.<br>[25] Carlson A, Betteridge J, Kisiel B, et al. Toward anarchitecture for never-Ending language learning.[c]// twenty-Fourth aaai conference on artificialIntelligence, AAAI 2010, Atlanta, Georgia, Usa, July.DBLP, 2010:529-573.<br>[26] Mitchell T, Fredkin E. Never-ending Languagelearning[M]// never-Ending language learning.Alphascript Publishing, 2014.</p>
<h3 id="Seed-based-or-bootstrapping-approaches"><a href="#Seed-based-or-bootstrapping-approaches" class="headerlink" title="Seed-based or bootstrapping approaches"></a>Seed-based or bootstrapping approaches</h3><p>半监督学习主要是利用少量的标注信息进行学习，这方面的工作主要是<strong>基于 Bootstrap 的方法</strong>以及<strong>远程监督方法（distance supervision）</strong>。<strong>基于 Bootstrap 的方法</strong> 主要是利用少量实例作为初始种子(seed tuples)的集合，然后利用 pattern 学习方法进行学习，通过不断迭代从非结构化数据中抽取实例，然后从新学到的实例中学习新的 pattern 并扩充 pattern 集合，寻找和发现新的潜在关系三元组。<strong>远程监督</strong> 方法主要是对知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。</p>
<h4 id="Relation-Bootstrapping"><a href="#Relation-Bootstrapping" class="headerlink" title="Relation Bootstrapping"></a>Relation Bootstrapping</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">•  Gather a set of seed pairs that have relation R</div><div class="line">•  Iterate:</div><div class="line">1.  Find sentences with these pairs</div><div class="line">2.  Look at the context between or around the pair and generalize the context to create patterns</div><div class="line">3.  Use the patterns for grep for more pairs</div></pre></td></tr></table></figure>
<p>看一个完整的例子<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/6.jpg" class="ful-image" alt="6.jpg"></p>
<p>从 5 对种子开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 $(authoer, book)$ 抽取到了 relation pattern，<strong><em>x, by y</em></strong>, 和 <strong><em>x, one of y’s</em></strong></p>
<p><strong>优点：</strong></p>
<ul>
<li>构建成本低，适合大规模构建</li>
<li>可以发现新的关系（隐含的）</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>对初始给定的种子集敏感</li>
<li>存在语义漂移问题</li>
<li>结果准确率较低</li>
<li>缺乏对每一个结果的置信度的计算</li>
</ul>
<h4 id="Snowball"><a href="#Snowball" class="headerlink" title="Snowball"></a>Snowball</h4><p>对 Dipre 算法的改进。Snowball 也是一种相似的迭代算法，Dipre 的 X,Y 可以是任何字符串，而 Snowball 要求 X,Y 必须是命名实体，并且 Snowball 对每个 pattern 计算了 confidence value<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Group instances w/similar prefix, middle, suffix, extract patterns</div><div class="line"> •  But require that X and Y be named entites</div><div class="line"> •  And compute a confidence for each pattern</div><div class="line"></div><div class="line">ORGANIZATION &#123;&apos;s, in, headquaters&#125; LOCATION</div><div class="line">LOCATION &#123;in, based&#125; ORGANIZATION</div></pre></td></tr></table></figure></p>
<h3 id="Distant-Supervision"><a href="#Distant-Supervision" class="headerlink" title="Distant Supervision"></a>Distant Supervision</h3><p><strong>基本假设：</strong>两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系。</p>
<p><strong>具体步骤：</strong></p>
<ol>
<li>从知识库中抽取存在关系的实体对</li>
<li>从非结构化文本中抽取含有实体对的句子作为训练样例，然后提取特征训练分类器。</li>
</ol>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/9.jpg" class="ful-image" alt="9.jpg">
<p>Distant Supervision 结合了 bootstrapping 和监督学习的长处，使用一个大的 corpus 来得到海量的 seed example，然后从这些 example 中创建特征，最后与有监督的分类器相结合。</p>
<p>与监督学习相似的是这种方法用大量特征训练了分类器，通过已有的知识进行监督，不需要用迭代的方法来扩充 pattern。<br>与无监督学习相似的是这种方法采用了大量没有标注的数据，对训练语料库中的 genre 并不敏感，适合泛化。</p>
<h4 id="PCNN-Attention"><a href="#PCNN-Attention" class="headerlink" title="PCNN + Attention"></a>PCNN + Attention</h4><p><a href="https://www.semanticscholar.org/paper/Distant-Supervision-for-Relation-Extraction-with-Ji-Liu/b8da823ad81e3b8e5b80d82f86129fdb1d9132e7" target="_blank" rel="external">Kang Liu et.al AI 2017</a></p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS.png" class="ful-image" alt="DS.png">
<ol>
<li><strong>PCNN</strong><br>单一池化难以刻画不同上下文对句向量的贡献，而进行分段池化，根据两个实体把句子分成三段然后对不同部分分别进行池化，刻画更为精准。<br>另见 <a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP203.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</a></li>
<li><strong>Sentence-level attention</strong><br>远程监督常用的 multi-instance learning，只选取最有可能的一个句子进行训练预测，丢失了大部分信息，句子层面的 attention 对 bag 里所有句子进行加权作为 bag 的特征向量，保留尽可能多的信息，能动态减少噪声句的权重，有利于解决错误标记的问题。<br>另见 <a href="http://www.aclweb.org/anthology/P16-1200" target="_blank" rel="external">Neural Relation Extraction with Selective Attention over Instances</a><br>这里对两个实体向量作差来表示 relation 向量 $v_{relation}$，如果一个实例能表达这种关系，那么这个实例的向量表达应该和 $v_{relation}$ 高度相似，根据这个假设来计算句向量和关系向量的相关性，其中 $[b_i; v_{relation}]$ 表示垂直级联，$b_i$ 是 PCNN 得到的特征输出，softmax 归一化再进行加权，最后再过softmax 进行分类。<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS_sum.png" class="ful-image" alt="DS_sum.png">
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS_att.png" class="ful-image" alt="DS_att.png"></li>
<li><strong>Entity representation</strong><br>引入了实体的背景知识（Freebase 和 Wikipedia 提供的实体描述信息），增强了实体表达（entity representation），D 是 (entity, description) 的集合表示，$e_i$ 是实体表示，$d_i$ 通过另一个传统 CNN 对收集到的实体的描述句抽特征得到<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/ed.png" class="ful-image" alt="ed.png">
希望 $e_i$ 和 $d_i$ 尽可能相似，定义两者间的误差：<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/errors.png" class="ful-image" alt="errors.png">
最后的损失函数是交叉熵和实体描述误差的加权和：<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/final_loss.png" class="ful-image" alt="final_loss.png">
</li>
</ol>
<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p><strong>优点：</strong></p>
<ul>
<li>可以利用丰富的知识库信息，减少一定的人工标注</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>假设过于肯定，引入大量噪声，存在语义漂移现象</li>
<li>很难发现新的关系</li>
</ul>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><h3 id="研究综述-2"><a href="#研究综述-2" class="headerlink" title="研究综述"></a>研究综述</h3><blockquote>
<p>Bollegala[27]从搜索引擎摘要中获取和聚合抽取模板，将模板聚类后发现由实体对代表的隐含语义关系; Bollegala[28]使用联合聚类(Co-clustering)算法，利用关系实例和关系模板的对偶性，提高了关系模板聚类效果，同时使用 L1 正则化 Logistics 回归模型，在关系模板聚类结果中筛选出代表性的抽取模板，使得关系抽取在准确率和召回率上都有所提高。</p>
<p>无监督学习一般利用语料中存在的大量冗余信息做聚类，在聚类结果的基础上给定关系，但由于聚类方法本身就存在难以描述关系和低频实例召回率低的问题，因此无监督学习一般难以得很好的抽取效果。</p>
</blockquote>
<p>[27] Bollegala D T, Matsuo Y, Ishizuka M. Measuringthe similarity between implicit semantic relationsfrom the Web[J]. Www Madrid! track semantic/dataWeb, 2009:651-660.<br>[28] Bollegala D T, Matsuo Y, Ishizuka M. RelationalDuality: Unsupervised Extraction of semantic relations between Entities on the Web[c]//International Conference on World Wide Web, WWW 2010, Raleigh, North Carolina, Usa, April. DBLP, 2010:151-160.</p>
<h3 id="Open-IE"><a href="#Open-IE" class="headerlink" title="Open IE"></a>Open IE</h3><p><strong>Open Information Extraction</strong> 从网络中抽取关系，没有训练数据，没有关系列表。过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1. Use parsed data to train a “trustworthy tuple” classifier</div><div class="line">2. Single-pass extract all relations between NPs, keep if trustworthy</div><div class="line">3. Assessor ranks relations based on text redundancy</div><div class="line"></div><div class="line">E.g.,</div><div class="line">(FCI, specializes in, sobware development)</div><div class="line">(Tesla, invented, coil transformer)</div></pre></td></tr></table></figure></p>
<h2 id="半监督-无监督学习-评价指标"><a href="#半监督-无监督学习-评价指标" class="headerlink" title="半监督/无监督学习-评价指标"></a>半监督/无监督学习-评价指标</h2><p>因为抽取的是新的关系，并不能准确的计算 precision 和 recall，所以我们只能估计，从结果集中随机抽取一个关系的 sample，然后人工来检验准确率</p>
<p>$$\hat P = {\text {Number of correctly extracted relations in the sample} \over \text {Total number of extracted relations in the sample}}$$</p>
<p>也可以计算不同 recall level 上的 precision，比如说分别计算在前 1000，10,000，100,000 个新的关系中的 precision，在各个情况下随机取样。</p>
<p>然而，并没有方法来计算 recall。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 &lt;a href=&quot;http://www.shuang0420.com/2017/03/18/NLP%20笔记%20-Information%20Extraction/&quot;&gt;NLP笔记 - Information Extraction&lt;/a&gt; 和 &lt;a href=&quot;http://www.shuang0420.com/2017/04/10/NLP笔记%20-%20Relation%20Extraction/&quot;&gt;NLP笔记 - Relation Extraction&lt;/a&gt;，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Knowledge Graph" scheme="http://www.shuang0420.com/categories/NLP/Knowledge-Graph/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="Relation Extraction" scheme="http://www.shuang0420.com/tags/Relation-Extraction/"/>
    
      <category term="Information Extraction" scheme="http://www.shuang0420.com/tags/Information-Extraction/"/>
    
  </entry>
  
  <entry>
    <title>99/100 天纪念日 - 第 1 期</title>
    <link href="http://www.shuang0420.com/2018/08/06/love99/"/>
    <id>http://www.shuang0420.com/2018/08/06/love99/</id>
    <published>2018-08-06T13:10:03.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<script src="/crypto-js.js"></script><script src="/mcommon.js"></script><h3 id="encrypt-message">Please enter the password to read the blog.</h3><link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"> <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap-theme.min.css"> <script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script> <div id="security"> <div> <div class="input-group"> <input type="text" class="form-control" aria-label="Enter the password." id="pass"/> <div class="input-group-btn"> <button type="button" class="btn btn-default" onclick="decryptAES()">Decrypt</button> </div> </div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div>]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
    
      <category term="小心情" scheme="http://www.shuang0420.com/tags/%E5%B0%8F%E5%BF%83%E6%83%85/"/>
    
  </entry>
  
  <entry>
    <title>2018 CCF-GAIR 参会笔记 - NLP 专场</title>
    <link href="http://www.shuang0420.com/2018/08/06/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/"/>
    <id>http://www.shuang0420.com/2018/08/06/2018 CCF-GAIR 参会笔记 - NLP 专场/</id>
    <published>2018-08-06T01:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇居然忘了发了……<br><a id="more"></a></p>
<h1 id="孙茂松-漫谈基于深度学习的中文计算"><a href="#孙茂松-漫谈基于深度学习的中文计算" class="headerlink" title="孙茂松 - 漫谈基于深度学习的中文计算"></a>孙茂松 - 漫谈基于深度学习的中文计算</h1><p>强调的一个概念是 <strong>中文自然语言处理需要加入专家知识</strong>。主要介绍的工作是 <strong>词表学习</strong>：</p>
<ul>
<li><strong>嵌入字信息的词表学习</strong><br>实践中还是经常会用到的技巧；<br>词向量本身对高频词是没问题的，比如说取相近词 K 近邻，猪肉/鸡肉语义是相似的，但对低频词/新词像马肉/龙肉，语义相关性就不高了；<br>因此在词向量出现歧义时可以加入字向量，相当于平滑作用，在这个刻度上没有这种信息，就进行回退；<br>提到了一些其他 trick<ul>
<li><strong>Position-based character embeddings</strong> 区分字在词中出现的位置，也就是用 char+pos 来表示字，idea 是通常一个字可能出现在词的开始、中间、尾部（用 $c^B$, $c^M$, $c^E$ 表示），却分别代表不同的含义，如车道、人行道和道法、道经中的道就不是一个含义；</li>
<li><strong>Cluster-based character embeddings</strong>，对每个字的所有 occurrence 进行聚类，然后对每个类建一个 embedding<br>参考论文：<a href="http://nlp.csai.tsinghua.edu.cn/~lzy/publications/ijcai2015_character.pdf" target="_blank" rel="external">Joint Learning of Character and Word Embeddings</a></li>
</ul>
</li>
<li><strong>嵌入中文资源，基于知网的词表学习</strong><br>作用大概是消歧，利用 hownet 解决中文词语的多义性，类比 wordnet 用来加强英语的多义性学习一样<br>当然 HowNet 和 WordNet 的构造还是有很大不同的。HowNet 对十几万汉语常用词进行了描述，描述用的三要素分别是 sememe，sense 和 word，比如 apple 包含了两个 sense，sense1 是水果，sense2 是电脑，对每个 sense，sememe 可以描述其对应的属性，这些属性会通过相对复杂的层级结构来对目标 sense 进行说明。<img src="http://images.shuang0420.com/images/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/hownet.png" class="ful-image" alt="hownet.png">
在基于 hownet 的词表学习里，<strong>sememe 是最小的语义单元</strong>，数量有限，大概两千个。每个单词可能对应多个 sense，将每个 sense 对应的 sememe 看成是一个集合，相似的 sense 会包含相同的 sememe。训练模型基于经典的 skip-gram，考虑上下文的同时，也考虑了词的 sememe 信息以及 sememe 与 sense 之间的关系。提供了三种融合方法，SSA/SAC/SAT，<strong>SSA</strong> 对每个 target word 取它对应所有 sememe embeddings 的平均值，<strong>SAC</strong> 对 context words 进行消歧来更好的学习目标单词，也就是 context 用 sememe embedding 来表示 ，target word embedding 可以看做是为 context word embedding 选择最合适的 sense 和 sememe 的一个 attention 机制，而 <strong>SAT</strong> 中 context 用原来的 embedding 表示，但 target word 用 sememe embedding 表示，把 context words 看做是 target word 不同 sense 上的 attention。<img src="http://images.shuang0420.com/images/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/SAC.png" class="ful-image" alt="SAC.png">
<img src="http://images.shuang0420.com/images/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/SAT.png" class="ful-image" alt="SAT.png">
基于 HowNet 的词表学习里，sememe, sense, word 之间能够互相打通。在对低频词和新词问题上，由于多了词与词之间共享的 sememe embeddings，低频词能够被解码成 sememe 并通过其他词得到良好的训练，相比于传统 WRL 模型能有更好的表现。<br>参考论文：<a href="http://nlp.csai.tsinghua.edu.cn/~xrb/publications/ACL-17_sememe.pdf" target="_blank" rel="external">Improved Word Representation Learning with Sememes</a></li>
<li>最后还介绍了清华出品的古诗系统，提到了要通过与情感结合、与知识图谱结合等方法来增强作诗系统。</li>
</ul>
<h1 id="赵军-开放域事件抽取"><a href="#赵军-开放域事件抽取" class="headerlink" title="赵军 - 开放域事件抽取"></a>赵军 - 开放域事件抽取</h1><p>主要讲的还是关系抽取中的远程监督（Distant Supervision）问题。远程监督基本假设是“<strong>两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系</strong>”，这样的假设太强，带来的问题是<strong>噪声很多</strong>，一个解决方案是引入<strong>多示例学习</strong>，假定<strong>至少有一个句子表示了这种关系</strong>而不是每个句子都表示这种关系，把最有可能的句子标注出来，以提高性能。介绍的 paper 是 <a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP203.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</a>，EMNLP 2015 挺有名的一篇文章，用分段卷积神经网络 PCNN 来自动学习特征，以及加入 multi-instance learning 来解决远程监督引起的噪声问题。主要 idea 是在池化层通过两个实体的位置把句子分成三个部分，分别池化，再把三个部分的向量结合起来，做整个句子的向量化表示。<br><img src="http://images.shuang0420.com/images/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/PCNN.png" class="ful-image" alt="PCNN.png"><br>后面还讲了开放域更复杂的事件抽取，像是缺少触发词，可以通过从一堆要素中定位核心要素，用核心要素到句子当中找到触发词，将触发词和前面的要素关联到一起，再回标，然后在文本当中找到更多数据。</p>
<h1 id="秦兵-机器智能中的情感计算"><a href="#秦兵-机器智能中的情感计算" class="headerlink" title="秦兵 - 机器智能中的情感计算"></a>秦兵 - 机器智能中的情感计算</h1><p>分享了文本情感计算的六个维度：</p>
<ol>
<li><strong>情感分类</strong><br>面向评价对象的情感分类（aspect-based sentiment analysis）比较典型的还是利用上下文信息，采用注意力机制，使某个评价对象和词语进行更好的搭配，然后分类</li>
<li><strong>隐式情感</strong><br>不含情感词的情感表达（即隐式情感）在情感表达中约占 20%-30%，类型有事实型、比喻型、反问型等，事实型情感占多数，比如住酒店时说“桌子上有一层灰”，实际表达的就是不满。要判断这种情感需要依赖上下文，如 “桌子上有一层灰“ 后面一句是 ”我很不高兴”，就可以把 “桌子上有一层灰” 定义为贬义。找不到上下文可以考虑跨文档，在其他文档中找与之类似的句子再判定情感<br>同时，这类情感的计算通常也需要借助外部知识如隐式情感语料库等，尤其是修辞型的隐式情感，比如隐喻，可以借助隐喻语料库<img src="http://images.shuang0420.com/images/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/%E4%BA%8B%E5%AE%9E%E5%9E%8B%E9%9A%90%E5%BC%8F.png" class="ful-image" alt="%E4%BA%8B%E5%AE%9E%E5%9E%8B%E9%9A%90%E5%BC%8F.png"></li>
<li><strong>情感溯因</strong><br>类似问答系统，有情感词、有原文，可以通过记忆网络判别哪句话是原因</li>
<li><strong>个性化</strong><br>在情感计算中加入用户特征/用户画像信息，包括自然属性、社会属性、兴趣属性、心理属性等，融入到已有的神经网络模型，来做情感分类</li>
<li><strong>跨领域</strong><br>利用领域无关词和领域相关词的链接关系，分别进行聚类；<br>通过神经网络的隐层参数提取与情感相关、但与领域无关的词的特征来分类</li>
<li><strong>情感生成</strong><br>根据指定的情感类别生成情感表达，应用如产品评论生成、聊天系统、对情感表达进行情感极性变换、润色等</li>
</ol>
<p>还有一个有意思的应用是中考、高考时经常看到的诗词鉴赏。<br><img src="http://images.shuang0420.com/images/2018%20CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0%20-%20NLP%20%E4%B8%93%E5%9C%BA/%E8%AF%97%E8%AF%8D%E9%89%B4%E8%B5%8F.png" class="ful-image" alt="%E8%AF%97%E8%AF%8D%E9%89%B4%E8%B5%8F.png"></p>
<h1 id="钟黎-从-0-到1-打造下一代智能对话引擎"><a href="#钟黎-从-0-到1-打造下一代智能对话引擎" class="headerlink" title="钟黎 - 从 0 到1 打造下一代智能对话引擎"></a>钟黎 - 从 0 到1 打造下一代智能对话引擎</h1><p>这个和之前的项目/工作经验高度相关，感觉更像是梳理了一遍之前的工作~~<br>业界通用智能问答平台要解决的问答类型：</p>
<ul>
<li><strong>任务驱动型（Task Oriented Dialogue）</strong><br>用户希望去完成一些任务，比如查天气、查汇率等，包括词槽填充、多轮会话、对话管理等</li>
<li><strong>信息获取型（Information &amp; Answers）</strong><br>目前业界落地最多的一种问答系统类型，包括搜索、单轮对话，根据数据类型划分有下面几类<ol>
<li>结构化知识，比如 CommunityQA（eg., FAQ）和 KBQA</li>
<li>半结构化/非结构化知识，比如说 TableQA（表格），PassageQA（文档）</li>
<li>多模态、跨媒体问答，比如说 VQA，存在视频、音频问答的语料库</li>
</ol>
</li>
<li><strong>通用闲聊型（General Conversation）</strong><br>基础会话，包括闲聊、情感联系、用户信息等，使对话系统更富于人性化</li>
</ul>
<p>重点讲的是第二类，具体讲了两个部分，一是<strong>快速召回</strong>，二是<strong>深度匹配</strong>。</p>
<h2 id="无监督-快速检索"><a href="#无监督-快速检索" class="headerlink" title="无监督-快速检索"></a>无监督-快速检索</h2><p>提高快速召回（无监督的快速检索）的三种方案，<strong>基于词汇计数（Lexical term counting）</strong>、<strong>基于语言模型</strong>、<strong>基于向量化</strong>。</p>
<p><img src="https://static.leiphone.com/uploads/new/article/740_740/201807/5b433cd974e8a.png?imageMogr2/format/jpg/quality/90" alt="腾讯知文团队负责人钟黎：从 0 到1  打造下一代智能对话引擎 | CCF-GAIR 2018"></p>
<p>很多是信息检索的思路，在 <strong><a href="http://www.shuang0420.com/categories/NLP/Search-Engines/">信息检索专题类</a></strong> 的博客都有探讨过。</p>
<h2 id="有监督-深度匹配"><a href="#有监督-深度匹配" class="headerlink" title="有监督-深度匹配"></a>有监督-深度匹配</h2><p>深度匹配的两类常用方法，<strong>Siamese 网络</strong> 和 <strong>基于交互矩阵的网络</strong>。</p>
<p><strong>Siamese 网络</strong>的基本思路：两个输入用同一个编码器进行编码，然后做相似度的计算，特点是共享网络结构和参数；</p>
<p><strong>基于交互矩阵的网络</strong>：除了最后的相关性度量，中间过程里两个输入的某些词也会有交互。</p>
<p>问句较短时/短文档时两类网络一般能打成平手，但对长文档而言，基于交互矩阵的网络就会有更好的表现。</p>
<p>再后面还讲了如何在非结构化文档里寻找信息和答案，具体应用是机器阅读理解（MRC），<strong><a href="http://www.shuang0420.com/tags/阅读理解/">系列博客</a></strong>也有提到。</p>
<p>最后总结了下业界问答系统建设的一些心得：</p>
<ol>
<li>要重视 Baseline。</li>
<li>尽早建立起整个流程的 pipeline。</li>
<li>没有免费午餐定理，不存在万能算法。</li>
<li>领域相关的数据准备、数据清洗非常重要。</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇居然忘了发了……&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Others" scheme="http://www.shuang0420.com/categories/Others/"/>
    
    
      <category term="AI" scheme="http://www.shuang0420.com/tags/AI/"/>
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="chatbot" scheme="http://www.shuang0420.com/tags/chatbot/"/>
    
  </entry>
  
  <entry>
    <title>论文梳理：问题生成(QG)与答案生成(QA)的结合</title>
    <link href="http://www.shuang0420.com/2018/07/08/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90(QG)%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90(QA)%E7%9A%84%E7%BB%93%E5%90%88/"/>
    <id>http://www.shuang0420.com/2018/07/08/论文梳理：问题生成(QG)与答案生成(QA)的结合/</id>
    <published>2018-07-08T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>继续 QG，梳理一下 MSRA 其他 3 篇关于 QG 的 paper：<br><a id="more"></a></p>
<ul>
<li>Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension</li>
<li>Question Answering and Question Generation as Dual Tasks</li>
<li>A Joint Model for Question Answering and Question Generation</li>
</ul>
<p>QG 系列其他的笔记：</p>
<ul>
<li><a href="http://www.shuang0420.com/2018/06/03/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/">论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation</a></li>
<li><a href="http://www.shuang0420.com/2018/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/">论文笔记 - Semi-Supervised QA with Generative Domain-Adaptive Nets</a></li>
</ul>
<p>目前的 QA 大多是<strong>抽取式（extractive）</strong>的任务，答案是文本中的一个连续片段，通常是命名实体这类语义概念，而 QG 是<strong>生成式的（abstractive）</strong>，问句是完整句子，部分单词可能是文档中没出现过的，很多情况下，问句和答案的语言结构不同，因此甚至可以看做两种不同类型的数据。所以第 1 篇 <strong>SynNet 就把答案生成当作序列标注任务，把 QG 当作生成任务</strong>；第 3 篇 <strong>Joint Model 从另一个角度出发，把 QA 和 QG 都当作生成任务，放到同一个 encoder-decoder 框架下，用转变输入数据来实现联合训练</strong>，用 pointer-softmax 来处理抽取/生成问题。</p>
<p>另外，QA 和 QG 任务在概率上是有联系的，可以通过 q、a 的联合概率分布联系起来，P(q|a) 就是 QG 模型，P(a|q) 类似 QA 模型，于是第 2 篇 <strong>dual tasks 就把这两个任务当做对偶任务，用一个正则项把两个任务联合在一起</strong>。<br>$$P(q,a)=P(a)P(q|a)=P(q)P(a|q)$$</p>
<h1 id="Two-Stage-Synthesis-Networks-for-Transfer-Learning-in-Machine-Comprehension"><a href="#Two-Stage-Synthesis-Networks-for-Transfer-Learning-in-Machine-Comprehension" class="headerlink" title="Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension"></a>Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension</h1><p>我们知道 MRC 系统的输入是 (passage, question, answer) 三元组，q 和 a 依赖人工标注，这是制约 MRC 落地应用的最大问题之一，这篇 paper 提出了 SynNet，利用已有领域中可用的监督数据为基础进行训练，训练完成后迁移到新的领域中，根据新领域的文档模型能自动合成与文档 p 相关的 (q, a) 对，替代昂贵的人工标注，为 MRC 的迁移落地提供了便利。</p>
<p>SynNet 把 QA 对（question-answer pair）的生成过程 P(q,a|p) 分解为条件概率 P(a|p) P(q|p,a) ，也就是下面两个步骤：</p>
<ol>
<li><strong>基于文档生成答案 P(a|p)</strong><br>学习文档中的 potential “interestingness” pattern，包括文章中可作为常见问题答案的关键知识点、命名实体或语义概念<br>由于答案是文档的片段，所以看做序列标注任务</li>
<li><strong>基于文档和答案生成问题 P(q|p,a)</strong><br>学习生成自然语言的完整问句<br>作为生成任务</li>
</ol>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/SynNet1.png" class="ful-image" alt="SynNet1.png">
<p><strong>答案合成模块（Answer Synthesis Module）</strong>，序列标注问题，训练了一个 IOB tagger （4 种标记，start, mid, end, none）来预测段落里的每个单词是不是答案。结构很简单，BiLSTM 对 p 的词向量进行编码，然后加两个 FC 层和一个 Softmax 产生每个单词的 tag likelihoods，选择连续的 span 作为 candidate answer chunks，喂给问题生成模块。</p>
<p><strong>问题合成模块（Question Synthesis Module）</strong>学习的是 $P(q_1,…q_n|p_1…p_n,a_{start},a_{end})$。模型结构是 encoder-decoder + attention + copy mechanism。通过在段落词向量中加入一个 0/1 特征来表示单词是不是出现在答案中。</p>
<p><strong>训练算法：</strong><br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/SynNet_transfer.png" class="ful-image" alt="SynNet_transfer.png"></p>
<p>在源领域上训练 SynNet，产生新领域的 QA 对，然后和源领域的数据一起来 finetune 源领域的 MC 模型（用 SGD），源领域和新领域的数据采样比是 k:1（paper 里设的 k=4），这主要是为了处理合成数据的噪音问题而进行的正则化操作。</p>
<p>测试阶段也就是用 finetune 完成的 MC 模型回答新领域的问题时，可以对不同时刻的 checkpoints 的 answer likelihoods 做平均，然后用 DP 找到最佳的 answer span ($p_s, p_e$)，最大化 $p_sp_e$，复杂度是 linear，和 BiDAF 的逻辑相同。</p>
<p>难得的是这篇 paper 还提供了实现细节，其中一个 trick 是，在训练问题合成模块时，他们只用了 SQuAD 的训练集，但是在答案合成模块，还引入了 NER Tagger 来增强答案数据，基本假设任何命名实体都可以被当做某个问题的潜在答案。</p>
<p>在 Ablation Studies 和 Error Analysis 中还提到了一些有趣的发现，具体可以看论文。待解决的问题一个是 copy 机制导致的产生的问句和 paragraph 高度相似的问题，可以通过改进 cost function 在促进解码过程的多样化，另一篇 paper 有提到。还有一个问题是 SynNet 在解决比如数字、人名这种问题的效果很好，但是在需要一些推理的问题，像是 what was / what did 这些问题就很弱了，这也是后续的研究方向。</p>
<p>这篇 paper 个人非常喜欢，实现细节和一些结果的分析都很赞。</p>
<h1 id="Question-Answering-and-Question-Generation-as-Dual-Tasks"><a href="#Question-Answering-and-Question-Generation-as-Dual-Tasks" class="headerlink" title="Question Answering and Question Generation as Dual Tasks"></a>Question Answering and Question Generation as Dual Tasks</h1><p>把 QA 和 QG 当作对偶任务。关键还是下面这个式子：<br>$$P(q,a)=P(a)P(q|a)=P(q)P(a|q)$$</p>
<p>P(q|a) 即 QG 模型，和 P(a|q) 即 QA 模型可以通过联合概率联系起来，于是这里把 QA 和 QG 当作对偶任务，Seq2Seq 实现 QG，RNN 实现 QA，通过一个正则项把两个任务联系起来，联合训练一起学习 QA 和 QG 的参数，损失函数服从下面的条件：</p>
<p>$$P_a(a)P(q|a;\theta_{qg})=P_q(q)P(a|q;\theta_{qa})$$<br>其中 $P_a(a)$ 和 $P_q(q)$ 分别对应答案句和问句的语言模型。</p>
<p>这里 QA 任务不再是在 context 里选 answer span 的任务，而被看作是在一组候选答案句集合中选择可能性最高的 answer sentence 的一个<strong>排序任务</strong>。也就是说，这里的 a 是答案所在的句子，而不是前一篇 paper 提到的简单的语义概念/实体。</p>
<p>QG 任务还是一个生成任务，输入是答案句 a。要注意的是这里 QA 和 QG 的输入都没有 p，都只考虑了句子层面的信息。</p>
<p>和之前介绍的 <a href="(http://www.shuang0420.com/2018/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/">GDAN</a>) 不同的是，这里 <strong>QA 和 QG 的地位是相同的</strong>，也并不需要预训练 QA。</p>
<p>下面看一下模型细节：<br><strong>QA 模型</strong> 分别用 BiGRU 对 q 和 a 进行编码，拼接 last hidden state 作为向量得到 $v_q$ 和 $v_a$，question-answer pair 的表达由四个向量拼接构成 $v(q,a)=[v_q;v_a;v_q⊙v_a;e_{c(q,a)}]$，c(q,a) 表示 q,a 的共现词，对应的词向量表达通过引入额外的 embedding 矩阵 $L_c \in R^{d_c * |V_c|}$ 实现，$d_c$ 表示词共现向量的维度，$|V_c|$ 则是词汇表大小。$f_{qa}(a,q)$ 也就是 qa 相关性函数通过对 $v(q,a)$ 进行线性变换加 tanh 激活得到，最后 softmax 得到概率，损失函数还是 negative log-likelihood。</p>
<p><strong>QG 模型</strong> 还是经典的 encoder-decoder + attention 模型，输入是 answer sentence，还是用 BiGRU 进行编码，连接两个方向的 last hidden state 作为 encoder 的输出以及 deocder 的初始状态。对 attention 做了改进，希望模型能记住 answer sentence 中哪些 context 被使用过了，在产生 question words 的时候就不再重复使用。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/dual_task_attn.png" class="ful-image" alt="dual_task_attn.png">
<p>拼接 $s_t$ 和 $c_t$，接一个 linear layer 和 softmax 得到输出单词在词汇表上的概率分布，一个 trick 是softmax 输出维度取 top frequent question words，OOV 用 attention probability 最高的词替换，相当于对文档单词的一个 copy 机制，当然也可以用 pointer network 来做。</p>
<p>模型每次输入 m 个 QA 对正例和 m 个负例，通过 QG 和 QA 各自模型计算各自 loss，再加上一个正则化项一起计算参数梯度并更新参数。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/dual_task_algo.png" class="ful-image" alt="dual_task_algo.png"></p>
<p>正则化 dual 项利用了 QA 和 QG 的对偶关系：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/dual_task_term.png" class="ful-image" alt="dual_task_term.png"></p>
<p>考虑到 $P(a|q;\theta_{qa})$ 和 QA 模型的输出有差异，因此给定 q，sample 一系列 answer sentences A’，从中得到 $P(a|q;\theta_{qa})$<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/dual_task_pa.png" class="ful-image" alt="dual_task_pa.png"></p>
<p>在实现细节里提到模型对 question words 和 answer words 用了不同的 emebdding 矩阵来学习特定的语义。另外 sampled answer sentence 来自其他的 passage，这降低了 QA 的难度。</p>
<p>结果分析再次证明了 word co-occurrence 是一个简单但非常有效的特征。</p>
<p>实验设计部分不大能看出模型的实际效果，不明白为什么不直接刷榜看一下结果。另外 QG 部分的评价指标也只用了 BLEU-4 分数，对 fluency 没有进行说明。</p>
<blockquote>
<p>We ﬁrst report results on the MARCO and SQUAD datasets. As the dataset is splitted by ourselves, we do not have pre- viously reported results for comparison. </p>
</blockquote>
<h1 id="A-Joint-Model-for-Question-Answering-and-Question-Generation"><a href="#A-Joint-Model-for-Question-Answering-and-Question-Generation" class="headerlink" title="A Joint Model for Question Answering and Question Generation"></a>A Joint Model for Question Answering and Question Generation</h1><p>这篇和上篇都是讲怎么同时生成答案和问题，不同的是上篇通过一个 dual regularization term 将两者联合起来训练，这里把 QA 和 QG 任务都作为生成任务，模型基本结构还是 <strong>Seq2Seq + Attention + Pointer Softmax</strong>，和之前提到的一篇  <a href="http://www.shuang0420.com/2018/06/03/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/">论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation</a> 差不多。输入是文档，以及一个 condition sequence，在 QA 任务里表现为 question word sequence，给定 question 生成 answer；QG 任务里表现为 answer word sequence，给定 answer 生成 qestion，condition 由一个0/1 变量来控制，表示收到的数据是给 a-gen 还是给 q-gen。Joint training 通过对输入数据的转换实现。</p>
<p>Pointer-softmax 一定程度上能解决 extractive/abstractive 的混合问题，通过选择 copy 文档的单词还是生成词汇表的单词来产生下一个单词，表达了 extractive/abstractive 的切换。这带来的一个额外好处是<strong>可以产生 abstractive answer</strong>。</p>
<p>具体来讲，Encoder 里，词向量和字向量拼接得到 word embedding，其中字向量用 BiLSTM 产生，word embedding 经过另一个 BiLSTM 编码得到文档编码 $h^d_i$ 和条件序列的编码 $h^c_j$。</p>
<p>条件序列的另一种编码是“抽取式的”，也就是从 document encoding 中直接抽取出出现在 condition sequence 中的单词的对应部分，这和 <a href="http://www.shuang0420.com/2018/06/03/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/">论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation</a> 原理相同。然后抽取的向量经过 BiLSTM 产生对应编码 $h^e_k$。两种条件序列的编码 $h^c_j$ 和 $h^e_k$ 的 final state 分别为 $h^c_J$ 和 $h^e_K$。在 a-gen mode 也就是对问句进行编码是采用 $h^c_J$，在 q-gen mode 也就是对答案进行编码时采用 $h^e_K$，相当于模拟了 extractive 和 abstractive 的特性。</p>
<p>Decoder 用了 pointer-softmax mechanism，比之前的工作复杂一些。用了两个 LSTM cell $c_1$、$c_2$<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model1.png" class="ful-image" alt="joint_model1.png"></p>
<p>context vector:<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model2.png" class="ful-image" alt="joint_model2.png"></p>
<p>distribution over the document word position:<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model3.png" class="ful-image" alt="joint_model3.png"></p>
<p>Generative mode 由两层 MLP产生：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model4.png" class="ful-image" alt="joint_model4.png"></p>
<p>每个 step 的 switch scalar，由三层 MLP 得到，前两层用 tanh 激活，最后一层用 sigmoid，第一第二层之间是 highway 连接，在最后一层的输入加入 softmax distribution 的 entropy 来进一步提高 performance，相当于给了 point or generate 的更多信息。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model5.png" class="ful-image" alt="joint_model5.png"></p>
<p>最后结果：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model6.png" class="ful-image" alt="joint_model6.png"></p>
<p>损失函数<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model7.png" class="ful-image" alt="joint_model7.png"></p>
<p>实现细节里，encoder 用了整个词表，decoder 用了训练数据里 gold question 中的频率最高的 100 个单词的词表。另外一个 trick 是 decoder 保留了之前产生的单词的历史来防止输出的重复。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86%EF%BC%9A%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90%28QG%29%E4%B8%8E%E7%AD%94%E6%A1%88%E7%94%9F%E6%88%90%28QA%29%E7%9A%84%E7%BB%93%E5%90%88/joint_model_res.png" class="ful-image" alt="joint_model_res.png">
<p>联合训练下，a-gen 的表现有显著提升，q-gen 略有下降。一个直观结论是，模型并没有提高 QA 任务的效果，但是增加了 QG 的能力。</p>
<p>过去大多模型都把 QA 当做 point to answer span within a document 而不是 NLG 任务，这一篇的创新之处就在于把 QA 也当作了生成问题，与 QG 放到同一个框架下，用 pointer-softmax 来调节生成/抽取的比率，给 QA 也增加了“生成”的能力。</p>
<p>一个显著优势是，和上一篇 paper 相同，这里不需要预训练 QA，可以直接用 QG 辅助 QA 的实现同时给模型提供QG 的能力。</p>
<blockquote>
<p>a key distinction of our model is that we harness the process of asking questions to benefit question answering, without training the model to answer the generated questions.</p>
</blockquote>
<p>MSRA 出品的 QG 系列的 paper 在各自模型及实现上有共性也有个性，一些 trick 基本是通用的，具体的实用性能还待具体领域的实践检验。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继续 QG，梳理一下 MSRA 其他 3 篇关于 QG 的 paper：&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Machine Comprehension" scheme="http://www.shuang0420.com/tags/Machine-Comprehension/"/>
    
      <category term="阅读理解" scheme="http://www.shuang0420.com/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
      <category term="Question Generation" scheme="http://www.shuang0420.com/tags/Question-Generation/"/>
    
      <category term="问题生成" scheme="http://www.shuang0420.com/tags/%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation</title>
    <link href="http://www.shuang0420.com/2018/06/03/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/"/>
    <id>http://www.shuang0420.com/2018/06/03/论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation/</id>
    <published>2018-06-03T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>继续来瞅瞅问题生成~<br><a id="more"></a></p>
<p>QG 的应用还是挺广泛的，像是<strong>为 QA 任务产生训练数据、自动合成 FAQ 文档、自动辅导系统（automatic tutoring systems）</strong>等。</p>
<p>传统工作主要是利用<strong>句法树</strong>或者<strong>知识库</strong>，基于规则来产生问题。如<strong>基于语法</strong>（Heilman and Smith, 2010; Ali et al., 2010; Kumar et al., 2015），<strong>基于语义</strong>（Mannem et al., 2010; Lindberg et al., 2013），大多是利用规则操作句法树来形成问句。还有是<strong>基于模板</strong>（templates），定好 slot，然后从文档中找到实体来填充模板（Lindberg et al., 2013; Chali and Golestanirad, 2016）。</p>
<p>深度学习方面的工作不多，有意思的有下面几篇：</p>
<ul>
<li><a href="http://www.aclweb.org/anthology/P16-1056" target="_blank" rel="external">Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus</a><br>将 KB 三元组转化为问句</li>
<li><a href="https://www.aclweb.org/anthology/P16-1170" target="_blank" rel="external">Generating natural questions about an image</a><br>从图片生成问题</li>
<li><a href="https://arxiv.org/abs/1702.02206" target="_blank" rel="external">Semi-supervised QA with generative domain-adaptive nets</a><br>用 domain-adaptive networks 的方法做 QA 的数据增强<br><a href="http://www.shuang0420.com/2018/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/">论文笔记</a></li>
</ul>
<p>神经网络做 QG 基本套路还是 encoder-decoder 模型，对 P(q|d) 或者 P(q|d, a) 进行建模。像是 17年 ACL 的 paper  <a href="https://arxiv.org/abs/1705.00106" target="_blank" rel="external">Learning to Ask: Neural Question Generation for Reading Comprehension</a>，就是用一个基本的 attention-based seq2seq 模型对 P(q|d) 进行建模，并在 encoder 引入了句子和段落级的编码。</p>
<p>这一篇 Microsoft Maluuba 出的 paper 把 answer 作为先验知识，对 P(q|d, a) 进行建模。同时用监督学习和强化学习结合的方法来训练 QG，先用最大似然预训练一波，然后用 policy gradient 方法进行 fine-tune ，最大化能反映问题质量的一些 rewards。</p>
<h1 id="Encoder-Decoder-Model"><a href="#Encoder-Decoder-Model" class="headerlink" title="Encoder-Decoder Model"></a>Encoder-Decoder Model</h1><p>基础架构是 encoder-decoder，加了 attention mechanism (Bahdanau et al. 2015)和 pointer-softmax coping mechanism (Gulcehre et al. 2016)。</p>
<h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>输入：</p>
<ul>
<li>document $D=(d_1, …, d_n)$</li>
<li>answer $A = (a_1, …, a_m)$</li>
</ul>
<p>$d_i, a_j \in R^{D_e}$ 是词向量。</p>
<p>在文档词向量后面拼了个二维特征表示文档单词是否在答案中出现。然后过 Bi-LSTM 对文档表示进行编码得到 annotation vectors $h_d=(h^d_1,…h^d_n)$，$h^d_i \in R^D_h$, $h^d_i$ 是每一时刻前向和后向 hidden state 的拼接。</p>
<p>接着对 answer 编码。主要根据 answer 在 document 的位置找到对应的 annotation vector，然后把它和 answer 的词向量拼接起来也就是 $[h^d_j;a_j], s&lt;=j &lt;=e$，s,e 表示 answer 在 document 的起始结束位置，经过第二个 biLSTM 得到 $h^a \in R^{D_h}$，$h_a$ 是两个方向 final hidden state 的拼接。</p>
<p>计算 decoder 的初始状态 $s_0 \in R^D_s$</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/decoder_s0.png" class="ful-image" alt="decoder_s0.png">
<p>$L \in R^{D_h * D_h}, W_0 \in R^{D_s * D_h}, b_0 \in R^{D_s}$</p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>解码器产生输出，输出单词从 $p_\theta(y_t|y_{&lt;t}, D, A)$ 分布中得到。</p>
<p>为了在问句中直接产生文档中的一些短语和实体，在 decoder 的时候采用了 pointer-softmax，也就是两个输出层，shortlist softmax 和 location softmax，shortlist softmax 就是传统的 softmax，产生 predefined output vocabulary，对应 copynet 中的 generate-mode，location softmax 则表示某个词在输入端的位置，对应 copynet 中的 copy-mode。</p>
<p>Decoder：<br>$$s_t=LSTM(s_{t-1}, y_{t-1}, v_t)$$<br>$v_t$ 是从 document 和 answer encoding 计算得到的 context vector，用了 attention 机制，$a_{tj}$ 同时可以用作location softmax。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/decoder_attn.png" class="ful-image" alt="decoder_attn.png">
<p>context vector:<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/decoder_context_vec.png" class="ful-image" alt="decoder_context_vec.png"></p>
<p>shortlist softmax vector $o_t$ 用了 deep output layer (Pascanu et al., 2013)<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/decoder_deep_output.png" class="ful-image" alt="decoder_deep_output.png"></p>
<p>最后的 $p_t \in R^{|V|+|D|}$ 由 $z_t$ 对两个 softmax 输出进行加权和拼接得到。$z_t$ 由 MLP 产生，输入也是 $s_t, v_t, y_{t-1}$，两个隐层然后输出层 sigmoid 激活得到 $z_t$。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/decoder_output.png" class="ful-image" alt="decoder_output.png"></p>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>三个 loss:</p>
<ol>
<li>negative log-likelihood<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/loss1.png" class="ful-image" alt="loss1.png">
用了 teacher forcing，也就是 $y_{t-1}$ 不是从模型输出得到的，而是来自 source sequence</li>
<li>not to generate answer words in question<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/loss2.png" class="ful-image" alt="loss2.png">
$\hat a$ 表示在 answer 中出现但没有在 groud-truth question 中出现的单词</li>
<li>Variety<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/loss3.png" class="ful-image" alt="loss3.png">
最大化信息熵来鼓励输出多样性</li>
</ol>
<h1 id="Policy-Gradient-Optimization"><a href="#Policy-Gradient-Optimization" class="headerlink" title="Policy Gradient Optimization"></a>Policy Gradient Optimization</h1><p>Teacher forcing 会带来一个问题，训练阶段和测试阶段的结果会存在很大差异。在训练阶段，tearcher force 使得模型不能从错误中学习，因为最大化 groud-truth likelihood 并不能教模型给没有 groud-truth 的 example 分配概率。于是就有了 RL 方法。在预训练一波 maximum likelihood 之后，使用一些和问题质量相关的 rewards，来进行 policy gradient optimzation。</p>
<h2 id="Rewards"><a href="#Rewards" class="headerlink" title="Rewards"></a>Rewards</h2><ol>
<li><strong>Question answering</strong><br>好的问题能被回复<br>把 model-generated question 喂给预训练好的 QA 系统（论文用的 MPCM 模型），然后用 QA 系统的 accuracy（比如 F1） 作为 reward<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/reward_qa.png" class="ful-image" alt="reward_qa.png"></li>
<li><strong>Fluency (PPL)</strong><br>是否符合语法，过一个语言模型计算 perplexity<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/reward_ppl.png" class="ful-image" alt="reward_ppl.png"></li>
<li><strong>Combination</strong><br>两者加权<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/reward_comb.png" class="ful-image" alt="reward_comb.png">
</li>
</ol>
<h2 id="Reinforce"><a href="#Reinforce" class="headerlink" title="Reinforce"></a>Reinforce</h2><p>“loss”:<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/reinforce_loss.png" class="ful-image" alt="reinforce_loss.png"></p>
<p>$\pi$ 是要训练的 policy，是action 的概率分布，action space 就是 decoder output layer 的词汇表，可以通过 beam-search 采样选择 action，采样结果通过 decoder teacher-force 还原得到 state，计算 reward 进行梯度更新。</p>
<p>Policy gradient:<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/reinforce_gradient.png" class="ful-image" alt="reinforce_gradient.png"></p>
<h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>Baseline Seq2Seq 可以产生更符合语法更流畅的英文问题，但是语义可能更加模糊，这篇 paper 提出的系统可以产生更具体的问题，虽然没那么流畅。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/evaluation.png" class="ful-image" alt="evaluation.png"></p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Machine%20Comprehension%20by%20Text-to-Text%20Neural%20Question%20Generation/examples.png" class="ful-image" alt="examples.png">
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继续来瞅瞅问题生成~&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Machine Comprehension" scheme="http://www.shuang0420.com/tags/Machine-Comprehension/"/>
    
      <category term="阅读理解" scheme="http://www.shuang0420.com/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
      <category term="Question Generation" scheme="http://www.shuang0420.com/tags/Question-Generation/"/>
    
      <category term="问题生成" scheme="http://www.shuang0420.com/tags/%E9%97%AE%E9%A2%98%E7%94%9F%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Making Neural QA as Simple as Possible but not Simpler（FastQA）</title>
    <link href="http://www.shuang0420.com/2018/05/13/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/"/>
    <id>http://www.shuang0420.com/2018/05/13/论文笔记 - Making Neural QA as Simple as Possible but not Simpler/</id>
    <published>2018-05-13T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>阅读理解系列的框架很多大同小异，但这篇 paper 真心觉得精彩，虽然并不是最新最 state-of-art~<br><a id="more"></a></p>
<p>现在大多数的阅读理解系统都是 top-down 的形式构建的，也就是说一开始就提出了一个很复杂的结构（一般经典的就是 <strong>emedding-, encoding-, interaction-, answer-layer</strong>），然后通过 ablation study，不断的减少一些模块配置来验证想法，大多数的创新点都在 interaction 层。而这篇 paper 提供了抽取式 QA 基于神经网络的两个 baseline，BoW- 和 RNN-based nerual QA (FastQA) ，创新的以 bottom-up 的方式分析了框架复杂性以及主流 interaction layer 的作用。</p>
<p>一个基本认识，构建好的 QA 系统必不可少的两个要素是：</p>
<ol>
<li>在处理 context 时对 question words 的意识</li>
<li>有一个超越简单的 bag-of-words modeling 的函数，像是 RNN</li>
</ol>
<p>另外，作者还发现了很多看似复杂的问题其实通过简单的 context/type matching heruistic 就可以解出来了，过程是选择满足条件的 answer spans：</p>
<ol>
<li><strong>与 question 对应的 answer type 匹配</strong><br>比如说问 when 就回答 time</li>
<li><strong>与重要的 question words 位置上临近</strong><br>如下图的 St. Kazimierz Church</li>
</ol>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/heuristic.png" class="ful-image" alt="heuristic.png">
<p>FastQA 的表现对额外的复杂度，尤其是 interaction 的复杂交互，提出了质疑。</p>
<h1 id="A-BoW-Neural-QA-System"><a href="#A-BoW-Neural-QA-System" class="headerlink" title="A BoW Neural QA System"></a>A BoW Neural QA System</h1><p>比照传统思路来构建。</p>
<ol>
<li><strong>Embedding</strong><br>词向量和字向量的拼接，字向量用 CNN 进行训练，$x=[x^w; x^c] \in R^d$</li>
<li><strong>Type matching</strong><br>抽取 question words 得到 lexical answer type(LAT)。抽哪些？<ul>
<li>who, when, why, how, how many, etc.</li>
<li>what, which 后面的第一个名词短语，如 what year did…<br>将 LAT 的第一个和最后一个单词的 embedding，以及 LAT 所有单词的平均的 embedding 拼接起来，再通过全连接层和 tanh 做一个非线性变换得到 $\hat z$。<br>用同样方法对每个 potential answer span(s, e) 做编码。所有 span，最长为 10 个单词，同样把 span 里第一个和最后一个单词的 embedding 和所有单词的 embedding 进行拼接，又因为 potential answer span 周围的单词会对 answer span type 提供线索（比如上文提到的 St. Kazimierz Church），所以额外的拼接了 span 往左、往右 5 个单词的平均 embedding，这样一共就是 5 个 embedding，接 FC 层和 tanh 非线性变换，得到 $\hat x_{s,e}$<br>最后，拼接 LAT 和 span 的表示，$[\hat z; \hat x_{s, e}; \hat z \ ☉ \ \hat x_{s,e}]$，用一个前馈网络计算每个 span(s,e) 和 LAT 的分数 $g_{type}(s,e)$</li>
</ul>
</li>
<li><strong>Context Matching</strong><br>引入两个 word-in-question 特征，对 context 中的每个单词 $x_j$<ul>
<li><strong>binary</strong><br>$wiq^b$ ，如果 $x_j$ 出现在了 question 中，就为 1，否则为 0</li>
<li><strong>weighted</strong><br>计算 $q_i$ 和 $x_j$ 的词向量相似性<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/weighted_wiq.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/weighted_wiq.png">
Softmax 保证了 infrequent occurrences of words are weighted more heavily.<br>对每个 answer span(s,e)，计算往左、往右 5/10/20 token-windows 内 $wiq^b$ 和 $wiq^w$ 的平均分数，也就是计算 2(kind of features) <em> 3(windows) </em> 2(left/right)=12个分数的加权和得到 context-matching score $g_{ctxt}(s,e)$，各分数的权重由训练得到</li>
</ul>
</li>
<li><strong>Answer span scoring</strong><br>最后每个 span(s,e) 的分数就是 type matching score 和 context matching score 的和<br>$$g(s,e)=g_{type}(s,e)+g_{ctxt}(s,e)$$</li>
</ol>
<p>最小化 softmax-cross-entropy loss 进行训练。</p>
<h1 id="FastQA"><a href="#FastQA" class="headerlink" title="FastQA"></a>FastQA</h1><p>上面的方法中语义特征完全被缩减成了 answer-type 和 word-in-question features，另外 answer span 也受到了长度限制，对语义的捕捉很弱。</p>
<p>BiRNN 在识别 NER 上面非常有优势，context matching 也可以通过给 BiRNN 喂 wiq-features 得到，answer-type 会间接由网络学习得到。</p>
<p>模型相对简单，就三层 <strong>embedding-, encoding-, answer layer</strong>。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/fastQA.png" class="ful-image" alt="fastQA.png">
<ol>
<li><strong>Embedding</strong><br>和 BoW baseline 相同。</li>
<li><strong>Encoding</strong><br>为了让 question 和 context embedding 可以交互，先映射到 n 维向量，再过一个 highway layer。<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/encoding1.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/encoding1.png">
然后加上 wiq features<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/encoding2.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/encoding2.png">
再一起过一个 BiRNN，输出再做个 projection<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/encoding3.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/encoding3.png">
初始化 project matrix B 为 $[I_n; I_n]$，$I_n$ 是 n 维的 identity matrix，H 是 forawrd 和 backward LSTM 的输出的加和。<br>question 和 context 的参数共享，question 对应的两个 wiq 特征设为 1。projection matrix B 不共享。</li>
<li><strong>Answer layer</strong><br>context x $H=[h_1,…,h_{L_X}]$<br>question Q $Z=[Z_1,…Z_{L_Q}]$<br>对 Z 做一个变换，同样是 context-independent<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/answer1.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/answer1.png">
answer 的开始位置的概率 $p_s$ 由 2 个前馈网络加一个 ReLU 激活得到。<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/answer2.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/answer2.png">
结束位置：<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/answer3.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/answer3.png">
$$p(s,e)=p_s(s)•p_e(e|s)$$</li>
</ol>
<p>最小化 p(s,e) 的交叉熵来训练。</p>
<p>在预测的时候，可以用 beam-search。</p>
<h1 id="FastQA-Extended"><a href="#FastQA-Extended" class="headerlink" title="FastQA Extended"></a>FastQA Extended</h1><p>相当于主流模型的 <strong>interaction layer</strong>。对当前的 context state，考虑和剩下的 context（intra）或者和 question（inter）做注意力计算，将其余 context/question 的信息融入当前 context。</p>
<ul>
<li><strong>Intra-fustion</strong><br>between passages of the context</li>
<li><strong>Inter-fusion</strong><br>between question and context</li>
</ul>
<p>实验结果：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/res1.png" class="ful-image" alt="res1.png"></p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/res2.png" class="ful-image" alt="res2.png">
<p>一些小结论：</p>
<ol>
<li>简单的 $wiq^b$ 特征能大幅度提升 performance，原因是让 encoder 有了真实 question 的部分知识后，encoder 就可以有选择性的追踪问题相关的信息并进一步将具体的实体抽象为对应的类型，如果在问题中提到了人名，那么 context encoder 就会记住 “question-person” 而不是具体名字。</li>
<li>Beam-search 可以微弱提升结果，因为最可能的开始位置不一定是最好的 answer span</li>
<li>额外的 character embedding 对结果有显著提升</li>
<li>进一步的 fusion 对结果也有帮助，但并没有那么显著</li>
</ol>
<p>讨论 <strong>Do we need additional interaction?</strong><br>对比试验，FastQA 与 FastQAExt 和 DCN 相比，快两倍，而且少 2-4 倍的显存。分析了结果发现 FastQAExt 泛化能力更强些，但并没有 systematic advantage，并不会对某类问题（主要分析了推理）有一致性的提升。</p>
<h1 id="Qualitative-Analysis"><a href="#Qualitative-Analysis" class="headerlink" title="Qualitative Analysis"></a>Qualitative Analysis</h1><p>对 FastQA 的错误结果进行了一些分析，大部分的错误来自：</p>
<ol>
<li>缺乏对句法结构的理解</li>
<li>不同词位相似语义的词的细粒度语义之间的区分</li>
</ol>
<p>其他很多的错误也是来自人工标注偏好。</p>
<p>举了一些典型的错误例子，像 例1 是缺乏对某些答案类型的细化理解。例2 缺乏指代消解和上下文缩略语的认识，例3 模型有时难以捕捉基本的句法结构，尤其是对于重要的分隔符如标点符号和连词被忽略的嵌套句子</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Making%20Neural%20QA%20as%20Simple%20as%20Possible%20but%20not%20Simpler/error.png" class="ful-image" alt="error.png">
<p>现有 top-down 模型用到实际业务当中通常需要为了 fit 进显存或者是满足一定的响应时间而进行模型的各种简化，FastQA 在显存占用和响应速度上有着绝对优势，感觉还是非常有意义的~</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;阅读理解系列的框架很多大同小异，但这篇 paper 真心觉得精彩，虽然并不是最新最 state-of-art~&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Machine Comprehension" scheme="http://www.shuang0420.com/tags/Machine-Comprehension/"/>
    
      <category term="阅读理解" scheme="http://www.shuang0420.com/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
      <category term="FastQA" scheme="http://www.shuang0420.com/tags/FastQA/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Semi-Supervised QA with Generative Domain-Adaptive Nets</title>
    <link href="http://www.shuang0420.com/2018/04/07/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/"/>
    <id>http://www.shuang0420.com/2018/04/07/论文笔记 - Semi-Supervised QA with Generative Domain-Adaptive Nets/</id>
    <published>2018-04-07T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>GDAN，Question Generation 和 Question Answering 相结合，利用少量的有标注的 QA 对 + 大量的无标注的 QA 对来训练 QA 模型。<br><a id="more"></a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>看到这篇论文，看到来自 CMU，就忍不住推测作者估计是 LTI 的，估计还上过 411/611/711，毕竟 idea 和 final project 太像了。。</p>
<p>回顾下 CMU 11411/611/711 的 final project，项目是阅读理解，分为 Asking System 和 Answering System 两个子系统。17年初的时候，Alan 鼓励用课上学到的东西 &amp; 隐晦的不鼓励用 DL，anyway 那时候也并没有看到用 DL 做 QG 的 paper，网上唯几和 QG 相关的 paper 都是 CMU 的，估计和这门课相辅相成。</p>
<p>611 的 asking system 和 answering system 都没有标注，只是纯粹的 wiki 文本，asking system 基于 document 产生 question 以及 answer，answering system 根据 question 和 document 产生 answer。具体见之前的两篇博文：<br><a href="http://www.shuang0420.com/2017/03/02/NLP%20%E7%AC%94%E8%AE%B0%20-%20Question%20Answering%20System/">NLP 笔记 - Question Answering System</a><br><a href="http://www.shuang0420.com/2017/04/06/QA%20system%20-%20Question%20Generation/">QA system - Question Generation</a></p>
<p>因为没有标注，所以两个系统其实是相互补充相互促进的。如果产生的 question 太简单，和原文太过相近，那么 answering system 的泛化能力有可能就很差，而如果 question 太难，answering system 也就学很难学习很难训练。</p>
<p>评价产生的 question 的好坏的标准除了流畅、符合语法等基于 question 本身的特点外，我们还希望好的问题能找到答案，这些逻辑在这篇论文中都有所体现。</p>
<p>回到 paper，主要思想其实就是用 <strong>少量的有标注的 QA 对 + 大量的无标注的 QA 对</strong> 来训练 QA 模型。主要做法是，给部分 unlabelled text，用 tagger 抽一些答案，训练 generative model 来生成对应的问题，然后补充训练集，再训练 QA model。实际是用改进的 GAN 方法来构建一个半监督问答模型。</p>
<h1 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h1><h2 id="Generative-Model-seq2seq-with-attention-and-copy"><a href="#Generative-Model-seq2seq-with-attention-and-copy" class="headerlink" title="Generative Model - seq2seq with attention and copy"></a>Generative Model - seq2seq with attention and copy</h2><p>对 P(q|p,a) 进行建模。输入是 unlabelled text p 和从中抽取的答案 a，输出是 q，或者说 (q, p, a)。答案 a 的抽取依赖 POS tagger + constituency parser + NER tagger。生成模型这里用的是 <strong>seq2seq model</strong>(Sutskever et al., 2014) + <strong>copy mechanism</strong>(Gu et al., 2016; Gulcehre et al., 2016)。</p>
<p>Encoder 用一个 GRU 把 paragraph 编码成 sequence of hidden states H。注意论文在 paragraph token 的词向量上加了额外的一维特征来表示这个词是否在答案中出现，如果出现就为 1，否则为 0。<br>Decoder 用另一个 GRU + Attention 对 H 进行解码，在每一个时刻，生成/复制单词的概率是：</p>
<p>$$P_{overall} = g_tp_{vocab}+(1-g_t)p_{copy}$$<br>$$g_t=\sigma(w^T_gh_t)$$</p>
<p>具体细节不多说了，相关可以看 Copy or Generate。</p>
<p>生成模型 G 产生的 (q, p, a) 作为判别模型的输入。</p>
<h2 id="Discriminative-Model-gated-attention-reader"><a href="#Discriminative-Model-gated-attention-reader" class="headerlink" title="Discriminative Model - gated-attention reader"></a>Discriminative Model - gated-attention reader</h2><p>对 P(a|p,q)进行建模。输入是人为标注数据 L 以及模型产生的数据 U，由于 L 和 U 来自不同分布，所以引入了 domain tag 来区分两类数据，“true”来表示人为标记数据 L，“gen”标签来表示模型生成数据 U（Johnson et al., 2016; Chu et al., 2017）。在测试时，只加入 d_true。</p>
<p>论文这里用了 GA (gated-attention) Reader 作为基本结构，也是 CMU 出的模型，当然事实上别的模型也可以。模型很简单，embedding 层用词向量，encoder 层用双向 GRU 分别得到 $H_q$ 和 $H^k_p$，context-query attention 层用 gated attention($H^k_p$, $H_q$ 做 element-wise 乘法)做下一层网络的输入，重复进入 encoder 和 attention 层进行编码和乘法（共 k 层），最后将 p, q 做內积（inner product）得到一个最终向量输入 output 层，output 层用两个 softmax 分别预测答案在段落中的起始和结束位置。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/GA_reader.png" class="ful-image" alt="GA_reader.png">
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>整体的目标函数：</p>
<p>$$max_D \ J(L, d_{true, D})+ J(U_G, d_{gen}, D)$$<br>$$max_G \ J(U_G, d_{true}, D)$$</p>
<h2 id="Training-Algorithm"><a href="#Training-Algorithm" class="headerlink" title="Training Algorithm"></a>Training Algorithm</h2><p>主要要解决下面两个问题。</p>
<h3 id="Issue-1-discrepancy-between-datasets"><a href="#Issue-1-discrepancy-between-datasets" class="headerlink" title="Issue 1: discrepancy between datasets"></a>Issue 1: discrepancy between datasets</h3><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/issue1.png" class="ful-image" alt="issue1.png">
<p>如上，判别模型很容易在 U 上 overfit，所以才用了 domain tag 做区分。</p>
<h3 id="Issue-2-jointly-train-G-and-D"><a href="#Issue-2-jointly-train-G-and-D" class="headerlink" title="Issue 2: jointly train G and D"></a>Issue 2: jointly train G and D</h3><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/issue2.png" class="ful-image" alt="issue2.png">
<p>如上，如果用 auto-encoder，容易让 question 和 answer 的表达非常接近，question 甚至可能完全 copy answer，所以这里用了判别模型。</p>
<blockquote>
<p>Intuitively, the goal of G is to generate “useful” questions where the usefulness is measured by the probability that the generated questions can be answered correctly by D</p>
</blockquote>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/issue22.png" class="ful-image" alt="issue22.png">
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/model.png" class="ful-image" alt="model.png">
<p>分两个阶段：<br><strong>第一阶段:</strong> 固定 G，利用 d_true 和 d_gen，用 SGD 来更新 D。在 L 上计算 MLE 来完成 G 的初始化，对 D 进行随机初始化。<br><strong>第二阶段:</strong> 固定 D，利用 d_true，用 RL 和 SGD 更新 G。由于 G 的输出是不可导的，所以用到了 reinforce algorithm。action space 是长度为 T’ 的所有可能的 questions，reward 是 $J(U_G,d_{true}, D)$。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets/algo.png" class="ful-image" alt="algo.png">
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>QANet 那篇论文中提到了另一篇 Question Generation 的论文：</p>
<blockquote>
<p>Zhou et al. (2017) improved the diversity of the SQuAD data by generating more questions. However, as reported by Wang et al. (2017), their method did not help improve the performance.</p>
</blockquote>
<p>相信 GDAN 在一定程度上一定能缓解 QA 中标注数据稀少的问题，但是能否在数据较为充足，模型较为优势的情况下提升 performance，估计难说，下次尝试后再来填这个坑了。Anyway，看到了曾经思考过的问题有人做出了实践还是万分开心的~</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;GDAN，Question Generation 和 Question Answering 相结合，利用少量的有标注的 QA 对 + 大量的无标注的 QA 对来训练 QA 模型。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Machine Comprehension" scheme="http://www.shuang0420.com/tags/Machine-Comprehension/"/>
    
      <category term="阅读理解" scheme="http://www.shuang0420.com/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
      <category term="Question Generation" scheme="http://www.shuang0420.com/tags/Question-Generation/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Bi-Directional Attention Flow for Machine Comprehension</title>
    <link href="http://www.shuang0420.com/2018/04/01/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Bi-Directional%20Attention%20Flow%20for%20Machine%20Comprehension/"/>
    <id>http://www.shuang0420.com/2018/04/01/论文笔记 - Bi-Directional Attention Flow for Machine Comprehension/</id>
    <published>2018-04-01T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>BiDAF，相对复杂 attention 机制。<br><a id="more"></a></p>
<p><strong>论文：</strong> <a href="https://arxiv.org/abs/1611.01603" target="_blank" rel="external">Bidirectional Attention Flow for Machine Comprehension</a><br><strong>代码：</strong> <a href="https://github.com/allenai/bi-att-flow" target="_blank" rel="external">allenai/bi-att-flow</a></p>
<h1 id="Attention-Summary"><a href="#Attention-Summary" class="headerlink" title="Attention Summary"></a>Attention Summary</h1><p>这篇论文主要对 attention 机制做了改进，为此作者总结了 MC 任务上过去常用的三类 attention：</p>
<ol>
<li><strong>Attention Reader。</strong>通过动态 attention 机制从文本中<strong>提取相关信息（context vector）</strong>，再依据该信息给出预测结果。<br>代表论文：Bahdanau et al. 2015, Hermann et al. 2015, Chen et al. 2016, Wang &amp; Jiang 2016</li>
<li><strong>Attention-Sum Reader。</strong>只计算一次 attention weights，然后直接喂给输出层做最后的预测，也就是利用 attention 机制直接获取文本中各位置作为答案的概率，和 pointer network 类似的思想，效果很依赖对 query 的表示<br>代表论文：Kadlec et al. 2016, Cui et al. 2016</li>
<li><strong>Multi-hop Attention</strong>。计算多次 attention<br>代表论文：<a href="http://www.shuang0420.com/2017/12/04/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/">Memory Network(Weston et al., 2015)</a>，Sordoni et al., 2016; Dhingra et al., 2016., Shen et al. 2016.</li>
</ol>
<p>在此基础上，作者对注意力机制做出了改进，具体 BiDAF attention 的特点如下：</p>
<ol>
<li>并没有把 context 编码进固定大小的 vector，而是让 vector 可以流动，减少早期加权和的信息损失</li>
<li>Memory-less，在每一个时刻，仅仅对 query 和当前时刻的 context paragraph 进行计算，并不直接依赖上一时刻的 attention，这使得后面的 attention 计算不会受到之前错误的 attention 信息的影响</li>
<li>计算了 query-to-context（Q2C） 和 context-to-query（C2Q）两个方向的 attention 信息，认为  C2Q 和 Q2C 实际上能够相互补充。实验发现模型在开发集上去掉 C2Q 与 去掉 Q2C 相比，分别下降了 12 和 10 个百分点，显然 C2Q 这个方向上的 attention 更为重要</li>
</ol>
<h1 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h1><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Bi-Directional%20Attention%20Flow%20for%20Machine%20Comprehension/bidaf.png" class="ful-image" alt="bidaf.png">
<p><strong>论文提出的是六层结构：</strong><br><strong>Character Embedding Layer -&gt; Word Embedding Layer -&gt; Contextual Embedding Layer -&gt; Attention Flow Layer -&gt; Modeling Layer -&gt; Output Layer</strong></p>
<p>然而我还是压缩成五层结构来讲吧：</p>
<ol>
<li><strong>Input embedding layer</strong> = Character Embedding Layer + Word Embedding Layer<br>和其他模型差不多，word embedding + character embedding，预训练词向量，OOV 和字向量可训练，字向量用 CNN 训练<br>单词 w 的表示由词向量和字向量的拼接然后经过两层 highway network 得到，得到 context vector $X \in R^{d*T}$ 和 query vector $Q \in R^{d*J}$</li>
<li><strong>Embedding encoder layer</strong> = Contextual Embedding Layer<br>对上一步的结果 X 和 Q 分别使用 Bi-LSTM 编码，捕捉 X 和 Q 各自单词间的局部关系，拼接双向 LSTM 的输出，得到 $H \in R^{2d*T}$ 和 $U \in R^{2d*J}$<br>这前面的两层（or 原文三层）用来捕捉 query 和 context 各自不同粒度（character, word, phrase）上的特征</li>
<li><p><strong>Context-query attention layer</strong> = Attention Flow Layer</p>
<blockquote>
<p>The attention flow layer is not used to summarize the query and context into single feature vectors. instead, the attention vector at each time step, along with the embeddings from previous layers, are allowed to <strong>flow through to the subsequent modeling layer</strong>. This reduces the information loss caused by early summarization.</p>
</blockquote>
<p>输入是 H 和 U，输出是 context words 的 query-aware vector G，以及上一层传下来的 contextual embeddings。做 context-to-query 以及 query-to-context 两个方向的 attention。做法还是一样，先计算相关性矩阵，再归一化计算 attention 分数，最后与原始矩阵相乘得到修正的向量矩阵。<br>c2q 和 q2c 共享相似度矩阵，$S \in R^{T*J}$，相似度计算方式是：<br>$$S_{tj}=\alpha(H_{:t}, U_{:j}) \in R$$<br>$$\alpha(h,u)=w^T_{(S)}[h;u;h⊙u]$$<br>$S_{tj}$ : 第 t 个 context word 和第 j 个 query word 之间的相似度<br>$\alpha$: scalar function<br>$H_{:t}$: H 的第 t 个列向量<br>$U_{:j}$：U 的第 j 个列向量<br>⊙：element-wise multiplication<br>[;]：向量在行上的拼接</p>
<ul>
<li><strong>context-to-query attention(C2Q):</strong> 计算对每一个 context word 而言哪些 query words 和它最相关。前面得到了相关性矩阵，现在 softmax 对列归一化然后计算 query 向量加权和得到 $\hat U$<br>$$a_t=softmax(S_{t:}) \in R^J$$<br>$$\hat U_{:t}=\sum_ja_{tj}U_{:j}$$</li>
<li><strong>query-to-context attention(Q2C):</strong> 计算对每一个 query word 而言哪些 context words 和它最相关，这些 context words 对回答问题很重要。取相关性矩阵每列最大值，对其进行 softmax 归一化计算 context 向量加权和，然后 tile T 次得到 $\hat H \in R^{2d*T}$。<br>$$b=softmax(max_{col}(S)) \in R^T$$<br>$$\hat h=\sum_tb_tH_{:t} \in R^{2d}$$<br>$\hat U$ 和 $\hat H$ 都是 2dxT 的矩阵<br>将三个矩阵拼接起来得到 G<br>$$G_{:t}=\beta (H_{:t}, \hat U_{:t}, \hat H_{:t}) \in R^{d_G}$$<br>$\beta$ 可以是多层 perceptron，不过如上简单的拼接效果也不错。<br>$$\beta(h, \hat u, \hat h)=[h;\hat u; h⊙\hat u; h⊙\hat h] \in R^{8d*T}$$<br>于是就得到了 context 中单词的 query-aware representation。</li>
</ul>
</li>
<li><strong>Model encoder layer</strong> = Modeling Layer<br>输入是 G，再经过一次 Bi-LSTM 得到 $M \in r^{2D * T}$，捕捉的是 interaction among the context words conditioned on the query<br>M 的每一个列向量都包含了对应单词关于整个 context 和 query 的上下文信息</li>
<li><p><strong>Output layer</strong><br>预测开始位置 p1 和结束位置 p2<br>$$p_1=softmax(W^T_{(p^1)}[G; M]), \ \ \ p_2=softmax(W^T_{(p^2)}[G; M^2])$$<br>M 再经过一个 Bi-LSTM 得到 $M^2 \in R^{2d * T}$，用来得到结束位置的概率分布</p>
<p>​<br>最后的目标函数：<br>$$L(\theta)=-{1 \over N} \sum^N_i[log(p^1_{y_i^1})+log(p^2_{y_i^2})]$$<br>$y^1_i$ 和 $y^2_i$ 分别是第 i 个样本的 groundtruth 的开始和结束位置</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;BiDAF，相对复杂 attention 机制。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Machine Comprehension" scheme="http://www.shuang0420.com/tags/Machine-Comprehension/"/>
    
      <category term="阅读理解" scheme="http://www.shuang0420.com/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
      <category term="BiDAF" scheme="http://www.shuang0420.com/tags/BiDAF/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution</title>
    <link href="http://www.shuang0420.com/2018/03/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Fast%20and%20Accurate%20Reading%20Comprehension%20by%20Combining%20Self-Attention%20and%20Convolution/"/>
    <id>http://www.shuang0420.com/2018/03/25/论文笔记 - Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution/</id>
    <published>2018-03-25T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>CMU &amp; Google 出品的 Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution，SQuAD 榜单上对应模型 QANet，这名字是不是太随意了TAT…<br><a id="more"></a></p>
<h1 id="Fast-and-Accurate-Reading-Comprehension-by-Combining-Self-Attention-and-Convolution"><a href="#Fast-and-Accurate-Reading-Comprehension-by-Combining-Self-Attention-and-Convolution" class="headerlink" title="Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution"></a>Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution</h1><p>CMU 和 Google Brain 新出的文章，SQuAD 目前的并列第一，两大<strong>特点：</strong></p>
<ol>
<li><strong>模型方面创新的用 CNN+attention 来完成阅读理解任务</strong><br> 在编码层放弃了 RNN，只采用 CNN 和 self-attention。CNN 捕捉文本的局部结构信息（ local interactions），self-attention 捕捉全局关系（ global interactions），在没有牺牲准确率的情况下，加速了训练（训练速度提升了 3x-13x，预测速度提升 4x-9x）</li>
<li><strong>数据增强方面通过神经翻译模型（把英语翻译成外语（德语/法语）再翻译回英语）的方式来扩充训练语料，增加文本多样性</strong></li>
</ol>
<p>其实目前多数 NLP 的任务都可以用 word vector + RNN + attention 的结构来取得不错的效果，虽然我挺偏好 CNN 并坚定相信 CNN 在 NLP 中的作用（捕捉局部相关性&amp;方便并行），但多数情况下也是跟着主流走并没有完全舍弃过 RNN，这篇论文还是给了我们很多想象空间的。</p>
<h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Fast%20and%20Accurate%20Reading%20Comprehension%20by%20Combining%20Self-Attention%20and%20Convolution/cnn_self_attention.png" class="ful-image" alt="cnn_self_attention.png">
<p>先看模型，在 BiDAF 基础上的一些改进，主要在 embedding encoder 层。还是阅读理解经典五层结构：</p>
<ol>
<li><strong>Input embedding layer</strong><br>和其他模型差不多，word embedding + character embedding，预训练词向量，OOV 和字向量可训练，字向量用 CNN 训练<br>单词 w 的表示由词向量和字向量的拼接 $[x_w; x_c] \in R^{p_1+p_2}$然后经过两层 highway network 得到，这个和 BiDAF 相同</li>
<li><strong>Embedding encoder layer</strong><br>重点是这一层上的改变，由几个基本 block 堆叠而成，每个 block 的结构是：<br><strong>[convolution-layer x # + self-attention-layer + feed-forward-layer]</strong><br>卷积用的 <strong>separable convolutions</strong> 而不是传统的 convolution，因为更加 memory efficient，泛化能力也更强。核心思想是将一个完整的卷积运算分解为 <strong>Depthwise Convolution</strong> 和 <strong>Pointwise Convolution</strong> 两步进行，两幅图简单过一下概念<br>先做 depthwise conv， 卷积在二维平面进行，filter 数量等于上一次的 depth/channel，相当于对输入的每个 channel 独立进行卷积运算，然后就结束了，这里没有 ReLU<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Fast%20and%20Accurate%20Reading%20Comprehension%20by%20Combining%20Self-Attention%20and%20Convolution/depth_conv.png" class="ful-image" alt="depth_conv.png">
然后做 pointwsie conv，和常规卷积相似，卷积核尺寸是 1x1xM，M 为上一层的 depth，相当于将上一步depthwise conv 得到的 map 在深度上进行加权组合，生成新的 feature map<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Fast%20and%20Accurate%20Reading%20Comprehension%20by%20Combining%20Self-Attention%20and%20Convolution/pointwise_conv.png" class="ful-image" alt="pointwise_conv.png">
<strong>Self-attention-layer</strong> 用的是多头注意力机制（head=8），常用的也不多说了。<br>注意的是这里每个基本运算（conv/self-attention/ffn）之间是 <strong>残差连接</strong>，对输入 x 和操作 f，输出是 f (layernorm(x))+x，也就是说某一层的输出能够直接跨越几层作为后面某一层的输入，有效避免了信息损失<br>4 个卷积层，1 个 encoding block</li>
<li><strong>Context-query attention layer</strong><br>几乎所有 machine reading comprehension 模型都会有，而这里依旧用了 context-to-query 以及 query-to-context 两个方向的 attention，先计算相关性矩阵，再归一化计算 attention 分数，最后与原始矩阵相乘得到修正的向量矩阵。相似度函数这里用的<br>$$f(q,c)=W_0[q,c,q⊙c]$$<br>对行、列分别做归一化得到 S’ 和 S’’，最后 context-to-query attention 就是 $A=S’Q^T$，query-to-context attention 就是 $B=S’S’’^TC^T$，用了 DCN attention 的策略</li>
<li><strong>Model encoder layer</strong><br>和 BiDAF 差不多，不过这里依旧用 CNN 而不是 RNN。这一层的每个位置的输入是 [c, a, c⊙a, c⊙b]，a, b 是 attention 矩阵 A,B 的行，参数和 embedding encoder layer 相同，除了 cnn 层数不一样，这里是每个 block 2 层卷积，一共 7 个 block</li>
<li><strong>Output layer</strong><br>再次和 BiDAF 相同<br>$p1=softmax(W_1[M_0; M_1]), p2=softmax(W_2[M_0; M_2])$<br>目标函数：<br>$$L(\theta)=-{1 \over N} \sum^N_i[log(p^1_{y_i^1})+log(p^2_{y_i^2})]$$<br>其中 $y^1_i$ 和 $y^2_i$ 分别是第 i 个样本的 groundtruth 的开始和结束位置</li>
</ol>
<h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h2><p>CNN 速度快所以有条件用更多的数据来训练啦，然后进一步增强模型的泛化能力啦。这里数据增强的基本 idea 就是通过 NMT 把数据从英文翻译成法文（English-to-French），另一个翻译模型再把法文翻回英文（French-to-English）<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Fast%20and%20Accurate%20Reading%20Comprehension%20by%20Combining%20Self-Attention%20and%20Convolution/data_augmentation.png" class="ful-image" alt="data_augmentation.png"><br>看图说话，对段落中每个句子先用 English-to-French 模型的 beam decoder 得到 k 个法语翻译，然后对每一条翻译，都再经过一个 reversed translation model 的 beam decoder，这最后就得到了 k^2 个改写的句子（paraphrases），然后从这 k^2 个句子中随机选一个</p>
<p>具体到 SQuAD 任务就是 (d,q,a) -&gt; (d’, q, a’)，问题不变，对文档 d 翻译改写，由于改写后原始答案 a 现在可能已经不在改写后的段落 d’ 里了，所以需要从改写后的段落 d’ 里抽取新的答案 a’，采用的方法是计算 s’ 里每个单词和原始答案里 start/end words 之间的 character-level 2-gram score，分数最高的单词就被选择为新答案 a’ 的 start/end word<br>这个方法还可以从 quality 和 diversity 改进，quality 方面用更好的翻译模型，diversity 方面可以考虑引入问题的改写，也可以使用其他的数据增广的方法（Raiman&amp;Miller, 2017）</p>
<p>实验结论是英文语料：法语语料：德语语料是 3:1:1 的比例时效果最好，EM 提升了 1.5，F1 提升了 1.1</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CMU &amp;amp; Google 出品的 Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution，SQuAD 榜单上对应模型 QANet，这名字是不是太随意了TAT…&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Machine Comprehension" scheme="http://www.shuang0420.com/tags/Machine-Comprehension/"/>
    
      <category term="阅读理解" scheme="http://www.shuang0420.com/tags/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/"/>
    
      <category term="BiDAF" scheme="http://www.shuang0420.com/tags/BiDAF/"/>
    
  </entry>
  
  <entry>
    <title>扯扯 Semi-hard Negative Samples</title>
    <link href="http://www.shuang0420.com/2018/03/17/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/"/>
    <id>http://www.shuang0420.com/2018/03/17/扯扯 Semi-hard Negative Samples/</id>
    <published>2018-03-17T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>谈谈排序模型的 negative sampling 问题。取不好题目TAT…<br><a id="more"></a></p>
<p>之前在用 Dual Encoder 这类 ranking model 时，发现在一些问题上尽管大方向上匹配的很好，比如人名问题答的都是人名，歌曲问题回答的都是歌曲名，但是具体到再细的粒度就完全匹配不上了。明明知道这显然是 negative sampling 的问题，却一直没找到好的解决方案，毕竟 google 一下 negative sampling 发现前 5 页都是在讲 word2vec……</p>
<p>感觉这应该算是 ranking 模型中一个非常实际也非常常见的问题。在训练的时候，我们一般不会在整个模板库上进行排序，这样效率太低也容易错，而是会做随机负采样，比如随机选 19 个负样本，和正确答案一起作为候选答案（ranking size=20）。但在实际应用中，又往往需要对整个模板库排序，或者至少要用别的方法召回一批样本（包含正确答案）再进行预测。这样一来，如果训练时随机的负样本太弱太简单（和正确答案差异性很大），而在预测时候选答案又太难太挑战（和正确答案很相似），效果当然就不好了。</p>
<p>当时自己折腾的时候尝试过很多方法，比如扩大 ranking size，多采样负样本，发现收益并不大，也试过先召回一部分和答案相似的样本，再做 reranking，或者在 DE 前或者后加别的 ranking 来进一步缩小范围，也是收效甚微，另外资源限制很多实验都没跑的很完美就暂时把这个问题放下了。直到最近看到了 <a href="https://github.com/tambetm/allenAI" target="_blank" rel="external">tambetm/allenAI</a> 这个，发现这个小哥哥用了一种不错的 negative sampling 的方法，看上去很有道理的样子，借鉴的还是 15 年的工作，哎都怪我读书少之前木有接触过现在才发现(╥﹏╥)</p>
<p>简单来说就是选择难度适当的错误回复（<strong>semi-hard negative samples</strong>）作为负样本，这个 idea 来自 15年 FaceNet 那篇文章，过去瞅了瞅，就从 FaceNet 讲起吧。FaceNet 最大特点应该就是提出了 Triplet Loss 的概念，也就是在向量空间内，希望保证单个个体的图像 $x^a_i (anchor)$和该个体的所有其它图像 $x^p_i(positive)$ 之间的特征距离尽可能的小，而与其它个体的图像 $x^n_i(negitive)$ 之间的特征距离要尽可能的大（差不多就是 LDA 的思路嘛，最大化类间距离最小化类内距离）。</p>
<blockquote>
<p>Here we want to ensure that an image $x^a_i (anchor)$ of a specific person is closer to all other images $x^p_i(positive)$ of the same person than it is to any image  $x^n_i(negitive)$  of any other person.</p>
</blockquote>
<img src="http://images.shuang0420.com/images/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/triple_loss.png" class="ful-image" alt="triple_loss.png">
<p>然后 loss 的设定就是说通过学习，使得类间距离大于类内距离，$\alpha$ 作为 positive/negtive 边界，是一个常量。<br><img src="http://images.shuang0420.com/images/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/triple_loss_for.png" class="ful-image" alt="triple_loss_for.png"></p>
<p>Triplets 显然不能穷举，这样一来筛选 triplets 就很重要，为了最快收敛考虑当然是首选最难区分的图像对了，也就是 hard positive ($argmax_{x^p_i}||f(x^a_i)-f(x^p_i)||^2_2$) 和 hard negative ($argmin_{x^n_i}||f(x^a_i)-f(x^n_i)||^2_2$)。举个例子，如果整体样本集是 1000 个人每个人 40 张图片，给定某个人的图片来选 triple，那么自然选这个人另外 39 张图片中和它最不相似的图片作为 hard positive，以及剩下 40*999 张图片中和它最相似的图片作为 hard negative。</p>
<p>挑选 hard positive 和 hard negative 有 offline (generate triplets every n steps) 和 online (select triplets within a mini-batch) 方法。论文重点聚焦在了 online 方法，在一个大的 mini-batch （1800 个样本）中选择所有的 anchor-positive pairs，同时，来选择一定的 hard anchor-negative pairs，但选择 hardest negatives 在实际当中容易导致在训练最开始的时候就陷入局部最优，所以实际会选择 semi-hard negatives，使挑选样本满足下面的式子：<br><img src="http://images.shuang0420.com/images/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/form.png" class="ful-image" alt="form.png"></p>
<p>这个约束就是 semi-hard。再回过头来看开始的 repo，模型用 RNN 对 question 和 answer 进行编码，然后用 cosine ranking loss，也就是让 question 和 right answer 的 cosine 距离小于 question 和 wrong answer 的 cosine 距离。<br><img src="http://images.shuang0420.com/images/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/cosine_loss.png" class="ful-image" alt="cosine_loss.png"></p>
<p>wrong answer 采用 neagtive sampling，选择难度适当的 wrong answer，或者说选择当前模型能正确分类但是没那么 confident 的 wrong answer。<br><img src="http://images.shuang0420.com/images/%E6%89%AF%E6%89%AF%20Semi-hard%20Negative%20Samples/semi_hard.png" class="ful-image" alt="semi_hard.png"></p>
<p>他们是发现 too hard answer 会使模型难以收敛，而实验表明：</p>
<blockquote>
<p>Semi-hard negative samples, which are further than the right answer, but still within the margin - works best</p>
</blockquote>
<p>参考连接：</p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/24837264" target="_blank" rel="external">谷歌人脸识别系统FaceNet解析</a><br><a href="https://arxiv.org/abs/1503.03832" target="_blank" rel="external">FaceNet: A Unified Embedding for Face Recognition and Clustering</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;谈谈排序模型的 negative sampling 问题。取不好题目TAT…&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="negative sampling" scheme="http://www.shuang0420.com/tags/negative-sampling/"/>
    
      <category term="负采样" scheme="http://www.shuang0420.com/tags/%E8%B4%9F%E9%87%87%E6%A0%B7/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - 基于神经网络的推理</title>
    <link href="http://www.shuang0420.com/2018/03/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%8E%A8%E7%90%86/"/>
    <id>http://www.shuang0420.com/2018/03/05/论文笔记 - 基于神经网络的推理/</id>
    <published>2018-03-05T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>DeepMind Relational Reasoning(RNs)<br><a id="more"></a></p>
<h1 id="Relational-reasoning-RNs"><a href="#Relational-reasoning-RNs" class="headerlink" title="Relational reasoning(RNs)"></a>Relational reasoning(RNs)</h1><ul>
<li>论文：<a href="https://arxiv.org/abs/1706.01427" target="_blank" rel="external">A simple neural network module for relational reasoning(2017)</a></li>
<li>github代码: <a href="https://github.com/siddk/relation-network" target="_blank" rel="external">https://github.com/siddk/relation-network</a></li>
</ul>
<p>关系推理的传统方法有<strong>基于符号的方法（symbolic approaches）</strong>和<strong>基于统计的方法（statistical learning）</strong>。基于符号的方法存在着 symbol grounding 的问题，在小任务（small task）和输入变化（input variations）的问题上也不够鲁棒，学习能力不强；而基于统计的方法像深度学习，虽然泛化能力强，但是对数据稀疏但关系复杂的问题也是束手无策。DeepMind 2017年出的这篇论文提出的<strong>Relation network(RN)</strong>，是用于关系推理（relational reasoning）的一个神经网络模块（NN module），能直接加载到已有的神经网络架构中。与 GNN 等网络结构相比，更为简单和灵活，即插可用（plug-and-play），在一些关系推理的测试上的准确率已经超过了人类。</p>
<h2 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h2><p>RN 的网络结构是真的很简单（不然也不会说是”simple neural network”），以至于通篇下面一个公式就可以概括，核心就是利用神经网络来找出任意 pairwise 对象之间的潜在关系。</p>
<p>$$RN(O) = f_\phi (\sum_{i,j}g_\theta(o_i, o_j))$$</p>
<ul>
<li>Inputs: O={$o_1, …, o_n$}</li>
<li>MLPs: $f_\phi$, $g_\theta$<ul>
<li>$g_\theta$: 使用一个全连接的神经网络来量化 $o_i$ 和 $o_j$ 的关系，任意两个对象之间的关系使用同一套参数 $g_\theta(•,•)$</li>
<li>$f_\phi (\sum_{i,j}g_\theta(o_i, o_j))$: 考虑所有组合的关系，相当于考虑一个完全连接图，在这个图上计算各个边的权重，把重要的关系凸显出来，f 函数就计算了这个重要关系的集合</li>
</ul>
</li>
</ul>
<p>用在自然语言处理里，就是把每个句子当做一个对象，每个句子与句子的 pair 用 g 计算关系，再把所有关系加权和放到最终的预测网络里。</p>
<p>小结一下，RNs有以下三个特点：</p>
<ol>
<li><strong>可以学习推理</strong>。这里 RNs 计算了所有的两个对象之间的关系，当然也可以只计算部分两个对象之间的关系，这里的“部分”需要预定义</li>
<li><strong>RNs的数据效率更高(data efficient)</strong>。RNs 使用一个 gθ 函数来计算所有的关系，任意两个对象之间的关系使用同一套参数，泛化能力更强</li>
<li><strong>RNs作用在一个集合上</strong>，对输入和输出都是与顺序无关的（input/output invariation）</li>
</ol>
<h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><p>简单提一下和 NLP 有关的任务。</p>
<h3 id="VQA"><a href="#VQA" class="headerlink" title="VQA"></a>VQA</h3><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%8E%A8%E7%90%86%20/RN_vqa.png" class="ful-image" alt="RN_vqa.png">
<p>RN 在 VQA 任务上的结构也很简单，CNN 处理图像，LSTM 编码 question，然后两两配对的 spatial cell（红蓝；黄红；蓝黄…）和 question embedding 拼接，后面接几个 FC 层，最后 softmax 得到某个 answer word。</p>
<p>Word-embedding: dim32; LSTM: dim128<br>$g_\theta$: 4-layer MLP, dim256-256-256, RELU<br>$f_\phi$: 3-layer MLP, dim256-256-29, RELU<br>$f_\phi (\sum_{i,j}g_\theta(o_i, o_j, q)$: 综合所有组合 $g_\theta(o_i, o_j;q)$，implicitly 提取有用的组合预测最终答案</p>
<h3 id="bAbI"><a href="#bAbI" class="headerlink" title="bAbI"></a>bAbI</h3><p>RN 在 bAbI 测试集上的结构，每个问题之前的最多 20个句子作为 support set，使用 LSTM-dim32 把 support set 连同每个句子在 set 里的相对位置编码转化为 RN 的 object set，同时使用另一个 LSTM-dim32 的 encoding state 表示问题。</p>
<p>$g_\theta$: 4-layer MLP, dim256-256-256-256<br>$f_\phi$: 3-layer MLP, dim 256-512-159</p>
<p>在 joint training 也就是 20 个任务一起训练一个 QA 模型的情况下，通过了 18/20 bAbI test。DNC 在 path finding 任务上表现不错，但在 basic induction 上误差达到 55.1%，而 RN 达到了 2.1% 的误差水平。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DeepMind Relational Reasoning(RNs)&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Relational reasoning" scheme="http://www.shuang0420.com/tags/Relational-reasoning/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - 从神经图灵机 NTM 到可微分神经计算机 DNC</title>
    <link href="http://www.shuang0420.com/2018/01/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/"/>
    <id>http://www.shuang0420.com/2018/01/20/论文笔记 - 从神经图灵机 NTM 到可微分神经计算机 DNC/</id>
    <published>2018-01-20T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Neural Turing Machine(NTC) 和 Differentiable Neural Machine(DNC) 的相关笔记。<br><a id="more"></a></p>
<p>涉及论文：</p>
<ul>
<li><strong>Neural Turing Machine</strong><br>Neural Turing Machine(2014)</li>
<li><strong>Differentiable Neural Machine</strong><br>Hybrid computing using a neural network with dynamic external memory (2016)</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>当今所有的计算机体系都源自冯诺依曼体系(Von Neumann, 1945)，三大要素：</p>
<ol>
<li><strong>elementary operations</strong><br>基本操作，如加减乘除</li>
<li><strong>logical flow control (branching)</strong><br>逻辑流程控制，如 if-else-then, for, while</li>
<li><strong>external memory</strong><br>外部存储器，内存和硬盘</li>
</ol>
<p>RNN 被认为是 Turing-complete 的，理论上可以拟合任何函数，有模拟流程的能力，然而理论上可以，实际实现并没有那么简单。NTM/DNC 的重点是 <strong>存储管理</strong>，它能够通过一个大的、可寻址的外部存储器来扩展标准 RNN 能力，大大简化算数等任务。</p>
<h2 id="Turing-Machine"><a href="#Turing-Machine" class="headerlink" title="Turing Machine"></a>Turing Machine</h2><p>NTM/DNC 的灵感来自于图灵机。图灵机就是一种简单的计算机模型，摘一段概念：</p>
<blockquote>
<p>A <strong>Turing machine</strong> is a simple model of the computer. Like modern computers, it encapsulates the idea of having an external memory as well as some sort of processor. Essentially, a Turing machine consists of a tape with instructions written on it and the device that can read up and down the tape. Based on what it reads on the tape, it can decide to move in a different direction to write a new symbol or erase a symbol, and so on.</p>
</blockquote>
<p>很简单，由 <strong>外部存储器（写有指令的磁带）和存储器（能够沿着磁带读取的设备）</strong> 组成，根据磁带上读取到的指令，计算机能够决定在磁带上不同的方向上移动来进行写入或者擦除新符号等操作。</p>
<p>神经图灵机的灵感就来自图灵机的架构，也有 <strong>控制器（神经网络）和外部存储器（memory）</strong> 构成，试图去解决一些计算机能够解决的很好但机器学习模型很难解决的问题，比如说算法，或者说上面提到的冯诺依曼体系的一些要素。</p>
<h2 id="NTM-DNC-vs-TM"><a href="#NTM-DNC-vs-TM" class="headerlink" title="NTM/DNC vs. TM"></a>NTM/DNC vs. TM</h2><p>NTM/DNC 灵感来自于 TM，最关键的区别是神经图灵机是 <strong>可微分的（differentiable）</strong> 图灵机。计算机/图灵机的计算是绝对的，要么是 0 要么是 1，计算机在非此即彼的逻辑或者整数中运作。然而大多数的神经网络和机器学习更多会使用实数，使用更平滑的曲线，这样会更容易训练（如 BP，可以通过输出追踪回去调整参数以得到希望的输出）。神经图灵机采用基本的图灵机思想，但同时找到了平滑的模拟函数，也就是说，在图灵机磁带上，神经图灵机 NTM 可以决定“稍微”向左或者向右移动，而不是单纯的向左跳一个或者向右跳一个。</p>
<h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><ul>
<li><strong>Learn simple algorithms(Copy, repeat, recognize simple formal languages)</strong><br>能够学习简单的算法（夸张一点，本质上就是尝试着取代程序员）<br>NTM/DNC 能够接受输入和输出，并且学习得到能够从输入映射到输出的算法<br>如说复制任务，它能够学会接受相对短的序列，并重复几次。这让 LSTM 来做它就会崩溃，因为 LSTM 并不是在学习算法，而是试图一次性解决一个整体问题，它意识不到前两次所做的事情就是它们之后应该做的<br>再比如说识别平衡的括号，这涉及到了栈（stack）的算法，NTM/DNC 可以像程序员一样完成这个任务</li>
<li><strong>Generalize</strong><br>NTM/DNC 的计算图是对所有任务通用的</li>
<li><strong>Do well at language modeling</strong><br>擅长语言建模<br>比如做完型填空，能够猜测一个单词在句子或者文档语境中的意思</li>
<li><strong>Do well at bAbI</strong><br>擅长推理<br>在 bAbI 数据集上效果很好</li>
</ul>
<h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><ol>
<li><strong>Architecture dependent</strong><br>实现的时候需要谨慎做出如对每一时刻的输入能读取/写入多少向量这类的决策，否则很有可能永远都得不到一个合理的结果</li>
<li><strong>Large number of parameters</strong><br>参数量非常大 =&gt; RAM 压力很大</li>
<li><strong>Dosen’t benefit much from GPU acceleration</strong><br>序列输入，每一步输入都依赖之前的输入，也就很难并行化，不能受益于 GPU 加速 =&gt; 很难训练</li>
</ol>
<p>很难训练还表现在：</p>
<ol>
<li><strong>Numerical Instability</strong><br>数值不稳定性。在试图学习算法时会更倾向于犯大错误，而如果在算法中犯了一个错误，所有的输出结果都会是不正确的。换言之，训练时神经图灵机总是很难找到需要的算法</li>
<li><strong>Using memory is hard</strong><br>大量数据+足够时间，大多数神经网络都会得到一些结果，而神经图灵机经常会卡住，它们经常一遍又一遍地一味地产生那些经常重复的值<br>因为使用记忆是很困难的，不仅要学会记住之后解决问题需要的东西，还不能意外的忘记它</li>
<li><strong>Need smart optimization</strong><br>1+2 =&gt; 需要很好的优化<br>如 <strong>gradient clipping, loss clipping, RMSprop, Adam, try different initialization, curriculum learning…</strong></li>
</ol>
<p>上面这些问题会让神经图灵机很难在实际中应用。</p>
<h2 id="NTM-DNC-vs-MemNN"><a href="#NTM-DNC-vs-MemNN" class="headerlink" title="NTM/DNC vs. MemNN"></a>NTM/DNC vs. MemNN</h2><p><strong>异：</strong><br><strong>DNC 侧重记忆管理</strong>。MemNN 侧重 memory 查询，在记忆管理上非常简单，一般以 QA 为例，就是每句话 encode 成 vector，然后保存下来，所谓的更新大多是把不重要的 memory 清出去空个位出来给新的 memory。而 DNC 花更多努力在记忆管理上，注重更新 memory 和 memory 的时间关系，包含更多的操作，更新、删除、添加等。<br>另外，<strong>NTM/DNC 侧重算法任务</strong>，能够自动从数据中学习算法，而一般而言 MemNN 侧重的是 QA 任务。</p>
<p><strong>同：</strong><br>都是从 model architecture 层面，将多个 machine learning model 联合起来处理复杂的任务，比如 LSTM 通常是来处理线性数据，MemNN/NTM 可能包含多个 LSTM，能够处理多个线性结构（类似图结构）</p>
<h1 id="Neural-Turing-Machines-NTM"><a href="#Neural-Turing-Machines-NTM" class="headerlink" title="Neural Turing Machines(NTM)"></a>Neural Turing Machines(NTM)</h1><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>主要创新是将神经网络与外部存储器（external memory）结合来扩展神经网络的能力（通过注意力机制进行交互），可以类比图灵机，不过 NTM 是端到端可微的，所以可以使用梯度下降进行高效训练。</p>
<p>两个 <strong>主要元件</strong> 是 <strong>controller</strong> 和 <strong>memory bank</strong>。类比计算机来看 <strong>基本思路</strong>，实际是把神经网络看成是 CPU，把 memory 看做是计算机内存。CPU 根据任务来确定到内存的哪个位置读写信息，不过计算机的内存位置是离散数据，而 NTM 里是连续可导的。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/basic_idea.png" class="ful-image" alt="basic_idea.png"></p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>一张图读懂架构，取 <a href="http://people.idsia.ch/~rupesh/rnnsymposium2016/slides/graves.pdf" target="_blank" rel="external">DeepMind DNC Slides</a> 做了部分修改。最重要的概念还是那句话，每个组件都是可微分的，<strong>所有操作皆可导</strong>，这就可以直接用梯度下降训练来训练。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/ntm_arch.png" class="ful-image" alt="ntm_arch.png"></p>
<p>主要来研究读写操作。</p>
<h2 id="Read-Heads"><a href="#Read-Heads" class="headerlink" title="Read Heads"></a>Read Heads</h2><p>读操作和普通的 MemNN 相似，使用 attention 原理计算每个 memory vector 的权重向量，然后对 memory vector 进行加权生成读操作的结果。<br>$$r_t \leftarrow \sum^N_{i=1} w_t(i)M_t(i)$$</p>
<p>$M_t$ 是一个 NxM 的矩阵，表示 t 时刻的 memory，N 是 memory 的数量，M 是 memory vector 的维度。$w_t$是 t 时刻产生的权重向量，和 memory 数量相同，进行了归一化，$\sum_iw_t(i)=1, \ \ 0 \le w_t(i) \le 1, \forall i$</p>
<h2 id="Write-Heads"><a href="#Write-Heads" class="headerlink" title="Write Heads"></a>Write Heads</h2><h3 id="Erase-and-Add"><a href="#Erase-and-Add" class="headerlink" title="Erase and Add"></a>Erase and Add</h3><p>写操作包含两个步骤：先<strong>擦除（erase）</strong> 后<strong>添加（add）</strong></p>
<ul>
<li><strong>Erase</strong><br>input + controller 产生 erase vector $e_t \in R^M$, $e_t(d) \in (0,1)$<br>input + memory 产生 $M_t^{erased}(i) \leftarrow M_{t-1}(i)[1-w_t(i)e_t]$<br>和读操作一样，需要由 attention 机制得到 weight vector，表示每个 memory vector 被改动的幅度的大小，有多少个 memory 就有多少个 $w_t$<br>将上一时刻每个 memory vector 都乘上一个 0-1 之间的 vector，就是擦除操作，相当于 forget gate<br>如果 $w_t$ 和 $e_t$ 都为 1，memory 就会被重置为 0，如果两者有一个为 0，那么 memory 保持不变。多个 erase 操作可以以任意顺序叠加</li>
<li><strong>Add</strong><br>input + controller 产生 add vector $a_t \in R^M$ ，$a_t(d) \in (0,1)$<br>input + memory 产生 $M_t(i) \leftarrow M_t^{erased}(i) + w_t(i)a_t$<br>相当于 update gate<br>同样的，多个 add 操作的顺序并没有关系</li>
</ul>
<p>所有的 memory vector 共享 $e_t, \ a_t$，erase 和 add 操作中的 $w_t$ 也是共享的。再次注意 erase vector 和 add vector 都是由 controller 对 input 做编码得到的。<br>擦除和添加动作都有 M 个独立的 component，使得对每个 memory location 的修改可以在更细的粒度上进行。</p>
<h3 id="Addressing"><a href="#Addressing" class="headerlink" title="Addressing"></a>Addressing</h3><p>知道了怎么读写，现在来看看权重是如何产生的。主要通过两种方式来进行寻址，一是 <strong>content-based addressing</strong>，基于 controller 提供的状态向量 key vector 和当前 memory vector 的相似度来决定对内存地址的聚焦程度，另一个是 <strong>location-based addressing</strong>，通过地址来寻址，可能还会伴随权重的位移（rotational shift）。</p>
<p>整个 Addressing 过程的流程图：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/ntm_write.png" class="ful-image" alt="ntm_write.png"></p>
<h4 id="Content-based-addressing"><a href="#Content-based-addressing" class="headerlink" title="Content-based addressing"></a>Content-based addressing</h4><p>Controller 会产生一个长度为 M 的状态向量 key vector $k_t$，基于每一个 memory vector $M_t(i)$ 和 controller 状态向量  $k_t$ 的相似程度 K[·,·]，计算每个 memory vector 的 attention 权重。其中相似度可以用 cosine similarity 计算，$K(u,v)={u v \over ||u|| ||v||}$</p>
<p>使用 softmax 将相似度转化为概率分布：<br>$$w^c_t(i) \leftarrow {exp(\beta_tK[k_t, M_t(i)]) \over \sum_j exp(\beta_tK[k_t, M_t(j)])}$$</p>
<p>其中，$\beta_t$ 可以放大或减弱聚焦的程度。$\beta_t=1$ 时就是标准的 softmax，而 $\beta$ 的值越大，越会强化最大相似度分数的 memory vector 的优势，可以看做赢者通吃。要注意的是 $\beta$ 不是超参数，而是 controller 预测得到的。举个具体的例子，在对话领域，如果输入时“呵呵”这类没有太多信息量的句子，那么 controller 就会产生一个非常接近 0 的 $\beta$，表示没有明确倾向去访问某个特定的信息；反之，如果是包含很多信息的输入，产生的 $\beta$ 值会很大。</p>
<p>content addressing 完成的下面一个流程，$k_t$ 可以看做是 controller 对输入进行编码产生的状态向量，$\beta_t$ 是标量，一个 concentration 参数。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/ntm_content.png" class="ful-image" alt="ntm_content.png">
<h4 id="Location-based-addressing"><a href="#Location-based-addressing" class="headerlink" title="Location-based addressing"></a>Location-based addressing</h4><p>不是所有的问题都可以通过 content-based addressing 来解决的。在一些特定任务尤其是有 variable-binding 的任务中，变量的内容是任意的，但变量还是需要一个可识别的名字/地址来 refer。比如说算数任务，x, y 代表任意值，要计算 $f(x,y)=x * y$，这时候 controller 就会把 x,y 存到对应的地址上，然后通过地址而不是数值内容来获取它们并进行乘法操作。</p>
<p>Content-based addressing 比 location-based addressing 更为通用，因为 Content-based addressing 本身可能包含地址信息。然而 location-based addressing 对某些形式的通用化很有必要，所以论文同时引入了两种寻址机制。</p>
<h5 id="1-Interpolation-Gate"><a href="#1-Interpolation-Gate" class="headerlink" title="1. Interpolation Gate"></a>1. Interpolation Gate</h5><p>第一步要进行插值计算。<br>$$w_t^g \leftarrow g_tw^c_t + (1-g_t)w_{t-1}$$</p>
<p>基于内容的 weight vector $w^c_t$ 和上一个时间的 weight vector $w_{t-1}$ 的线性组合，线性组合的参数 $g_t$ 是一个 （0, 1）之间的标量，由 controller 产生，表示多大程度上使用当前时刻基于内容的寻址，多大程度上使用上一时刻产生的 $w_{t-1}$</p>
<p>如果 g=0，那么 content-weighting 整个就被忽略了，只用上一时刻的权重；如果 g=1，那么上一时刻的权重就被忽略了，只使用 content-based addressing。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/ntm_inter.png" class="ful-image" alt="ntm_inter.png"></p>
<h5 id="2-Shifting-and-Sharpening"><a href="#2-Shifting-and-Sharpening" class="headerlink" title="2. Shifting and Sharpening"></a>2. Shifting and Sharpening</h5><p>基于地址的寻址机制既可以用做简单的 memory bank 遍历，也可以用于随机访问，通过对 weighting 的旋转位移操作来实现。如果当前 weight 全力聚焦在一个单一地址上，那么一个为 1 的旋转可以把部分焦点位移到下一个地址，一个负的位移则相反。</p>
<p>具体是在 Interpolation 之后进行。controller 产生的 shift weighting $s_t$ 定义了所有允许的整数位移值上的归一化分布。如果 -1 到 1 间的位移是被允许的，那么 $s_t$ 就有三个对应位移值 -1，0，1 上的概率分布。最简单是用 softmax 来预测 shift weighting，不过这里用了另一种方法，controller 产生一个 single scalar 表示均匀分布的下界（the lower bound of a width one uniform distribution over shifts），也就是如果 shift scalar=6.7，那么 $s_t(6)=0.3$，$s_t(7)=0.7$，剩下的 $s_t(i)$ 都是 0。</p>
<p><strong>Shift attention:</strong><br>$$\hat w_t \leftarrow \sum^{R-1}_{j=0}w^g_t(j)s_t(i-j)$$<br>$s_t$ 其实相当于一个 convolution filter，每一个元素表示当前位置和对应位置的相关程度，像是定义了一个滑动窗里的权重，shift attention 将滑动窗里的 vector 做加权平均。<br>如果位移权重不是 sharp 的，也就是说权重分布相对均匀，那么这个卷积操作会使权重随时间变化更加发散。例如，如果给 -1，0，1 的对应的权重 0.1，0.8 和 0.1，旋转位移就会将聚焦在一个点上的权重轻微分散到三个点上。</p>
<p>controller 还会给出一个标量 $\gamma_t$ 用来 sharpen 最终的权重，作用和之前讲过的 $\beta_t$ 差不多，值越大权重大的越突出。<br><strong>Sharpening:</strong><br>$$w_t(i) \leftarrow {\hat w_t(i)\gamma_t \over \sum_j \hat w_t(i)\gamma_t}$$<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/ntm_post.png" class="ful-image" alt="ntm_post.png"></p>
<p>结合<strong>权重插值（weighting interpolation）</strong>、<strong>内容寻址（content-based addressing）</strong>和<strong>地址寻址（location-based addressing）</strong>的寻址系统可以在三种补充模式下工作：</p>
<ol>
<li>权重可以完全由 content-based addressing 来自主选择而不受 location system 的影响</li>
<li>由 content-based addressing 产生的权重可以被选择然后进行位移。这使得 focus 能够跳跃到通过内容寻址产生的地址附近而不是具体一个点。在计算方面，这使得 head 可以访问一个连续的数据块，然后访问这个块中的特定数据</li>
<li>来自上一个时刻的权重可以在没有任何 content-based addressing 的输入的情况下被旋转，以便权重可以以相同的时间间隔连续地访问一个地址序列（allows the weighting to iterate through a sequence of addresses by advancing the same distance at each time-step）。</li>
</ol>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>input 被 controller 加工产生 key vector 和一些中间变量，基于 key vector 和 memory bank 里的记忆向量的相似程度，用 attention 机制将 memory 检索结果转化成 vector 返回给读操作；基于 controller 加工后的外界输入，把一些信息写到 memory 里面，实现更新 memory 的效果（擦除+更新，都需要 weight vector 来确定 memory vector 的权重，权重由 content-base+location-base 产生，表示输入与记忆的相似程度，记忆与记忆的相似程度）。</p>
<p>NTM 架构有三个 free parameters：</p>
<ul>
<li>size of memory</li>
<li>number of read and write heads</li>
<li>range of allowed location shifts</li>
</ul>
<p>但最重要的选择还是用作 controller 的网络模型。来探讨下 recurrent 和 feedforward network 的选择</p>
<ul>
<li>递归网络像 LSTM 拥有自己的 internal memory，可以对矩阵中更大的存储器起到补充作用。想象 controller 是 CPU，memory 是 RAM，那么 RN 里的 hidden activations 相当于处理器的寄存器（rigisters），允许 controller 跨时间操作时可以共享信息</li>
<li>前馈网络 FN 可以通过每一时刻读写同一个记忆地址来模拟 RN，在网络操作上有更大透明度，读写 memory matrix 的模式比 RNN 的中间状态更容易解释。但局限是并行 read/write heads 的数量有限，在 NTM 计算时会成为瓶颈。单个 read head 在每个时刻只能对单个 memory vector 进行一元变换，而两个 read heads 可以进行二元向量变换，以此类推。递归控制器能够存储上一时刻的读出的向量，不会受到这个限制。</li>
</ul>
<h1 id="Differentiable-Neural-Computer-DNC"><a href="#Differentiable-Neural-Computer-DNC" class="headerlink" title="Differentiable Neural Computer(DNC)"></a>Differentiable Neural Computer(DNC)</h1><p>NTM 的第二个版本。更加复杂一些吧。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_arch.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_arch.png">
<p>和 NTM 一样，controller 由若干个神经网络组成，负责和输入、输出交互，产生一些中间变量（又叫 interface parameter）。根据这些中间变量，可以进行 memory 的读写操作，注意这里是 <strong>先写再读！</strong> 绿色的方块表示写操作，可以看到先是会释放某些区域的记忆，然后分配记忆，写入东西，完成后输出，表示 done，可以重新分配记忆了，然后交替，整个是动态分配的过程。</p>
<p>紫色的方块表示读操作，更新完 memory，会从更新过的 memory 里定位和读取信息。有多个互相独立的 read model，互相独立的来从 memory 里读取信息并拼到一起，可以从各个角度来衡量信息的有用程度。</p>
<p>记忆区的右边（d Memory usage and temporal links）有一个附加的链表，追踪上面的箭头能够“回想”最近输入和输出的过程。</p>
<p>和 Seq2seq 类比一下，图中 controller 指向自己的箭头其实相当于 RNN decoder里的 RNN state vector，黄线从 memory 到 controller 的路径其实相当于 attention 提取的 context vector。</p>
<h2 id="Architecture-1"><a href="#Architecture-1" class="headerlink" title="Architecture"></a>Architecture</h2><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_arch2.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_arch2.png">
<p>梳理一下，有三大部分：</p>
<ol>
<li><strong>Controller 产生 interface parameters 和 output parameters</strong><br>$x_t=[x_t;r^1_{t-1};…;r^R_{t-1}]$<br>$(\xi t, v_t)=NNC([x_1;…;x_t];\theta)$</li>
<li><strong>对 memory 的操作，先写再读</strong><br>Content-based writing and reading weight<br>History-based writing weight =&gt; final writing weights<br>History-based reading weight =&gt; final reading weights</li>
<li><strong>Memory 结果（类比对话系统里的上下文 context vector）和 controller 产生的 $v_t$（类比RNN decoder 的 state vector）拼到一起产生最后的输出</strong><br>$y_t=W_r[r^1_t,…r^R_t]+v_t$</li>
</ol>
<p>完整的连续输入的结构图如下，上一时刻读的信息也会作为输入放到 controller 里做预测，也就是说除了 input，controller 还会用到历史信息。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_arch3.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_arch3.png"></p>
<h2 id="Details"><a href="#Details" class="headerlink" title="Details"></a>Details</h2><p>下面说一下 memory 读写操作的细节。沿着下图走一遍，图中六角形部分都是控制器的输出也就是 interface parameter<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_details.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20%E4%BB%8E%E7%A5%9E%E7%BB%8F%E5%9B%BE%E7%81%B5%E6%9C%BA%20NTM%20%E5%88%B0%E5%8F%AF%E5%BE%AE%E5%88%86%E7%A5%9E%E7%BB%8F%E8%AE%A1%E7%AE%97%E6%9C%BA%20DNC/DNC_details.png"></p>
<h3 id="1-Content-based-weighting-for-memory-write"><a href="#1-Content-based-weighting-for-memory-write" class="headerlink" title="1. Content-based weighting for memory write"></a>1. Content-based weighting for memory write</h3><p>这一部分 $c^w_t$ 和 NMT.v1 相同。D 是相似度函数，可以取 cosine similarity; $\beta$ 是 concentration parameter，表示 key strength，是大于 1 的 scalar</p>
<p>$$C(M_{t-1}, k^w_t, \beta^w_t)[i]={exp(D(k^w_t, M_{t-1}[i, ·])\beta_t^w \over \sum_j exp(D(k^w_t, M_{t-1}[j,·])\beta^w_t))}$$</p>
<h3 id="2-History-based-write-weighting-Dynamic-memory-allocation"><a href="#2-History-based-write-weighting-Dynamic-memory-allocation" class="headerlink" title="2. History-based write weighting(Dynamic memory allocation)"></a>2. History-based write weighting(Dynamic memory allocation)</h3><p>对应 NTM 的 remove 和 add 操作。每一个存储单元都是一个等长 vector，里面有若干个 element，只要 element 没有全部被占用，就可以写入新数据。如果被完全占用了，也可以通过一定方法将存储单元释放。</p>
<p>Controller 有三种选择：</p>
<ol>
<li>不写</li>
<li>写 &amp; 写到新分配的位置（未使用过的/最新释放的存储单元）</li>
<li>写 &amp; 写到内容相似且还没有被完全占用的存储单元<br>也就是更新这个存储单元的信息</li>
</ol>
<p>如果所有存储空间都用完了，那么控制器必须释放空间才可以进行写操作。每一个时刻的写操作完成后，位置信息会和 L 矩阵也就是 links of association 连接起来，记录信息存储的顺序。</p>
<ul>
<li><strong>memory retention vector:</strong> $\psi_t = \prod^R_{i=1}(1-f^i_t \omega^{r,i}_{t-1})$<br>$\omega^{w,i}_{t-1}$ 是上一时刻的 write weights，$f^i_t$ 是 controller 产生的 free gates，决定最近读取的位置要不要被释放。i 是 read head 的 index。$\psi_t \in [0,1]$ 也就是 memory retention vector，表示每个位置上有多少信息被保留下来</li>
<li><strong>usage vector:</strong> $u_t=(u_{t-1}+\omega^w_{t-1}-(u_{t-1}⊙\omega_{t-1}^w))⊙ \psi_t$<br>$u_t$ 是 t 时刻的 usage vector，衡量每一个 memory vector 最近被用到的程度，如果很久没用&amp;需要腾地方，就会优先把它给踢掉<br>$u_t$ 被 $\psi_t$ 限制，在 0-1 之间，⊙ 表示 element-wise 乘法</li>
<li><strong>least used location:</strong> $\phi_t=SortIndicesAscending(u_t)$<br>升序排序，于是 $\phi_t[1]$ 表示最少使用到的位置</li>
<li><strong>allocation weighting:</strong> $a_t[\phi_t[j]]=(1-u_t[\phi_t[j]])\prod^{j-1}_{i=1}u_t[\phi_t[j]]$<br>最近读取的 memory 在更新 memory 的时候有更大的权重<br>$a_t$ 是 allocation weighting，提供写操作的新的位置，如果所有的 u 都是 1，那么 $a_t=0$，必须先释放存储空间才能够分配空间</li>
</ul>
<h3 id="3-Final-write-weight"><a href="#3-Final-write-weight" class="headerlink" title="3. Final write weight"></a>3. Final write weight</h3><p>Usage attention 和 content attention 通过 gate 线性组合, gate 也是 interface parameter, 再做后续 filter。</p>
<ul>
<li>$\omega^w_t=g^w_t[g^a_ta_t+(1-g^a_t)c^w_t]$<br> $g^a_t$ 是线性组合的 allocation gate，$g^w_t$是 write gate，如果 write gate 是 0，那么啥都不写</li>
<li>$M_t=M_{t-1}⊙(E-\omega^w_te^T_t)+\omega^w_tv^T_t = M_{t-1}-M_{t-1}⊙\omega^w_te^T_t+\omega^w_tv^T_t$<br> Memory writes，改变 t-1 时刻的 memory bank</li>
</ul>
<h3 id="4-Content-based-weighting-for-memory-read"><a href="#4-Content-based-weighting-for-memory-read" class="headerlink" title="4. Content-based weighting for memory read"></a>4. Content-based weighting for memory read</h3><p>$$C(M_t, k^{r,i}_t,\beta^{r,i}_t)[k]={exp(D(k^{r,i}_t, M_t[k, ·])\beta^{r,i}_t) \over \sum_j exp(D(k^{r,i}_t,M_t[j, ·])\beta^{r,i}_t)}$$<br>总共读 R 次（$R\ge 1,$超参数），从更新过以后的 memory $M_t$ 里读信息</p>
<h3 id="5-History-based-reading-weights"><a href="#5-History-based-reading-weights" class="headerlink" title="5. History-based reading weights"></a>5. History-based reading weights</h3><p>通过有时间信息的历史记录（temporal links），和 content-based read 挑出来的 C，进一步挑选出不直接相关但历史上有间接联系的 memory vector。举个例子理解一下，t 时刻的 input 通过内容的相似程度定位到了第 5 个 memory vector，然后 L 矩阵通过写操作的历史记录，发现第 5 个 vector 和第 2，4，6 个 vector 非常相关，所以尽管 t 时刻的 input 和 vector 2，4，6 在这一时刻表面上不相关，但有了第 5 个 vector 作为中介找到了 2，4，6，就有了间接关系，这可以通过 f, b 挑选出来。</p>
<p>$p_0=0$<br>$p_t=(1-\sum^N_{i=1}\omega^w_t[i])p_{t-1}+\omega^w_t$<br>$L_0[i,j]=0 \ \ \forall i,j $<br>$L_t[i,i]=0 \ \ \forall i $<br>$L_t[i,j]=(1-\omega^w_t[i]-\omega^w_t[j])L_{t-1}[i,j]+\omega^w_t[i]p^w_{t-1}[j]$</p>
<p>$L_t[i,j]$: <em>the degree to which location i was the location written to after location j,the rows and columns of Lt represent the weights of the temporal links going into and out from particular memory slots, respectively</em></p>
<p>每次修改存储空间时，链接矩阵都会更新，删除旧位置的链接，添加最后写入的位置的新链接。 </p>
<p>从 L 中挑选：</p>
<ul>
<li>$b^i_t$ backward weighting<br>$b^i_t=L^T_t\omega^{r,i}_{t-1}$</li>
<li>$f^i_t$ forward weighting<br>$f^i_t=L_t\omega^{r,i}_{t-1}$</li>
</ul>
<p>这种 temporal links 特别适用于NLP的任务。比如一段文本以单词为单位输入喂给 DNC，每个单词输入下 memory 都会被更新，但根据 L 可以知道上一个单词都影响了哪些 memory，也就是能够去关注单词的时序关系，这对捕捉文本意义有重要作用。</p>
<h3 id="6-Final-read-weighting"><a href="#6-Final-read-weighting" class="headerlink" title="6. Final read weighting"></a>6. Final read weighting</h3><ul>
<li>$\omega^{r,i}_t=\pi^i_t[1]b^i_t+\pi^i_t[2]c^{r,i}_t+\pi^i_t[3]f^i_t$<br>$\pi^i_t$ 表示读的模式，如果 $\pi^i_t[2]$ 占主导，那么只用 content lookup，如果  $\pi^i_t[3]$ 占主导，那么就按 memory 写入的顺序来遍历，如果  $\pi^i_t[1]$ 占主导，按 memory 写入顺序反向遍历</li>
<li>$r^i_t=M^T_t\omega^{r,i}_t$<br>Read from memory，三个 weight vector 加权相加得到最后的 weight vector，然后从更新过的 memory vector 把 memory 读出来加权平均返回给控制器</li>
</ul>
<p>小结一下，对于读操作，控制器可以从多个位置读取记忆，可以基于内容读取，也可以基于 associative temporal links 读取（向前/向后以顺序或反序的方式回调依次读取写入的信息）。读取的信息可以用来生成问题答案或者在环境中采取的行为。</p>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p>controller 可以用简单的 RNN，复杂些的 LSTM，也可以用 RL。论文还举了一些 DNC 的应用例子，比如学会找最短路径、伦敦地铁的路径规划、家族树（回答 who is Freya’s maternal great uncle 这类问题）、移动块问题等。</p>
<h1 id="DNC-vs-NTM"><a href="#DNC-vs-NTM" class="headerlink" title="DNC vs. NTM"></a>DNC vs. NTM</h1><p>DNC 是 NTM 的第二版，它改进了 NTM 的寻址机制，去掉了 index shift，更好支持了对记忆的 allocate 和 de-allocate 的功能。具体来说表现在下面几个方面：</p>
<ol>
<li><strong>No index shift based addressing</strong><br>NTM 是沿着磁带（或者说记忆）左右移动，而 DNC 则尝试基于输入直接在记忆中搜索给定的 vector</li>
<li><strong>Can ‘allocate’ and ‘deallocate’ memory</strong><br>DNC 可以分配和释放记忆。NTM 不能保证多个存储单元之间互不重叠、互不干扰（=&gt; allocate a free space），也不能释放存储单元，这意味着不能重复使用存储单元，也就很难处理很长的序列（=&gt; free gates used for deallocation）<br>另外，这种机制也很容易能将记忆中的某个区域标记为禁止访问，避免在以后意外地删除它们，这有助于优化</li>
<li><strong>Remembers recent memory use</strong><br>NTM 中，序列信息只能通过连续位置的写操作来顺序保存，并回到 memory 起点将它们读出来。一旦写操作跳跃到一个很远的位置，那么跳跃前和跳跃后的存储顺序就丢失了，读操作是没办法获取的<br>而 DNC 有一个 temporal link matrix 记录了写操作的顺序，也就是说 DNC 有某种形式的 temporal memory，在某个瞬时记忆下 DNC 可以回想起上一步做的事，以及上一步的上一步，以此类推，也就是可以遍历由它们需要做的事组成地一个链表</li>
</ol>
<blockquote>
<p>参考链接<br><a href="http://people.idsia.ch/~rupesh/rnnsymposium2016/slides/graves.pdf" target="_blank" rel="external">DeepMind DNC Slides</a><br><a href="http://blog.talla.com/neural-turing-machines-perils-and-promise" target="_blank" rel="external">Neural Turing Machines: Perils and Promise</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Neural Turing Machine(NTC) 和 Differentiable Neural Machine(DNC) 的相关笔记。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Memory Networks" scheme="http://www.shuang0420.com/tags/Memory-Networks/"/>
    
  </entry>
  
  <entry>
    <title>NLP笔记 - 多轮对话之对话管理(Dialog Management)</title>
    <link href="http://www.shuang0420.com/2018/01/03/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86(Dialog%20Management)/"/>
    <id>http://www.shuang0420.com/2018/01/03/NLP笔记 - 多轮对话之对话管理(Dialog Management)/</id>
    <published>2018-01-03T02:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>开始涉猎多轮对话，这一篇想写一写对话管理（Dialog Management），感觉是个很庞大的工程，涉及的知识又多又杂，在这里只好挑重点做一个引导性的介绍，后续会逐个以单篇形式展开。–持续更新中–<br><a id="more"></a></p>
<p>放一张多轮语音对话流程图，理解下 DM 在整个对话流程中处于什么地位。<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92.png" class="ful-image" alt="%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92.png"></p>
<p>简单描述一下这个流程图常见的一种信息流动方式，首先是语音识别 ASR，产生语音识别结果也就是用户话语 $u_u$ ；语义解析模块 NLU 将 $u_u$ 映射成用户对话行为 $a_u$；对话管理模块 DM 选择需要执行的系统行为$a_m$；如果这个系统行为需要和用户交互，那么语言生成模块 NLG 会被触发，生成自然语言或者说是系统话语 $u_m$；最后，生成的语言由语音合成模块 TTS 朗读给用户听。 </p>
<p>这一篇第一部分介绍下对话管理及重要的几个小知识点，第二部分介绍对话管理的一些方法，主要有三大类：</p>
<ul>
<li><strong>Structure-based Approaches</strong><ul>
<li>Key phrase reactive</li>
<li>Tree and FSM</li>
<li>…</li>
</ul>
</li>
<li><strong>Principle-based Approaches</strong><ul>
<li>Frame</li>
<li>Information-State</li>
<li>Plan</li>
<li>…</li>
</ul>
</li>
<li><strong>Statistical Approaches</strong><ul>
<li>这一类其实和上面两类有交叉…不过重点想提的是：</li>
<li><strong>Reinforcement Learning</strong></li>
</ul>
</li>
</ul>
<p>方法不等于模型，这里只介绍一些重要概念，不会涉及模型细节。最后一部分会介绍一下 DM 设计工程上的一些 tips。</p>
<h1 id="Dialog-Management"><a href="#Dialog-Management" class="headerlink" title="Dialog Management"></a>Dialog Management</h1><p><strong>对话管理（Dialog Management, DM）</strong>控制着人机对话的过程，DM 根据对话历史信息，决定此刻对用户的反应。最常见的应用还是任务驱动的多轮对话，用户带着明确的目的如订餐、订票等，用户需求比较复杂，有很多限制条件，可能需要分多轮进行陈述，一方面，用户在对话过程中可以不断修改或完善自己的需求，另一方面，当用户的陈述的需求不够具体或明确的时候，机器也可以通过询问、澄清或确认来帮助用户找到满意的结果。</p>
<p>总的来说，对话管理的任务大致有下面一些：</p>
<ul>
<li><strong>对话状态维护（dialog state tracking, DST）</strong><br>维护 &amp; 更新对话状态<br>t+1 时刻的对话状态 $s_{t+1}$，依赖于之前时刻 t 的状态 $s_t$，和之前时刻 t 的系统行为 $a_t$，以及当前时刻 t+1 对应的用户行为 $o_{t+1}$。可以写成 $s_{t+1} \leftarrow s_t+a_t+o_{t+1}$</li>
<li><strong>生成系统决策（dialog policy）</strong><br>根据 DST 中的对话状态（DS），产生系统行为（dialog act），决定下一步做什么<br>dialog act 可以表示观测到的用户输入（用户输入 -&gt; DA，就是 NLU 的过程），以及系统的反馈行为（DA -&gt; 系统反馈，就是 NLG 的过程）<br>DA 的具体介绍将在 NLU 系列中展开</li>
<li><strong>作为接口与后端/任务模型进行交互</strong></li>
<li><strong>提供语义表达的期望值（expectations for interpretation）</strong><br>interpretation: 用户输入的 internal representation，包括 speech recognition 和 parsing/semantic representation 的结果</li>
</ul>
<p>本质上，任务驱动的对话管理实际就是一个决策过程，系统在对话过程中不断根据当前状态决定下一步应该采取的最优动作（如：提供结果，询问特定限制条件，澄清或确认需求…）从而最有效的辅助用户完成信息或服务获取的任务。</p>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/dm1.png" class="ful-image" alt="dm1.png">
<p>如图，DM 的<strong>输入</strong>就是用户输入的语义表达（或者说是用户行为，是 NLU 的输出）和当前对话状态，<strong>输出</strong>就是下一步的系统行为和更新的对话状态。这是一个循环往复不断流转直至完成任务的过程，其中，<strong>语义输入就是流转的动力，DM 的限制条件（即通过每个节点需要补充的信息/付出的代价）就是阻力</strong>，输入携带的语义信息越多，动力就越强；完成任务需要的信息越多，阻力就越强。</p>
<p>一个例子<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/DM_eg.png" class="ful-image" alt="DM_eg.png"></p>
<p>实际上，DM 可能有更广泛的职责，比如融合更多的信息（业务+上下文），进行第三方服务的请求和结果处理等等。</p>
<h2 id="Initiative"><a href="#Initiative" class="headerlink" title="Initiative"></a>Initiative</h2><p>对话引擎根据对话按<strong>对话由谁主导</strong>可以分为三种类型：</p>
<ul>
<li><strong>系统主导</strong><br>系统询问用户信息，用户回答，最终达到目标</li>
<li><strong>用户主导</strong><br>用户主动提出问题或者诉求，系统回答问题或者满足用户的诉求</li>
<li><strong>混合</strong><br>用户和系统在不同时刻交替主导对话过程，最终达到目标<br>有两种类型，一是用户/系统转移任何时候都可以主导权，这种比较困难，二是根据 prompt type 来实现主导权的移交<br>Prompts 又分为 open prompt（如 ‘How may I help you‘ 这种，用户可以回复任何内容 ）和 directive prompt（如 ‘Say yes to accept call, or no’ 这种，系统限制了用户的回复选择）。</li>
</ul>
<h2 id="Basic-concepts"><a href="#Basic-concepts" class="headerlink" title="Basic concepts"></a>Basic concepts</h2><p><strong>Ground and Repair</strong><br>对话是对话双方共同的行为，双方必须不断地建立<strong>共同基础（common ground, Stalnaker, 1978）</strong>，也就是双方都认可的事物的集合。共同基础可以通过听话人<strong>依靠（ground）</strong>或者<strong>确认（acknowledge）</strong>说话人的话段来实现。<strong>确认行为（acknowledgement）</strong>由弱到强的 5 种方法（Clark and Schaefer 1989）有：<strong>持续关注（continued attention），相关邻接贡献（relevant next contribution），确认（acknowledgement），表明（demonstration），展示（display）</strong>。</p>
<p>听话人可能会提供<strong>正向反馈（如确认等行为）</strong>，也可能提供<strong>负向反馈（如拒绝理解/要求重复/要求 rephrase等）</strong>，甚至是<strong>要求反馈（request feedback）</strong>。如果听话人也可以对说话人的语段存在疑惑，会发出一个<strong>修复请求（request for repair）</strong>，如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">A: Why is that?</div><div class="line">B: Huh?</div><div class="line">A: Why is that?</div></pre></td></tr></table></figure>
<p>还有的概念如 <strong>speech acts，discourse</strong> 这类，之前陆陆续续都介绍过一些了。</p>
<h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><p>人的复杂性（complex）、随机性（random）和非理性化（illogical）的特点导致对话管理在应用场景下面临着各种各样的<strong>问题</strong>，包括但不仅限于：</p>
<ul>
<li><strong>模型描述能力与模型复杂度的权衡</strong></li>
<li><strong>用户对话偏离业务设计的路径</strong><br>如系统问用户导航目的地的时候，用户反问了一句某地天气情况</li>
<li><strong>多轮对话的容错性</strong><br>如 3 轮对话的场景，用户已经完成 2 轮，第 3 轮由于ASR或者NLU错误，导致前功尽弃，这样用户体验就非常差</li>
<li><strong>多场景的切换和恢复</strong><br>绝大多数业务并不是单一场景，场景的切换与恢复即能作为亮点，也能作为容错手段之一</li>
<li><strong>降低交互变更难度，适应业务迅速变化</strong></li>
<li><strong>跨场景信息继承</strong></li>
</ul>
<h1 id="Structure-based-Approaches"><a href="#Structure-based-Approaches" class="headerlink" title="Structure-based Approaches"></a>Structure-based Approaches</h1><h2 id="Key-Pharse-Reactive-Approaches"><a href="#Key-Pharse-Reactive-Approaches" class="headerlink" title="Key Pharse Reactive Approaches"></a>Key Pharse Reactive Approaches</h2><p>本质上就是关键词匹配，通常是通过捕捉用户最后一句话的<strong>关键词/关键短语</strong>来进行回应，比较知名的两个应用是 <strong>ELIZA</strong> 和 <strong>AIML</strong>。AIML （人工智能标记语言），XML 格式，支持 ELIZA 的规则，并且更加灵活，能支持一定的上下文实现简单的多轮对话（利用 that），支持变量，支持按 topic 组织规则等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&lt;category&gt;</div><div class="line">&lt;pattern&gt;DO YOU KNOW WHO * IS&lt;/pattern&gt; </div><div class="line">&lt;template&gt;&lt;srai&gt;WHO IS &lt;star/&gt;&lt;/srai&gt;&lt;/template&gt; </div><div class="line">&lt;/category&gt;</div><div class="line"></div><div class="line">&lt;category&gt;</div><div class="line">&lt;pattern&gt;MOTHER&lt;/pattern&gt;</div><div class="line">&lt;template&gt; Tell me more about your family. &lt;/template&gt; </div><div class="line">&lt;/category&gt;</div><div class="line"></div><div class="line">&lt;category&gt;</div><div class="line">&lt;pattern&gt;YES&lt;/pattern&gt;</div><div class="line">&lt;that&gt;DO YOU LIKE MOVIES&lt;/that&gt; </div><div class="line">&lt;template&gt;What is your favorite movie?&lt;/template&gt; </div><div class="line">&lt;/category&gt;</div></pre></td></tr></table></figure>
<p>附上自己改写的 <a href="https://github.com/Shuang0420/aiml" target="_blank" rel="external">aiml</a> 地址，在原有基础上增添了一些功能：</p>
<ul>
<li>支持 python3</li>
<li>支持中文</li>
<li>支持 * 扩展</li>
</ul>
<h2 id="Trees-and-FSM-based-Approaches"><a href="#Trees-and-FSM-based-Approaches" class="headerlink" title="Trees and FSM-based Approaches"></a>Trees and FSM-based Approaches</h2><p>Trees and FSM-based approach 通常把对话建模为通过树或者有限状态机（图结构）的路径。 相比于 simple reactive approach，这种方法融合了更多的上下文，能用一组有限的信息交换模板来完成对话的建模。这种方法<strong>适用于</strong>：</p>
<ul>
<li>系统主导</li>
<li>需要从用户收集特定信息</li>
<li>用户对每个问题的回答在有限集合中</li>
</ul>
<p>这里主要讲 FSM，把对话看做是在有限状态内跳转的过程，每个状态都有对应的动作和回复，如果能从开始节点顺利的流转到终止节点，任务就完成了。<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/fsa.png" class="ful-image" alt="fsa.png"></p>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/credit_card_eg.png" class="ful-image" alt="credit_card_eg.png">
<p>FSM 的<strong>状态</strong>对应系统问用户的问题，<strong>弧线</strong>对应将采取的行为，依赖于用户回答。</p>
<p>FSM-based DM 的<strong>特点</strong>是：</p>
<ul>
<li>人为定义对话流程</li>
<li>完全由系统主导，系统问，用户答</li>
<li>答非所问的情况直接忽略</li>
<li>建模简单，能清晰明了的把交互匹配到模型</li>
<li>难以扩展，很容易变得复杂</li>
<li>适用于简单任务，对简单信息获取很友好，难以处理复杂的问题</li>
<li>缺少灵活性，表达能力有限，输入受限，对话结构/流转路径受限</li>
</ul>
<p>对特定领域要设计 task-specific FSM，简单的任务 FSM 可以比较轻松的搞定，但稍复杂的问题就困难了，毕竟要考虑对话中的各种可能组合，编写和维护都要细节导向，非常耗时。一旦要扩展 FSM，哪怕只是去 handle 一个新的 observation，都要考虑很多问题。实际中，通常会加入其它机制（如变量等）来扩展 FSM 的表达能力。</p>
<h1 id="Principle-based-Approaches"><a href="#Principle-based-Approaches" class="headerlink" title="Principle-based Approaches"></a>Principle-based Approaches</h1><h2 id="Frame-based-Approaches"><a href="#Frame-based-Approaches" class="headerlink" title="Frame-based Approaches"></a>Frame-based Approaches</h2><p>Frame-based approach 通过允许多条路径更灵活的获得信息的方法扩展了基于 FSM 的方法，它将对话建模成一个填槽的过程，<strong>槽</strong>就是多轮对话过程中将初步用户意图转化为明确用户指令所需要补全的信息。一个槽与任务处理中所需要获取的一种信息相对应。槽直接没有顺序，缺什么槽就向用户询问对应的信息。</p>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/slot_filling.png" class="ful-image" alt="slot_filling.png">
<p>Frame-based DM 包含下面一些<strong>要素：</strong></p>
<ul>
<li><strong>Frame：</strong> 是槽位的集合，定义了需要由用户提供什么信息</li>
<li><strong>对话状态：</strong>记录了哪些槽位已经被填充</li>
<li><strong>行为选择：</strong>下一步该做什么，填充什么槽位，还是进行何种操作<br>行为选择可以按槽位填充/槽位加权填充，或者是利用本体选择</li>
</ul>
<p>基于框架/模板的系统本质上是一个生成系统，不同类型的输入激发不同的生成规则，每个生成能够灵活的填入相应的模板。常常用于用户可能采取的行为相对有限、只希望用户在这些行为中进行少许转换的场合。</p>
<p><strong>Frame-based DM 特点：</strong></p>
<ul>
<li>用户回答可以包含任何一个片段/全部的槽信息</li>
<li>系统来决定下一个行为</li>
<li>支持混合主导型系统</li>
<li>相对灵活的输入，支持多种输入/多种顺序</li>
<li>适用于相对复杂的信息获取</li>
<li>难以应对更复杂的情境</li>
<li>缺少层次</li>
</ul>
<p>槽的更多信息可以参考<a href="http://www.pmcaff.com/article/index/971158746030208?from=related&amp;pmc_param%5Bentry_id%5D=950709304427648" target="_blank" rel="external">填槽与多轮对话 | AI产品经理需要了解的AI技术概念</a></p>
<h2 id="Agenda-Frame-CMU-Communicator"><a href="#Agenda-Frame-CMU-Communicator" class="headerlink" title="Agenda + Frame(CMU Communicator)"></a>Agenda + Frame(CMU Communicator)</h2><p><strong>Agenda + Frame(CMU Communicator)</strong> 对 frame model 进行了改进，有了层次结构，能应对更复杂的信息获取，支持话题切换、回退、退出。主要<strong>要素</strong>如下：</p>
<ul>
<li><strong>product</strong><br>树的结构，能够反映为完成这个任务需要的所有信息的顺序<br>相比于普通的 Tree and FSM approach，这里产品树（product tree）的创新在于它是动态的，可以在 session 中对树进行一系列操作比如加一个子树或者挪动子树</li>
<li><strong>process</strong><ul>
<li><strong>agenda</strong><br>相当于任务的计划（plan）<br>类似栈的结构（generalization of stack）<br>是话题的有序列表（ordered list of topics）<br>是 handler 的有序列表（list of handlers），handler 有优先级</li>
<li><strong>handler</strong><br>产品树上的每个节点对应一个 handler，一个 handler 封装了一个 information item</li>
</ul>
</li>
</ul>
<p>从 product tree 从左到右、深度优先遍历生成 agenda 的顺序。当用户输入时，系统按照 agenda 中的顺序调用每个 handler，每个 handler 尝试解释并回应用户输入。handler 捕获到信息就把信息标记为 consumed，这保证了一个 information item 只能被一个 handler 消费。</p>
<p>input pass 完成后，如果用户输入不会直接导致特定的 handler 生成问题，那么系统将会进入 output pass，每个 handler 都有机会产生自己的 prompt（例如，departure date handler 可以要求用户出发日期）。</p>
<p>可以从 handler 返回代码中确定下一步，选择继续 current pass，还是退出 input pass 切换到 output pass，还是退出 current pass 并等待来自用户输入等。handler 也可以通过返回码声明自己为当前焦点（focus），这样这个 handler 就被提升到 agenda 的顶端。为了保留特定主题的上下文，这里使用 sub-tree promotion 的方法，handler 首先被提升到兄弟节点中最左边的节点，父节点同样以此方式提升。</p>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/rotate_subtree.png" class="ful-image" alt="rotate_subtree.png">
<p>系统还能处理产品树中节点之间的依赖关系。典型的依赖关系在父节点和子节点之间。通常父节点的值取决于其子节点。每个节点都维护一个依赖节点的列表，并且会通知依赖节点值的变化，然后依赖节点可以声明自己是无效的并成为当前对话的候选主题。</p>
<p>给一个例子，能够回应用户的显式/隐式话题转移（A1-A3, U11），也能够动态添加子树到现有的 agenda（A8-A10）。<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/cmu_ex.png" class="ful-image" alt="cmu_ex.png"></p>
<p>具体还是看论文吧<br><a href="http://www.cs.cmu.edu/~xw/asru99-agenda.pdf" target="_blank" rel="external">AN AGENDA-BASED DIALOG MANAGEMENT ARCHITECTURE FOR SPOKEN LANGUAGE SYSTEMS</a></p>
<h2 id="Information-State-Approaches"><a href="#Information-State-Approaches" class="headerlink" title="Information-State Approaches"></a>Information-State Approaches</h2><p>Information State Theories 提出的背景是：</p>
<ul>
<li><strong>很难去评估各种 DM 系统</strong></li>
<li><strong>理论和实践模型存在很大的 gap</strong><br>理论型模型有：logic-based, BDI, plan-based, attention/intention<br>实践中模型大多数是 finite-state 或者 frame-based<br>即使从理论模型出发，也有很多种实现方法</li>
</ul>
<p>因此 Information State Models 作为对话建模的形式化理论，为工程化实现提供了理论指导，也为改进当前对话系统提供了大的方向。Information-state theory 的<strong>关键</strong>是识别对话中流转信息的 relevant aspects，以及这些成分是怎么被更新的，更新过程又是怎么被控制的。idea 其实比较简单，不过执行很复杂罢了。理论架构如下：<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/IS_arch.png" class="ful-image" alt="IS_arch.png"></p>
<p>介绍下简单的一些<strong>要素</strong>：<br><strong>Statics</strong></p>
<ul>
<li><strong>Informational components</strong><br>包括上下文、内部驱动因子（internal motivating factors）<br>e.g., QUD, common ground, beliefs, intentions, dialogue history, user models, etc.</li>
<li><strong>Formal representations</strong><br>informational components 的表示<br>e.g., lists, records, DRSs,…</li>
</ul>
<p><strong>Dynamics</strong></p>
<ul>
<li><strong>dialog moves</strong><br>会触发更新 information state 的行为的集合<br>e.g., speech acts</li>
<li><strong>update rules</strong><br>更新 information state 的规则集合<br>e.g., selection rules</li>
<li><strong>update strategy</strong><br>更新规则的选择策略，选择在给定时刻选用哪一条 update rules</li>
</ul>
<p>意义在于可以遵循这一套理论体系来构建/分析/评价/改进对话系统。基于 information-state 的系统有：</p>
<ul>
<li><strong>TrindiKit Systems</strong><br>–  GoDiS (Larsson et al) – information state: Questions Under Discussion<br>–  MIDAS – DRS information state, first-order reasoning (Bos &amp;Gabsdil, 2000)<br>–  EDIS – PTT Information State, (Matheson et al 2000)<br>–  SRI Autoroute –Conversational Game Theory (Lewin 2000)</li>
<li><strong>Successor Toolkits</strong><br>–  Dipper (Edinburgh)<br>–  Midiki (MITRE)</li>
<li><strong>Other IS approaches</strong><br>–  Soar (USC virtual humans)<br>–  AT&amp;T MATCH system</li>
</ul>
<h2 id="Plan-based-Approaches"><a href="#Plan-based-Approaches" class="headerlink" title="Plan-based Approaches"></a>Plan-based Approaches</h2><p>一般指大名鼎鼎的 <strong>BDI (Belief, Desire, Intention)</strong> 模型。起源于三篇经典论文：</p>
<ul>
<li>Cohen and Perrault 1979</li>
<li>Perrault and Allen 1980</li>
<li>Allen and Perrault 1980</li>
</ul>
<p>基本假设是，一个试图发现信息的行为人，能够利用标准的 plan 找到让听话人告诉说话人该信息的 plan。这就是 Cohen and Perrault 1979 提到的 <strong>AI Plan model</strong>，Perrault and Allen 1980 和 Allen and Perrault 1980 将 BDI 应用于理解，特别是间接言语语效的理解，本质上是对 Searle 1975 的 speech acts 给出了可计算的形式体系。</p>
<p>官方描述（Allen and Perrault 1980）：</p>
<blockquote>
<p>A has a goal to acquire certain information. This causes him to create a plan that involves asking B a question. B will hopefully possess the sought information. A then executes the plan, and thereby asks B the question. B will now receive the question and attempt to infer A’s plan. In the plan there might be goals that A cannot achieve without assistance. B can accept some of these obstacles as his own goals and create a plan to achieve them. B will then execute his plan and thereby respond to A’s question.</p>
</blockquote>
<p>重要的概念都提到了，<strong>goals, actions, plan construction, plan inference</strong>。理解上有点绕，简单来说就是 agent 会捕捉对 internal state (beliefs) 有益的信息，然后这个 state 与 agent 当前目标（goals/desires）相结合，再然后计划（plan/intention）就会被选择并执行。对于 communicative agents 而言，plan 的行为就是单个的 speech acts。speech acts 可以是复合（composite）或原子（atomic）的，从而允许 agent 按照计划步骤传达复杂或简单的 conceptual utterance。</p>
<p>这里简单提一下重要的概念。</p>
<ul>
<li><strong>信念（Belief）</strong><br>基于谓词 KNOW，如果 A 相信 P 为真，那么用 B(A, P) 来表示</li>
<li><strong>期望（Desire）</strong><br>基于谓词 WANT，如果 S 希望 P 为真（S 想要实现 P），那么用 WANT(S, P) 来表示，P 可以是一些行为的状态或者实现，W(S, ACT(H)) 表示 S 想让 H 来做 ACT</li>
</ul>
<p>Belief 和 WANT 的逻辑都是基于公理。最简单的是基于 action schema。每个 action 都有下面的参数集：</p>
<ul>
<li><strong>前提（precondition）</strong><br>为成功实施该行为必须为真的条件</li>
<li><strong>效果（effect）</strong><br>成功实施该行为后变为真的条件</li>
<li><strong>体（body）</strong><br>为实施该行为必须达到的部分有序的目标集（partially ordered goal states）</li>
</ul>
<p><strong>计划推理（Plan Recognition/Inference, PI）：</strong><br>根据 B 实施的行为，A 试图去推理 B 的计划的过程。</p>
<ul>
<li>PI.AE Action-Effect Rule（行为-效果规则）</li>
<li>PI.PA Precondition-Action Rule（前提-行为规则）</li>
<li>PI.BA Body-Action Rule（体-行为规则）</li>
<li>PI.KB Know-Desire Rule（知道-期望规则）</li>
<li>E1.1 Extended Inference Rule（扩展推理规则）</li>
</ul>
<p><strong>计划构建（Plan construction）：</strong></p>
<ul>
<li>找到从当前状态（current state）达到目标状态（goal state）需要的行为序列（sequence of actions）</li>
<li>Backward chaining，大抵是说，试图找到一个行为，如果这个行为实施了能够实现这个目标，且它的前提在初始状态已经得到满足，那么计划就完成了，但如果未得到满足，那么会把前提当做新的目标，试图满足前提，直到所有前提都得到满足。（find action with goal as effect then use preconditions of action as new goal, until no unsatisfied preconditions）<br>backward chaining 在 <a href="http://www.shuang0420.com/2017/04/07/NLP%20笔记%20-%20Meaning%20Representation%20Languages/">NLP 笔记 - Meaning Representation Languages</a> 中提到过。</li>
</ul>
<p>还有个重要的概念是 speech acts，在 <a href="http://www.shuang0420.com/2017/09/20/NLP%20笔记%20-%20Discourse%20Analysis/">NLP 笔记 - Discourse Analysis</a> 中提到过，之后会细讲。</p>
<p>更多见 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.8451&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Plan-based models of dialogue</a></p>
<p>值得一提的是，<strong>基于 logic 和基于 plan</strong> 的方法虽然有更强大更完备的功能，但实际场景中并不常用，大概是因为大部分的系统都是相对简单的单个领域，任务小且具体，并不需要复杂的推理。</p>
<h1 id="Statistical-Approaches"><a href="#Statistical-Approaches" class="headerlink" title="Statistical Approaches"></a>Statistical Approaches</h1><h2 id="RL-Based-Approaches"><a href="#RL-Based-Approaches" class="headerlink" title="RL-Based Approaches"></a>RL-Based Approaches</h2><p>前面提到的很多方法还是需要人工来定规则的（hand-crafted approaches），然而人很难预测所有可能的场景，这种方法也并不能重用，换个任务就需要从头再来。而一般的基于统计的方法又需要大量的数据。再者，对话系统的评估也需要花费很大的代价。这种情况下，强化学习的优势就凸显出来了。RL-Based DM 能够对系统理解用户输入的不确定性进行建模，让算法来自己学习最好的行为序列。首先利用 simulated user 模拟真实用户产生各种各样的行为（捕捉了真实用户行为的丰富性），然后由系统和 simulated user 进行交互，根据 reward function 奖励好的行为，惩罚坏的行为，优化行为序列。由于 simulated user 只用在少量的人机互动语料中训练，并没有大量数据的需求，不过 user simulation 也是个很难的任务就是了。</p>
<p>对话仿真的整体框架如下图：<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D%E4%B9%8B%E5%AF%B9%E8%AF%9D%E7%AE%A1%E7%90%86%28Dialog%20Management%29/rl_arch.png" class="ful-image" alt="rl_arch.png"></p>
<h1 id="DM-设计"><a href="#DM-设计" class="headerlink" title="DM 设计"></a>DM 设计</h1><p>一般在冷启动阶段，会先用规则方法打造一个 DM，快速上线并满足业务需求，收集数据之后再转换成模型。</p>
<p>DM 的<strong>设计理念：</strong></p>
<ul>
<li><strong>完整性</strong><br>具备建模各种类型对话的能力（不仅仅是slot filling）</li>
<li><strong>独立性</strong><br>当设计（变更）一个场景时，不需要考虑当前场景跳转到其他场景的情况</li>
<li><strong>模块化</strong><br>一些常用的业务组件(如：确认，slot filling，翻页等)，能呈模块化复用(同时允许业务自定义内部的多种属性)</li>
</ul>
<p>DM 里可以有很多小的 dialogs，这些 dialogs 的特点是：</p>
<ul>
<li>可以重用（reusable modules）</li>
<li>完成一个简单操作（Perform a single operation）</li>
<li>可以被其他 dialog 调用（callable from other dialogs）</li>
<li>可以是全局的（”global”）</li>
</ul>
<p>Global dialog 的特点是：</p>
<ul>
<li>在 recognizer 能够匹配时 trigger </li>
<li>可以提供一些 conversation support，像是 help/cancel 这些全局功能</li>
<li>应对各种话题切换（Tangents）</li>
</ul>
<p>通常只有一个 root dialog，在满足下面两个条件的情况下被唤醒</p>
<ul>
<li>dialog stack 里没有其他的 dialog 剩余了</li>
<li>当前时刻 recognizer 并不能 trigger 其他的 dialog </li>
</ul>
<p>dialog stack 会存放目前已经被激活但还没完成的 dialog。dialog 一旦完成就会被 pop 出去。</p>
<blockquote>
<p><strong>参考链接：</strong><br><a href="https://www.slideshare.net/YunChaoHe1/ss-73195982" target="_blank" rel="external">多轮对话 multi-turn dialog for task-oriented system</a><br><a href="https://www.youtube.com/watch?v=FiytlAalO_g" target="_blank" rel="external">Dialog Management in Bot Framework</a><br><a href="http://www.cs.cmu.edu/~xw/asru99-agenda.pdf" target="_blank" rel="external">AN AGENDA-BASED DIALOG MANAGEMENT ARCHITECTURE FOR SPOKEN LANGUAGE SYSTEMS</a><br><a href="http://people.ict.usc.edu/~traum/Papers/traumlarsson.pdf" target="_blank" rel="external">The Information State Approach to Dialogue Management</a><br><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.8451&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Plan-based models of dialogue</a><br><a href="https://yq.aliyun.com/articles/276269" target="_blank" rel="external">对话管理的一些思考</a><br><a href="http://www.pmcaff.com/article/index/971158746030208?from=related&amp;pmc_param%5Bentry_id%5D=950709304427648" target="_blank" rel="external">填槽与多轮对话 | AI产品经理需要了解的AI技术概念</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开始涉猎多轮对话，这一篇想写一写对话管理（Dialog Management），感觉是个很庞大的工程，涉及的知识又多又杂，在这里只好挑重点做一个引导性的介绍，后续会逐个以单篇形式展开。–持续更新中–&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="NLU" scheme="http://www.shuang0420.com/tags/NLU/"/>
    
      <category term="Dialog Management" scheme="http://www.shuang0420.com/tags/Dialog-Management/"/>
    
      <category term="DM" scheme="http://www.shuang0420.com/tags/DM/"/>
    
      <category term="slot-filling" scheme="http://www.shuang0420.com/tags/slot-filling/"/>
    
      <category term="FSM" scheme="http://www.shuang0420.com/tags/FSM/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Learning to Remember Translation History with a Continuous Cache</title>
    <link href="http://www.shuang0420.com/2017/12/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Remember%20Translation%20History%20with%20a%20Continuous%20Cache/"/>
    <id>http://www.shuang0420.com/2017/12/20/论文笔记 - Learning to Remember Translation History with a Continuous Cache/</id>
    <published>2017-12-20T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>介绍一种 cache-like memory network。<br><a id="more"></a></p>
<p><strong>涉及论文：</strong></p>
<ul>
<li>Learning to Remember Translation History with a Continuous Cache</li>
</ul>
<p><strong>相关博客：</strong></p>
<ul>
<li><a href="http://www.shuang0420.com/2017/07/10/-NLP%20笔记%20-%20Machine%20Translation-Neuron%20models/">NLP 笔记 - Neural Machine Translation</a></li>
<li><a href="http://www.shuang0420.com/2017/12/04/论文笔记%20-%20Memory%20Networks/">论文笔记 - Memory Networks</a></li>
</ul>
<p>比较传统的 NMT 把文档当做一系列独立的句子来进行翻译，忽略了句子之间的关系，或者说是忽略了篇章信息，这样会带来两个问题：</p>
<ol>
<li><strong>一致性问题（inconsistency）</strong><br>如时态一致性问题，以及术语选择的一致性问题，这些通常都需要联系上下文/篇章信息</li>
<li><strong>歧义问题（ambiguity）</strong><br>NMT 基本的翻译单位是词向量，也是通过 word-by-word 的方式产生翻译的。向量表示的泛化问题会导致歧义进一步放大，如机遇/挑战，教师/培训这些词在空间里比较靠近，很容易导致翻译错误</li>
</ol>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Remember%20Translation%20History%20with%20a%20Continuous%20Cache/nmt_drawback.png" class="ful-image" alt="nmt_drawback.png">
<p>在 SMT 中，引入 cross-sentence 的作用对解决上面两个问题非常有效，因此 NMT 方面也有人做了一些尝试，比如说用分层 RNN 来总结前 K 个 source sentences 的语境信息（Wang et al. 2017a），或者用额外的 encoder 和 attention model 来动态选择聚焦前一个 source sentence 的某个部分 （Jean et al. 2017），这些方法有一定效果，但是都只考虑了单语的信息，没有用到目标端的信息，并且仍然是从 discrete lexicon 中产生 context，词级别的错误会继续传递下去，这在口语字幕的语料上表现的更为明显（不能得到多大改善）。另外，这两个模型计算量也很大，不利于 scale。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Remember%20Translation%20History%20with%20a%20Continuous%20Cache/performance.png" class="ful-image" alt="performance.png">
<p>这篇论文用到了 cache-like memory networks 的思想，用一个额外的 cache model  把源端表示作为 KEY，目标端表示作为 VALUE，从 memory 里定位相关的信息，然后把相关信息也作为输入，翻译时能得到更多方面比如说时态的信息。这样的好处 <strong>一是可以规模化，通过 cache 获得更长的历史信息，二是因为用的是 internal representation （并且是 attention 后的片段信息）而不是单词，能缓解错误传播的问题，也考虑进了目标端的信息。</strong></p>
<p>与 Standard NMT 的对比如下：</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Remember%20Translation%20History%20with%20a%20Continuous%20Cache/architecture.png" class="ful-image" alt="architecture.png">
<p>主要还是读取/写入 cache 的过程。</p>
<h1 id="Reading-from-Cache"><a href="#Reading-from-Cache" class="headerlink" title="Reading from Cache"></a>Reading from Cache</h1><h2 id="Key-Matching"><a href="#Key-Matching" class="headerlink" title="Key Matching"></a>Key Matching</h2><p>cache lookup 最简单用点积来做，也可以加中间转换矩阵或者用 attention 方法，不过点积最简单高效，不用学新的参数也能学到相似度</p>
<p>$$P_m(c_i|c_t)={exp(c^T_tc_i)\over \sum^I_{i’=1}exp(c^T_tc_i’)}$$</p>
<p>$c_t$ 是 t step 的 attention context，$c_i$ 是 cache 里第 i 个位置的 representation，I 是 cache slots 的总量</p>
<h2 id="Value-Reading"><a href="#Value-Reading" class="headerlink" title="Value Reading"></a>Value Reading</h2><p>得到概率分布后对每个 value 进行加权</p>
<p>$$m_t=\sum_{(c_i, s_i) \in cache} P_m(c_i|c_t)s_i$$</p>
<p>$P_m(c_i|c_t)$ 可以解释为给定 source side context $c_t$，从 cache 里检索得到相似的 target-side info $m_t$，答案是和过去产生的相似的 target words 相关的语境</p>
<h2 id="Representation-Combining"><a href="#Representation-Combining" class="headerlink" title="Representation Combining"></a>Representation Combining</h2><p>用原始的 decoder state $s_t$ 和当前的 output vector $m_t$ 进行线性组合，相当于 GRU 里的 update gate</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Remember%20Translation%20History%20with%20a%20Continuous%20Cache/repres_combing.png" class="ful-image" alt="repres_combing.png">
<p>其中 lambda 是一个动态调节的 weight vector，在每个 decoding step 都要重新计算</p>
<p>$$\lambda_t = \sigma (Us_t + Vc_t+Wm_t)$$</p>
<p>U(dxd), V(dxl), W(dxd) 是参数矩阵</p>
<h1 id="Writing-to-Cache"><a href="#Writing-to-Cache" class="headerlink" title="Writing to Cache"></a>Writing to Cache</h1><p>在整个句子翻译完后，再写入 cache，写入 cache 的内容包括</p>
<ul>
<li><strong>generated translation sentence</strong><br>  {$y_1,…,y_t…,y_T$}</li>
<li><strong>attention vector sequence</strong><br>  {$c_1,…,c_t,…c_T$}</li>
<li><strong>decoder state sequence</strong><br>  {$s_1,…,s_t,…,s_T$}</li>
</ul>
<p>如果 $y_t$ 在 cache 里不存在，那么会选择一个空的 slot 或者覆盖一个 LRU(least recently used) slot，key 是 $c_t$，value 是 $s_t$，indicator 是 $y_t$</p>
<p>如果 $y_t$ 已经存在，那么更新 key, value，$k_i=(k_i+c_t)/2, \ v_i=(v_i+s_t)/2$，像是一个 exponential decay，每一次更新之前的 key, value 都会减半，基本逻辑是最近的历史会有更高的重要性。通过可视化图可以看一下效果：</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Remember%20Translation%20History%20with%20a%20Continuous%20Cache/vis.png" class="ful-image" alt="vis.png">
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>理解下来还是非常简单的。亮点还是 cache 的设计，一方面用到了历史信息，另一方面用到了源端和目标端的信息，并且是单词粒度之上的信息（attention context vector）。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍一种 cache-like memory network。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Memory Networks" scheme="http://www.shuang0420.com/tags/Memory-Networks/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Memory Networks</title>
    <link href="http://www.shuang0420.com/2017/12/04/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/"/>
    <id>http://www.shuang0420.com/2017/12/04/论文笔记 - Memory Networks/</id>
    <published>2017-12-04T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Memory Networks 相关笔记。<br><a id="more"></a></p>
<p>这一篇会覆盖下面三个版本的 Memory Networks</p>
<ul>
<li>Memory Network with strong supervision</li>
<li>End-to-End Memory Network</li>
<li>Dynamic Memory Network</li>
</ul>
<p>涉及下面一些论文：</p>
<ul>
<li>Memory Networks (2015)</li>
<li>End-To-End Memory Networks (2015)   </li>
<li>Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (2016)</li>
<li>Dynamic Memory Networks for Visual and Textual Question Answering (2016)</li>
</ul>
<p>首先要明确的是，Memory Networks 只是一种思想或者说一个框架，像一个 base class，里面的各个 module 都可以自己定制。其中基本的一些思路：</p>
<ul>
<li><strong>分层 RNN 的 context RNN</strong><br>与 context RNN 类似，Memory Network 同样以句子为单位来提取、保存语境信息</li>
<li><strong>Attention 原理</strong><br>使用多个 state vector 来保存信息，并从中寻找有用的记忆，而不是寄希望于 final state 存储的信息</li>
<li><strong>Incorporate reasoning with attention over memory(RAM): Memory Network</strong><br>使用记忆以及记忆上的 attention 来做推理</li>
</ul>
<h1 id="Memory-Networks-2015"><a href="#Memory-Networks-2015" class="headerlink" title="Memory Networks (2015)"></a>Memory Networks (2015)</h1><p>对应论文：Memory Networks (2015)</p>
<p>Memory Networks 提出的基本动机是我们需要 <strong>长期记忆（long-term memory）</strong>来保存问答的知识或者聊天的语境信息，而现有的 RNN 在长期记忆中表现并没有那么好。</p>
<h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>4 个重要组件：</p>
<ul>
<li><strong>I: input feature map</strong><br>把输入映射为特征向量（input -&gt; feature representation）<br>通常以句子为单位，一个句子对应一个向量</li>
<li><strong>G: generalization</strong><br>使用新的输入数据更新 memories</li>
<li><strong>O: output</strong><br>给定新的输入和现有的 memory state，在特征空间里产生输出<br>类比 attention RNN decoder 产生 outputs/logits</li>
<li><strong>R: response</strong><br>将输出转化为自然语言</li>
</ul>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/memory_networks1.png" class="ful-image" alt="Memory%20Networks/memory_networks1.png">
<p>上面的 4 个 component 就对应了整个工作流程：</p>
<ol>
<li><strong>把输入 x 映射为特征向量 I(x)</strong><br>可以选择多种特征，如 bag of words, RNN encoder states, etc.<br>如果用 embedding model 来表达文本的话，一个郁闷的地方是 embdding 的参数在不断变化，所以训练时保存的 vector 也要变化……当然这在测试时就成了优势，因为测试时 embedding 参数就固定啦</li>
<li><strong>更新 memory mi</strong>，$m_i = G(m_i, I(x), m), \forall i.$<br>将输入句子的特征 x 保存到下一个合适的地址 $m_n$，可以简单的寻找下一个空闲地址，也可以使用新的信息更新之前的记忆<br>简单的函数如 $m_{H(x)}=I(x)$，H(x) 是一个寻址函数（slot choosing function），G 更新的是 m 的 index，可以直接把新的输入 I(x) 保存到下一个空闲的地址 $m_n$，并不更新原有的 memory，当然更复杂的 G 函数可以去更新更早的 memory 甚至是所有的 memory</li>
<li><strong>给定新的输入和 memory，计算 output feature o: o=O(I(x),m)</strong><br>Addressing，寻址，给定 query Q，在 memory 里寻找相关的包含答案的记忆<br>$qUU^Tm$： 问题 q 和事实 m 的相关程度，当然这里的 q，m 都是特征向量，可以用同一套参数也可以用不同的参数<br>U：bilinear regression 参数，相关事实的 $qUU^Tm_{true}$ 分数高于不相关事实的分数 $qUU^Tm_{random}$<br>n 条记忆就有 n 条 bilinear regression score<br>回答一个问题可能需要寻找多个相关事实，先根据 query 定位到第一条最相关的记忆，再用第一条 fact 和 query 通过加总或拼接等方式得到 u1 然后一起定位第二条<br>$o_1 = O_1(q,m) = argmax_{i=1,…N} \ s_o(q, m_i)$<br>$o_2 = O_2(q,m) = argmax_{i=1,…N} \ s_o([q, o_1], m_i)$</li>
<li><strong>对 output feature o 进行解码，得到最后的 response: r=R(o)</strong><br>将 output 转化为自然语言的 response<br>$r = argmax_{w \in W} \ s_R([q, o_1, o_2], w)$<br>$s_R(x,y)=xUU^Ty$<br>可以挑选并返回一个单词比如说 playground<br>在词汇表上做一个 softmax 然后选最有可能出现的单词做 response，也可以使用 RNNLM 产生一个包含回复信息的句子，不过要求训练数据的答案就是完整的句子，比如说 football is on the playground</li>
</ol>
<h2 id="Huge-Memory-问题"><a href="#Huge-Memory-问题" class="headerlink" title="Huge Memory 问题"></a>Huge Memory 问题</h2><p><strong>如果 memory 太大怎么办？</strong></p>
<ol>
<li>可以按 entity 或者 topic 来存储 memory，这样 G 就不用在整个 memories 上操作了</li>
<li>如果 memory 满了，可以引入 forgetting 机制，替换掉没那么有用的 memory，H 函数可以计算每个 memory 的分数，然后重写</li>
<li>还可以对单词进行 hashing，或者对 word embedding 进行聚类，总之是把输入 I(x) 放到一个或多个 bucket 里面，然后只对相同 bucket 里的 memory 计算分数</li>
</ol>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>损失函数如下，选定 2 条 supporting fact (k=2)，response 是单词的情况：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/memory_networks_loss.png" class="ful-image" alt="Memory%20Networks/memory_networks_loss.png"></p>
<p>(6) 有没有挑选出正确的第一句话<br>(7) 正确挑选出了第一句话后能不能正确挑出第二句话<br>(6)+(7) 合起来就是能不能挑选出正确的语境，用来训练 attention 参数<br>(8) 把正确的 supporting fact 作为输入，能不能挑选出正确的答案，来训练 response 参数</p>
<h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2><p>在 bAbI QA 部分数据集上的结果<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/memory_networks_performance.png" class="ful-image" alt="memory_networks_performance.png"></p>
<p>部分 QA 实例：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/memory_networks_performance1.png" class="ful-image" alt="memory_networks_performance1.png"></p>
<h2 id="局限"><a href="#局限" class="headerlink" title="局限"></a>局限</h2><ol>
<li><strong>需要很强的标记信息</strong><br>bAbI 提供了 supporting fact 的 ID，但对大多数 QA 数据而言，并不存在明确的 supporting fact 标记</li>
<li><strong>Loss2 无法 backpropagate 到模型的左边部分，BP 过程到 m 就停了，并不能 end-to-end 进行训练</strong><br>这相当于一个链状的贝叶斯网络，考虑 A-&gt;B-&gt;C 的有向图，B 对应 m，B 不确定的时候，C 依赖于 A，但是当 B 确定的时候，C 就不依赖于 A 了。 也就是说，在给定 m 的情况下，loss2 和前面的参数是独立的，所以优化 loss2 并不能优化左边的参数</li>
</ol>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/memory_networks_drawback.png" class="ful-image" alt="Memory%20Networks/memory_networks_drawback.png">
<h1 id="End-to-End-learning"><a href="#End-to-End-learning" class="headerlink" title="End-to-End learning"></a>End-to-End learning</h1><p>对应论文：End-To-End Memory Networks (2015)   </p>
<p>End-to-End learning 用了 soft attention 来估计每一个 supporting fact 的相关程度，实现了端到端的 BP 过程。</p>
<h2 id="Single-Layer"><a href="#Single-Layer" class="headerlink" title="Single Layer"></a>Single Layer</h2><p>一张图就解决了：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/end_to_end_struc.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/end_to_end_struc.png"></p>
<p>模型输入:</p>
<ul>
<li><strong>Input:</strong> $x_1, …, x_n$，会被存储到 memory 中</li>
<li><strong>Query:</strong> q</li>
<li><strong>Answer:</strong> a</li>
</ul>
<p>具体过程（以单层为例）：</p>
<ol>
<li><strong>映射到特征空间</strong><br>{$x_i$} $\xrightarrow{A}$ {$m_i$}<br>$q \xrightarrow{B} u$</li>
<li><strong>计算 attention，得到 query 和 memory 的匹配度，有多少个 memory 就有多少个 $p_i$</strong><br>$p_i = Softmax(u^Tm_i)$</li>
<li><strong>得到 context vector</strong><br>$o = \sum_ip_ic_i$<br>和 Memory Networks with Strong Supervision 版本不同，这里的 output 是加权平均而不是一个 argmax</li>
<li><strong>context vector 和 query 一起，预测最后答案，通常是一个单词</strong><br>$\hat a=Softmax(W(o+u))$</li>
<li><strong>对 $\hat a$ 进行解码，得到自然语言的 response</strong><br>$\hat a \xrightarrow{C} a$</li>
</ol>
<p>其中，<br>A: intput embedding matrix<br>C: output embedding matrix<br>W: answer prediction matrix<br>B: question embedding matrix</p>
<p>损失函数是交叉熵，用 SGD 训练。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/end_to_end_struc2.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/end_to_end_struc2.png"></p>
<h2 id="Multi-hop-Architecture"><a href="#Multi-hop-Architecture" class="headerlink" title="Multi-hop Architecture"></a>Multi-hop Architecture</h2><p>多层结构（K hops）也很简单，相当于做多次 addressing/多次 attention，每次 focus 在不同的 memory 上，不过在第 k+1 次 attention 时 query 的表示需要把之前的 context vector 和 query 拼起来，其他过程几乎不变。<br>$u^{k+1}=u^k + o^k$</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/end_to_end_multi_hop.png" class="ful-image" alt="%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/end_to_end_multi_hop.png">
<h3 id="一些技术细节"><a href="#一些技术细节" class="headerlink" title="一些技术细节"></a>一些技术细节</h3><p>通常来说 encoding 和 decoding 的词向量参数是不一样的，因为一个是单词-词向量，一个是 隐状态-词向量。</p>
<ul>
<li><strong>Adjacent</strong><br>前一层的输出是这一层的输入<br>$A^{k+1}=C^k$<br>$W^T=C^L$<br>$B=A^1$</li>
<li><strong>Layer-wise(RNN-like)</strong><br>不同层之间用同样的 embedding<br>$A^1=A^2=…=A^K$<br>$C^1=C^2=…=C^K$<br>可以在 hop 之间加一层线性变换 H 来更新 $\mu$<br>$u^{k+1}=Hu^k+o^k$</li>
</ul>
<h1 id="Dynamic-Memory-Networks"><a href="#Dynamic-Memory-Networks" class="headerlink" title="Dynamic Memory Networks"></a>Dynamic Memory Networks</h1><p>对应论文：Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (2016)</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN_struc1.png" class="ful-image" alt="DMN_struc1.png">
<h2 id="Input-Module"><a href="#Input-Module" class="headerlink" title="Input Module"></a>Input Module</h2><p>这一部分像是一个 semantic memory。<strong>输入</strong>可以是一个/多个句子，一篇/几篇文章，包含语境信息和知识库等，使用 RNN 进行 encoding，每一个句子编码成固定维度的 state vector。<br>具体做法是把句子拼到一起（每个句子结尾加标记符 EOS），用 GRU-RNN 进行编码，如果是单个句子，就<strong>输出</strong>每个词的 hidden state；如果是多个句子，就<strong>输出</strong>每个句子 EOS 标记对应的 hidden state，其实相当于分层 RNN 的下面一层。</p>
<p>$$h_t=GRU(L[w_t], h_{t-1})$$</p>
<p>$L[w_t] $ 是 word embedding。</p>
<h2 id="Question-Module"><a href="#Question-Module" class="headerlink" title="Question Module"></a>Question Module</h2><p><strong>输入</strong>是 question 对应的词序列，同样用 GRU-RNN 进行编码。</p>
<p>$$q_t=GRU([L[w_t^Q], q_{t-1})$$</p>
<p>同样的，L 是词向量参数，和 input module 的 L 相同。<strong>输出</strong>是 final hidden state</p>
<h2 id="Episodic-Memory-Module"><a href="#Episodic-Memory-Module" class="headerlink" title="Episodic Memory Module"></a>Episodic Memory Module</h2><p>由 internal memory, attention mechansim, memory update mechanism 组成。 <strong>输入</strong>是 input module 和 question module 的输出。</p>
<p>把 input module 中每个句子的表达（fact representation c）放到 episodic memory module 里做推理，使用 attention 原理从 input module 中提取相关信息，同样有 multi-hop architecture。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN_process.png" class="ful-image" alt="DMN_process.png">
<h3 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h3><p>觉得论文里的 attention mechanism 和 memory update mechanism 描述的有点问题，个人以为 attention mechanism 的目的还是生成 context vector，memory update mechanism 的目的是更新 memory，所以把部分公式按自己的理解移动了下，便于理解。</p>
<p>计算 query 和 fact 的分数，query 和上一个 memory $m^{i-1}$ 作为<strong>输入</strong>产生<strong>输出</strong> episode $e^i$。要注意的是，End-to-End MemNN 的 attention 用的是 linear regression，DMN 用的是  gating function，一个两层的前向神经网络。</p>
<p>在每一轮迭代中，都有<strong>输入</strong>：</p>
<ol>
<li>$c_t$（input module 中第 t 个位置的 fact vector)</li>
<li>上一轮迭代得到的 memory $m_{i-1}$</li>
<li>question q  </li>
</ol>
<p>利用 gating function 计算第 t 个位置的得分  $g^i_t=G(c_t, m_{i-1}, q)$。G 是一个两层的前向神经网络的 score function，不过描述 input, memory, question 相似度的 feature vector z(c,m,p) 是人工定义的，这也成为了之后 DMN+ 的一个优化点。</p>
<p>计算完每一次迭代每一个位置的分数后，来更新 episode $e^i$，或者说产生 context vector。<strong>输入</strong>是 $c_1, …, c_{T_C}$，和它们的 gate score $g^i_t$。</p>
<p>$$ h^i_t=g^i_tGRU(c_t, h^i_{t-1})+(1-g^i_t)h^i_{t-1}$$</p>
<p>$$e^i=h^i_{T_C}$$</p>
<p>总结一下，这部分 attention mechanism 的目的是生成 episode $e^i$，$e^i$ 是第 t 轮迭代的所有相关 input 信息的 summary。与 End-to-End MemNN 不同的是，End-to-End 用了 soft attention，也就是加权和来计算 context，而这里用了 GRU。</p>
<h3 id="Memory-Update-Mechanism"><a href="#Memory-Update-Mechanism" class="headerlink" title="Memory Update Mechanism"></a>Memory Update Mechanism</h3><p>上一步算的 episode $e^i$ 以及上一轮迭代的 memory $m^{i-1}$ 作为<strong>输入</strong> 来更新 episodic memory $m^i$。</p>
<p>$$m^i=GRU(e^i, m^{i-1})$$</p>
<p><strong>输出</strong>是最后一次迭代的 $m=m^{T_M}$</p>
<p>End-to-End MemNN 的 memory update 过程里，第 k+1 次 query vector 直接是上一个 context vector 和 query 的拼接，$u^{k+1}=u^k + o^k$。而 DMN 里，采用了 RNN 做非线性映射，用 episode $e^i$ 和上一个 memory $m^{i-1}$ 来更新 episodic memory，其 GRU 的初始状态包含了 question 信息，$m^0=q$。</p>
<p>Episodic Memory Module 需要一个停止迭代的信号。一般可以在输入中加入一个特殊的 end-of-passes 的信号，如果 gate 选中了该特殊信号，就停止迭代。对于没有显性监督的数据集，可以设一个迭代的最大值。</p>
<p>总结一下，这部分 memory update mechanism 的目的是生成 t 时刻的 episode memory $m^t$，最后一个 pass 的$m^T$ 将包含用于回答问题 q 的所有信息。</p>
<h3 id="Example-Understanding"><a href="#Example-Understanding" class="headerlink" title="Example Understanding"></a>Example Understanding</h3><p>来用例子解释下 Episodic Memory Module 上面那张图，question 是 where is the football? 第一次迭代找到的是第 7 个句子，John put down the football，第二次找到第 6 个句子 John went to the hallway，第三次找到第 2 个句子 John moved to the bedroom。</p>
<p>多次迭代第一次找到的是字面上最相关的 context，然后一步步迭代会逐渐定位到真正语义相关的 context，这感觉上就是一个推理的过程。</p>
<h3 id="Answer-Module"><a href="#Answer-Module" class="headerlink" title="Answer Module"></a>Answer Module</h3><p>使用了 GRU-RNN 作为 decoder。<strong>输入</strong>是 question module 的输出 q 和上一时刻的 hidden state $a_{t-1}$，初始状态是episode memory module 的输出 $a_0=m^{T_M}$</p>
<p>$$<br>  \begin{aligned}<br>  y_t=Softmax(W^{(a)}a_t) \\<br>  a_t=GRU([y_{t-1}, q], a_{t-1}) \\<br>  \end{aligned}<br>$$</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>使用 cross-entroy 作为目标函数。如果数据集有 gate 的监督数据，还可以将 gate 的 cross-entroy 加到总的 cost上去，一起训练。训练直接使用 backpropagation 和 gradient descent 就可以。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>总的来说，DMN 在 addressing，memory 提取，query/memory update 部分都用了 DL 手段，相比于 End-to-End MemNN 更为复杂。</p>
<h1 id="DMN"><a href="#DMN" class="headerlink" title="DMN+"></a>DMN+</h1><p>对应论文：Dynamic Memory Networks for Visual and Textual Question Answering (2016)</p>
<p>DMN 存在的两个问题：</p>
<ol>
<li>输入模块只考虑了过去信息，没考虑到将来信息</li>
<li>只用 word level 的 GRU，很难记忆远距离 supporting sentences 之间的信息</li>
</ol>
<p>这一部分重点讲与 DMN 不同的地方。</p>
<h2 id="Input-Module-1"><a href="#Input-Module-1" class="headerlink" title="Input Module"></a>Input Module</h2><p>DMN+ 把 single GRU 替换成了类似 hierarchical RNN 结构，一个 sentence reader 得到每个句子的 embedding，一个 input infusion layer 把每个句子的 embedding 放入另一个 GRU 中，得到 context 信息，来解决句子远距离依赖的问题。HRED 相关思路见 <a href="http://www.shuang0420.com/2017/11/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20HRED%20%E4%B8%8E%20VHRED/">论文笔记 - HRED 与 VHRED</a>。这里还做了一些微调，sentence reader 用的是 positional encoding，input fusion layer 用了双向 GRU，兼顾了过去和未来的信息。</p>
<p>用 positional encoding 的原因是在这里用 GRU/LSTM 编码句子计算量大而且容易过拟合（毕竟 bAbI 的单词量很小就几十个单词。。），这种方法反而更好。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2B_textual_input.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2B_textual_input.png"></p>
<p>除了处理文本信息，作者也提出了图像信息的方案，CNN+RNN，把局部位置的图像信息当做 sentence 处理，在这不多介绍。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2B_image_input.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2B_image_input.png"></p>
<h2 id="Episodic-Memory-Module-1"><a href="#Episodic-Memory-Module-1" class="headerlink" title="Episodic Memory Module"></a>Episodic Memory Module</h2><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2BMemoryUpdate.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2BMemoryUpdate.png">
<h3 id="Attention-Mechanism-1"><a href="#Attention-Mechanism-1" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h3><p>仍然是人工构造特征向量来计算 attention，但与之前版本的 DMN 相比更为简化，省去了两项含有参数的部分，减少了计算量。另外与 DMN 不同的是，gate 值不是简单的二层前馈网络的结果，而是接着计算了一个 sofmax 评分向量。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2B_gate.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/DMN%2B_gate.png">
<p>也就是说，从公式上看，相对于 DMN，式 8 更为简洁，式 9 不变（结果就是 DMN 的 gate 值），增加了式 10。 </p>
<p>进行到下一步关于 context vector 的计算，两种方案，一种是 soft attention，简单的加权求和，另一种是 attention based GRU。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/AttnGRU.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/AttnGRU.png">
<p>AttnGRU 考虑了输入 facts 的位置和顺序信息（position and ordering），或者说是时序信息。在得到 attenion 后，把 attention 作为 gate，如上图，把传统 GRU 中的 update gate $u_i$ 替换成了 attention 的输出 $g^t_i$，这样 gate 就包含了 question 和前一个 episode memory 的知识，更好的决定了把多少 state 信息传递给下一个 RNN cell。同时这也大大简化了 DMN 版本的 context 计算。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/AttnGRU2.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/AttnGRU2.png">
<p>$\hat h$ 是更新的 state，$h_{i-1}$ 是传入的上一时刻的 state，$g^t_i$ 是 attention value，是一个由 softmax 产生的标量（scalar）而不是 sigmoid 激活产生的 vector $u_i \in R^{n_H}$，context vector 是 GRU 的 final hidden state。</p>
<p>AttnGRU 要优于 weighted sum，因为使用了一些时间上的关系，比如小明在操场，小明回了家，小明进了卧室，这些事实实际上有先后关系，而 weighted sum 不一定能反映这种时序关系。</p>
<h3 id="Memory-Update-Mechanism-1"><a href="#Memory-Update-Mechanism-1" class="headerlink" title="Memory Update Mechanism"></a>Memory Update Mechanism</h3><p>DMN 中 memory 更新采用以 q 向量为初始隐层状态的 GRU 进行更新，用同一套权重，这里替换成了一层 ReLU 层，实际上简化了模型。</p>
<p>$$m^t = ReLU(W^t[m^{t-1};c^t;q]+b)$$</p>
<p>其中 ; 表示拼接，这能进一步提高近 0.5% 的准确率。</p>
<h2 id="Performance-1"><a href="#Performance-1" class="headerlink" title="Performance"></a>Performance</h2><p>最后上一个不同模型的 performance 比较图。<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/final_performance.png" class="ful-image" alt="../../static/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Memory%20Networks/final_performance.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Memory Networks 相关笔记。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="Memory Networks" scheme="http://www.shuang0420.com/tags/Memory-Networks/"/>
    
  </entry>
  
  <entry>
    <title>机器学习策略(Andrew Ng. DL 笔记)</title>
    <link href="http://www.shuang0420.com/2017/11/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5(Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0)/"/>
    <id>http://www.shuang0420.com/2017/11/26/机器学习策略(Andrew Ng. DL 笔记)/</id>
    <published>2017-11-26T04:20:02.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Andrew Ng. Deep Learning Course 3 Structuring Machine Learning Projects 的重点笔记。<br><a id="more"></a></p>
<h1 id="常用策略及考虑问题"><a href="#常用策略及考虑问题" class="headerlink" title="常用策略及考虑问题"></a>常用策略及考虑问题</h1><p><strong>常用的 ML 策略：</strong></p>
<ul>
<li>收集更多数据（collect more data）</li>
<li>收集更多样化的训练集（collect more diverse training set）</li>
<li>梯度下降训练更长时间（train algorithm longer with gradient descent）</li>
<li>尝试 Adam 算法（try Adam instead of gradient descent）</li>
<li>尝试更大的网路（try bigger network）</li>
<li>尝试小一点的网络（try smaller network）</li>
<li>尝试 dropout（try dropout）</li>
<li>加 L2 正则（add L2 regularization）</li>
<li>改善网络结构（network architecture）<ul>
<li>激活函数（activation functions）</li>
<li>隐藏单元数量（number of hidden units）</li>
<li>…</li>
</ul>
</li>
</ul>
<p><strong>要考虑的几个问题：</strong></p>
<ul>
<li>训练集上拟合良好 fit training set well on cost function</li>
<li>训练开发集上拟合良好 fit training-dev set well on cost function<br>在训练集和开发/测试集来自不同分布时考虑</li>
<li>开发集上拟合良好 fit dev set well on cost function</li>
<li>测试集上拟合良好 fit test set well on cost function</li>
<li>现实世界中表现良好 performs well in real world</li>
</ul>
<p>另外，调优要注意的是，尽量用 <strong>正交化（Orthogonalization）</strong> 的手段，比如说 <strong>early stopping</strong> 其实不是一个优先的选择，因为它不那么正交化，会同时影响模型对训练集的拟合以及开发集的表现，同时影响了两件事情，对误差分析造成干扰。</p>
<h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><p><strong>单实数评价指标</strong>（Using a single number evaluation metric）<br>用单实数评价指标，能够提高比较各种模型的效率，便于优化模型。 一个简单的例子是用 precision 和 recall，我们知道二者不可兼得，也就是比较哪个模型好的时候我们会发现 A 的 precision 高，B 的 recall 高，选哪个呢？这时候不妨引入 F1 来综合 precision 和 recall。</p>
<p><strong>满足和优化指标</strong><br>如果有多个评价指标，可以选择线性组合，如 cost = accuracy - β*time，也可以选其中一个为 optimizing metric，其他为 satisfying metrics。</p>
<p>例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">分类器	| 准确率 | 耗时</div><div class="line">  A     |  90%  | 80ms</div><div class="line">  B	|  92% |	95ms</div><div class="line">  C	|  95% |	1500ms</div></pre></td></tr></table></figure></p>
<p>我们更关心准确率，所以准确率是优化目标，同时希望耗时不要太长，所以运行时间是满足指标，最后整体指标就是在 100ms 运行时间的条件下准确率的大小。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">maximize accuracy</div><div class="line">subject to running time &lt;= 100ms</div></pre></td></tr></table></figure></p>
<p><strong>什么时候改变评价指标？</strong><br>模型在 metric + dev/test 上表现很好，但是在实际应用中表现不好的时候，就应该考虑改变 metric 了。</p>
<p>假设现在有两个算法:</p>
<ul>
<li>算法 A:  喵咪图片识别误差是 3%，但是会把少儿不宜的图片分类为猫</li>
<li>算法 B：误差是 5%，但是不会给用户推送不健康的图片</li>
</ul>
<p>我们的 dev + metric 偏好 A，但我们的用户偏好 B，两者存在分歧，这时我们就需要改变评价指标了。根据上面的例子，假设原来的评价指标是：<br><img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/error_metric0.png" class="ful-image" alt="error_metric0.png"></p>
<p>那么现在可以给“把少儿不宜的图片分类为猫”这个错误一个大的惩罚权重，当然前提是先把这些少儿不宜的图片标注好。<br><img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/error_metric1.png" class="ful-image" alt="error_metric1.png"></p>
<h1 id="训练-开发-测试集"><a href="#训练-开发-测试集" class="headerlink" title="训练/开发/测试集"></a>训练/开发/测试集</h1><p>机器学习通常会把数据集分为<strong>训练/开发/测试集</strong>，这一篇讲一讲这三个子集扮演的角色。</p>
<p>最重要的一点是：<br><strong>dev set + single metric =&gt; target（瞄准的目标）</strong></p>
<p>开发集和测试集的选择通常是现实中希望去处理的数据，很重要的一点是 <strong>开发集和测试集必须服从同一分布</strong>。举个例子，复习考试，训练集是复习资料，开发集像是考试前的模拟试卷，测试集则是真实考卷，我们最终目标是在真实考卷（测试集）中取得好成绩，准备过程中优化的是模拟试题（开发集）上的成绩，而复习资料（训练集）的选择会影响我们逼近这个目标有多快。而如果开发集和测试集来自不同分布，比如说在英语模拟试卷上考了 99 分，但最后你去参加了语文考试，这不是白复习白训练了么~</p>
<p><strong>训练/开发/测试集的大小</strong><br>之前传统 ML 时代数据集比较小， 一般 &lt; 10,000，所以 train/dev/test 的划分通常是 60%/20%/20%，而现在的数据量很大，动辄百万级，划分 40% 的数据处理做开发/测试集显然是浪费，所以比例可以是 98%/1%/1%。</p>
<p>可避免偏差 <strong>available bias</strong> 和<strong>Human-level performance</strong><br><img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/bayes_bias.png" class="ful-image" alt="bayes_bias.png"></p>
<p>Humans error 与 Training Error之间的差距是 <strong>Avoidable bias</strong>，Training Error 与 Dev Error之间的差距是  <strong>Variance</strong>，提到过好多次啦，具体见 <a href="http://www.shuang0420.com/2017/03/17/会议笔记%20-%20Nuts%20and%20Bolts%20of%20Applying%20Deep%20Learning/">会议笔记 - Nuts and Bolts of Applying Deep Learning</a>，这里简单附个图吧。<br><img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/improve_model.png" class="ful-image" alt="improve_model.png"></p>
<h1 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h1><p><strong>误差分析</strong> 的作用在于弄清楚误差最主要来自哪个部分，然后给未来的工作指明优化方向，便于解决主要矛盾，节省时间。</p>
<p>还是猫分类器的例子，假设我们分析模型的预测结果后发现，预测错误的数据中有一部分狗的图片被错误标成了猫。这时可能会想着设计一些处理狗的特征/分类的算法功能来提高猫分类器。然而，假如 100 个错误标记的开发集样本中，只有 5 个是狗，那么这意味着你针对狗的算法提高最终也只能优化误差的 5%，比如原来误差是 10%，最好的情况也只是优化到 9.5%，这是优化上限。</p>
<p>把误差的来源以及在总误差的占比列个表统计，就能清楚的发现解决哪类误差对模型优化帮助最大。这个过程中可能会发现新的错误类型，比如滤镜导致的误差。<br><img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/error_analysis.png" class="ful-image" alt="error_analysis.png"></p>
<p>统计完成后根据误差占比、问题难度、团队的时间精力，来选择其中优先级高的几个进行优化。</p>
<p><strong>如果训练数据中有一些标记错误的例子怎么办？</strong></p>
<p>如果这种误差是 <strong>随机误差</strong>，人没有注意而随机产生的，那么不用花太多时间修复它们，只要数据集足够大，对最后的结果不会有太大影响，因为<strong>深度学习算法对随机误差有一定健壮性（robustness）。</strong></p>
<p>但如果这种误差是 <strong>系统性误差</strong>，比如把把所有白色的狗都标注成了猫，那么问题就大了，学习之后所有白色的狗都会被分类成猫，这就需要重新标记了。</p>
<p><strong>如果开发/测试集中有一些标记错误的例子怎么办？</strong><br>在误差分析中加一列 incorrectly labeled，然后看是否值得修正这些标记错误的例子</p>
<img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/error_analysis2.png" class="ful-image" alt="error_analysis2.png">
<p>如果人工错误标记引起的错误样本比例是 0.6%，而总体开发集误差是 10%，那么应该集中精力解决剩下的 9.4%，而如果总体开发集误差是 2%，那么就应该考虑去纠正这些人为错误了。</p>
<p>但要注意的是，不管要不要纠正人为误差，都要同时作用在开发集和测试集上，确保两者服从同一分布。同时，也可以考虑再次检查那些分类正确的例子，因为本来 no 的例子可能被标记成了 yes，不过正常情况下判断错的次数比判断对的次数要少的多，所以检查这部分数据花的时间也长的多。</p>
<h1 id="训练-测试集来自不同分布"><a href="#训练-测试集来自不同分布" class="headerlink" title="训练/测试集来自不同分布"></a>训练/测试集来自不同分布</h1><p><strong>如果训练集的分布和开发/测试集不一样怎么办？</strong> 这种情况并不少见。比如说，我们有网上爬取的猫的图片 20w，但只有用户在手机 APP 上传的图片 1w。</p>
<p>这时候，可能会想到把这 21w 条数据 shuffle 然后来划分，这样的好处是训练/开发/测试集来自同一分布，但是！你会发现开发/测试集上的很多图片都来自网页下载，这并不是我们真心关心的数据分布，也就是说，只有一小部分的数据是我们的模型真心要瞄准、要优化的目标，而实际上我们大部分精力都在优化网页下载的图片！</p>
<p>再回顾一下核心思想，<strong>开发集/测试集是真正关心的要优化的目标数据</strong>。所以更恰当的做法是，<strong><em>把手机上传的一半图片 5k 条划给训练集，剩下的 5k 条全部划分为开发/测试集</em></strong>。</p>
<p>要注意的是，训练/测试集来自不同分布会对 <strong>方差/偏差分析</strong> 造成影响，因为这不再是正交化的分析了。比如说</p>
<ul>
<li>training error 1%</li>
<li>dev error 10%</li>
</ul>
<p>如果训练集和开发集来自同一分布，很简单，这是出现了高方差的问题。但如果训练集和开发集来自不同的分布，那么可能这里就不是高方差的问题了，造成这种情况的原因有两种：</p>
<ol>
<li>算法看不到开发集数据，难以泛化</li>
<li>训练集和开发集来自不同的分布</li>
</ol>
<p>我们需要知道哪个因素影响更大，才能判断是不是高方差的原因。这时需要定义一个新的数据集 <strong>training-dev set</strong>，通过随机打散训练集，分出一部分训练集和开发集一起作为训练-开发集，这样的话，training-dev set 和 training set 来自同一分布，同时 trainging-dev set 和 dev/test set 也来自同一分布。</p>
<p>现在只在训练集上训练模型</p>
<ul>
<li>training error    1%    </li>
<li>training-dev error  9%    </li>
<li>dev error                10%</li>
</ul>
<p>这就是方差问题，模型泛化能力差。</p>
<ul>
<li>training error    1%    </li>
<li>training-dev error1.5%</li>
<li>dev error10%</li>
</ul>
<p>这时候就是 <strong>数据不匹配问题（data mismatch problem ）</strong>了。</p>
<p>也就是说，当训练集和开发/测试集来自不同分布的时候，我们需要考虑下面 5 种 error：</p>
<ul>
<li>human error: 0%</li>
<li>training error: 10%</li>
<li>training-dev error: 11%</li>
<li>dev error: 20%</li>
<li>test error: 20%</li>
</ul>
<p>这个例子就是 <strong>高方差+数据不匹配</strong> 问题。</p>
<img src="http://images.shuang0420.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/mismatch.png" class="ful-image" alt="mismatch.png">
<p><strong>如果误差分析显示有数据不匹配的问题该怎么办</strong></p>
<ul>
<li>可以人工做误差分析，了解训练集和开发测试集的差异</li>
<li>收集更多与开发集、测试集相似的训练数据，人工数据合成<br>比如 clear audio + car noise =&gt; synthesized in-car audio</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Andrew Ng. Deep Learning Course 3 Structuring Machine Learning Projects 的重点笔记。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/categories/Deep-learning/"/>
    
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/tags/Deep-learning/"/>
    
      <category term="过拟合" scheme="http://www.shuang0420.com/tags/%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    
      <category term="overfitting" scheme="http://www.shuang0420.com/tags/overfitting/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - HRED 与 VHRED</title>
    <link href="http://www.shuang0420.com/2017/11/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20HRED%20%E4%B8%8E%20VHRED/"/>
    <id>http://www.shuang0420.com/2017/11/17/论文笔记 - HRED 与 VHRED/</id>
    <published>2017-11-17T01:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>介绍一下经典的 HRED 和 VHRED。<br><a id="more"></a></p>
<p>主要涉及到下面几篇论文</p>
<ul>
<li><a href="https://arxiv.org/abs/1507.04808" target="_blank" rel="external">Building end-to-end dialogue systems using generative hierarchical neural network models</a></li>
<li><a href="https://arxiv.org/abs/1605.06069" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a></li>
<li><a href="https://arxiv.org/abs/1511.06349" target="_blank" rel="external">Generating Sentences From a Continuous Spaces motivation</a></li>
</ul>
<h1 id="HRED"><a href="#HRED" class="headerlink" title="HRED"></a>HRED</h1><p>HRED 在之前<a href="http://www.shuang0420.com/2017/10/05/经典的端到端聊天模型/">经典的端到端聊天模型</a> 提到过，这里拎出来再具体分析一下。</p>
<p>传统 Seq2Seq 在对话任务上对上下文依赖考虑有限，<a href="https://arxiv.org/abs/1507.04808" target="_blank" rel="external">Building end-to-end dialogue systems using generative hierarchical neural network models</a> 论文提出了一种 <strong>分层 RNN 结构 -  HRED（Hierarchical Recurrent Encoder-Decoder）</strong>，能同时对句子和对话语境（上下文）进行建模，来实现多轮对话。</p>
<p>先来看一下如果不使用分层 RNN，在传统 Seq2Seq 模型基础上，如果我们想得到 context 信息应该怎么做。 </p>
<p>第一个想法是将上一个句子的 final state 作为下一个句子的 initial state，然后将句子信息不断传递下去，这样的话 context vector 里的信息会在 propagation 的过程中会被新句子的词语逐步稀释，对信息/梯度的传播极不友好。</p>
<p>因此为了让信息更好的传递，我们可能会考虑把 final state 传递到下一个句子的 last state，而不是 initial state，然后用拼接或者非线性的方法来表达之前的和当前的句子信息。</p>
<p>更干脆的，直接将语境中的多个 utterance vector 提取出来再用一个 RNN 来处理，捕捉 context 信息，这就有了分层 RNN。</p>
<img src="http://images.shuang0420.com/images/%E7%BB%8F%E5%85%B8%E7%9A%84%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%81%8A%E5%A4%A9%E6%A8%A1%E5%9E%8B/HRED.png" class="ful-image" alt="%E7%BB%8F%E5%85%B8%E7%9A%84%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%81%8A%E5%A4%A9%E6%A8%A1%E5%9E%8B/HRED.png">
<p>简单来说，HRED 在传统 encoder-decoder 模型上，额外增加了一个 encoder，相比于普通的 RNN-LM 来说，考虑了 turn-taking nature，能够对上下文进行建模，减少了相邻句子间的计算步骤，有助于信息/梯度的传播，从而实现多轮对话。整个过程有下面三个阶段：</p>
<ol>
<li><strong>encoder RNN</strong><br>第一个 encoder 和标准的 seq2seq 相同，将一句话编码到固定长度的 utterance vector，也就是 RNN 的 last hidden state<br>encoder RNN 或者说 utterance RNN 记忆的是对话的细节</li>
<li><strong>context RNN</strong><br>n 个句子的 utterance vector 作为第二个 encoder 也就是 <strong>context-level encoder</strong> 各个时间上的的输入，对应长度为 n 的 sequence，产生一个 context vector 实现对语境的编码，也就是 RNN 的 output (注意这里不是 last hidden state)<br>context RNN 记忆的是更为全局的语义信息</li>
<li><strong>decoder RNN</strong><br>上一个句子的 utterance vector 作为 response 的初始状态，目前为止产生的 context vector 和上一个单词的 word embedding 拼接作为 decoder 的输入</li>
</ol>
<p>然而 HRED 相对于传统的 Seq2Seq 模型的提高并不明显，bootstrapping 的作用更加明显。一方面可以用 pre-trained word embedding，另一方面可以使用其他 NLP 任务的数据预训练我们的模型，使得模型的参数预先学到一些对自然语言的理解，然后再来学习聊天任务。</p>
<h1 id="VHRED"><a href="#VHRED" class="headerlink" title="VHRED"></a>VHRED</h1><p>先简单看一下 auto-encoder 的两个变体 dAE 和 VAE。</p>
<p><strong>Denoising auto-encoder(dAE)</strong> 在输入数据引入一些随机噪声，要求 auto-encoder 去重构加噪声之前的原始观测值，来增加模型鲁棒性，避免过拟合。</p>
<p>而 <strong>Variational Autoencoder(VAE)</strong> 则是在中间层（hidden layer）引入噪音，来重构输入数据，因此 auto-encoder 出来的样本具有更高的全局性。</p>
<p><strong>VHRED(Latent Variable Hierarchical Recurrent Encoder-Decoder Model)</strong>，就是在 HRED 基础上引入了 VAE 的思想，不同的是在 reconstruction 时生成的是下一个 utterance 而不是原来的 input。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20HRED%20%E4%B8%8E%20VHRED/VHRED.png" class="ful-image" alt="VHRED.png">
<p>VHRED 是为了解决 RNNLM 和 HRED 很难产生有意义的、高质量的回复而提出的。传统 Seq2Seq 倾向于产生短的安全回答（safe response），因为它有确定性的编码和解码过程，着重拟合具体、有限的回复样本，缺少对 response 语义信息的理解。另外 decoder 时两个目标，一是生成下一个 token，二是占据控制真实输出路径的 embedding space 的一个位置，来影响之后 token 的生成，而由于梯度衰减的影响，模型会更聚焦第一个目标，response 的产生更容易限于 token level，尤其对于 high-entropy 的句子，模型更偏好短期预测而不是长期预测，所以模型很难产生长的、高质量的回复。</p>
<p>VHRED 针对这个问题引入了全局（语义层面）的随机因素，一是能增强模型的 robustness，二是能捕捉 high level concepts。Latent variable 使得 response 不再和一个/几个固定的句子绑定，鼓励了回复的多样性。</p>
<p>和 HRED 不同的是，VHRED 在第二个 context RNN 产生 context vector c 后，由 c sample 了一些高斯随机变量 z（latent variable），期望值和标准差由 c 决定（前向网络+矩阵乘法得到 $\mu$，+矩阵乘法和 softplus 得到 $\Sigma$），高斯变量和 context vector 拼接就得到了包含全局噪声的 vector，作为每个时间的观测值，和 query vector 一起放到 decoder 里产生 response。</p>
<p>训练时，z 从后验采样，测试时由于 KL 已经把分布拉近，z 可以从先验采样。模型的训练技巧如 KL annealing 等借鉴了 <a href="https://arxiv.org/abs/1511.06349" target="_blank" rel="external">Generating Sentences From a Continuous Spaces motivation</a> 这篇论文的思想。</p>
<p>因为 z 是从 context state 计算出来的，latent variable 的期望值和标准差包含一些 high-level 的语义信息，更鼓励模型抽取抽象的语义概念。实验表明，HRED 能产生更长的回复，更好的 diversity。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍一下经典的 HRED 和 VHRED。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/tags/Chatbot/"/>
    
      <category term="多轮对话" scheme="http://www.shuang0420.com/tags/%E5%A4%9A%E8%BD%AE%E5%AF%B9%E8%AF%9D/"/>
    
  </entry>
  
  <entry>
    <title>关于微信公众号和知乎专栏的开通</title>
    <link href="http://www.shuang0420.com/2017/11/11/%E5%85%B3%E4%BA%8E%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E5%92%8C%E7%9F%A5%E4%B9%8E%E4%B8%93%E6%A0%8F%E7%9A%84%E5%BC%80%E9%80%9A/"/>
    <id>http://www.shuang0420.com/2017/11/11/关于微信公众号和知乎专栏的开通/</id>
    <published>2017-11-11T11:55:12.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>终于等到你~<br><a id="more"></a></p>
<blockquote>
<p><em>贵有恒何必五更起三更眠</em>，<em>最无益只怕一日曝十日寒</em></p>
</blockquote>
<p>写博客也有一年多了，回国后忧伤的遇到了 GitPage 加载速度慢、CodingNet 容量限制、百度收录速度慢（收录条目不及谷歌的一半）等诸多问题。入乡随俗，大刀阔斧租了服务器，上了 CDN，注册了域名，折腾了好一番。想要喘口气的时候想到之前有小伙伴嫌弃我博客不能主动推送（嗯，她不用 RSS），于是就干脆趁热打铁，开个 <strong>公众号/专栏</strong> 吧。</p>
<p>欢迎关注。名字是不变的，谷歌搜索<strong>徐阿衡</strong>，不出意外第二条应该是知乎专栏地址，公众号的话二维码在文末。<strong>主题</strong> 也是不变的，依然是 <strong>自然语言处理</strong> 与 <strong>深度学习</strong> 的相关内容，只是 <strong>定位</strong> 可能会有所不同。</p>
<p><strong>公众号</strong> 的定位是 <strong>短文</strong>，可能是零散的知识点，新的 idea，也可能是论文的分享，总之，是便于碎片时间阅读的内容，许多个短文串联才可能覆盖一篇完整的博文。<strong>更新频率</strong>大概会是 2-3 天。除分享外，也在计划上线部分自己正在做的项目，比如说带个人风格的机器人等，在这立个 FLAG 先~</p>
<p><strong>知乎和博客</strong> 则是 <strong>长文</strong>，是相关知识的一个框架性整理。<strong>更新频率</strong> 大概是 1-2 周。</p>
<p>大胆假设，小心求证。不能保证我对知识的理解、我的 idea、我的代码是完全准确无 bug 的，欢迎讨论，欢迎批评指正，但希望各位客观评论，以礼相待。</p>
<p>学习之路，道阻且长。道阻且长，行则将至。希望和小伙伴们一起，每天进步一点点，嗯，话不多说，就这样。</p>
<p><strong>公众号：</strong> xu_a_heng<br><strong>知乎专栏：</strong> <a href="https://zhuanlan.zhihu.com/c_136690664" target="_blank" rel="external">徐阿衡-自然语言处理</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;终于等到你~&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Others" scheme="http://www.shuang0420.com/categories/Others/"/>
    
    
      <category term="公众号" scheme="http://www.shuang0420.com/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/"/>
    
      <category term="知乎" scheme="http://www.shuang0420.com/tags/%E7%9F%A5%E4%B9%8E/"/>
    
      <category term="专栏" scheme="http://www.shuang0420.com/tags/%E4%B8%93%E6%A0%8F/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Copy or Generate</title>
    <link href="http://www.shuang0420.com/2017/10/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20CopyNet%20or%20Generate/"/>
    <id>http://www.shuang0420.com/2017/10/25/论文笔记 - CopyNet or Generate/</id>
    <published>2017-10-25T05:02:27.000Z</published>
    <updated>2018-11-25T08:24:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>关于 Point Network &amp; CopyNet 的几篇论文笔记。<br><a id="more"></a></p>
<p>普通的 Seq2Seq 的 output dictionary 大小是固定的，对输出中包含有输入单词(尤其是 OOV 和 rare word) 的情况很不友好。一方面，训练中不常见的单词的 word embedding 质量也不高，很难在 decoder 时预测出来，另一方面，即使 word embedding 很好，对一些命名实体，像人名等，word embedding 都很相似，也很难准确的 reproduce 出输入提到的单词。Point Network 及 CopyNet 中的 copy mechanism 就可以很好的处理这种问题，decoder 在各 time step 下，会学习怎样直接 copy 出现在输入中的关键字。</p>
<p><strong>涉及到的论文：</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1506.03134" target="_blank" rel="external">Pointer Networks. NIPS 2015</a></li>
<li><a href="https://arxiv.org/abs/1603.06393" target="_blank" rel="external">Incorporating Copying Mechanism in Sequence-to-Sequence Learning. ACL 2016.</a></li>
<li><a href="https://arxiv.org/abs/1704.04368" target="_blank" rel="external">Get To The Point: Summarization with Pointer-Generator Networks. ACL 2017</a></li>
<li><a href="http://link.zhihu.com/?target=http%3A//www.nlpr.ia.ac.cn/cip/shizhuhe/articles/acl2017-coreqa.pdf" target="_blank" rel="external">Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning. ACL 2017</a></li>
</ul>
<h1 id="Pointer-Network-Ptr-Net"><a href="#Pointer-Network-Ptr-Net" class="headerlink" title="Pointer Network(Ptr-Net)"></a>Pointer Network(Ptr-Net)</h1><p>主要来解决传统 Seq2Seq 中 output dictionary 大小固定(fixed prior)的问题。思路非常简单，实际上就是 attention Seq2Seq 的一个简化版本，不过产生的不是输出序列，而是指向输入序列的一堆指针(或者从输入序列中挑选一个元素进行输出)。论文解释了这种结构可以用来解决 <strong>旅行商(Travelling Salesman Problem)、凸包(convex hulls)</strong> 等问题。</p>
<p><strong>结构对比:</strong><br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/PtrNet.png" class="ful-image" alt="PtrNet.png"></p>
<p>还是先来看一下经典的 attention-based seq2seq， 在每一个 decoder step，先计算 $e_{ij}$ 得到对齐概率(或者说 how well input position j matches output position i)，然后做一个 softmax 得到 $a_{ij}$，再对 $a_{ij}$ 做一个加权和作为 context vector $c_i$，得到这个 context vector 之后在固定大小的 output dictionary 上做 softmax 预测输出的下一个单词。</p>
<p><strong>经典 Attention:</strong><br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/birnnattention.png" class="ful-image" alt="birnnattention.png"></p>
<p>而 Ptr-Net 不过是简化了后面的步骤，有了 $e_{ij}$ 后直接做 sofmax，可以得到一系列指向输入元素的指针 $a_{ij}$，最直观的用法就是对输入元素进行排序输出了。</p>
<h1 id="CopyNet"><a href="#CopyNet" class="headerlink" title="CopyNet"></a>CopyNet</h1><p><strong>CopyNet</strong> 实现的是能够把输入中的部分信息原封不动的保留到输出中，相当于一个 refer back。一个简单的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Q: 你好呀，我叫毛毛</div><div class="line">A: 毛毛，你好，很高兴认识你</div></pre></td></tr></table></figure>
<p>这个”毛毛”，可能是 OOV，也可能是其他实体或者是日期等很难被 decoder “还原” 出来的信息，CopyNet 可以更好的处理这类的信息。</p>
<p>那么问题主要有两个：</p>
<ul>
<li><strong>What to copy: 输入中的哪些部分应该被 copy?</strong> </li>
<li><strong>Where to paste: 应该把这部分信息 paste 到输出的哪个位置？</strong></li>
</ul>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/CopyNet1.png" class="ful-image" alt="CopyNet1.png">
<p>框架还是基于 attention-based encoder-decoder，不过在 decoder 的时候，做了部分改进，总的来说，下一个单词的预测是由一个 generate-mode g 和 copy-mode c 的混合概率模型决定的。</p>
<p>$$p(y_t|s_t, y_{t-1}, c_t, M) = p(y_t, g|s_t, y_{t-1}, c_t, M) + p(y_t, c|s_t, y_{t-1}, c_t, M) $$</p>
<p>要实现 CopyNet 需要有两个词汇表，一个是通常意义的高频词词汇表 V={$v_1,…,v_N$} 加上 OOV，另一个是在输入中出现的所有 unique words X={$x_1, …, x_{T_S}$}，这部分可能会包含没有在 V 里出现的单词，也就是 OOV 单词，第二个词汇表用来支持 CopyNet，最终输入的词汇表是三者的并集 $V  ∪ UNK ∪ X$。</p>
<p>对 encoder 部分(双向 RNN) 的输出 $h_1, …, h_{T_S}$，记做 M，M 其实同时包含了 <strong>语义</strong> 和 <strong>位置</strong> 信息。decoder 部分对 M 的读取有两种形式：</p>
<ul>
<li><strong>Content-base</strong><br>Attentive read from word-embedding</li>
<li><strong>location-base</strong><br>Selective read from location-specific hidden units</li>
</ul>
<p><strong>两种模式对应的 score function</strong><br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/CopyNet_mode.png" class="ful-image" alt="CopyNet_mode.png"></p>
<p>$$<br>  \begin{aligned}<br>  φ(y_t=v_i) &amp;= v_i^TW_os_t, \ \ \ \ v_i ∈ V ∪ UNK \\<br>  φ(y_t=x_j) &amp;= σ(h_j^TW_c)s_t, \ \ \ \ vi ∈ V ∪ UNK \\<br>  \end{aligned}<br>$$</p>
<p>$φ(y_t=v_i)$ 和普通的 RNN encoder-decoder 计算相同，$φ(y_t=x_j)$ 将 $h_t$ 和 $s_t$ 映射到了同一个语义空间，$\sigma$ 发现用 tanh 比较好，注意 $p(y_t, c|・)$ 的计算加总了所有 $x_j=y_t$ 的情况。</p>
<p><strong>$s_t$ 的更新：</strong><br>在用 $y_{t-1}$ 更新 t 时刻的状态 $s_t$ 时，CopyNet 不仅仅考虑了词向量，还使用了 M 矩阵中特定位置的 hidden state，或者说，$y_{t-1}$ 的表示中就包含了这两个部分的信息 $[e(y_{t-1}); ζ(y_{t-1})]$，$e(y_{t-1})$ 是词向量，$ζ(y_{t-1})$ 和 attention 的形式差不多，是 M 矩阵中 hidden state 的加权和</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/similar_attention.png" class="ful-image" alt="similar_attention.png">
<p>K 是 normalization term，直观上，是去找输入中也出现 $y_{t-1}$ 的单词对应的 hidden state，考虑到 $y_{t-1}$ 可能在输入中出现多次，$ρ_{tT}$ 更关注这些多次出现的词。</p>
<p><strong>整条路径：</strong></p>
<p>$$ζ(y_{t-1}) \longrightarrow{update} \ s_t \longrightarrow predict \ y_t \longrightarrow sel. read \  ζ(y_t)$$</p>
<p>一些结果：<br><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/res.png" class="ful-image" alt="res.png"></p>
<h1 id="Get-To-The-Point-Summarization-with-Pointer-Generator-Networks"><a href="#Get-To-The-Point-Summarization-with-Pointer-Generator-Networks" class="headerlink" title="Get To The Point: Summarization with Pointer-Generator Networks"></a>Get To The Point: Summarization with Pointer-Generator Networks</h1><p>Copy 机制在文本摘要中的应用。传统 attention-based seq2seq 存在下面两个问题</p>
<ol>
<li><strong>无法正确产生文中的事实细节</strong><br>e.g. <em>Germany beat Argentina 3-2</em><br>尤其是对 OOV 或者 rare word。在训练中不常见的单词的 word embedding 质量也不高，很难 reproduce，而即使 word embedding 很好，对一些命名实体，像是人名之类的，含义都很相似，也很难准确的 reproduce 出来<br>所以作者引入了一个 <strong>pointer-generator network</strong>，在 generation 的基础上，加入了 copy 输入中的一些词的能力来提高摘要的准确性，相当于引入了部分 extractive summary 的能力</li>
<li><strong>倾向重复一些词组</strong><br>e.g. <em>Germany beat Germany beat Germany beat…</em><br>主要是因为 decoder 过程太过依赖于上一个单词，而不是 longer-term 的信息，所以一个重复的单词会 trigger 出死循环，比如上面这个例子就陷入了 Germany beat Germany beat Germany beat… 的死循环，产生不出 Germany beat Germany 2-0 这样的句子<br>所以有了 <strong>coverage</strong>，来追踪哪些部分已经被 summarize 过了，之后的 attention 就不会注意这些部分</li>
</ol>
<h2 id="Pointer-generation-network"><a href="#Pointer-generation-network" class="headerlink" title="Pointer-generation network"></a>Pointer-generation network</h2><img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/pointer_generator.png" class="ful-image" alt="pointer_generator.png">
<p>上图展示了 decoder 的第三个 step，预测 Germany beat 后面一个单词，像之前一样，我们会计算一个 attention distribution 和 vocabulary distribution，不过同时，也会计算一个产生概率 $p_{gen}$，是 0-1 间的一个值，表示从 vocabulary 中产生一个单词的概率，相应的 $1-p_{gen}$ 就是从输入中 copy 一个单词的概率</p>
<p>$$<br>  \begin{aligned}<br>  P(w) &amp;= p_{gen}P_{vocab}(w) + (1-p_{gen})\sum_{i:w_i=w}a_i^t \\<br>  p_{gen} &amp;= \sigma(w^T_{h^*}h^*_t + w^T_ss_t+w^T_xx_t+b_{ptr}) \\<br>  \end{aligned}<br>$$</p>
<p>其中 $h^*_t$ 是 context vector，在前面我们用的是 $c_i$ 来表示。如果 w 是 OOV， 那么 $P_{vocab}=0$，如果 w 没有在输入中出现，那么 $\sum_{i:w_i=w}a_i^t=0$。</p>
<h2 id="Coverage"><a href="#Coverage" class="headerlink" title="Coverage"></a>Coverage</h2><p>用 attention distribution 来记录哪些部分已经总结过了，来惩罚再次加入计算的部分。decoder 的每个时刻，有一个 coverage vector $c_t$ 来将记录之前所有时刻 attention 的总和。</p>
<p>$$c^t=\sum^{t-1}_{t’=0}a^{t’}$$</p>
<p>这个 coverage 会作为 attention 计算的一个输入<br>$$e^t_i=v^Ttanh(W_hh_i+W_ss_t+w_cc^t_i+b_{attn})$$</p>
<p>对应的，有一个 coverage loss<br>$$covloss_t=\sum_imin(a^t_i,c^t_i)$$</p>
<p>整体的 loss 就是<br>$$loss_t=-logP(w^*_t)+\lambda \sum_i min(a^t_i, c^t_i)$$</p>
<h1 id="Generating-Natural-Answers-by-Incorporating-Copying-and-Retrieving-Mechanisms-in-Sequence-to-Sequence-Learning"><a href="#Generating-Natural-Answers-by-Incorporating-Copying-and-Retrieving-Mechanisms-in-Sequence-to-Sequence-Learning" class="headerlink" title="Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning"></a>Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning</h1><p>Copy 机制在问答系统中的应用。论文的模型用三种不同模式获取词汇并进行选取：<strong>用拷贝方式取得问句中的实体、用预测方式产生让答案更自然的连接词、用检索方式获取相关事实</strong> 并结合多个相关事实产生复杂问句的自然形式的答案。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/COREQA1.png" class="ful-image" alt="COREQA1.png">
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Q: Do you know where was Jet Li from ?</div><div class="line">A1: Beijing.</div><div class="line">A2: Jet Li was born in Beijing. He is now a Singaporean citizen.</div></pre></td></tr></table></figure>
<p>传统的 QA 系统只会返回 A1，一个孤零零的实体，这对用户并不友好，A2 才是自然语言形式的答案。COREQA 利用 <strong>拷贝(copy)、检索(retrieval)和预测(prediction)</strong> 从不同来源获取不同类型的词汇，产生复杂问句的自然答案。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/COREQA2.png" class="ful-image" alt="COREQA2.png">
<p>具体过程，以 <strong>Do you know where was Jet Li from</strong> 这个问题为例来说明：</p>
<ol>
<li><strong>知识检索:</strong> 首先识别问题中的包含的 topic entities。这里我们识别出的 topic entity 是  Jet Li 。然后根据 entity 从知识库中检索出相关的三元组(subject, property, object)。针对李连杰这个实体，我们可以检索出(Jet Li, gender, Male)，(Jet Li, birthplace, Beijing)，(Jet, nationality, Singapore) 等三元组。</li>
<li><strong>编码(Encoder):</strong> 将问题和检索到的知识编码成向量<br><strong>问题编码:</strong> 双向 RNN(Bi-RNN)，把前向和后向对应的 hidden state 拼接起来形成每一时刻的 short-term memory $M_Q={h_t}$，两个方向 RNN 的最后一个向量拿出来拼在一起就得到向量 q 来表示整个问题<br><strong>知识编码:</strong> 使用了记忆网络(Memory Network)，对知识检索阶段得到的知识三元组 spo 分别进行编码得到 $e_s, e_p, e_o$，拼接成一个 $f_i$ 来表示这个三元组，所有这些三元组向量形成一个 list，用 $M_{KB}$ 表示<br><strong>分数计算: </strong> $S(q, s_t, f_j) = DNN_1(q, s_t, f_j)$</li>
<li><strong>解码(Decoder):</strong> 根据 $M_Q$ 和 $M_{KB}$ 来生成自然答案。单词预测有三种模式，predict-mode, copy-mode 和 retrieve-mode，predict-mode 和普通 seq2seq 原理相同，生成词汇表中的单词，copy-mode 从问句中复制单词，retrieve-mode 从知识库中选取单词。过程和 CopyNet 差不多，也有两种读取方式，一种是读取语义，一种是读取位置。</li>
</ol>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/COREQA_formula1.png" class="ful-image" alt="COREQA_formula1.png">
<p>$p_{pr}, p_{co}, p_{re}$ 以及对应的 score function 和前面的 CopyNet 非常相似，包括之后的 state update 部分也和 CopyNet 差不多，不过是多了 $r_{kb}$ 而已。</p>
<img src="http://images.shuang0420.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Copy%20or%20Generate/COREQA_formula2.png" class="ful-image" alt="COREQA_formula2.png">
<blockquote>
<p><strong>参考链接：</strong><br><a href="https://zhuanlan.zhihu.com/p/26826765" target="_blank" rel="external">让问答更自然 - 基于拷贝和检索机制的自然答案生成系统研究 | 论文访谈间 #02</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于 Point Network &amp;amp; CopyNet 的几篇论文笔记。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Chatbot" scheme="http://www.shuang0420.com/categories/NLP/Chatbot/"/>
    
    
      <category term="text summarization" scheme="http://www.shuang0420.com/tags/text-summarization/"/>
    
      <category term="CopyNet" scheme="http://www.shuang0420.com/tags/CopyNet/"/>
    
      <category term="Pre-Net" scheme="http://www.shuang0420.com/tags/Pre-Net/"/>
    
  </entry>
  
</feed>
