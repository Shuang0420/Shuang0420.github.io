{"pages":[{"title":"如何测试你的 NLP 模型？- Behavioral Testing of NLP Models with CheckList","url":"/2020/09/10/如何测试你的 NLP 模型？- Behavioral Testing of NLP Models with CheckList/","text":"Best Paper at ACL 2020 这篇 paper 要解决的问题就一个 How do I know if my model really works，为此作者提出了一个 NLP 模型的评估体系 CHECKLIST，这不是什么 SOTA 模型，也不是啥先进的 theory，就只是一套指导我们像测试软件一样测试模型的 方法论 而已，这个方法可以让我们了解 NLP 模型的能力，也能够指导我们去理解问题、解决问题。 可能很多人都有这样的困惑，训练完一个模型，离线评估准确率 90%+，然而一到线上各种问题，效果却大跌眼镜，这是为什么呢？比较显而易见的一个原因是离线测试集和线上数据集分布的一个 discrepancy。我们的离线测试集通常是 held-out datasets，和训练集同分布，是从同一个数据集 split 来的，而这个数据集可能是不全面的，有偏的，也就是说，测试集和训练集一样有着相同的 bias，而线上数据集的分布可能不一样（out-of-distribution），所以在测试集上表现的好不一定意味着在相关数据集上表现的好。 与之伴随的可能是 shortcut learning，简单解释一下就是模型没有学习我们想让它学习的特征，而去学习了其他东西，比如说图像分类，模型在测试集上能正确区分出现在草地上的奶牛，但是一旦把奶牛移到别的场景里，模型就会分错，这个“草地”就是奶牛的 shortcut。那么模型究竟该学习哪种特征呢？下面一张图可能比较直观，如果模型学到的是 uninformative features，那么模型在训练集的表现就不会好，如果模型学到的是 overfitting features，那么模型在训练集上表现很好但是在测试集上表现很差，而如果模型学到的是 shortcut features，那么模型在训练集和测试集上表现都很好，但在相关的 o.o.d. 的测试集上表现却很差，只有模型在学习 intended features 的时候，才是我们想要的，模型才能有我们想要的泛化能力。更多可以看 Shortcut Learning in Deep Neural Networks 另一方面，现在的模型评估一般评估的都是整体表现，像是准确率、召回率等，这些能判断模型整体怎么样，但却无法简单的通过这个指标去找模型可能存在的 bug。要知道我们的模型肯定不是完美的，我们希望像软件测试一样，能有一个测试体系来指导我们分析问题原因、指导解决具体问题，便于我们进一步优化。尽管也有一些 paper 会针对单个任务或某几种特定能力提出一些分析的指标，但是并没有一个 comprehensive guidance。 于是这么看来，作者凭借一个启发性的测试框架夺得 2020 ACL best paper，也就更加合理了。CEHCKLIST 借鉴了软件设计里面的黑盒测试，通过验证输入-输出的行为来测试一个系统的不同方面的能力，测试人员并不需要知道模型结构就可以去测试。而整个测试体系从语义上拆分成了各个更细的能力（linguistic capabilities），通过不同的表现方式（test types）来进行测试。除此之外，还提供了快速构建 test cases 的一系列方法和工具。在此基础上，作者用 CHECKLIST 对现在一些商用的 NLP 产品和 SOTA 模型进行了测试，结论是无论是大厂的付费接口还是知名的开源项目（BERT/RoBERTa），在这些能力上表现的都很糟糕，有些能力上错误率会到 80-90%，甚至 100%。 CHECKLIST what to test: linguistic capabilities 10 种通用的语言能力，后面逐个看例子 Vocabulary + POS: important words or word types for the task Taxonomy: synonyms, antonyms, etc Robustness: typos, irrelevant changes, etc NER: appropriately understanding named entities Fairness Temporal: understanding order of events Negation Coreference Semantic Role Labeling: understanding roles such as agent, object, etc Logic: ability to handle symmetry, consistency, and conjunctions how to test: test behaviors with different test types 一种能力进行多个方面的分析，3 种测试类型： Minimum Functionality Test, MFT Invariance Test, INV Directional Expectation Test, DIR MFT 其实就是单元测试，和通常的模型评估一样，需要带标签的测试集，一个能力对应一个测试集，INV 和 DIR 属于 perturbation test，对输入加入扰动，我们期望结果不变/结果有一定程度的改变。INV 比如说我们对输入引入一些拼写错误，希望模型预测结果不变。DIR 比如在情感分析的例子里，我们在输入后面加一个负向表述，那么无论原来标签是啥，我们都期望预测结果至少不应该变得更加正向，这个变化指的是置信度的变化。 writing tests at scale: templating + RoBERTa, lexicons, perturbation library, visualizations… 评估体系下生成测试用例的方法，主要通过模板，填充模板槽位的时候可以用字典词表，也可以用 masked language model 来做词的推荐。 Capability 和 test type 制成表格，构建 test case 测试并计算 failure rate，填表汇总就好啦~ 对于词汇而言，我们希望模型能够理解重要词汇的含义，比如在情感分析中，模型要能识别带有情感色彩的词语，在重复问题检测任务中，模型要能识别能够区别两个句子的修饰词，在阅读理解任务中，模型要能理解比较级和最高级。 Taxonomy，很明显， BERT/RoBERTa 并不能很好的理解同义词/反义词，BERT 对属性和类别也不具备理解能力，不能区分颜色/尺寸，动物/机械等类别。 鲁棒性，加了点短链接、@用户等无关信息各产品/模型就不行了，typo /同义改写处理的也不是很好，然而这些问题在实际应用中还是挺常见的，比如在一些问答场景里，首尾加上你好/谢谢等其他信息，中间加上一些吐槽口吻，模型处理的就没有预期那么好。 命名实体，情感分析任务里替换实体名/人名对预测不应该有影响，重复问题检测中，模型明显不能正确的理解命名实体的含义。这里文章解释说是因为 shortcut learning，模型过于依赖一些线索词如命名实体，而不是去理解命名实体和命名实体在这个任务中的作用。事实上，仔细看例子我们可以发现，不仅在 NER 这个能力上，QQP 对应的所有能力，都显著的有着 shortcut learning 的现象。 Fairness，情感分析任务里，商业模型在判断 “I am a black woman” 这类句子时总能判断成中性，然而这并不意味着模型就没有性别和种族等偏见了。BERT 在判断 black, atheist, gay, lesbian + 名词的句子时，总会判断成负向的，而 asian, straight 则会判断成积极的。另一方面，在阅读理解任务中，也能看到对性别的偏见，在 John is not a doctor, Mary is 这类 context 里，如果问 who is a doctor，那么错误预测男性（John）是医生的概率有 89.1%，而如果把职位改成 secretary，那么错误预测女性为秘书的概率有 60.5%，显然带上了“医生大多是男性，秘书大多是女性”的偏见，没有忠于真实 context。 模型也不能识别 temporal 相关的概念，比如过去式现在时、before, after, first, last，模型不能正确的理解这些时间顺序。 否定就更难了，简单的否定还行，双重否定太难了，否定放在句尾或者在否定和情感成分中间加个中立成分，商业产品的错误率几乎是 100%，简直不忍直视。 指代消解，本来发展的也不成熟，也是惨不忍睹。 SRL，就更不用说了。这其实还挺重要的，比如在搜索场景的“人民币兑换美元”和“美元兑换人民币”就需要模型有语义角色标注的能力。 逻辑方面，文中举例不多，主要是满足对称性、传递性等特质，比如说在文本相似性，或者说距离度量上，起码要满足对称性吧，AB距离和BA距离应该是相等的吧，还有三角不等式也该满足吧，AB距离+BC距离&gt;AC距离这种。","tags":"nlp"},{"title":"Slice-based learning - 基于数据切片的学习","url":"/2020/06/16/Slice-based learning - 基于数据切片的学习/","text":"Slice-based learning 的目的是为了提高模型在特定的数据子集上的表现。 正常模型的学习目标是优化模型在整个数据集上的指标，而有时候我们想在此基础上，提高模型在一些特定的重要数据子集上的指标。 因为在实际应用场景中，除了模型整体的表现，我们也关注甚至更关注模型在一些重要的子集上的表现，这些数据子集通常出现频率少但又格外的重要，比如自动驾驶模型中与安全相关的一些数据子集（如检测路上的骑自行车的人）。而 Slice-based learning 的目的就是为了提高模型在这些特定的数据子集上的表现。 要提高模型在特定数据子集上的表现首先一个问题是如何划分数据子集，划分标准可以是基于经验，通过写一些规则，通过简单的分类器，也可以通过 error analysis 得到，我们定义 k 个 Slice Function (SF)， 相当于 k 个 binary classifer，表示数据是否属于当前 slice。这个 SFs 不一定要很完美，事实上也很难完美。 划分了数据子集接下来的问题就是如何提高模型在特定数据子集上的模型表现，有以下挑战： Copying with noise：SFs 以弱监督的方式定义，模型需要对这些存在噪音的数据有足够的鲁棒性 Scalability：当增加 slices 的时候，不能增加太多的参数 Stable improvement of the model：slices 增多的时候，不能伤害现有的 slice 以及整体的 performance 这篇 paper 的思路是 专家组合（Mixtuer-of-Experts, MoE) + multi-task（MTE），在每一个 slice 训练单独的模型（即专家模型），然后用 gated function 融合各个模型输出，相当于 ensemble 的做法，麻烦的是参数利用率低，scalability 差，有多少 slice 就需要训练多少个单独的模型。而相应的，MTE 可以通过参数共享，对每个 data slice 训练单独的 task head，计算效率高，但是这样一来并不能跨 slice 共享数据，另外 MTL 中多个任务各不相同，而在 slice-based learning 中，基本任务是由相关的 slice task 来补充完善的。 于是就有了下面这个框架： 我们想训练一个标准的预测模型，称为 base task，对每个 slice，我们学习 expert representation，然后用 gated function 来组合这些 expert representation 得到一个 slice-aware representation，做出 final prediction。 (a) Backbone: 用来提取特征的模型，比如说 BERT，把输入数据 x 映射到 z (b) Slice indicator heads: 每个 slice 对应一个 indicator head，作用是预测输入数据是否属于这个 slice，输入是 z，输出是 logits q，监督信号是 SF 的输出 (c) Slice-specific representations: 对每个 slice，学习一个 expert feature，输入是 z，输出是 r (d) Shared slice prediction head: 共享的 slice prediction head，把各个 slice expert feature r 映射到 logit pi，只在属于这个 slice 的数据上训练，监督信号就是 base task 的真实标签 y。用共享的 head 可以保证 expert head 的输出具有一致性，便于后面的加权组合 (e) Slice-aware representation: 把 (b) slice indicator output Q 和 (d) prediction head confidence P 做 element-wise，作为 attention 权重来 re-weight 各个 slice 的特征 (c) ，得到 slice-aware representation z’，这一步也体现了对噪声 slice 的 robustness，如果某个 slice indicator 或者 prediction task 做出了置信度低的预测，那就下调它对应表示的权重 注意这一步的时候初始化了一个 base slice，base slice 包含了所有的输入数据，并且有对应的 indicator qbase，和 predictor pbase，目的是显性的来建模从 slice representation 到 base representation 的残差，所以 Q 和 P 其实包含了 k+1 个 vector (f) Prediction head: 输入是 z’，得到最后的输出，监督信号就是 base task 的真实标签 y loss 是 (b)(d)(f) 三部分 loss 的相加。实验结果就不贴了，读 paper 吧~","tags":"nlp"},{"title":"Sequential transfer learning in NLP","url":"/2020/06/01/Sequential transfer learning in NLP/","text":"NAACL 2019 tutorial on “Transfer Learning in Natural Language Processing” 的部分笔记，资料链接见文末。 迁移学习的概念就不多描述了，可以参考迁移学习小册子，讲的非常好。总的来说迁移学习有两大类（应该是 Sebastian Ruder 博士论文提出的分类？）： Inductive transfer learning 任务不同，但在目标领域有标注数据 同时学习不同任务就是 multi-task learning，顺序学习不同任务就是 sequential transfer learning 具体方法有基于样本（instance based transfer）、基于特征（feature representation transfer）、基于参数（parameter transfer）、基于关系（relational knowledge transfer）的迁移，其中最为常见的就是基于特征的迁移，如把预训练模型当做特征提取器，后加分类层等应用，以及基于参数的迁移，如我们常用的 fine-tuning Transductive transfer learning 任务相同但是领域不同，源领域有标注数据，但是目标领域没有标注数据 不同领域就是领域适应（domain adaptation），不同语言就是跨语言学习（cross-lingual learning）。领域适应问题一般假设源领域和目标领域有相同的样本空间，但数据分布不一致，迁移学习小册子重点介绍了这一热门研究方向 通常是基于样本和基于特征的学习 这一篇关注的是 Sequential inductive transfer learning，通常来说第一阶段在源领域上预训练，学习 general 的一些表征，然后做 adaption，迁移到新的任务。由于源领域的训练数据非常大，预训练模型通常有很好的泛化能力（参考大力出奇迹的 GPT3）。预训练之前讨论的比较多，而这次要解决的问题是 How to adapt the pretrained model in NLP，主要从下面三个方面进行讨论： Architectural modifications? 怎么改模型结构 Optimization schemes 去训练哪些权重，以什么顺序来训练 More signal: Weak supervision, Multi-tasking &amp; Ensembling 获取更多监督信号 Architecture有两种选择，大多数情况下第一种选择就可以解决问题： 模型内部结构不变，可以在最上层加分类器，在最下层补充 embdding，也可以把模型输出当做特征 一方面，删除一些对目标任务无效的 pretraining task head，像是预训练 LM 的 softmax 分类器，当然也可以留着做 multi-task 另一方面，在顶层或者底层加上目标任务需要的层，简单来讲可以加个 linear 层，复杂一点也可以把模型输出当做目标模型的输入 修改模型内部结构，如改成 encoder-decoder 模式，或者为目标任务加一些 adapters（像加在 transformer 上的 multi-head attention，layer norm）等 BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning Parameter-Efficient Transfer Learning for NLP Adaptation layer 在 CV 领域有更广泛的研究，这里提到的 adapters 是为了优化目标任务，而 CV 领域提到的自适应模块是为了 domain adaption 提出的，通常用来完成 source 和 target 数据的自适应，拉近两者的数据分布，使得网络效果更好，常见的有在分类器的前一层/几层加入适配层（如 MK-MMD），用来计算 source 和 target 的距离，加入损失进行训练 Optimization几个需要考虑的问题： 选择更新哪些权重（Which weights） 不更新权重：feature extraction 更新权重：fine-tuning Adapters feature extraction 还是 fine-tuning 取决于目标任务和预训练任务之间的相似性 选择什么时候更新，以及怎样更新（What schedule） top-bottom gradual unfreezing discriminative fine-tuning 考虑一些 trade-offs 时间/空间复杂度，性能要求 Which weightsFreeze pretrained weights来看图说话： 不更新预训练的权重，只训练目标任务相关的权重（比如新加的分类层） 特征提取要注意的是不要傻傻的只用 top layer 的特征，可以学习各层特征的线性组合Deep contextualized word representations 2018Latent Multi-task Architecture Learning 2019 预训练特征当做下游任务的特征 Adapters，在预训练模型结构已有的 layers 之间加入目标任务的适配器，如下图，只训练红色部分的权重 Change pretrained weights另外一种就是 fine-tuning 啦，用预训练的权重来初始化下游模型的参数，在迁移阶段训练所有参数 What schedule决定好更新什么权重，下一步就要看用什么顺序，以及怎样的方式来更新了，记住我们的目标： We want to avoid overwriting useful pretrained information and maximize positive transfer. 在一个完全不同的领域/任务上直接对所有层进行更新可能会带来不稳定的结果，所以更明智的选择是分层训练，给不同的 layer 一点时间来适应新的任务和数据，这感觉就像是回到了 DL 初期的 layer-wise 训练方法（Hinton et al., 2006，Bengio et al., 2007）。 Anyway，一个重要的指导原则是自顶向下（top-to-bottom）的更新，也就是先 freeze 住低层的参数，去更新高层的参数，因为高层的参数更加的 task-specific。这里要考虑的是 time 和 intensity，每一层更新的时间可以通过 freeze 其他层来控制，更新的强度可以通过学习率的变化来控制。另外，可以通过正则化来平衡更新与保留之间的关系。 Time自底向上，从 embedding 到中间层到 top layer 再到 target layer 各层表示为：E -&gt; L1 -&gt; … Ln -&gt; T。 Freezing all but the top layer 只训练 top layer Ln Long et al.,ICML 2015 Chain-thaw Felbo et al., EMNLP 2017 只训练 T 层参数 自底向上，每次只训练一层的参数，E -&gt; L1 -&gt; … -&gt; Ln 训练所有层 Gradually unfreezing Howard &amp; Ruder, ACL 2018 逐层解冻，先训练 T，训练 T + Ln，训练 T + Ln + Ln-1，直到全部放开训练所有层 Sequential unfreezing Chronopoulou et al., NAACL 2019 用超参来决定 fine-tuning 的过程 先训练新增参数，训练 n epochs 训练除 embedding 层外的所有层，训练 k epochs 训练所有层直到收敛 这里多数的方法到最后都会一起训练所有的参数 Intensity降低学习率来防止重写有用信息，问题是什么时候降低学习率？ Lower layers，捕捉底层信息的时候 Early in training，模型还需要去适应目标分布 Late in training，模型快收敛的时候 如 ULMFiT 一文提到了一些技巧，一个是 discriminative fine-tuning，每层设置一个学习率，越底层学习率越小，另一个是 slanted triangular learning rates，学习率先逐渐增加后逐渐下降，相当于 warm up。 Regularization用来减小灾难性遗忘，通过一个正则项来让目标模型参数接近预训练参数，让模型不要忘记预训练时学到的东西。 最简单的方法 Wiese et al., CoNLL 2017 高级一点的方法（elastic weight consolidation; EWC）Overcoming catastrophic forgetting in neural networks 如果任务之间很相似，可以用交叉熵来鼓励 source 和 target 的预测相近，类似蒸馏的做法 Trade-offs选择权重更新时，不可避免的要考虑空间、时间复杂度、性能等问题。在时间、空间复杂度的要求上，都是 feature extraction &gt; adapters &gt; fine-tuning。 考虑 performance 的话，有一条经验法则： If task source and target tasks are dissimilar, use feature extraction – To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks 事实上，大部分情况下 feature extraction 和 fine-tuning 的效果都差不多，除非任务非常相似，那么 fine-tune 强，或者非常不相似，那么 feature extraction 更胜一筹。一个例子是，在文本相似度任务上，BERT 上进行 fine-tune 的效果比 feature extraction 显著要好很多，这大概是因为 BERT 的 NSP 任务和 STS 任务非常相似；同样的，skip-thoughts 和 quick-thoughts 同样也用了 NSP 任务，在 STS 这类相似度任务上表现的也很好；而相反，ELMo 这种纯 LM 预训练目标的模型在 sentence pair tasks 上 fine-tune 的表现就不如人意了。另外，对于文本相似度这类 sentence pair 的任务，通过实验也可以发现，它依赖的并不是顶层的预训练特征（如下图，用 4-5 层之后的特征效果提升就显得非常平缓了），这也解释了为什么 fine-tune 的方法会更好一些。 另外，Adapters 的效果和 fine-tuning 有的一拼，Transformers 结构相比于 LSTMs 要更容易 fine-tune，对超参更不敏感。 More signal目标任务的数据量/标签一般都比较少，所以我们通常会通过组合一些信号来提高效果，从最基础的在单目标任务上 fine-tune 单模型，可以延伸到从其他数据集/相关任务中收集信号（Weak Supervision, Multi-tasking and Sequential Adaptation），再到集成模型，结合多个 fine-tune 模型的预测。 Basic fine-tuning以一个分类任务为例，简单来说就是下面几步： 从模型提取一个 fixed-length vector，可以是 CLS 的 hidden state，也可以是所有 hidden-states 的平均/最大池化 额外的分类层投射到分类空间 训练分类目标 Related datasets/tasks从其他数据集和相关任务中收集更多监督信号。 Sequential adaptation 在相关数据集/任务上先做一次微调 适用于数据有限但有一些相似任务的情景，先在有更多数据的相关任务上进行 fine-tune，然后再在目标任务上 fine-tune 也可以在没有标注数据的领域数据上用 LM 等任务进行 fine-tune，然后在目标任务上 fine-tune 2018 Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks 2019 Learning and Evaluating General Linguistic Intelligence 在目标任务上提高样本的复杂度 Multi-task fine-tuning with related tasks 如 NLI tasks in GLUE 每个 step 采样一个任务和一个 batch 来训练，多任务训练的方式训练几个 epochs，最后在目标任务上 fine-tune 几个 epochs LM 很有用 即使没有预训练也有用 Semi-supervised Multitask Learning for Sequence Labeling 引入 lambda 比率 An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models $L = L1 + \\lambda L2$ 这在 ULMFiT 里作为一个单独的步骤 Dataset Slicing when the model consistently underperforms on particular slices of the data 用 error analysis 挑选子集 用经验自动选择一些挑战性的数据子集 auxiliary head 和 main head 一起训练 只在特定的数据子集上训练额外的 head Massive Multi-Task Learning with Snorkel MeTaL Semi-supervised learning 可以使模型预测结果和未标注的数据更加一致 基本思路是最小化在原始输入 x 上的预测与引入扰动后的输入 x’ 的预测之间的距离 扰动可以是 noise, masking 2018 Semi-Supervised Sequence Modeling with Cross-View Training data augmentation, e.g. back-translation 2019 Unsupervised Data Augmentation for Consistency Training Ensembling Ensembling models on different tasks on different dataset-splits with different parameters (dropout, initializations…) from variant of pre-trained models (e.g. cased/uncased) Knowledge distillation 把集成的大模型蒸馏到一个小模型 利用 teacher (the ensemble) 模型的 soft targets 来训练一个 student model $-\\sum_c Q(c|X)log(P_r(c|X))$ teacher label 的相对概率包含了 teacher 模型怎样泛化的信息 相关资料：Video: https://vimeo.com/359399507Slides: https://tinyurl.com/NAACLTransferColab: https://tinyurl.com/NAACLTransferColabCode: https://tinyurl.com/NAACLTransferCodeNeural Transfer Learning for Natural Language Processing","tags":"nlp transfer-learning"},{"title":"论文笔记 - Pre-trained Models for Natural Language Processing","url":"/2020/05/07/论文笔记 - Pre-trained Models for Natural Language Processing/","text":"Pre-trained Models for Natural Language Processing: A Survey 花了一上午看完的综述，强烈推荐每个 NLPer 都读一读，很长一段时间内都能当做工具书来用（下一个 break-through 来临前）。 这篇作为笔记就记录下一些个人认为的重点，方便日后查阅。（不解释基础概念/模型，适合熟悉 PTMs 的人阅读） 先来说说为啥要用预训练模型： 在大语料下预训练的模型可以学习到 universal language representations，来帮助下游任务 PTMs 提供了一个更好的初始化模型，可以提高目标任务的效果和加速收敛 PTMs 可以看做是一种正则，防止模型在小数据集上的过拟合 既然 PTMs 有这么大优势，那当然是，用它！用它！用它！ 这篇综述从四个方面（Representation Types、Architectures、Pre-training Task Types、Extensions）对现有 PTMs (Pre-trained Models) 进行了系统分类，一幅图来概括全文精华： Representation Types and Architectures 第一代的 PTMs 是预训练的 word embeddings，像 skip-gram, glove，可以捕捉一定的语义信息，但是它是 context-free（上下文无关）的，不能捕捉上下文 higher-level 的一些特征，像概念、多义性、句法特征、语义角色、指代等。 二代的 PTMs 则是预训练的 contextual encoders，融入了上下文信息，像 CoVe, ELMo, GPT, BERT。现代的 PTMs 通常在更大的语料库上训练，采用更加强大/深的网络结构（如 Transformer），以及新的预训练任务。 论文把 contextual encoders 分为了 Sequence Models 和 Graph-based models 两大类： 有代表性的 PTMs 及其架构： Pre-training Task Types 预训练任务分为三类： Supervised learning (SL) Unsupervised learning (UL) Self-Supervised learning (SSL) 这一类在传统意义上也是 UL 的一种，不过这里把它们区分了开来，UL 指不用人类标注的有监督的标签，而 SSL 指标签可以自动从训练数据中产生，如 MLM 任务，SSL 的学习过程其实和 SL 一样 一张表总结预训练任务及其对应的损失函数： LM（Language Modeling）是 NLP 中最常见的无监督任务，通常特指自回归或单向语言建模，BiLM 虽然结合了两个方向的语言模型，但只是两个方向的简单拼接，并不是真正意义上的双向语言模型。MLM（Masked Language Modeling）可以克服传统单向语言模型的缺陷，结合双向的信息，但是 [MASK] 的引入使得预训练和 fine-tune 之间出现 gap，PLM（Permuted Language Modeling）则克服了这个问题，实现了双向语言模型和自回归模型的统一。 DAE（Denoising Autoencoder）接受部分损坏的输入，并以恢复原始输入为目标。与 MLM 不同，DAE 会给输入额外加一些噪声。 CTL（Contrastive Learning） 的原理是在对比中学习，其假设是一些 observed pairs of text 在语义上比随机采样的文本更为接近。CTL 比 LM 计算复杂度更低。 一些补充： 文中 MLM 部分除了普通的 Seq2Seq MLM，还总结了一些 Enhanced MLM (E-MLM): RoBERTa: dynamic masking UniLM: unidirectional, bidirectional, seq2seq prediction XLM: translation language modeling (TLM) Span-BERT: random contiguous words masking, span boundary objective StructBERT: span order recovery task External knowledge…. DAE 中一些破坏文本的方法： Token Masking Token Deletion: 模型需要预测删除的位置 Text Infilling：像 SpanBERT，模型预测 mask 的 span 有几个单词 Sentence Permutation：把文档分为句子然后随机打乱 Document Rotation：选择一个单词然后 rotate 文档，模型预测文档的真实起始位置 CTL 的一些任务： Deep InfoMax (DIM)：比较难解释，上图 Replaced Token Detection (RTD)：e.g., CBOW-NS 中的负样本选择可以看做是简单的 RTD, ELECTRA 利用生成器来选择替代序列中的某些 token, WKLM 替换某些实体为同一实体类型下的其他实体 Next Sentence Prediction (NSP)：两个输入句子是否为训练数据中的连续片段 Sentence Order Prediction (SOP)：两个连续片段作为正样本，而相同的两个连续片段互换顺序作为负样本。ALBERT 首次提出，NSP 同时做了 topic prediction 和 coherence prediction，而 topic prediction 太简单了模型会倾向用主题信息来做最后预测，而 SOP 更加聚焦在 coherence prediction 上 Extentions of PTMs 一些补充： Knowledge-Enriched，外部知识的融入具体来说大概有下面几类： Linguistic LIBERT 通过额外的 linguistic constraint task 来融入语言学知识 SentiLR 引入 token 级别的情感极性，改造 MLM 为 label-aware MLM KnowBERT Semantic SenseBERT 不仅预测 masked token，还预测 token 在 WordNet 对应的 supersenses Commonsense ConceptNet, ATOMIC， 用来提高 GPT-2 在故事生成上的效果 Factual ERNIE(THU), KnowBERT, K-BERT, KEPLER Domain-specific K-BERT KG-conditioned language models KGLM, LRLM 模型压缩的几种方法，很好理解 Model Pruning：CompressingBERT Weight Quantization: Q-BERT, Q8BERT Parameter Sharing: ALBERT Knowledge Distillation Distillation from soft target probablilites: DistilBERT Distillation from other knowledge: TinyBERT, MobileBERT, MiniLM Distillation to other structures: from transformer to RNN / CNN Model Replacing BERT-of-Theseus Others FastBERT，动态减少计算步骤 Adapting PTMs to Downstream Tasks迁移学习需要考虑的问题： 选择合适的预训练任务、模型框架和语料 选择合适的 layerEmbedding only; Top layer; All layers (更灵活的方式是像 ELMo 一样自动选择最好的层) 选择迁移方式（to tune or not to tune）Feature extraction: pre-trained parameters are frozenFine-tuning: pre-trained parameters are unfrozen and fine-tuned Fine-tuning strategies： Two-stage fine-tuning 第一阶段，在一个中间任务/语料上进行迁移，第二阶段，迁移到目标任务 Story ending predic- tion by transferable bert: TransBERT How to ﬁne-tune BERT for text classiﬁcation? Sentence encoders on STILTs: Supplementary training on intermediate labeled-data tasks Convolutional sequence to sequence learning Multi-task fine-tuning 多任务和预训练互为补充 Multi-task deep neural networks for natural language understanding Fine-tuning with extra adaptation modules 原始参数固定，在 PTMs 里接入一些 fine-tunable adaptation modules BERT and PALs: Projected attention layers for eﬃcient adaptation in multi-task learning Parameter-eﬃcient transfer learning for NLP Others Improving BERT ﬁne-tuning via self-ensemble and self-distillation Universal language model ﬁne-tuning for text classiﬁcation: gradual unfreezing An embarrassingly simple approach for transfer learning from pretrained language models: sequential unfreezing Future Direction Upper Bound of PTMs PTMs 并没有发展到其上限。目前大多数的 PTMs 都可以通过使用更多的步长以及更大的数据集来提升性能，因此一个实际的方向是在现有的软/硬件基础上，去设计更高效的模型结构、自监督预训练任务、优化器和训练技巧，如 ELECTRA Architecture of PTMs Transformer 的主要局限在于其计算复杂度（输入长度的平方）。GPU 显存大小的限制使得多数 PTMs 无法处理超过 512 个 token 的序列长度。打破这一限制需要改进 Transformer 的结构设计，如 Transformer-XL。设计深层神经网络结构是很有挑战性的任务，或许使用如神经结构搜索 (NAS) 这类自动化的方案 Task-oriented Pre-training and Model Compression 在实践中，不同的目标任务需要 PTMs 的不同功能。PTMs 和下游任务的差异通常在于模型架构与数据分发。更大的差异可能会使得 PTMs 的使用收益更小，比如 text generation 和 text matching 的任务就有很大差异 大型 PTMs 应用到实际场景时面临的低容量设备和低延迟应用的要求：为下游任务精心设计特定的模型结构与预训练任务，或者直接从现有的 PTMs 中提取部分与任务有关的知识 使用模型蒸馏技术对现有的 PTMs 进行教育，来完成目标任务 Knowledge Transfer Beyond Fine-tuning 提高 Fine-tuning 的参数利用效率。之前 fine-tune 中的参数效率很低，要为每个下游任务 fine-tune 各自的参数。一个改进方案是之前提到过的固定 PTMs 的原始参数，并为特定任务添加小的 fine-tunable adaptation modules，这样就可以使用共享的 PTM 来支持多个下游任务 更灵活的从 PTMs 中挖掘知识，如 feature extraction, knowledge distillation, data augmentation, using PTMs as external knowledge Interpretability and Reliability of PTMs 可解释性：PTMs 的深层非线性结构/Transformer 类结构/语言的复杂性使得解释 PTM 变得更加困难 可靠性：PTMs 在对抗性样本中显得非常脆弱。Adversarial defenses 也是一个非常有前景的方向","tags":"nlp ptm"},{"title":"NLP 2018 Highlights","url":"/2019/01/20/NLP 2018 Highlights/","text":"近来很多大拿做了 2018 年 NLP 的回顾，今天推荐一波 Elvis Saravia 的一篇报告，总结了上一年 NLP 学术界和工业界发生的大事，也包括 SOTA 的论文结果及有趣的研究方向，每个 NLPer 闲下来都可以读一读。 18 年 1 月在知乎上的回答 在NLP领域，现阶段最有希望突破深度学习牢笼的研究/思路有哪些？ - 徐阿衡的回答 - 知乎，部分方向在这一年都有了可喜的突破。 不容辩驳，18 年最大的亮点还是在 transfer learning，从 ELMo 到 ULMFit 到 GPT 到 BERT，性能横扫各大 NLP 测试任务。然而除了 BERT，迁移学习在其他方向上也有新的进展，如 任务型对话中，利用迁移学习将已经学好大语种的 dialog state tracking 迁移至小语种 测量并利用视觉任务之间的关联性来避免重复学习，用更少的数据学习“一组”任务 GLoMo 学习图表示，从大规模无标注数据中学习数据单元之间的依赖关系，输出隐关系图，将图迁移到下游任务提高任务性能 … 个人比较关心的是 对话机器人（Conversational AI） 和 医疗健康（Health and Lifestyle） 方向，重点关注，和各位分享一下~ 一方面，对话机器人在车载（奔驰MBUX）、电商（Facebook e-Commerce messager bot）、银行（Mastercard）、保险（AskArvi ）等各领域都有广泛的应用，另一方面 情感识别 成为 对话机器人 一个重要方向， Wired.com 解释了语音情感识别如何帮助机器与人建立健康的关系，初创公司 Hugging Face 获得 400万美元融资，来打造情感智能聊天机器人。另外在情感分析领域，学术界也涌现了大量有趣的 paper Deep Learning for Sentiment Analysis : A Survey Emotional Chatting Machine 情感领域的 style transfer 利用 multimodal learning 做的 sarcasm detection flow of emotions over a book … 之前预测的很难有突破的 常识（common sense），Allen AI 斥巨资（125 million 美元）在 Alexandria 项目 上，来支持开发具有常识的 AI，可以期待一下~ 当然对话机器人的发展也不是一帆风顺只有鲜花与赞好，Wired 发了一篇文章来讨论 Facebook 虚拟助理 M 的现状 ，以及公司为何计划将其关闭。 而在 医疗健康 领域，通过 NLP 技术，初创公司 Proven Beauty 向消费者提供定制化的护肤产品线；Stitch 销售具有个人风格的时尚；Jessica Kent 将 NLP 应用于电子医疗记录，精确分析数据来提高心脏衰竭病人的护理工作；Anthem 与 doc.ai 合作分析并预测过敏模式；Woebot 作为自动心理治疗机器人获得 A 轮 800 万美元融资；Linguamatics 提供新药研发的工具；机器在 CT 扫描中的疾病检测比人类肿瘤学家的诊断速度快150倍；文本挖掘技术 能根据病人的生物标记制定癌症治疗方案……可以说 2018 年 AI 在医疗健康领域焕发着勃勃生机，而在学术界的 clinical NLP 方向，也有一些不错的 paper： 数据整合 最火的 CT 扫描等医疗影像相关任务 NLP 在 clinical informatics research 的应用和挑战 CV、语音、NLP 相结合来预测抑郁程度 用多模态医疗数据训练词向量，学习医学概念 … 除了在对话机器人和医疗健康领域，NLP 在金融、法律和广告等行业中也有崭新的表现，如 ASIC（Australian Securities and Investments Commission）希望利用 NLP 加强管理公司和金融服务法律；Tumi 使用 NLP 技术进行目标营销；华尔街的各大金融公司也在 NLP 和 ML 上下了血本，希望能实现 自动化投资管理；律所也在用 AI 技术对战…… 报告自然是不止这些，还介绍了许多有趣的工作像 Code2vec、长篇音乐生成、看图写诗、通过文字描述生成人脸等等等等，阿衡都觉得颇为之有趣~~ 公众号回复 2018 NLP 就可以获取原文 PDF 啦~","tags":"ai nlp chatbot"},{"title":"知识抽取-事件抽取","url":"/2018/10/15/知识抽取-事件抽取/","text":"接上一篇知识抽取-实体及关系抽取，前置知识在这一篇不多做解释啦。 事件是促使事情状态和关系改变的条件[Dong et.al., 2010]。目前已存在的知识资源（如维基百科等） 所描述实体及实体间的关系大多是静态的，而事件能描述粒度更大的、动态的、 结构化的知识，是现有知识资源的重要补充。 与关系抽取相比，事件抽取同样需要从文本中抽取 predicate 和对应的 arguments，但不同的是，关系抽取的问题是 binary 的，且两个 arguments 通常都会在同一个句子中出现，而事件抽取的难点在于，有多个 arguments 和 modifiers，可能会分布在多个句子中，且有些 arguments 不是必须的（some of which are omitted in any given instance of an event），这使得 bootstrapping/distant learning/coreference 都变得非常困难。 事件抽取的任务可以分两大类： 事件识别和抽取从描述事件信息的文本中识别并抽取出事件信息并以结构化的形式呈现出来，包括发生的时间、地点、参与角色以及与之相关的动作或者状态的改变。 事件检测和追踪事件检测与追踪旨在将文本新闻流按照其报道的事件进行组织，为传统媒体多种来源的新闻监控提供核心技术，以便让用户了解新闻及其发展。具体而言，事件发现与跟踪包括三个主要任务：分割，发现和跟踪，将新闻文本分解为事件， 发现新的（不可预见的）事件，并跟踪以前报道事件的发展。事件发现任务又可细分为历史事件发现和在线事件发现两种形式，前者目标是从按时间排序的新闻文档中发现以前没有识别的事件，后者则是从实时新闻流中实时发现新的事件。 本文的重点在于事件识别与抽取。首先看一下相关的核心概念： 事件描述（Event Mention）描述事件的词组/句子/句群，包含一个 trigger 以及任意数量的 arguments 事件触发（Event Trigger）事件描述中最能代表事件发生的词汇，决定事件类别的重要特征，一般是动词或者名词 事件元素（Event Argument）事件的重要信息，或者说是实体描述（entity mention），主要由实体、属性值等表达完整语义的细粒度单位组成 元素角色（Argument Role）事件元素在事件中扮演的角色，事件元素与事件的语义关系，可以理解为 slot 事件类型（Event Type） 事件识别和抽取直观上来看，可以把事件抽取的任务理解成从文本中找到特定类别的事件，然后进行填表的过程。 严肃些看下事件识别和抽取的任务定义： Given a text document, an event extraction system should predict event triggers with specific sub-types and their arguments for each sentence. 也就是说，事件抽取任务最基础的部分包括： 识别事件触发词及事件类型 抽取事件元素（Event Argument）同时判断其角色（Argument Role） 抽出描述事件的词组或句子 当然还有一些其他的子任务包括事件属性标注、事件共指消解等。 事件抽取大多是分阶段进行，通常由 trigger classifier 开始，如果有 trigger，把 trigger 以及它的上下文作为特征进行分类判断事件类型，再进行下一步的 argument classifier，对句子中的每个 entity mention 进行分类，判断是否是 argument，如果是，判定它的角色。 基于模式匹配的方法MUCs 最开始，事件抽取的系统都是基于人工编写的规则，基于语法树或者正则表达式，如 CIRCUS (Lehnert 1991), RAPIER (Califf &amp; Mooney 1997), SRV (Freitag 1998), AutoSlog (Riloff 1993), LIEP (Huffman 1995), PALKA (Kim &amp; Moldovan 1995), CRYSTAL (Soderland et al. 1995), HASTEN (Krupka 1995) 等等，后来，慢慢的有了监督学习的模型，在 ACE 的阶段，大多数系统都是基于监督学习了，但由于标注一致性的问题，系统的效果普遍较差，ACE 事件抽取只举行了一次，在 2005 年。 下面先来看一下基于模板的抽取方法，基本都是通过 句法（syntactic） 和 语义约束（semantic constraints） 来进行识别。 基于人工标注语料在早期，模板创建过程通常从一个大的标注集开始，模板的产生完全基于人工标注语料，学习效果高度依赖于人工标注质量。 AutoSlog（Riloff）基本假设：a. 事件元素首次提及之处即可确定该元素与事件间的关系b. 事件元素周围的语句中包含了事件元素在事件中的角色描述通过监督学习和人工审查来建立抽取规则。通过训练数据中已经填充好的槽（filled slot），AutoSlog 解析 slot 附近的句法结构，来自动形成抽取规则，由于这个过程产生的模板 too-general，所以需要人工来审核。本质上形成的是一个字典。举个例子Ricardo Castellar, the mayor, was kidnapped yesterday by the FMLN.假设 Ricardo Castellar 被标注成了 victim，AutoSlog 根据句法分析判断出 Ricardo Castellar 是主语，然后触发了主语的相关规则 (subj) passive-verb，将句子中相关的单词填充进去就得到了规则 (victim) was kidnapped，所以在之后的文本中，只要 kidnapped 在一个被动结构中出现，它对应的主语就会被标记为 victim。 PALKA基本假设：特定领域中高频出现的语言表达方式是可数的用语义框架和短语模式结构来表示特定领域中的抽取模式，通过融入 WordNet 的语义信息，PALKA 在特定领域可取得接近纯人工抽取的效果。 基于弱监督人工标注耗时耗力，且存在一致性问题，而弱监督方法不需要对语料进行完全标注，只需人工对语料进行一定的预分类或者制定种子模板，由机器根据预分类语料或种子模板自动进行模式学习。 一些系统： AutoSlog-TSRiloff and Shoen, 1995AutoSlog-TS 不需要进行文本的标注，只需要一个预先分类好的训练语料，类别是与该领域相关还是不相关。过程是先过一遍语料库，对每一个名词短语（根据句法分析识别）都产生对应的抽取规则，然后再整体过一遍语料库，产生每个规则的一些相关统计数据，基本的 idea 是与不相关文本相比，在相关文本中更常出现的抽取规则更有可能是好的抽取规则。假设训练语料中相关与不相关的文本比例是 1:1，对产生的每条抽取规则计算相关比率 relevance rate，相关文档中出现规则的实例数/整个语料库中出现规则的实例数，那么 relevance rate &lt; 50% 的抽取规则就被丢弃了，剩下的规则会按照 relevance_rate * log(frequency) 的形式从高到低进行排序，然后由人工进行审核。 TIMESChai and Biermann, 1998引入了领域无关的概念知识库 WordNet，提升模式学习的泛化能力，并通过人工或规则进行词义消歧，使最终的模式更加准确 NEXUSPiskorski et.al., 2001; Tanev et.al., 2008用聚类对语料进行预处理 GenPAMJiang, 2005在由特例生成泛化模式的学习过程中，有效利用模式间的相似性实现词义消歧，最大限度地减少了人工的工作量和对系统的干预 小结基于模式匹配的方法在特定领域中性能较好，知识表示简洁，便于理解和后续应用，但对于语言、领域和文档形式都有不同程度的依赖，覆盖度和可移植性较差。 模式匹配的方法中，模板准确性是影响整个方法性能的重要因素。在实际应用中，模式匹配方法应用非常广泛，主要特点是高准确率低召回率，要提高召回率，一是要建立更完整的模板库，二是可以用半监督的方法来建 trigger 字典。 基于统计 - 传统机器学习建立在统计模型基础上，事件抽取方法可以分为 pipeline 和 joint model 两大类。 Pipeline将事件抽取任务转化为多阶段的分类问题（管道抽取），需要顺序执行下面的分类器： 事件触发词分类器（Trigger Classifier）判断词汇是否是事件触发词，以及事件类别 元素分类器（Argument Classifier）词组是否是事件元素 元素角色分类器（Role Classifier）判定元素的角色类别 属性分类器（Attribute Classifier）判定事件属性 可报告性分类器（Reportable-Event Classifier）判定是否存在值得报告的事件实例 分类器可以用 MaxEnt, SVM。重点还是在于提取和集成有区分性的特征，包括 句子级信息 和 篇章级信息。 句子级信息：与候选词相关的词法特征、上下文特征、实体特征、句法特征、语言学特征等，如：篇章级特征：跨文档利用全局信息。对于一个句子级的抽取结果不仅要考虑当前的置信度，还要考虑与待抽取文本相关的文本对它的影响，以及全局信息如事件与话题的关系，事件与事件的共现信息等，主要工作有： Ji and Grishman, 2008 Liao and Grishman, 2010 Hong et.al., 2011 Liu et.al., 2016a 早期大部分的研究都是基于 Pipeline 方法，然而它的问题也很明显： 误差传递，导致性能衰减 各环节预测任务独立，缺少互动，如忽略了事件触发词和事件元素之间的相互影响 无法处理全局的依赖关系 Joint Model又分为 Joint Inference 和 Joint Modeling 两种。Joint Inference 使用集成学习的思路，将各模型通过整体优化目标整合起来，可以通过整数规划等方法进行优化。Joint Modeling (Structured) 又可以称为基于结构的方法，将事件结构看作依存树，抽取任务相应转化为依存树结构预测问题，触发词识别和元素抽取可以同时完成，共享隐层特征，使用搜索进行求解，避免了误差传播导致的性能下降，另外，全局特征也可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。相关工作有： Li et.al., 2013aLi 提出基于结构感知机的联合模型同时完成事件触发词识别和事件元素识别两个子任务，并通过 beam search 缩小搜索解空间 Li et.al., 2014为了利用更多的句子级信息，Li 等提出利用结构预测模型将实体、关系和事件进行联合抽取 尽管 Li 等人的联合系统优势明显，但在未见词和特征上缺乏泛化，人工提取的特征集是离散表达，能力有限。 几种方法的 trigger 和 argument 抽取结果，可以看出，实体之间协同消歧对效果提升非常明显 基于统计 - 深度学习上面的方法在特征提取过程中还是会依赖依存分析、句法分析、词性标注等传统的外部 NLP 工具，还是会造成误差积累，另外有些语言和领域并没有这类处理工具，加之特征也需要人工设定，2015 年起基于深度学习的事件抽取方法逐渐成为研究热点，相比于传统机器学习，深度学习方法优势明显： 减少对外部 NLP 工具的依赖 ， 甚至不依赖 NLP 工具 ， 建立成端对端的系统 使用词向量作为输入，蕴含更为丰富的语言特征 自动提取句子特征， 避免了人工特征设计的繁琐工作 Pipeline - DMCNNEvent Extraction via Dynamic Multi-Pooling Convolutional Neural Networks Yubo Chen et. al., ACL 2015 自然语言处理中，传统 CNN 使用的最大池化对一个 feature map 只能得到一个最大值，这对事件抽取并不适用，因为事件抽取中一个句子中可能会包含多个事件，一个 argument candidate 在不同的 trigger 下也会扮演不同的角色，传统的最大池化只保留“最重要”的信息，而丢失的信息会导致 multiple-event sentence 下的事件漏分。DMCNN 使用动态多池化卷积能实现对一个句子中不同部分的最大值获取，以保留更多有价值的信息，逻辑和 PCNN 相似。 DMCNN 作者把事件抽取看做两个阶段的多分类任务，第一步是触发词分类（trigger classification），利用 DMCNN 对句子中每个词进行分类，判断是否是触发词，如果句子中存在触发词，执行第二步论元分类（argument classification），同样使用 DMCNN，给 trigger 分配 arguments，同时匹配 arguments 到 role，以第二个任务为例介绍一下过程。 主要包括四个部分，以 argument classification 为例： 词向量学习； Lexical-level 词汇级别特征提取； 候选论元/触发词及其前后单词的词向量 Sentence-level 句子级别特征提取； 输入特征： Context-word feature(CWF) Position feature(PF) 当前词语和候选论元/触发词之间的相对距离，距离值用向量表示，随机初始化 Event-type feature(EF) 当前 trigger 对应的事件类型特征 CWF, PF, EF 拼接作为卷积的输入 卷积后，根据 candidate argument 和 predicted trigger 将 feature map 分成三部分，分别对各部分进行最大池化 Output 分类输出 拼接词汇级别和句子级别的特征 F=[L, P] O = WF+b 算分，进行 softmax，得到 argument role 的类别 Trigger classification 阶段： Lexical-level 只使用候选触发词和其左右token Sentence-level CWF + PF，PF 只使用候选触发词的位置作为嵌入位置特征 句子由触发词分割成两部分 DMCNN 的表现： DMCNN 的效果是突破性的，但分两个阶段的预测仍有误差传递的问题，也没有利用好 trigger 和 argument 之间的依赖关系。 Joint Model - JRNNJRNN: Joint Event Extraction via Recurrent Neural Networks, ACL 2016 Nguyen et.al., 2016 通过 RNN 用联合方法解决时间抽取的问题，继承了 Li (2013) 和 Chen (2015) 的优点，并克服了它们的一些缺陷。 Encoding phase word embedding + entity type embedding + dependency tree relationdependency tree relation 是 binary 的，个人理解应该是维度对应依存树中单词间所有可能的关系（如 conj_and, advcl 等），只有在依存树 W 中存在与 w_i 连接的一条对应边（如 conj_and 连接了 w_i 与 w_j）时，该维度（conj_and 对应维度）的值才设为 1，这个向量在 Li et al., 2013 的研究中是有用的。没有用到位置特征，因为同时预测 trigger 和 argument roles，没有固定的锚点。 双向 GRU 进行编码 Prediction phase 对 W 对应的 trigger 和 argument role 分别维护了一个 binary memory vector $G^{trg}_i$ , binary memory matrices $G^{arg}_i$ 以及 $G^{arg/trg}_i$ 每个时间点 i，或者说对 $w_i$ 对 $w_i$ 进行 trigger 预测 如果 trigger 预测结果 $t_i$ 是 other，那么 $a_{ij}$ j 从 1-k 都设为 other，然后进行下一步，否则对所有的 entity mention e1, e2,…,ek 进行 argument role 预测 利用上一步的记忆向量以及之前步骤的预测来计算 $G^{trg}_i$, $G^{arg}_i$ and $G^{arg/trg}_i$ Output: trigger subtype $t_i$ for $w_i$ predicted argument roles $a_{i1}$, $a_{i2}$,…$a_{ik}$ memory vector/matrics $G^{trg}_i$, $G^{arg}_i$ and $G^{arg/trg}_i$ Memory 向量代表的是同一个句子中触发词和论元角色之间的相互关系，$G^{trg}_i$ 代表的是 trigger subtypes 之间的关系，表示在 i 之前已经识别出哪些子事件，比如说句子中检测到了 Die 事件，那么很有可能下面会同时会出现 Attack 事件； $G^{arg}_i$ 代表的是论元角色之间的关系，总结了 entity mention 在过去扮演的 论元角色信息；$G^{arg/trg}_i$ 对应的是 arugment roles 和 trigger subtypes 之间的关系，表示 entity mention 在之前特定 event subtypes 扮演过 argument，$G^{arg/trg}_i[j][t]=1$ 代表 $e_j$ 在之前的 subtype t 中被认为是 argument。 实验表明，$G^{trg}$ 并没有帮助反而会导致整体性能下降，而 $G^{arg/trg}$ 还是很有效的。 当输入句子包含多个事件时（1/N），JRNN 明显优于其他方法。特别是，JRNN 在触发词识别上 DMCNN 好13.9％，而论元分类的相应改进为 6.5％，从而进一步表明 JRNN 具有记忆功能的好处。在单事件句子（1/1）的表现上，JRNN 在触发词分类上仍然是最好的系统，尽管在论元分类上比 DMCNN 要差一些。 弱监督/语料扩充有监督的方法需要大量的标注样本，人工标注耗时耗力，还存在一致性的问题，因此弱监督方法也是事件抽取的一个重要分支。Chen 等提出利用部分高质量的标注语料训练分类器，然后利用初步训练好的分类器判断未标注的数据，选取高置信度的分类样本作为训练样本，通过迭代自动扩充训练样本[Chen and Ji, 2009]。Liao 等在相关文档中使用自训练的（Self-Training）的半监督学习方法扩展标注语料，并利用全局推理的方法考虑样例的多样性进而完成事件抽取；进一步提出同时针对词汇和句子两个粒度训练最大熵分类器，并用协同训练（Co-training）的方法扩展标注数据，进而对分类器进行更充分的训练[Liao and Grishman, 2011a; 2011b]。 而目前，弱监督/训练数据生成方面比较流行的方向有 利用外部资源，通过远程监督，以及跨语料迁移的方法。 外部资源Leveraging FrameNet to Improve Automatic Event Detection, ACL2016 FrameNet 是语言学家定义及标注的语义框架资源，采用层级的组织结构，有1000+框架、1000+词法单元、150000+标注例句。在结构上，FrameNet 和事件抽取有着很高的相似性，一个框架由一个词法单元和若干框架元素组成，一个事件有触发词和若干事件角色组成。另外，FrameNet 中很多 frame 其实也能够表示某些事件，如 因此，Liu 等利用 ACE 语料训练的分类器去判定 FrameNet 中句子的事件类别，再利用全局推断将 FrameNet 的语义框架和 ACE 中的事件类别进行映射，进而利用 FrameNet 中人工标注的事件样例扩展训练数据以提升事件检测性能 [Liu et.al., 2016b]。 远程监督Automatically Labeled Data Generation for Large Scale Event Extraction, ACL2017 Yubo Chen 提出运用结构化的知识库来以及远程监督的方法来自动生成大规模事件语料。 当把关系抽取中常用的远程监督方法用到事件抽取中时，会发现有下面两个问题，一是现有事件知识库（如 Freebase）中缺乏触发词信息，如上图，在关系抽取中，我们可以用两个论元 Barack Obama, Michelle Obama 进行回标，但是在事件抽取中，marriage 这一事件类型在 Freebase 中被表示为 m.02nqglv，所以我们不能直接用事件类型和论元来进行回标，在用 DS 前，必须先检测触发词。 根据 DS 在 RE 中的应用，可以假设如果一个句子中出现了所有的论元，那么这个句子就可以被作为是一个事件，句子中的动词就可以作为触发词。然而一个事件中的论元可能出现在多个句子中，如果用所有论元来进行句子的回标，那么能抽出的训练数据就非常少了，所以应该对论元进行排序，选择有代表性的伦愿你进行回标。 整个流程如下，首先对 Freebase 中的核心论元进行检测，根据角色显著性（role saliency）、事件相关性（ event relevance）和核心率（key rate） 对论元进行优先级排序，接着利用所有的核心论元去 Wikipeida 中回标，根据触发率（trigger rate）、触发词频率（ trigger candidate frequency）、触发词事件频率（trigger event type frequency）来进行触发词检测，这一阶段得到的触发词表中只有动词，缺少名词，也存在噪声，于是再利用 FrameNet 过滤动词性触发词中的噪声，同时扩展名词性触发词，最后利用 Soft Distant Supervision 来自动生成标注数据。 还有方法如 Karthik Narasimhan et al., EMNLP 2016，从网络获取同一事件的不同报道，再使用强化学习方法，做信息融合的决策（互补信息的融合、冗余信息的选择）。 跨语料迁移由于目前中文事件抽取缺少公认语料，很多学者尝试利用现有大量的高质量英文标注语料辅助中文事件抽取。Chen 等首次提出该想法并利用跨语言协同训练的 Bootstrap 方法进行事件抽取[Chen and Ji, 2009]。Ji 提出基于中英文单语事件抽取系统和基于并行语料两种构建跨语言同义谓词集合的方法辅助进行中文事件抽取[Ji, 2009]，Zhu 等利用机器翻译同时扩大中文和英文训练语料，联合利用两种语料进行事件抽取[Zhu et.al., 2014]。Hsi 等联合利用符号特征和分布式特征的方法，利用英文事件语料提升中文事件抽取的性能[Hsi et.al., 2016]。 Event Detection via Gated Multilingual Attention Mechanism, AAAI2018 Motivation： 多语言一致性，不同语言中表达了相同含义的句子往往包含相同的语义成分如 MeiGuo TanKe 和 American tank 表达了相同含义，都是武器 多语言互补，某个词在一种语言中有歧义，但在另一种语言中缺没有歧义如英文 fire，因为有开火和解雇两种意思，所以对应事件可能是 Attack 也可能是 End-Position，然而在中文中开火，Attach 类型，解雇就是 End-Position 类型，两个词没有相同语义 所以文章提出了两种 attention 机制，一是利用多语言一致性，分别对每种语言进行单语语境的注意力计算，对每个候选触发词，对其上下文进行注意力机制，注意力权重表示句子中不同单词对预测事件类型的重要性，二是利用互补信息，用 gated cross-lingual attention 来模拟其他语言的可信度，gate 来控制目标语言流向源语言的信息，集成多语言的信息。 中文事件抽取目前事件抽取的相关研究大部分是面向英文文本，中文文本的工作才刚起步，一方面，中文的自身特点（需要分词、缺少时态和形态的变换）有一定挑战，另一方面，数据集上也缺乏统一、公认的语料资源和相关评测。尽管如此，近年来中文事件抽取在公开评测、领域扩展及上述的跨语料迁移方面也都取得了一些进展。 公开评测方面，除了在模型方面的创新[Chen and Ng, 2012;Li et.al., 2012a;2013b]，在中文语言特性的利用方面，Li 等通过中文词语的形态结构、同义词等信息捕获更多的未知触发词，进而解决中文事件抽取面临的分词错误和训练数据稀疏等问题； 进一步细分中文事件触发词内部的组合语义（复合、附加和转化），进而提高系统的性能[Li et.al., 2012b]。Ding 等利用聚类的方法自动生成新事件类型的语料， 在抽取过程中特别地考虑了待抽取文本的 HowNet 相似度[Ding et.al., 2013]。 特定领域方面，国内很多机构均面向实际应用展开特定领域的事件抽取研究， 覆盖突发灾难、金融、军事、体育、音乐等多个领域。例如，Zhou 等针对金融领域事件中的收购、分红和贷款三个典型事件，提出自动构建抽取规则集的方法进行中文金融领域事件抽取 [Zhou, 2003]；Liang 等利用事件框架的归纳和继承特性实现对灾难事件的抽取[Liang and Wu, 2006]。 其他方向的一些 Paper:特征表示：– Argument Attention: Exploiting Argument Information to Improve Event Detection via Supervised Attention Mechanisms (ACL2017)多事件抽取：– HBTNGMA: Collective Event Detection via a Hierarchical and Bias Tagging Networks with Gated Multi-level Attention (EMNLP-2018)篇章级事件抽取：– DCFEE: A Document-level Chinese Financial Event Extraction System based on Automatically Labeled Training Data (ACL 2018)事件关系抽取：– ATT-ERNN: Attention-based Event Relevance Model for Stock Price Movement Prediction (CCKS-2017 Best Paper Award)– MLNN: Event Coreference Resolution via Multi-loss Neural Network without Arguments （CCKS-2018） 事件监测和追踪 主流方法包括基于相似度聚类和基于概率统计两类。在这不多做介绍。以后有时间再补充。 关注公众号回复“事件抽取”获得相关综述及论文下载地址~","tags":"nlp relation-extraction information-extraction event-extraction"},{"title":"知识抽取-实体及关系抽取","url":"/2018/09/15/知识抽取-实体及关系抽取/","text":"这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 NLP笔记 - Information Extraction 和 NLP笔记 - Relation Extraction，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。 知识抽取涉及的“知识”通常是 清楚的、事实性的信息，这些信息来自不同的来源和结构，而对不同数据源进行的知识抽取的方法各有不同，从结构化数据中获取知识用 D2R，其难点在于复杂表数据的处理，包括嵌套表、多列、外键关联等，从链接数据中获取知识用图映射，难点在于数据对齐，从半结构化数据中获取知识用包装器，难点在于 wrapper 的自动生成、更新和维护，这一篇主要讲从文本中获取知识，也就是我们广义上说的信息抽取。 信息抽取三个最重要/最受关注的子任务： 实体抽取也就是命名实体识别，包括实体的检测（find）和分类（classify） 关系抽取通常我们说的三元组（triple） 抽取，一个谓词（predicate）带 2 个形参（argument），如 Founding-location(IBM,New York) 事件抽取相当于一种多元关系的抽取 篇幅限制，这一篇主要整理实体抽取和关系抽取，下一篇再上事件抽取。 相关竞赛与数据集信息抽取相关的会议/数据集有 MUC、ACE、KBP、SemEval 等。其中，ACE(Automated Content Extraction) 对 MUC 定义的任务进行了融合、分类和细化，KBP(Knowledge Base Population) 对 ACE 定义的任务进一步修订，分了四个独立任务和一个整合任务，包括 Cold Start KB (CSKB)端到端的冷启动知识构建 Entity Discovery and Linking (EDL)实体发现与链接 Slot Filling (SF)槽填充 Event事件抽取 Belief/Sentiment (BeSt)信念和情感 至于 SemEval 主要是词义消歧评测，目的是增加人们对词义、多义现象的理解。 ACE 的 17 类关系 具体的应用实例 常用的 Freebase relations123456people/person/nationality,people/person/profession,biology/organism_higher_classification,location/location/containspeople/person/place-of-birthfilm/film/genre 还有的一些世界范围内知名的高质量大规模开放知识图谱，如包括 DBpedia、Yago、Wikidata、BabelNet、ConceptNet 以及 Microsoft Concept Graph等，中文的有开放知识图谱平台 OpenKG…… 实体抽取实体抽取或者说命名实体识别（NER）在信息抽取中扮演着重要角色，主要抽取的是文本中的原子信息元素，如人名、组织/机构名、地理位置、事件/日期、字符值、金额值等。实体抽取任务有两个关键词：find &amp; classify，找到命名实体，并进行分类。 主要应用： 命名实体作为索引和超链接 情感分析的准备步骤，在情感分析的文本中需要识别公司和产品，才能进一步为情感词归类 关系抽取（Relation Extraction）的准备步骤 QA 系统，大多数答案都是命名实体 传统机器学习方法标准流程：Training: 收集代表性的训练文档 为每个 token 标记命名实体(不属于任何实体就标 Others O) 设计适合该文本和类别的特征提取方法 训练一个 sequence classifier 来预测数据的 label Testing: 收集测试文档 运行 sequence classifier 给每个 token 做标记 输出命名实体 编码方式看一下最常用的两种 sequence labeling 的编码方式，IO encoding 简单的为每个 token 标注，如果不是 NE 就标为 O(other)，所以一共需要 C+1 个类别(label)。而 IOB encoding 需要 2C+1 个类别(label)，因为它标了 NE boundary，B 代表 begining，NE 开始的位置，I 代表 continue，承接上一个 NE，如果连续出现两个 B，自然就表示上一个 B 已经结束了。 在 Stanford NER 里，用的其实是 IO encoding，有两个原因，一是 IO encoding 运行速度更快，二是在实践中，两种编码方式的效果差不多。IO encoding 确定 boundary 的依据是，如果有连续的 token 类别不为 O，那么类别相同，同属一个 NE；类别不相同，就分割，相同的 sequence 属同一个 NE。而实际上，两个 NE 是相同类别这样的现象出现的很少，如上面的例子，Sue，Mengqiu Huang 两个同是 PER 类别，并不多见，更重要的是，在实践中，虽然 IOB encoding 能规定 boundary，而实际上它也很少能做对，它也会把 Sue Mengqiu Huang 分为同一个 PER，这主要是因为更多的类别会带来数据的稀疏。 特征选择Features for sequence labeling:12345678• Words Current word (essentially like a learned dictionary) Previous/next word (context)• Other kinds of inferred linguistic classification Part of speech tags Dependency relations• Label context Previous (and perhaps next) label 再来看两个比较重要的 feature Word substringsWord substrings (包括前后缀)的作用是很大的，以下面的例子为例，NE 中间有 ‘oxa’ 的十有八九是 drug，NE 中间有 ‘:’ 的则大多都是 movie，而以 field 结尾的 NE 往往是 place。 Word shapes可以做一个 mapping，把 单词长度(length)、大写(capitalization)、数字(numerals)、希腊字母(Greek eltters)、单词内部标点(internal punctuation) 这些字本身的特征都考虑进去。如下表，把所有大写字母映射为 X，小写字母映射为 x，数字映射为 d… 序列模型NLP 的很多数据都是序列类型，像 sequence of characters, words, phrases, lines, sentences，我们可以把这些任务当做是给每一个 item 打标签，如下图： 常见的序列模型有 有向图模型 如 HMM，假设特征之间相互独立，找到使得 P(X,Y) 最大的参数，生成式模型；无向图模型 如 CRF，没有特征独立的假设，找到使得 P(Y|X) 最大的参数，判别式模型。相对而言，CRF 优化的是联合概率（整个序列，实际就是最终目标），而不是每个时刻最优点的拼接，一般而言性能比 HMM 要好，在小数据上拟合也会更好。 整个流程如图所示： 讨论下最后的 inference 最基础的是 “decide one sequence at a time and move on”，也就是一个 greedy inference，比如在词性标注中，可能模型在位置 2 的时候挑了当前最好的 PoS tag，但是到了位置 4 的时候，其实发现位置 2 应该有更好的选择，然而，greedy inference 并不会 care 这些。因为它是贪婪的，只要当前最好就行了。除了 greedy inference，比较常见的还有 beam inference 和 viterbi inference。 Greedy Inference优点: 速度快，没有额外的内存要求 非常易于实现 有很丰富的特征，表现不错 缺点: 贪婪 Beam Inference 在每一个位置，都保留 top k 种可能(当前的完整序列) 在每个状态下，考虑上一步保存的序列来进行推进 优点: 速度快，没有额外的内存要求 易于实现(不用动态规划) 缺点: 不精确，不能保证找到全局最优 Viterbi Inference 动态规划 需要维护一个 fix small window 优点: 非常精确，能保证找到全局最优序列 缺点: 难以实现远距离的 state-state interaction 深度学习方法LSTM+CRF最经典的 LSTM+CRF，端到端的判别式模型，LSTM 利用过去的输入特征，CRF 利用句子级的标注信息，可以有效地使用过去和未来的标注来预测当前的标注。 评价指标评估 IR 系统或者文本分类的任务，我们通常会用到 precision，recall，F1 这种 set-based metrics，见信息检索评价的 Unranked Boolean Retrieval Model 部分，但是在这里对 NER 这种 sequence 类型任务的评估，如果用这些 metrics，可能出现 boundary error 之类的问题。因为 NER 的评估是按每个 entity 而不是每个 token 来计算的，我们需要看 entity 的 boundary。 以下面一句话为例1First Bank of Chicago announced earnings... 正确的 NE 应该是 First Bank of Chicago，类别是 ORG，然而系统识别了 Bank of Chicago，类别 ORG，也就是说，右边界(right boundary)是对的，但是左边界(left boundary)是错误的，这其实是一个常见的错误。 12345正确的标注：ORG - (1,4)系统：ORG - (2,4) 而计算 precision，recall 的时候，我们会发现，对 ORG - (1,4) 而言，系统产生了一个 false negative，对 ORG - (2,4) 而言，系统产生了一个 false positive！所以系统有了 2 个错误。F1 measure 对 precision，recall 进行加权平均，结果会更好一些，所以经常用来作为 NER 任务的评估手段。另外，专家提出了别的建议，比如说给出 partial credit，如 MUC scorer metric，然而，对哪种 case 给多少的 credit，也需要精心设计。 其他-实体链接实体识别完成之后还需要进行归一化，比如万达集团、大连万达集团、万达集团有限公司这些实体其实是可以融合的。 主要步骤如下： 实体识别命名实体识别，词典匹配 候选实体生成表层名字扩展，搜索引擎，查询实体引用表 候选实体消歧图方法，概率生成模型，主题模型，深度学习 补充一些开源系统： http://acube.di.unipi.it/tagme https://github.com/parthatalukdar/junto http://orion.tw.rpi.edu/~zhengj3/wod/wikify.php https://github.com/yahoo/FEL https://github.com/yago-naga/aida http://www.nzdl.org/wikification/about.html http://aksw.org/Projects/AGDISTIS.html https://github.com/dalab/pboh-entity-linking 关系抽取关系抽取 需要从文本中抽取两个或多个实体之间的语义关系，主要方法有下面几类： 基于模板的方法(hand-written patterns) 基于触发词/字符串 基于依存句法 监督学习(supervised machine learning) 机器学习 深度学习（Pipeline vs Joint Model） 半监督/无监督学习(semi-supervised and unsupervised) Bootstrapping Distant supervision Unsupervised learning from the web 基于模板的方法基于触发词/字符串首先是基于字符串的 pattern，举一个 IS-A 的关系 1Agar is a substance prepared from a mixture of red algae, **such as** Gelidium, for laboratory or industrial use 通过 such as 可以判断这是一种 IS-A 的关系，由此可以写的规则是：123456“Y such as X ((, X)* (, and|or) X)”“such Y as X”“X or other Y”“X and other Y”“Y including X”“Y, especially X” 另一个直觉是，更多的关系是在特定实体之间的，所以可以用 NER 标签来帮助关系抽取，如123• located-in (ORGANIZATION, LOCATION)• founded (PERSON, ORGANIZATION)• cures (DRUG, DISEASE) 也就是说我们可以把基于字符串的 pattern 和基于 NER 的 pattern 结合起来，就有了下面的例子。 对应的工具有 Stanford CoreNLP 的 tokensRegex。 基于依存句法通常可以以动词为起点构建规则，对节点上的词性和边上的依存关系进行限定。流程为: 小结手写规则的 优点 是： 人工规则有高准确率(high-precision) 可以为特定领域定制(tailor) 在小规模数据集上容易实现，构建简单 缺点： 低召回率(low-recall) 特定领域的模板需要专家构建，要考虑周全所有可能的 pattern 很难，也很费时间精力 需要为每条关系来定义 pattern 难以维护 可移植性差 监督学习-传统机器学习研究综述漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025 Zhou[13] 在 Kambhatla 的基础上加入了基本词组块信息和 WordNet，使用 SVM 作为分类器，在实体关系识别的准确率达到了 55.5%，实验表明实体类别信息的特征有助于提高关系抽取性能； Zelenko[14] 等人使用浅层句法分析树上最小公共子树来表达关系实例，计算两颗子树之间的核函数，通过训练例如 SVM 模型的分类器来对实例进行分。但基于核函数的方法的问题是召回率普遍较低，这是由于相似度计算过程匹配约束比较严格，因此在后续研究对基于核函数改进中，大部分是围绕改进召回率。但随着时间的推移，语料的增多、深度学习在图像和语音领域获得成功，信息抽取逐渐转向了基于神经模型的研究，相关的语料被提出作为测试标准，如 SemEval-2010 task 8[15]。基于神经网络方法的研究有，Hashimoto[16] 等人利用 Word Embedding 方法从标注语料中学习特定的名词对的上下文特征，然后将该特征加入到神经网络分类器中，在 SemEval-2010 task 8 上取得了 F1 值 82.8% 的效果。基于神经网络模型显著的特点是不需要加入太多的特征，一般可用的特征有词向量、位置等，因此有人提出利用基于联合抽取模型，这种模型可以同时抽取实体和其之间的关系。联合抽取模型的优点是可以避免流水线模型存在的错误累积[17-22]。其中比较有代表性的工作是[20]，该方法通过提出全新的全局特征作为算法的软约束，进而同时提高关系抽取和实体抽取的准确率，该方法在 ACE 语料上比传统的流水线方法 F1 提高了 1.5%，；另一项工作是 [22]，利用双层的 LSTM-RNN 模型训练分类模型，第一层 LSTM 输入的是词向量、位置特征和词性来识别实体的类型。训练得到的 LSTM 中隐藏层的分布式表达和实体的分类标签信息作为第二层 RNN 模型的输入，第二层的输入实体之间的依存路径，第二层训练对关系的分类，通过神经网络同时优化 LSTM 和 RNN 的模型参数，实验与另一个采用神经网络的联合抽取模型[21]相比在关系分类上有一定的提升。但无论是流水线方法还是联合抽取方法，都属于有监督学习，因此需要大量的训练语料，尤其是对基于神经网络的方法，需要大量的语料进行模型训练，因此这些方法都不适用于构建大规模的 Knowledge Base。 [13] Guodong Z, Jian S, Jie Z, et al. ExploringVarious Knowledge in relation Extraction.[c]// acl2005, Meeting of the Association for ComputationalLinguistics, Proceedings of the Conference, 25-30 June, 2005, University of Michigan, USA. DBLP.2005:419-444.[14] Zelenko D, Aone C, Richardella A. KernelMethods for relation Extraction[J]. the Journal ofMachine Learning Research, 2003, 1083-1106.[15] Hendrickx I, Kim S N, Kozareva Z, et al.semEval-2010 task 8: Multi-way classification ofsemantic relations between Pairs of nominals[c]//the Workshop on semantic Evaluations: recentachievements and Future Directions. association forComputational Linguistics, 2009:94-99.[16] Hashimoto K, Stenetorp P, Miwa M, et al. Task-oriented learning of Word Embeddings for semanticRelation Classification[J], Computer Science,2015:268-278.[17] Singh S, Riedel S, Martin B, et al. JointInference of Entities, Relations, and Coreference[C]//the Workshop on automated Knowledge baseConstruction ,San Francisco, CA, USA, October27-november 1. 2013:1-6.[18] Miwa M, Sasaki Y. Modeling Joint Entity andrelation Extraction with table representation[c]//conference on Empirical Methods in naturalLanguage Processing. 2014:944-948.[19] Lu W, Dan R. Joint Mention Extraction andclassification with Mention Hypergraphs[c]//conference on Empirical Methods in naturallanguage Processing. 2015:857-867.[20] Li Q, Ji H. Incremental Joint Extraction of EntityMentions and relations[c]// annual Meeting of theAssociation for Computational Linguistics. 2014:402-412.[21] Kate R J, Mooney R J. Joint Entity andrelation Extraction using card-pyramid Parsing[c]//conference on computational natural languagelearning. 2010:203-212.[22] Miwa M, Bansal M. End-to-End Relation Extraction using lstMs on sequences and tree structures[c]// annual Meeting of the association for computational linguistics. 2016:1105-1116. 分类器标准流程：12345678910- 预先定义好想提取的关系集合- 选择相关的命名实体集合- 寻找并标注数据 选择有代表性的语料库 标记命名实体 人工标注实体间的关系 分成训练、开发、测试集- 设计特征- 选择并训练分类器- 评估结果 为了提高 efficiency，通常我们会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用 task-specific feature-set。 可以采用的分类器可以是 MaxEnt、Naive Bayes、SVM 等。 特征直接上例子：E.g., American Airlines, a unit of AMR, immediately matched the move, spokesman Tim Wagner said Mention 1: American AirlinesMention 2: Tim Wagner 用到的特征可以有：Word features Headwords of M1 and M2, and combination M1: Airlines, M2: Wagner, Combination: Airlines-Wagner Bag of words and bigrams in M1 and M2 {American, Airlines, Tim, Wagner, American Airlines, Tim Wagner} Words or bigrams in particular positions left and right of M1/M2 M2: -1 spokesman M2: +1 said Bag of words or bigrams between the two entities {a, AMR, of, immediately, matched, move, spokesman, the, unit} Named Entities Type and Mention Level Features Named-entities typesM1: ORGM2: PERSON Concatenation of the two named-entities typesORG-PERSON Entity Level of M1 and M2 (NAME, NOMINAL, PRONOUN)M1: NAME [it or he would be PRONOUN]M2: NAME [the company would be NOMINAL] Parse Features Base syntactic chunk sequence from one to the otherNP NP PP VP NP NP Constituent path through the tree from one to the otherNP ↑ NP ↑ S ↑ S ↓ NP Dependency pathAirlines matched Wagner said Gazetteer and trigger word features Trigger list for family: kinship termsparent, wife, husband, grandparent, etc. [from WordNet] Gazetteer:List of useful geo or geopolitical words Country name list Other sub-entities 或者从另一个角度考虑，可以分为 轻量级实体的特征，包括实体前后的词，实体类型，实体之间的距离等 中等量级考虑 chunk，如 NP，VP，PP 这类短语 重量级考虑实体间的依存关系，实体间树结构的距离，及其他特定的结构信息 监督学习-深度学习深度学习方法又分为两大类，pipeline 和 joint model Pipeline把实体识别和关系分类作为两个完全独立的过程，不会相互影响，关系的识别依赖于实体识别的效果 Joint Model实体识别和关系分类的过程共同优化 深度学习用到的特征通常有： Position embeddings Word embeddings Knowledge embeddings 模型通常有 CNN/RNN + attention，损失函数 ranking loss 要优于交叉熵。 PipelineCR-CNNSantos et. al Computer Science 2015 输入层 word embedding + position embedding，用 6 个卷积核 + max pooling 生成句子向量表示，与关系（类别）向量做点积求相似度，作为关系分类的结果。损失函数用的是 pairwise ranking loss function 训练时每个样本有两个标签，正确标签 y+ 和错误标签 c-，m+ 和 m- 对应了两个 margin，$\\gamma$ 用来缩放，希望 $s(x)_{y+}$ 越大越好，$s(x)_{c-}$ 越小越好。 另外还有一些 tips： 负样本选择 $s(x)_c$ 最大的标签，便于更好地将比较类似的两种 label 分开 加了一个 Artifical Class，表示两个实体没有任何关系，可以理解为 Other/拒识，训练时不考虑这一类，损失函数的第一项直接置 0，预测时如果其他 actual classes 的分数都为负，那么就分为 Other，对于整体的 performance 有提升 position feature 是每个 word 与两个 entity 的相对距离，强调了两个实体的作用，认为距离实体近的单词更重要，PE 对效果的提升明显，但实际上只用两个实体间的 word embedding 作为输入代替整个句子的 word embedding+position embedding，也有相近效果，且输入更少实现更简单。 Att-CNNRelation Classification via Multi-Level Attention CNNs 用了两个层面的 Attention，一个是输入层对两个 entity 的注意力，另一个是在卷积后的 pooling 阶段，用 attention pooling 代替 max pooling 来加强相关性强的词的权重。 输入特征还是 word embedding 和 position embedding，另外做了 n-gram 的操作，取每个词前后 k/2 个词作为上下文信息，每个词的 embedding size 就是 $(d_w + 2d_p)*k$。这个滑动窗口的效果其实和卷积一样，但因为输入层后直接接了 attention，所以这里先做了 n-gram。 第一层 input attention 用两个对角矩阵分别对应两个 entity，对角线各元素是输入位置对应词与实体间的相关性分数 $A^j_{i,i}=f(e_j, w_i)$，通过词向量內积衡量相关性，然后 softmax 归一化，每个词对两个实体各有一个权重 $\\alpha_1, \\alpha_2$，然后进行加权把权重与输入 $z_i$ 融合，有三种融合方法， 求平均、拼接、相减（类似 transE 操作，把 relation 看做两个权重的差）。这一层的 attention 捕捉的是句中单词与实体的词向量距离，但其实有些线索词如 caused 与实体的相似度不高但很重要。 接着做正常卷积，然后第二层用 attention pooling 代替 max-pooling，bilinear 方法计算相关度，然后归一化，再做 max pooling 得到模型最后的输出 $w^O$。 另外，这篇 paper 还改进了 Santos 提出的 Ranking loss，Ranking loss 里的 distance function 直接用了网络的输出，而这里定义了新的 distance function 来衡量模型输出 $w^O$ 和正确标签对应的向量 relation embedding $W^L_y$ 的距离： 用了 L2 正则，然后基于这一距离定义了目标函数： 两个距离分别为网络输出与正例和与负例的距离，负例照例用了所有错误类别中与输出最接近的，margin 设置的 1。 这应该是目前最好的方法，SemEval-2010 Task 8 上的 F1 值到了 88。 Att-BLSTMPeng Zhou et. al ACL 2016 CNN 可以处理文本较短的输入，但是长距离的依赖还是需要 LSTM，这一篇就是中规中矩的 BiLSTM+Attn 来做关系分类任务。 评测各方法在 SemEval-2010 Task 8 上的评测： Joint ModelPipeline 的方法会导致误差的传递，端到端的方法直觉上会更优。 LSTM-RNNsMiwa et. al ACL 2016 用端到端的方式进行抽取，实体识别和关系分类的参数共享，不过判断过程并没有进行交互。 三个表示层 Embedding layer (word embeddings layer)用到了词向量 $v_w$、词性 POS tags $v_p$、依存句法标签 Dependency types $v_d$、实体标签 entity labels $v_e$ Sequence layer (word sequence based LSTM-RNN layer)负责实体识别BiLSTM 对句子进行编码，输入是 word embedding 和 POS embedding 的拼接，输出是两个方向的隐层单元输出的拼接 $s_t$然后进行实体识别，还是序列标注任务，两层 NN 加一个 softmax 输出标签。打标签的方法用 BILOU(Begin, Inside, Last, Outside, Unit)，解码时考虑到当前标签依赖于上一个标签的问题，输入在 sequence layer 层的输出上还加了上一时刻的 label embedding，用 schedule sampling 的方式来决定用 gold label 还是 predict label Dependency layer (dependency subtree based LSTM-RNN layer )负责关系分类用 tree-structured BiLSTM-RNNs 来表示 relation candidate，捕捉了 top-down 和 bottom-up 双向的关系，输入是 sequence layer 的输出 $s_t$，dependency type embedding $v_d$，以及 label embedding $v_e$，输出是 $d_p$关系分类主要还是利用了依存树中两个实体之间的最短路径（shortest path）。主要过程是找到 sequence layer 识别出的所有实体，对每个实体的最后一个单词进行排列组合，再经过 dependency layer 得到每个组合的 $d_p$，然后同样用两层 NN + softmax 对该组合进行分类，输出这对实体的关系类别。$d_p$ 第一项是 bottom-up LSTM-RNN 的 top LSTM unit，代表实体对的最低公共父节点（the lowest common ancestor of the target word pair p），第二、三项分别是两个实体对应的 top-down LSTM-RNN 的 hidden state。 ​ 不同模型在 SemEval-2010 Task 8 数据集上的效果比较： 与我们的直觉相反，joint model 不一定能起正作用。不过上面的比较能得到的另一个结论是：外部资源可以来优化模型。 监督学习-评价指标最常用的 Precision, Recall, F1 监督学习-小结如果测试集和训练集很相似，那么监督学习的准确率会很高，然而，它对不同 genre 的泛化能力有限，模型比较脆弱，也很难扩展新的关系；另一方面，获取这么大的训练集代价也是昂贵的。 半监督学习研究综述漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025 Brin[23]等人通过少量的实例学习种子模板，从网络上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，其主要贡献是构建了 DIPRE 系统；Agichtein[24]在 Brin 的基础上对新抽取的实例进行可信度的评分和完善关系描述的模式，设计实现了 Snowball 抽取系统；此后的一些系统都沿着 Bootstrap 的方法，但会加入更合理的对 pattern 描述、更加合理的限制条件和评分策略，或者基于先前系统抽取结果上构建大规模 pattern；如 NELL（Never-EndingLanguage Learner）系统[25-26]，NELL 初始化一个本体和种子 pattern，从大规模的 Web 文本中学习，通过对学习到的内容进行打分来提高准确率，目前已经获得了 280 万个事实。 [23] brin s. Extracting Patterns and relations fromthe World Wide Web[J]. lecture notes in computerScience, 1998, 1590:172-183.[24] Agichtein E, Gravano L. Snowball : Extractingrelations from large Plain-text collections[c]// acMConference on Digital Libraries. ACM, 2000:85-94.[25] Carlson A, Betteridge J, Kisiel B, et al. Toward anarchitecture for never-Ending language learning.[c]// twenty-Fourth aaai conference on artificialIntelligence, AAAI 2010, Atlanta, Georgia, Usa, July.DBLP, 2010:529-573.[26] Mitchell T, Fredkin E. Never-ending Languagelearning[M]// never-Ending language learning.Alphascript Publishing, 2014. Seed-based or bootstrapping approaches半监督学习主要是利用少量的标注信息进行学习，这方面的工作主要是基于 Bootstrap 的方法以及远程监督方法（distance supervision）。基于 Bootstrap 的方法 主要是利用少量实例作为初始种子(seed tuples)的集合，然后利用 pattern 学习方法进行学习，通过不断迭代从非结构化数据中抽取实例，然后从新学到的实例中学习新的 pattern 并扩充 pattern 集合，寻找和发现新的潜在关系三元组。远程监督 方法主要是对知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。 Relation Bootstrapping12345• Gather a set of seed pairs that have relation R• Iterate:1. Find sentences with these pairs2. Look at the context between or around the pair and generalize the context to create patterns3. Use the patterns for grep for more pairs 看一个完整的例子 从 5 对种子开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 $(authoer, book)$ 抽取到了 relation pattern，x, by y, 和 x, one of y’s 优点： 构建成本低，适合大规模构建 可以发现新的关系（隐含的） 缺点： 对初始给定的种子集敏感 存在语义漂移问题 结果准确率较低 缺乏对每一个结果的置信度的计算 Snowball对 Dipre 算法的改进。Snowball 也是一种相似的迭代算法，Dipre 的 X,Y 可以是任何字符串，而 Snowball 要求 X,Y 必须是命名实体，并且 Snowball 对每个 pattern 计算了 confidence value123456Group instances w/similar prefix, middle, suffix, extract patterns • But require that X and Y be named entites • And compute a confidence for each patternORGANIZATION &#123;&apos;s, in, headquaters&#125; LOCATIONLOCATION &#123;in, based&#125; ORGANIZATION Distant Supervision基本假设：两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系。 具体步骤： 从知识库中抽取存在关系的实体对 从非结构化文本中抽取含有实体对的句子作为训练样例，然后提取特征训练分类器。 Distant Supervision 结合了 bootstrapping 和监督学习的长处，使用一个大的 corpus 来得到海量的 seed example，然后从这些 example 中创建特征，最后与有监督的分类器相结合。 与监督学习相似的是这种方法用大量特征训练了分类器，通过已有的知识进行监督，不需要用迭代的方法来扩充 pattern。与无监督学习相似的是这种方法采用了大量没有标注的数据，对训练语料库中的 genre 并不敏感，适合泛化。 PCNN + AttentionKang Liu et.al AI 2017 PCNN单一池化难以刻画不同上下文对句向量的贡献，而进行分段池化，根据两个实体把句子分成三段然后对不同部分分别进行池化，刻画更为精准。另见 Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks Sentence-level attention远程监督常用的 multi-instance learning，只选取最有可能的一个句子进行训练预测，丢失了大部分信息，句子层面的 attention 对 bag 里所有句子进行加权作为 bag 的特征向量，保留尽可能多的信息，能动态减少噪声句的权重，有利于解决错误标记的问题。另见 Neural Relation Extraction with Selective Attention over Instances这里对两个实体向量作差来表示 relation 向量 $v_{relation}$，如果一个实例能表达这种关系，那么这个实例的向量表达应该和 $v_{relation}$ 高度相似，根据这个假设来计算句向量和关系向量的相关性，其中 $[b_i; v_{relation}]$ 表示垂直级联，$b_i$ 是 PCNN 得到的特征输出，softmax 归一化再进行加权，最后再过softmax 进行分类。 Entity representation引入了实体的背景知识（Freebase 和 Wikipedia 提供的实体描述信息），增强了实体表达（entity representation），D 是 (entity, description) 的集合表示，$e_i$ 是实体表示，$d_i$ 通过另一个传统 CNN 对收集到的实体的描述句抽特征得到 希望 $e_i$ 和 $d_i$ 尽可能相似，定义两者间的误差： 最后的损失函数是交叉熵和实体描述误差的加权和： 小结优点： 可以利用丰富的知识库信息，减少一定的人工标注 缺点： 假设过于肯定，引入大量噪声，存在语义漂移现象 很难发现新的关系 无监督学习研究综述 Bollegala[27]从搜索引擎摘要中获取和聚合抽取模板，将模板聚类后发现由实体对代表的隐含语义关系; Bollegala[28]使用联合聚类(Co-clustering)算法，利用关系实例和关系模板的对偶性，提高了关系模板聚类效果，同时使用 L1 正则化 Logistics 回归模型，在关系模板聚类结果中筛选出代表性的抽取模板，使得关系抽取在准确率和召回率上都有所提高。 无监督学习一般利用语料中存在的大量冗余信息做聚类，在聚类结果的基础上给定关系，但由于聚类方法本身就存在难以描述关系和低频实例召回率低的问题，因此无监督学习一般难以得很好的抽取效果。 [27] Bollegala D T, Matsuo Y, Ishizuka M. Measuringthe similarity between implicit semantic relationsfrom the Web[J]. Www Madrid! track semantic/dataWeb, 2009:651-660.[28] Bollegala D T, Matsuo Y, Ishizuka M. RelationalDuality: Unsupervised Extraction of semantic relations between Entities on the Web[c]//International Conference on World Wide Web, WWW 2010, Raleigh, North Carolina, Usa, April. DBLP, 2010:151-160. Open IEOpen Information Extraction 从网络中抽取关系，没有训练数据，没有关系列表。过程如下：12345671. Use parsed data to train a “trustworthy tuple” classifier2. Single-pass extract all relations between NPs, keep if trustworthy3. Assessor ranks relations based on text redundancyE.g.,(FCI, specializes in, sobware development)(Tesla, invented, coil transformer) 半监督/无监督学习-评价指标因为抽取的是新的关系，并不能准确的计算 precision 和 recall，所以我们只能估计，从结果集中随机抽取一个关系的 sample，然后人工来检验准确率 $$\\hat P = {\\text {Number of correctly extracted relations in the sample} \\over \\text {Total number of extracted relations in the sample}}$$ 也可以计算不同 recall level 上的 precision，比如说分别计算在前 1000，10,000，100,000 个新的关系中的 precision，在各个情况下随机取样。 然而，并没有方法来计算 recall。","tags":"nlp relation-extraction information-extraction"},{"title":"99/100 天纪念日 - 第 1 期","url":"/2018/08/06/love99/","text":"Please enter the password to read the blog. Decrypt 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","tags":"小心情"},{"title":"2018 CCF-GAIR 参会笔记 - NLP 专场","url":"/2018/08/06/2018 CCF-GAIR 参会笔记 - NLP 专场/","text":"这篇居然忘了发了…… 孙茂松 - 漫谈基于深度学习的中文计算强调的一个概念是 中文自然语言处理需要加入专家知识。主要介绍的工作是 词表学习： 嵌入字信息的词表学习实践中还是经常会用到的技巧；词向量本身对高频词是没问题的，比如说取相近词 K 近邻，猪肉/鸡肉语义是相似的，但对低频词/新词像马肉/龙肉，语义相关性就不高了；因此在词向量出现歧义时可以加入字向量，相当于平滑作用，在这个刻度上没有这种信息，就进行回退；提到了一些其他 trick Position-based character embeddings 区分字在词中出现的位置，也就是用 char+pos 来表示字，idea 是通常一个字可能出现在词的开始、中间、尾部（用 $c^B$, $c^M$, $c^E$ 表示），却分别代表不同的含义，如车道、人行道和道法、道经中的道就不是一个含义； Cluster-based character embeddings，对每个字的所有 occurrence 进行聚类，然后对每个类建一个 embedding参考论文：Joint Learning of Character and Word Embeddings 嵌入中文资源，基于知网的词表学习作用大概是消歧，利用 hownet 解决中文词语的多义性，类比 wordnet 用来加强英语的多义性学习一样当然 HowNet 和 WordNet 的构造还是有很大不同的。HowNet 对十几万汉语常用词进行了描述，描述用的三要素分别是 sememe，sense 和 word，比如 apple 包含了两个 sense，sense1 是水果，sense2 是电脑，对每个 sense，sememe 可以描述其对应的属性，这些属性会通过相对复杂的层级结构来对目标 sense 进行说明。 在基于 hownet 的词表学习里，sememe 是最小的语义单元，数量有限，大概两千个。每个单词可能对应多个 sense，将每个 sense 对应的 sememe 看成是一个集合，相似的 sense 会包含相同的 sememe。训练模型基于经典的 skip-gram，考虑上下文的同时，也考虑了词的 sememe 信息以及 sememe 与 sense 之间的关系。提供了三种融合方法，SSA/SAC/SAT，SSA 对每个 target word 取它对应所有 sememe embeddings 的平均值，SAC 对 context words 进行消歧来更好的学习目标单词，也就是 context 用 sememe embedding 来表示 ，target word embedding 可以看做是为 context word embedding 选择最合适的 sense 和 sememe 的一个 attention 机制，而 SAT 中 context 用原来的 embedding 表示，但 target word 用 sememe embedding 表示，把 context words 看做是 target word 不同 sense 上的 attention。 基于 HowNet 的词表学习里，sememe, sense, word 之间能够互相打通。在对低频词和新词问题上，由于多了词与词之间共享的 sememe embeddings，低频词能够被解码成 sememe 并通过其他词得到良好的训练，相比于传统 WRL 模型能有更好的表现。参考论文：Improved Word Representation Learning with Sememes 最后还介绍了清华出品的古诗系统，提到了要通过与情感结合、与知识图谱结合等方法来增强作诗系统。 赵军 - 开放域事件抽取主要讲的还是关系抽取中的远程监督（Distant Supervision）问题。远程监督基本假设是“两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系”，这样的假设太强，带来的问题是噪声很多，一个解决方案是引入多示例学习，假定至少有一个句子表示了这种关系而不是每个句子都表示这种关系，把最有可能的句子标注出来，以提高性能。介绍的 paper 是 Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks，EMNLP 2015 挺有名的一篇文章，用分段卷积神经网络 PCNN 来自动学习特征，以及加入 multi-instance learning 来解决远程监督引起的噪声问题。主要 idea 是在池化层通过两个实体的位置把句子分成三个部分，分别池化，再把三个部分的向量结合起来，做整个句子的向量化表示。后面还讲了开放域更复杂的事件抽取，像是缺少触发词，可以通过从一堆要素中定位核心要素，用核心要素到句子当中找到触发词，将触发词和前面的要素关联到一起，再回标，然后在文本当中找到更多数据。 秦兵 - 机器智能中的情感计算分享了文本情感计算的六个维度： 情感分类面向评价对象的情感分类（aspect-based sentiment analysis）比较典型的还是利用上下文信息，采用注意力机制，使某个评价对象和词语进行更好的搭配，然后分类 隐式情感不含情感词的情感表达（即隐式情感）在情感表达中约占 20%-30%，类型有事实型、比喻型、反问型等，事实型情感占多数，比如住酒店时说“桌子上有一层灰”，实际表达的就是不满。要判断这种情感需要依赖上下文，如 “桌子上有一层灰“ 后面一句是 ”我很不高兴”，就可以把 “桌子上有一层灰” 定义为贬义。找不到上下文可以考虑跨文档，在其他文档中找与之类似的句子再判定情感同时，这类情感的计算通常也需要借助外部知识如隐式情感语料库等，尤其是修辞型的隐式情感，比如隐喻，可以借助隐喻语料库 情感溯因类似问答系统，有情感词、有原文，可以通过记忆网络判别哪句话是原因 个性化在情感计算中加入用户特征/用户画像信息，包括自然属性、社会属性、兴趣属性、心理属性等，融入到已有的神经网络模型，来做情感分类 跨领域利用领域无关词和领域相关词的链接关系，分别进行聚类；通过神经网络的隐层参数提取与情感相关、但与领域无关的词的特征来分类 情感生成根据指定的情感类别生成情感表达，应用如产品评论生成、聊天系统、对情感表达进行情感极性变换、润色等 还有一个有意思的应用是中考、高考时经常看到的诗词鉴赏。 钟黎 - 从 0 到1 打造下一代智能对话引擎这个和之前的项目/工作经验高度相关，感觉更像是梳理了一遍之前的工作~~业界通用智能问答平台要解决的问答类型： 任务驱动型（Task Oriented Dialogue）用户希望去完成一些任务，比如查天气、查汇率等，包括词槽填充、多轮会话、对话管理等 信息获取型（Information &amp; Answers）目前业界落地最多的一种问答系统类型，包括搜索、单轮对话，根据数据类型划分有下面几类 结构化知识，比如 CommunityQA（eg., FAQ）和 KBQA 半结构化/非结构化知识，比如说 TableQA（表格），PassageQA（文档） 多模态、跨媒体问答，比如说 VQA，存在视频、音频问答的语料库 通用闲聊型（General Conversation）基础会话，包括闲聊、情感联系、用户信息等，使对话系统更富于人性化 重点讲的是第二类，具体讲了两个部分，一是快速召回，二是深度匹配。 无监督-快速检索提高快速召回（无监督的快速检索）的三种方案，基于词汇计数（Lexical term counting）、基于语言模型、基于向量化。 很多是信息检索的思路，在 信息检索专题类 的博客都有探讨过。 有监督-深度匹配深度匹配的两类常用方法，Siamese 网络 和 基于交互矩阵的网络。 Siamese 网络的基本思路：两个输入用同一个编码器进行编码，然后做相似度的计算，特点是共享网络结构和参数； 基于交互矩阵的网络：除了最后的相关性度量，中间过程里两个输入的某些词也会有交互。 问句较短时/短文档时两类网络一般能打成平手，但对长文档而言，基于交互矩阵的网络就会有更好的表现。 再后面还讲了如何在非结构化文档里寻找信息和答案，具体应用是机器阅读理解（MRC），系列博客也有提到。 最后总结了下业界问答系统建设的一些心得： 要重视 Baseline。 尽早建立起整个流程的 pipeline。 没有免费午餐定理，不存在万能算法。 领域相关的数据准备、数据清洗非常重要。","tags":"ai nlp chatbot"},{"title":"论文梳理：问题生成(QG)与答案生成(QA)的结合","url":"/2018/07/08/论文梳理：问题生成(QG)与答案生成(QA)的结合/","text":"继续 QG，梳理一下 MSRA 其他 3 篇关于 QG 的 paper： Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension Question Answering and Question Generation as Dual Tasks A Joint Model for Question Answering and Question Generation QG 系列其他的笔记： 论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation 论文笔记 - Semi-Supervised QA with Generative Domain-Adaptive Nets 目前的 QA 大多是抽取式（extractive）的任务，答案是文本中的一个连续片段，通常是命名实体这类语义概念，而 QG 是生成式的（abstractive），问句是完整句子，部分单词可能是文档中没出现过的，很多情况下，问句和答案的语言结构不同，因此甚至可以看做两种不同类型的数据。所以第 1 篇 SynNet 就把答案生成当作序列标注任务，把 QG 当作生成任务；第 3 篇 Joint Model 从另一个角度出发，把 QA 和 QG 都当作生成任务，放到同一个 encoder-decoder 框架下，用转变输入数据来实现联合训练，用 pointer-softmax 来处理抽取/生成问题。 另外，QA 和 QG 任务在概率上是有联系的，可以通过 q、a 的联合概率分布联系起来，P(q|a) 就是 QG 模型，P(a|q) 类似 QA 模型，于是第 2 篇 dual tasks 就把这两个任务当做对偶任务，用一个正则项把两个任务联合在一起。$$P(q,a)=P(a)P(q|a)=P(q)P(a|q)$$ Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension我们知道 MRC 系统的输入是 (passage, question, answer) 三元组，q 和 a 依赖人工标注，这是制约 MRC 落地应用的最大问题之一，这篇 paper 提出了 SynNet，利用已有领域中可用的监督数据为基础进行训练，训练完成后迁移到新的领域中，根据新领域的文档模型能自动合成与文档 p 相关的 (q, a) 对，替代昂贵的人工标注，为 MRC 的迁移落地提供了便利。 SynNet 把 QA 对（question-answer pair）的生成过程 P(q,a|p) 分解为条件概率 P(a|p) P(q|p,a) ，也就是下面两个步骤： 基于文档生成答案 P(a|p)学习文档中的 potential “interestingness” pattern，包括文章中可作为常见问题答案的关键知识点、命名实体或语义概念由于答案是文档的片段，所以看做序列标注任务 基于文档和答案生成问题 P(q|p,a)学习生成自然语言的完整问句作为生成任务 答案合成模块（Answer Synthesis Module），序列标注问题，训练了一个 IOB tagger （4 种标记，start, mid, end, none）来预测段落里的每个单词是不是答案。结构很简单，BiLSTM 对 p 的词向量进行编码，然后加两个 FC 层和一个 Softmax 产生每个单词的 tag likelihoods，选择连续的 span 作为 candidate answer chunks，喂给问题生成模块。 问题合成模块（Question Synthesis Module）学习的是 $P(q_1,…q_n|p_1…p_n,a_{start},a_{end})$。模型结构是 encoder-decoder + attention + copy mechanism。通过在段落词向量中加入一个 0/1 特征来表示单词是不是出现在答案中。 训练算法： 在源领域上训练 SynNet，产生新领域的 QA 对，然后和源领域的数据一起来 finetune 源领域的 MC 模型（用 SGD），源领域和新领域的数据采样比是 k:1（paper 里设的 k=4），这主要是为了处理合成数据的噪音问题而进行的正则化操作。 测试阶段也就是用 finetune 完成的 MC 模型回答新领域的问题时，可以对不同时刻的 checkpoints 的 answer likelihoods 做平均，然后用 DP 找到最佳的 answer span ($p_s, p_e$)，最大化 $p_sp_e$，复杂度是 linear，和 BiDAF 的逻辑相同。 难得的是这篇 paper 还提供了实现细节，其中一个 trick 是，在训练问题合成模块时，他们只用了 SQuAD 的训练集，但是在答案合成模块，还引入了 NER Tagger 来增强答案数据，基本假设任何命名实体都可以被当做某个问题的潜在答案。 在 Ablation Studies 和 Error Analysis 中还提到了一些有趣的发现，具体可以看论文。待解决的问题一个是 copy 机制导致的产生的问句和 paragraph 高度相似的问题，可以通过改进 cost function 在促进解码过程的多样化，另一篇 paper 有提到。还有一个问题是 SynNet 在解决比如数字、人名这种问题的效果很好，但是在需要一些推理的问题，像是 what was / what did 这些问题就很弱了，这也是后续的研究方向。 这篇 paper 个人非常喜欢，实现细节和一些结果的分析都很赞。 Question Answering and Question Generation as Dual Tasks把 QA 和 QG 当作对偶任务。关键还是下面这个式子：$$P(q,a)=P(a)P(q|a)=P(q)P(a|q)$$ P(q|a) 即 QG 模型，和 P(a|q) 即 QA 模型可以通过联合概率联系起来，于是这里把 QA 和 QG 当作对偶任务，Seq2Seq 实现 QG，RNN 实现 QA，通过一个正则项把两个任务联系起来，联合训练一起学习 QA 和 QG 的参数，损失函数服从下面的条件： $$P_a(a)P(q|a;\\theta_{qg})=P_q(q)P(a|q;\\theta_{qa})$$其中 $P_a(a)$ 和 $P_q(q)$ 分别对应答案句和问句的语言模型。 这里 QA 任务不再是在 context 里选 answer span 的任务，而被看作是在一组候选答案句集合中选择可能性最高的 answer sentence 的一个排序任务。也就是说，这里的 a 是答案所在的句子，而不是前一篇 paper 提到的简单的语义概念/实体。 QG 任务还是一个生成任务，输入是答案句 a。要注意的是这里 QA 和 QG 的输入都没有 p，都只考虑了句子层面的信息。 和之前介绍的 GDAN) 不同的是，这里 QA 和 QG 的地位是相同的，也并不需要预训练 QA。 下面看一下模型细节：QA 模型 分别用 BiGRU 对 q 和 a 进行编码，拼接 last hidden state 作为向量得到 $v_q$ 和 $v_a$，question-answer pair 的表达由四个向量拼接构成 $v(q,a)=[v_q;v_a;v_q⊙v_a;e_{c(q,a)}]$，c(q,a) 表示 q,a 的共现词，对应的词向量表达通过引入额外的 embedding 矩阵 $L_c \\in R^{d_c * |V_c|}$ 实现，$d_c$ 表示词共现向量的维度，$|V_c|$ 则是词汇表大小。$f_{qa}(a,q)$ 也就是 qa 相关性函数通过对 $v(q,a)$ 进行线性变换加 tanh 激活得到，最后 softmax 得到概率，损失函数还是 negative log-likelihood。 QG 模型 还是经典的 encoder-decoder + attention 模型，输入是 answer sentence，还是用 BiGRU 进行编码，连接两个方向的 last hidden state 作为 encoder 的输出以及 deocder 的初始状态。对 attention 做了改进，希望模型能记住 answer sentence 中哪些 context 被使用过了，在产生 question words 的时候就不再重复使用。 拼接 $s_t$ 和 $c_t$，接一个 linear layer 和 softmax 得到输出单词在词汇表上的概率分布，一个 trick 是softmax 输出维度取 top frequent question words，OOV 用 attention probability 最高的词替换，相当于对文档单词的一个 copy 机制，当然也可以用 pointer network 来做。 模型每次输入 m 个 QA 对正例和 m 个负例，通过 QG 和 QA 各自模型计算各自 loss，再加上一个正则化项一起计算参数梯度并更新参数。 正则化 dual 项利用了 QA 和 QG 的对偶关系： 考虑到 $P(a|q;\\theta_{qa})$ 和 QA 模型的输出有差异，因此给定 q，sample 一系列 answer sentences A’，从中得到 $P(a|q;\\theta_{qa})$ 在实现细节里提到模型对 question words 和 answer words 用了不同的 emebdding 矩阵来学习特定的语义。另外 sampled answer sentence 来自其他的 passage，这降低了 QA 的难度。 结果分析再次证明了 word co-occurrence 是一个简单但非常有效的特征。 实验设计部分不大能看出模型的实际效果，不明白为什么不直接刷榜看一下结果。另外 QG 部分的评价指标也只用了 BLEU-4 分数，对 fluency 没有进行说明。 We ﬁrst report results on the MARCO and SQUAD datasets. As the dataset is splitted by ourselves, we do not have pre- viously reported results for comparison. A Joint Model for Question Answering and Question Generation这篇和上篇都是讲怎么同时生成答案和问题，不同的是上篇通过一个 dual regularization term 将两者联合起来训练，这里把 QA 和 QG 任务都作为生成任务，模型基本结构还是 Seq2Seq + Attention + Pointer Softmax，和之前提到的一篇 论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation 差不多。输入是文档，以及一个 condition sequence，在 QA 任务里表现为 question word sequence，给定 question 生成 answer；QG 任务里表现为 answer word sequence，给定 answer 生成 qestion，condition 由一个0/1 变量来控制，表示收到的数据是给 a-gen 还是给 q-gen。Joint training 通过对输入数据的转换实现。 Pointer-softmax 一定程度上能解决 extractive/abstractive 的混合问题，通过选择 copy 文档的单词还是生成词汇表的单词来产生下一个单词，表达了 extractive/abstractive 的切换。这带来的一个额外好处是可以产生 abstractive answer。 具体来讲，Encoder 里，词向量和字向量拼接得到 word embedding，其中字向量用 BiLSTM 产生，word embedding 经过另一个 BiLSTM 编码得到文档编码 $h^d_i$ 和条件序列的编码 $h^c_j$。 条件序列的另一种编码是“抽取式的”，也就是从 document encoding 中直接抽取出出现在 condition sequence 中的单词的对应部分，这和 论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation 原理相同。然后抽取的向量经过 BiLSTM 产生对应编码 $h^e_k$。两种条件序列的编码 $h^c_j$ 和 $h^e_k$ 的 final state 分别为 $h^c_J$ 和 $h^e_K$。在 a-gen mode 也就是对问句进行编码是采用 $h^c_J$，在 q-gen mode 也就是对答案进行编码时采用 $h^e_K$，相当于模拟了 extractive 和 abstractive 的特性。 Decoder 用了 pointer-softmax mechanism，比之前的工作复杂一些。用了两个 LSTM cell $c_1$、$c_2$ context vector: distribution over the document word position: Generative mode 由两层 MLP产生： 每个 step 的 switch scalar，由三层 MLP 得到，前两层用 tanh 激活，最后一层用 sigmoid，第一第二层之间是 highway 连接，在最后一层的输入加入 softmax distribution 的 entropy 来进一步提高 performance，相当于给了 point or generate 的更多信息。 最后结果： 损失函数 实现细节里，encoder 用了整个词表，decoder 用了训练数据里 gold question 中的频率最高的 100 个单词的词表。另外一个 trick 是 decoder 保留了之前产生的单词的历史来防止输出的重复。 联合训练下，a-gen 的表现有显著提升，q-gen 略有下降。一个直观结论是，模型并没有提高 QA 任务的效果，但是增加了 QG 的能力。 过去大多模型都把 QA 当做 point to answer span within a document 而不是 NLG 任务，这一篇的创新之处就在于把 QA 也当作了生成问题，与 QG 放到同一个框架下，用 pointer-softmax 来调节生成/抽取的比率，给 QA 也增加了“生成”的能力。 一个显著优势是，和上一篇 paper 相同，这里不需要预训练 QA，可以直接用 QG 辅助 QA 的实现同时给模型提供QG 的能力。 a key distinction of our model is that we harness the process of asking questions to benefit question answering, without training the model to answer the generated questions. MSRA 出品的 QG 系列的 paper 在各自模型及实现上有共性也有个性，一些 trick 基本是通用的，具体的实用性能还待具体领域的实践检验。","tags":"machine-comprehension 阅读理解 question-generation 问题生成"},{"title":"论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation","url":"/2018/06/03/论文笔记 - Machine Comprehension by Text-to-Text Neural Question Generation/","text":"继续来瞅瞅问题生成~ QG 的应用还是挺广泛的，像是为 QA 任务产生训练数据、自动合成 FAQ 文档、自动辅导系统（automatic tutoring systems）等。 传统工作主要是利用句法树或者知识库，基于规则来产生问题。如基于语法（Heilman and Smith, 2010; Ali et al., 2010; Kumar et al., 2015），基于语义（Mannem et al., 2010; Lindberg et al., 2013），大多是利用规则操作句法树来形成问句。还有是基于模板（templates），定好 slot，然后从文档中找到实体来填充模板（Lindberg et al., 2013; Chali and Golestanirad, 2016）。 深度学习方面的工作不多，有意思的有下面几篇： Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus将 KB 三元组转化为问句 Generating natural questions about an image从图片生成问题 Semi-supervised QA with generative domain-adaptive nets用 domain-adaptive networks 的方法做 QA 的数据增强论文笔记 神经网络做 QG 基本套路还是 encoder-decoder 模型，对 P(q|d) 或者 P(q|d, a) 进行建模。像是 17年 ACL 的 paper Learning to Ask: Neural Question Generation for Reading Comprehension，就是用一个基本的 attention-based seq2seq 模型对 P(q|d) 进行建模，并在 encoder 引入了句子和段落级的编码。 这一篇 Microsoft Maluuba 出的 paper 把 answer 作为先验知识，对 P(q|d, a) 进行建模。同时用监督学习和强化学习结合的方法来训练 QG，先用最大似然预训练一波，然后用 policy gradient 方法进行 fine-tune ，最大化能反映问题质量的一些 rewards。 Encoder-Decoder Model基础架构是 encoder-decoder，加了 attention mechanism (Bahdanau et al. 2015)和 pointer-softmax coping mechanism (Gulcehre et al. 2016)。 Encoder输入： document $D=(d_1, …, d_n)$ answer $A = (a_1, …, a_m)$ $d_i, a_j \\in R^{D_e}$ 是词向量。 在文档词向量后面拼了个二维特征表示文档单词是否在答案中出现。然后过 Bi-LSTM 对文档表示进行编码得到 annotation vectors $h_d=(h^d_1,…h^d_n)$，$h^d_i \\in R^D_h$, $h^d_i$ 是每一时刻前向和后向 hidden state 的拼接。 接着对 answer 编码。主要根据 answer 在 document 的位置找到对应的 annotation vector，然后把它和 answer 的词向量拼接起来也就是 $[h^d_j;a_j], s&lt;=j &lt;=e$，s,e 表示 answer 在 document 的起始结束位置，经过第二个 biLSTM 得到 $h^a \\in R^{D_h}$，$h_a$ 是两个方向 final hidden state 的拼接。 计算 decoder 的初始状态 $s_0 \\in R^D_s$ $L \\in R^{D_h * D_h}, W_0 \\in R^{D_s * D_h}, b_0 \\in R^{D_s}$ Decoder解码器产生输出，输出单词从 $p_\\theta(y_t|y_{&lt;t}, D, A)$ 分布中得到。 为了在问句中直接产生文档中的一些短语和实体，在 decoder 的时候采用了 pointer-softmax，也就是两个输出层，shortlist softmax 和 location softmax，shortlist softmax 就是传统的 softmax，产生 predefined output vocabulary，对应 copynet 中的 generate-mode，location softmax 则表示某个词在输入端的位置，对应 copynet 中的 copy-mode。 Decoder：$$s_t=LSTM(s_{t-1}, y_{t-1}, v_t)$$$v_t$ 是从 document 和 answer encoding 计算得到的 context vector，用了 attention 机制，$a_{tj}$ 同时可以用作location softmax。 context vector: shortlist softmax vector $o_t$ 用了 deep output layer (Pascanu et al., 2013) 最后的 $p_t \\in R^{|V|+|D|}$ 由 $z_t$ 对两个 softmax 输出进行加权和拼接得到。$z_t$ 由 MLP 产生，输入也是 $s_t, v_t, y_{t-1}$，两个隐层然后输出层 sigmoid 激活得到 $z_t$。 Training三个 loss: negative log-likelihood 用了 teacher forcing，也就是 $y_{t-1}$ 不是从模型输出得到的，而是来自 source sequence not to generate answer words in question $\\hat a$ 表示在 answer 中出现但没有在 groud-truth question 中出现的单词 Variety 最大化信息熵来鼓励输出多样性 Policy Gradient OptimizationTeacher forcing 会带来一个问题，训练阶段和测试阶段的结果会存在很大差异。在训练阶段，tearcher force 使得模型不能从错误中学习，因为最大化 groud-truth likelihood 并不能教模型给没有 groud-truth 的 example 分配概率。于是就有了 RL 方法。在预训练一波 maximum likelihood 之后，使用一些和问题质量相关的 rewards，来进行 policy gradient optimzation。 Rewards Question answering好的问题能被回复把 model-generated question 喂给预训练好的 QA 系统（论文用的 MPCM 模型），然后用 QA 系统的 accuracy（比如 F1） 作为 reward Fluency (PPL)是否符合语法，过一个语言模型计算 perplexity Combination两者加权 Reinforce“loss”: $\\pi$ 是要训练的 policy，是action 的概率分布，action space 就是 decoder output layer 的词汇表，可以通过 beam-search 采样选择 action，采样结果通过 decoder teacher-force 还原得到 state，计算 reward 进行梯度更新。 Policy gradient: EvaluationBaseline Seq2Seq 可以产生更符合语法更流畅的英文问题，但是语义可能更加模糊，这篇 paper 提出的系统可以产生更具体的问题，虽然没那么流畅。","tags":"machine-comprehension 阅读理解 question-generation 问题生成"},{"title":"论文笔记 - Making Neural QA as Simple as Possible but not Simpler（FastQA）","url":"/2018/05/13/论文笔记 - Making Neural QA as Simple as Possible but not Simpler/","text":"阅读理解系列的框架很多大同小异，但这篇 paper 真心觉得精彩，虽然并不是最新最 state-of-art~ 现在大多数的阅读理解系统都是 top-down 的形式构建的，也就是说一开始就提出了一个很复杂的结构（一般经典的就是 emedding-, encoding-, interaction-, answer-layer），然后通过 ablation study，不断的减少一些模块配置来验证想法，大多数的创新点都在 interaction 层。而这篇 paper 提供了抽取式 QA 基于神经网络的两个 baseline，BoW- 和 RNN-based nerual QA (FastQA) ，创新的以 bottom-up 的方式分析了框架复杂性以及主流 interaction layer 的作用。 一个基本认识，构建好的 QA 系统必不可少的两个要素是： 在处理 context 时对 question words 的意识 有一个超越简单的 bag-of-words modeling 的函数，像是 RNN 另外，作者还发现了很多看似复杂的问题其实通过简单的 context/type matching heruistic 就可以解出来了，过程是选择满足条件的 answer spans： 与 question 对应的 answer type 匹配比如说问 when 就回答 time 与重要的 question words 位置上临近如下图的 St. Kazimierz Church FastQA 的表现对额外的复杂度，尤其是 interaction 的复杂交互，提出了质疑。 A BoW Neural QA System比照传统思路来构建。 Embedding词向量和字向量的拼接，字向量用 CNN 进行训练，$x=[x^w; x^c] \\in R^d$ Type matching抽取 question words 得到 lexical answer type(LAT)。抽哪些？ who, when, why, how, how many, etc. what, which 后面的第一个名词短语，如 what year did…将 LAT 的第一个和最后一个单词的 embedding，以及 LAT 所有单词的平均的 embedding 拼接起来，再通过全连接层和 tanh 做一个非线性变换得到 $\\hat z$。用同样方法对每个 potential answer span(s, e) 做编码。所有 span，最长为 10 个单词，同样把 span 里第一个和最后一个单词的 embedding 和所有单词的 embedding 进行拼接，又因为 potential answer span 周围的单词会对 answer span type 提供线索（比如上文提到的 St. Kazimierz Church），所以额外的拼接了 span 往左、往右 5 个单词的平均 embedding，这样一共就是 5 个 embedding，接 FC 层和 tanh 非线性变换，得到 $\\hat x_{s,e}$最后，拼接 LAT 和 span 的表示，$[\\hat z; \\hat x_{s, e}; \\hat z \\ ☉ \\ \\hat x_{s,e}]$，用一个前馈网络计算每个 span(s,e) 和 LAT 的分数 $g_{type}(s,e)$ Context Matching引入两个 word-in-question 特征，对 context 中的每个单词 $x_j$ binary$wiq^b$ ，如果 $x_j$ 出现在了 question 中，就为 1，否则为 0 weighted计算 $q_i$ 和 $x_j$ 的词向量相似性 Softmax 保证了 infrequent occurrences of words are weighted more heavily.对每个 answer span(s,e)，计算往左、往右 5/10/20 token-windows 内 $wiq^b$ 和 $wiq^w$ 的平均分数，也就是计算 2(kind of features) 3(windows) 2(left/right)=12个分数的加权和得到 context-matching score $g_{ctxt}(s,e)$，各分数的权重由训练得到 Answer span scoring最后每个 span(s,e) 的分数就是 type matching score 和 context matching score 的和$$g(s,e)=g_{type}(s,e)+g_{ctxt}(s,e)$$ 最小化 softmax-cross-entropy loss 进行训练。 FastQA上面的方法中语义特征完全被缩减成了 answer-type 和 word-in-question features，另外 answer span 也受到了长度限制，对语义的捕捉很弱。 BiRNN 在识别 NER 上面非常有优势，context matching 也可以通过给 BiRNN 喂 wiq-features 得到，answer-type 会间接由网络学习得到。 模型相对简单，就三层 embedding-, encoding-, answer layer。 Embedding和 BoW baseline 相同。 Encoding为了让 question 和 context embedding 可以交互，先映射到 n 维向量，再过一个 highway layer。 然后加上 wiq features 再一起过一个 BiRNN，输出再做个 projection 初始化 project matrix B 为 $[I_n; I_n]$，$I_n$ 是 n 维的 identity matrix，H 是 forawrd 和 backward LSTM 的输出的加和。question 和 context 的参数共享，question 对应的两个 wiq 特征设为 1。projection matrix B 不共享。 Answer layercontext x $H=[h_1,…,h_{L_X}]$question Q $Z=[Z_1,…Z_{L_Q}]$对 Z 做一个变换，同样是 context-independent answer 的开始位置的概率 $p_s$ 由 2 个前馈网络加一个 ReLU 激活得到。 结束位置： $$p(s,e)=p_s(s)•p_e(e|s)$$ 最小化 p(s,e) 的交叉熵来训练。 在预测的时候，可以用 beam-search。 FastQA Extended相当于主流模型的 interaction layer。对当前的 context state，考虑和剩下的 context（intra）或者和 question（inter）做注意力计算，将其余 context/question 的信息融入当前 context。 Intra-fustionbetween passages of the context Inter-fusionbetween question and context 实验结果： 一些小结论： 简单的 $wiq^b$ 特征能大幅度提升 performance，原因是让 encoder 有了真实 question 的部分知识后，encoder 就可以有选择性的追踪问题相关的信息并进一步将具体的实体抽象为对应的类型，如果在问题中提到了人名，那么 context encoder 就会记住 “question-person” 而不是具体名字。 Beam-search 可以微弱提升结果，因为最可能的开始位置不一定是最好的 answer span 额外的 character embedding 对结果有显著提升 进一步的 fusion 对结果也有帮助，但并没有那么显著 讨论 Do we need additional interaction?对比试验，FastQA 与 FastQAExt 和 DCN 相比，快两倍，而且少 2-4 倍的显存。分析了结果发现 FastQAExt 泛化能力更强些，但并没有 systematic advantage，并不会对某类问题（主要分析了推理）有一致性的提升。 Qualitative Analysis对 FastQA 的错误结果进行了一些分析，大部分的错误来自： 缺乏对句法结构的理解 不同词位相似语义的词的细粒度语义之间的区分 其他很多的错误也是来自人工标注偏好。 举了一些典型的错误例子，像 例1 是缺乏对某些答案类型的细化理解。例2 缺乏指代消解和上下文缩略语的认识，例3 模型有时难以捕捉基本的句法结构，尤其是对于重要的分隔符如标点符号和连词被忽略的嵌套句子 现有 top-down 模型用到实际业务当中通常需要为了 fit 进显存或者是满足一定的响应时间而进行模型的各种简化，FastQA 在显存占用和响应速度上有着绝对优势，感觉还是非常有意义的~","tags":"machine-comprehension 阅读理解 fastqa"},{"title":"论文笔记 - Semi-Supervised QA with Generative Domain-Adaptive Nets","url":"/2018/04/07/论文笔记 - Semi-Supervised QA with Generative Domain-Adaptive Nets/","text":"GDAN，Question Generation 和 Question Answering 相结合，利用少量的有标注的 QA 对 + 大量的无标注的 QA 对来训练 QA 模型。 Introduction看到这篇论文，看到来自 CMU，就忍不住推测作者估计是 LTI 的，估计还上过 411/611/711，毕竟 idea 和 final project 太像了。。 回顾下 CMU 11411/611/711 的 final project，项目是阅读理解，分为 Asking System 和 Answering System 两个子系统。17年初的时候，Alan 鼓励用课上学到的东西 &amp; 隐晦的不鼓励用 DL，anyway 那时候也并没有看到用 DL 做 QG 的 paper，网上唯几和 QG 相关的 paper 都是 CMU 的，估计和这门课相辅相成。 611 的 asking system 和 answering system 都没有标注，只是纯粹的 wiki 文本，asking system 基于 document 产生 question 以及 answer，answering system 根据 question 和 document 产生 answer。具体见之前的两篇博文：NLP 笔记 - Question Answering SystemQA system - Question Generation 因为没有标注，所以两个系统其实是相互补充相互促进的。如果产生的 question 太简单，和原文太过相近，那么 answering system 的泛化能力有可能就很差，而如果 question 太难，answering system 也就学很难学习很难训练。 评价产生的 question 的好坏的标准除了流畅、符合语法等基于 question 本身的特点外，我们还希望好的问题能找到答案，这些逻辑在这篇论文中都有所体现。 回到 paper，主要思想其实就是用 少量的有标注的 QA 对 + 大量的无标注的 QA 对 来训练 QA 模型。主要做法是，给部分 unlabelled text，用 tagger 抽一些答案，训练 generative model 来生成对应的问题，然后补充训练集，再训练 QA model。实际是用改进的 GAN 方法来构建一个半监督问答模型。 Model ArchitectureGenerative Model - seq2seq with attention and copy对 P(q|p,a) 进行建模。输入是 unlabelled text p 和从中抽取的答案 a，输出是 q，或者说 (q, p, a)。答案 a 的抽取依赖 POS tagger + constituency parser + NER tagger。生成模型这里用的是 seq2seq model(Sutskever et al., 2014) + copy mechanism(Gu et al., 2016; Gulcehre et al., 2016)。 Encoder 用一个 GRU 把 paragraph 编码成 sequence of hidden states H。注意论文在 paragraph token 的词向量上加了额外的一维特征来表示这个词是否在答案中出现，如果出现就为 1，否则为 0。Decoder 用另一个 GRU + Attention 对 H 进行解码，在每一个时刻，生成/复制单词的概率是： $$P_{overall} = g_tp_{vocab}+(1-g_t)p_{copy}$$$$g_t=\\sigma(w^T_gh_t)$$ 具体细节不多说了，相关可以看 Copy or Generate。 生成模型 G 产生的 (q, p, a) 作为判别模型的输入。 Discriminative Model - gated-attention reader对 P(a|p,q)进行建模。输入是人为标注数据 L 以及模型产生的数据 U，由于 L 和 U 来自不同分布，所以引入了 domain tag 来区分两类数据，“true”来表示人为标记数据 L，“gen”标签来表示模型生成数据 U（Johnson et al., 2016; Chu et al., 2017）。在测试时，只加入 d_true。 论文这里用了 GA (gated-attention) Reader 作为基本结构，也是 CMU 出的模型，当然事实上别的模型也可以。模型很简单，embedding 层用词向量，encoder 层用双向 GRU 分别得到 $H_q$ 和 $H^k_p$，context-query attention 层用 gated attention($H^k_p$, $H_q$ 做 element-wise 乘法)做下一层网络的输入，重复进入 encoder 和 attention 层进行编码和乘法（共 k 层），最后将 p, q 做內积（inner product）得到一个最终向量输入 output 层，output 层用两个 softmax 分别预测答案在段落中的起始和结束位置。 Loss function整体的目标函数： $$max_D \\ J(L, d_{true, D})+ J(U_G, d_{gen}, D)$$$$max_G \\ J(U_G, d_{true}, D)$$ Training Algorithm主要要解决下面两个问题。 Issue 1: discrepancy between datasets 如上，判别模型很容易在 U 上 overfit，所以才用了 domain tag 做区分。 Issue 2: jointly train G and D 如上，如果用 auto-encoder，容易让 question 和 answer 的表达非常接近，question 甚至可能完全 copy answer，所以这里用了判别模型。 Intuitively, the goal of G is to generate “useful” questions where the usefulness is measured by the probability that the generated questions can be answered correctly by D Algorithm 分两个阶段：第一阶段: 固定 G，利用 d_true 和 d_gen，用 SGD 来更新 D。在 L 上计算 MLE 来完成 G 的初始化，对 D 进行随机初始化。第二阶段: 固定 D，利用 d_true，用 RL 和 SGD 更新 G。由于 G 的输出是不可导的，所以用到了 reinforce algorithm。action space 是长度为 T’ 的所有可能的 questions，reward 是 $J(U_G,d_{true}, D)$。 SummaryQANet 那篇论文中提到了另一篇 Question Generation 的论文： Zhou et al. (2017) improved the diversity of the SQuAD data by generating more questions. However, as reported by Wang et al. (2017), their method did not help improve the performance. 相信 GDAN 在一定程度上一定能缓解 QA 中标注数据稀少的问题，但是能否在数据较为充足，模型较为优势的情况下提升 performance，估计难说，下次尝试后再来填这个坑了。Anyway，看到了曾经思考过的问题有人做出了实践还是万分开心的~","tags":"machine-comprehension 阅读理解 question-generation"},{"title":"论文笔记 - Bi-Directional Attention Flow for Machine Comprehension","url":"/2018/04/01/论文笔记 - Bi-Directional Attention Flow for Machine Comprehension/","text":"BiDAF，相对复杂 attention 机制。 论文： Bidirectional Attention Flow for Machine Comprehension代码： allenai/bi-att-flow Attention Summary这篇论文主要对 attention 机制做了改进，为此作者总结了 MC 任务上过去常用的三类 attention： Attention Reader。通过动态 attention 机制从文本中提取相关信息（context vector），再依据该信息给出预测结果。代表论文：Bahdanau et al. 2015, Hermann et al. 2015, Chen et al. 2016, Wang &amp; Jiang 2016 Attention-Sum Reader。只计算一次 attention weights，然后直接喂给输出层做最后的预测，也就是利用 attention 机制直接获取文本中各位置作为答案的概率，和 pointer network 类似的思想，效果很依赖对 query 的表示代表论文：Kadlec et al. 2016, Cui et al. 2016 Multi-hop Attention。计算多次 attention代表论文：Memory Network(Weston et al., 2015)，Sordoni et al., 2016; Dhingra et al., 2016., Shen et al. 2016. 在此基础上，作者对注意力机制做出了改进，具体 BiDAF attention 的特点如下： 并没有把 context 编码进固定大小的 vector，而是让 vector 可以流动，减少早期加权和的信息损失 Memory-less，在每一个时刻，仅仅对 query 和当前时刻的 context paragraph 进行计算，并不直接依赖上一时刻的 attention，这使得后面的 attention 计算不会受到之前错误的 attention 信息的影响 计算了 query-to-context（Q2C） 和 context-to-query（C2Q）两个方向的 attention 信息，认为 C2Q 和 Q2C 实际上能够相互补充。实验发现模型在开发集上去掉 C2Q 与 去掉 Q2C 相比，分别下降了 12 和 10 个百分点，显然 C2Q 这个方向上的 attention 更为重要 Model Architecture 论文提出的是六层结构：Character Embedding Layer -&gt; Word Embedding Layer -&gt; Contextual Embedding Layer -&gt; Attention Flow Layer -&gt; Modeling Layer -&gt; Output Layer 然而我还是压缩成五层结构来讲吧： Input embedding layer = Character Embedding Layer + Word Embedding Layer和其他模型差不多，word embedding + character embedding，预训练词向量，OOV 和字向量可训练，字向量用 CNN 训练单词 w 的表示由词向量和字向量的拼接然后经过两层 highway network 得到，得到 context vector $X \\in R^{d*T}$ 和 query vector $Q \\in R^{d*J}$ Embedding encoder layer = Contextual Embedding Layer对上一步的结果 X 和 Q 分别使用 Bi-LSTM 编码，捕捉 X 和 Q 各自单词间的局部关系，拼接双向 LSTM 的输出，得到 $H \\in R^{2d*T}$ 和 $U \\in R^{2d*J}$这前面的两层（or 原文三层）用来捕捉 query 和 context 各自不同粒度（character, word, phrase）上的特征 Context-query attention layer = Attention Flow Layer The attention flow layer is not used to summarize the query and context into single feature vectors. instead, the attention vector at each time step, along with the embeddings from previous layers, are allowed to flow through to the subsequent modeling layer. This reduces the information loss caused by early summarization. 输入是 H 和 U，输出是 context words 的 query-aware vector G，以及上一层传下来的 contextual embeddings。做 context-to-query 以及 query-to-context 两个方向的 attention。做法还是一样，先计算相关性矩阵，再归一化计算 attention 分数，最后与原始矩阵相乘得到修正的向量矩阵。c2q 和 q2c 共享相似度矩阵，$S \\in R^{T*J}$，相似度计算方式是：$$S_{tj}=\\alpha(H_{:t}, U_{:j}) \\in R$$$$\\alpha(h,u)=w^T_{(S)}[h;u;h⊙u]$$$S_{tj}$ : 第 t 个 context word 和第 j 个 query word 之间的相似度$\\alpha$: scalar function$H_{:t}$: H 的第 t 个列向量$U_{:j}$：U 的第 j 个列向量⊙：element-wise multiplication[;]：向量在行上的拼接 context-to-query attention(C2Q): 计算对每一个 context word 而言哪些 query words 和它最相关。前面得到了相关性矩阵，现在 softmax 对列归一化然后计算 query 向量加权和得到 $\\hat U$$$a_t=softmax(S_{t:}) \\in R^J$$$$\\hat U_{:t}=\\sum_ja_{tj}U_{:j}$$ query-to-context attention(Q2C): 计算对每一个 query word 而言哪些 context words 和它最相关，这些 context words 对回答问题很重要。取相关性矩阵每列最大值，对其进行 softmax 归一化计算 context 向量加权和，然后 tile T 次得到 $\\hat H \\in R^{2d*T}$。$$b=softmax(max_{col}(S)) \\in R^T$$$$\\hat h=\\sum_tb_tH_{:t} \\in R^{2d}$$$\\hat U$ 和 $\\hat H$ 都是 2dxT 的矩阵将三个矩阵拼接起来得到 G$$G_{:t}=\\beta (H_{:t}, \\hat U_{:t}, \\hat H_{:t}) \\in R^{d_G}$$$\\beta$ 可以是多层 perceptron，不过如上简单的拼接效果也不错。$$\\beta(h, \\hat u, \\hat h)=[h;\\hat u; h⊙\\hat u; h⊙\\hat h] \\in R^{8d*T}$$于是就得到了 context 中单词的 query-aware representation。 Model encoder layer = Modeling Layer输入是 G，再经过一次 Bi-LSTM 得到 $M \\in r^{2D * T}$，捕捉的是 interaction among the context words conditioned on the queryM 的每一个列向量都包含了对应单词关于整个 context 和 query 的上下文信息 Output layer预测开始位置 p1 和结束位置 p2$$p_1=softmax(W^T_{(p^1)}[G; M]), \\ \\ \\ p_2=softmax(W^T_{(p^2)}[G; M^2])$$M 再经过一个 Bi-LSTM 得到 $M^2 \\in R^{2d * T}$，用来得到结束位置的概率分布 ​最后的目标函数：$$L(\\theta)=-{1 \\over N} \\sum^N_i[log(p^1_{y_i^1})+log(p^2_{y_i^2})]$$$y^1_i$ 和 $y^2_i$ 分别是第 i 个样本的 groundtruth 的开始和结束位置","tags":"machine-comprehension 阅读理解 bidaf"},{"title":"论文笔记 - Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution","url":"/2018/03/25/论文笔记 - Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution/","text":"CMU &amp; Google 出品的 Fast and Accurate Reading Comprehension by Combining Self-Attention and Convolution，SQuAD 榜单上对应模型 QANet，这名字是不是太随意了TAT… Fast and Accurate Reading Comprehension by Combining Self-Attention and ConvolutionCMU 和 Google Brain 新出的文章，SQuAD 目前的并列第一，两大特点： 模型方面创新的用 CNN+attention 来完成阅读理解任务 在编码层放弃了 RNN，只采用 CNN 和 self-attention。CNN 捕捉文本的局部结构信息（ local interactions），self-attention 捕捉全局关系（ global interactions），在没有牺牲准确率的情况下，加速了训练（训练速度提升了 3x-13x，预测速度提升 4x-9x） 数据增强方面通过神经翻译模型（把英语翻译成外语（德语/法语）再翻译回英语）的方式来扩充训练语料，增加文本多样性 其实目前多数 NLP 的任务都可以用 word vector + RNN + attention 的结构来取得不错的效果，虽然我挺偏好 CNN 并坚定相信 CNN 在 NLP 中的作用（捕捉局部相关性&amp;方便并行），但多数情况下也是跟着主流走并没有完全舍弃过 RNN，这篇论文还是给了我们很多想象空间的。 Model Architecture 先看模型，在 BiDAF 基础上的一些改进，主要在 embedding encoder 层。还是阅读理解经典五层结构： Input embedding layer和其他模型差不多，word embedding + character embedding，预训练词向量，OOV 和字向量可训练，字向量用 CNN 训练单词 w 的表示由词向量和字向量的拼接 $[x_w; x_c] \\in R^{p_1+p_2}$然后经过两层 highway network 得到，这个和 BiDAF 相同 Embedding encoder layer重点是这一层上的改变，由几个基本 block 堆叠而成，每个 block 的结构是：[convolution-layer x # + self-attention-layer + feed-forward-layer]卷积用的 separable convolutions 而不是传统的 convolution，因为更加 memory efficient，泛化能力也更强。核心思想是将一个完整的卷积运算分解为 Depthwise Convolution 和 Pointwise Convolution 两步进行，两幅图简单过一下概念先做 depthwise conv， 卷积在二维平面进行，filter 数量等于上一次的 depth/channel，相当于对输入的每个 channel 独立进行卷积运算，然后就结束了，这里没有 ReLU 然后做 pointwsie conv，和常规卷积相似，卷积核尺寸是 1x1xM，M 为上一层的 depth，相当于将上一步depthwise conv 得到的 map 在深度上进行加权组合，生成新的 feature map Self-attention-layer 用的是多头注意力机制（head=8），常用的也不多说了。注意的是这里每个基本运算（conv/self-attention/ffn）之间是 残差连接，对输入 x 和操作 f，输出是 f (layernorm(x))+x，也就是说某一层的输出能够直接跨越几层作为后面某一层的输入，有效避免了信息损失4 个卷积层，1 个 encoding block Context-query attention layer几乎所有 machine reading comprehension 模型都会有，而这里依旧用了 context-to-query 以及 query-to-context 两个方向的 attention，先计算相关性矩阵，再归一化计算 attention 分数，最后与原始矩阵相乘得到修正的向量矩阵。相似度函数这里用的$$f(q,c)=W_0[q,c,q⊙c]$$对行、列分别做归一化得到 S’ 和 S’’，最后 context-to-query attention 就是 $A=S’Q^T$，query-to-context attention 就是 $B=S’S’’^TC^T$，用了 DCN attention 的策略 Model encoder layer和 BiDAF 差不多，不过这里依旧用 CNN 而不是 RNN。这一层的每个位置的输入是 [c, a, c⊙a, c⊙b]，a, b 是 attention 矩阵 A,B 的行，参数和 embedding encoder layer 相同，除了 cnn 层数不一样，这里是每个 block 2 层卷积，一共 7 个 block Output layer再次和 BiDAF 相同$p1=softmax(W_1[M_0; M_1]), p2=softmax(W_2[M_0; M_2])$目标函数：$$L(\\theta)=-{1 \\over N} \\sum^N_i[log(p^1_{y_i^1})+log(p^2_{y_i^2})]$$其中 $y^1_i$ 和 $y^2_i$ 分别是第 i 个样本的 groundtruth 的开始和结束位置 Data AugmentationCNN 速度快所以有条件用更多的数据来训练啦，然后进一步增强模型的泛化能力啦。这里数据增强的基本 idea 就是通过 NMT 把数据从英文翻译成法文（English-to-French），另一个翻译模型再把法文翻回英文（French-to-English）看图说话，对段落中每个句子先用 English-to-French 模型的 beam decoder 得到 k 个法语翻译，然后对每一条翻译，都再经过一个 reversed translation model 的 beam decoder，这最后就得到了 k^2 个改写的句子（paraphrases），然后从这 k^2 个句子中随机选一个 具体到 SQuAD 任务就是 (d,q,a) -&gt; (d’, q, a’)，问题不变，对文档 d 翻译改写，由于改写后原始答案 a 现在可能已经不在改写后的段落 d’ 里了，所以需要从改写后的段落 d’ 里抽取新的答案 a’，采用的方法是计算 s’ 里每个单词和原始答案里 start/end words 之间的 character-level 2-gram score，分数最高的单词就被选择为新答案 a’ 的 start/end word这个方法还可以从 quality 和 diversity 改进，quality 方面用更好的翻译模型，diversity 方面可以考虑引入问题的改写，也可以使用其他的数据增广的方法（Raiman&amp;Miller, 2017） 实验结论是英文语料：法语语料：德语语料是 3:1:1 的比例时效果最好，EM 提升了 1.5，F1 提升了 1.1","tags":"machine-comprehension 阅读理解 bidaf"},{"title":"扯扯 Semi-hard Negative Samples","url":"/2018/03/17/扯扯 Semi-hard Negative Samples/","text":"谈谈排序模型的 negative sampling 问题。取不好题目TAT… 之前在用 Dual Encoder 这类 ranking model 时，发现在一些问题上尽管大方向上匹配的很好，比如人名问题答的都是人名，歌曲问题回答的都是歌曲名，但是具体到再细的粒度就完全匹配不上了。明明知道这显然是 negative sampling 的问题，却一直没找到好的解决方案，毕竟 google 一下 negative sampling 发现前 5 页都是在讲 word2vec…… 感觉这应该算是 ranking 模型中一个非常实际也非常常见的问题。在训练的时候，我们一般不会在整个模板库上进行排序，这样效率太低也容易错，而是会做随机负采样，比如随机选 19 个负样本，和正确答案一起作为候选答案（ranking size=20）。但在实际应用中，又往往需要对整个模板库排序，或者至少要用别的方法召回一批样本（包含正确答案）再进行预测。这样一来，如果训练时随机的负样本太弱太简单（和正确答案差异性很大），而在预测时候选答案又太难太挑战（和正确答案很相似），效果当然就不好了。 当时自己折腾的时候尝试过很多方法，比如扩大 ranking size，多采样负样本，发现收益并不大，也试过先召回一部分和答案相似的样本，再做 reranking，或者在 DE 前或者后加别的 ranking 来进一步缩小范围，也是收效甚微，另外资源限制很多实验都没跑的很完美就暂时把这个问题放下了。直到最近看到了 tambetm/allenAI 这个，发现这个小哥哥用了一种不错的 negative sampling 的方法，看上去很有道理的样子，借鉴的还是 15 年的工作，哎都怪我读书少之前木有接触过现在才发现(╥﹏╥) 简单来说就是选择难度适当的错误回复（semi-hard negative samples）作为负样本，这个 idea 来自 15年 FaceNet 那篇文章，过去瞅了瞅，就从 FaceNet 讲起吧。FaceNet 最大特点应该就是提出了 Triplet Loss 的概念，也就是在向量空间内，希望保证单个个体的图像 $x^a_i (anchor)$和该个体的所有其它图像 $x^p_i(positive)$ 之间的特征距离尽可能的小，而与其它个体的图像 $x^n_i(negitive)$ 之间的特征距离要尽可能的大（差不多就是 LDA 的思路嘛，最大化类间距离最小化类内距离）。 Here we want to ensure that an image $x^a_i (anchor)$ of a specific person is closer to all other images $x^p_i(positive)$ of the same person than it is to any image $x^n_i(negitive)$ of any other person. 然后 loss 的设定就是说通过学习，使得类间距离大于类内距离，$\\alpha$ 作为 positive/negtive 边界，是一个常量。 Triplets 显然不能穷举，这样一来筛选 triplets 就很重要，为了最快收敛考虑当然是首选最难区分的图像对了，也就是 hard positive ($argmax_{x^p_i}||f(x^a_i)-f(x^p_i)||^2_2$) 和 hard negative ($argmin_{x^n_i}||f(x^a_i)-f(x^n_i)||^2_2$)。举个例子，如果整体样本集是 1000 个人每个人 40 张图片，给定某个人的图片来选 triple，那么自然选这个人另外 39 张图片中和它最不相似的图片作为 hard positive，以及剩下 40*999 张图片中和它最相似的图片作为 hard negative。 挑选 hard positive 和 hard negative 有 offline (generate triplets every n steps) 和 online (select triplets within a mini-batch) 方法。论文重点聚焦在了 online 方法，在一个大的 mini-batch （1800 个样本）中选择所有的 anchor-positive pairs，同时，来选择一定的 hard anchor-negative pairs，但选择 hardest negatives 在实际当中容易导致在训练最开始的时候就陷入局部最优，所以实际会选择 semi-hard negatives，使挑选样本满足下面的式子： 这个约束就是 semi-hard。再回过头来看开始的 repo，模型用 RNN 对 question 和 answer 进行编码，然后用 cosine ranking loss，也就是让 question 和 right answer 的 cosine 距离小于 question 和 wrong answer 的 cosine 距离。 wrong answer 采用 neagtive sampling，选择难度适当的 wrong answer，或者说选择当前模型能正确分类但是没那么 confident 的 wrong answer。 他们是发现 too hard answer 会使模型难以收敛，而实验表明： Semi-hard negative samples, which are further than the right answer, but still within the margin - works best 参考连接： 谷歌人脸识别系统FaceNet解析FaceNet: A Unified Embedding for Face Recognition and Clustering","tags":"negative-sampling 负采样"},{"title":"论文笔记 - 基于神经网络的推理","url":"/2018/03/05/论文笔记 - 基于神经网络的推理/","text":"DeepMind Relational Reasoning(RNs) Relational reasoning(RNs) 论文：A simple neural network module for relational reasoning(2017) github代码: https://github.com/siddk/relation-network 关系推理的传统方法有基于符号的方法（symbolic approaches）和基于统计的方法（statistical learning）。基于符号的方法存在着 symbol grounding 的问题，在小任务（small task）和输入变化（input variations）的问题上也不够鲁棒，学习能力不强；而基于统计的方法像深度学习，虽然泛化能力强，但是对数据稀疏但关系复杂的问题也是束手无策。DeepMind 2017年出的这篇论文提出的Relation network(RN)，是用于关系推理（relational reasoning）的一个神经网络模块（NN module），能直接加载到已有的神经网络架构中。与 GNN 等网络结构相比，更为简单和灵活，即插可用（plug-and-play），在一些关系推理的测试上的准确率已经超过了人类。 StructureRN 的网络结构是真的很简单（不然也不会说是”simple neural network”），以至于通篇下面一个公式就可以概括，核心就是利用神经网络来找出任意 pairwise 对象之间的潜在关系。 $$RN(O) = f_\\phi (\\sum_{i,j}g_\\theta(o_i, o_j))$$ Inputs: O={$o_1, …, o_n$} MLPs: $f_\\phi$, $g_\\theta$ $g_\\theta$: 使用一个全连接的神经网络来量化 $o_i$ 和 $o_j$ 的关系，任意两个对象之间的关系使用同一套参数 $g_\\theta(•,•)$ $f_\\phi (\\sum_{i,j}g_\\theta(o_i, o_j))$: 考虑所有组合的关系，相当于考虑一个完全连接图，在这个图上计算各个边的权重，把重要的关系凸显出来，f 函数就计算了这个重要关系的集合 用在自然语言处理里，就是把每个句子当做一个对象，每个句子与句子的 pair 用 g 计算关系，再把所有关系加权和放到最终的预测网络里。 小结一下，RNs有以下三个特点： 可以学习推理。这里 RNs 计算了所有的两个对象之间的关系，当然也可以只计算部分两个对象之间的关系，这里的“部分”需要预定义 RNs的数据效率更高(data efficient)。RNs 使用一个 gθ 函数来计算所有的关系，任意两个对象之间的关系使用同一套参数，泛化能力更强 RNs作用在一个集合上，对输入和输出都是与顺序无关的（input/output invariation） Tasks简单提一下和 NLP 有关的任务。 VQA RN 在 VQA 任务上的结构也很简单，CNN 处理图像，LSTM 编码 question，然后两两配对的 spatial cell（红蓝；黄红；蓝黄…）和 question embedding 拼接，后面接几个 FC 层，最后 softmax 得到某个 answer word。 Word-embedding: dim32; LSTM: dim128$g_\\theta$: 4-layer MLP, dim256-256-256, RELU$f_\\phi$: 3-layer MLP, dim256-256-29, RELU$f_\\phi (\\sum_{i,j}g_\\theta(o_i, o_j, q)$: 综合所有组合 $g_\\theta(o_i, o_j;q)$，implicitly 提取有用的组合预测最终答案 bAbIRN 在 bAbI 测试集上的结构，每个问题之前的最多 20个句子作为 support set，使用 LSTM-dim32 把 support set 连同每个句子在 set 里的相对位置编码转化为 RN 的 object set，同时使用另一个 LSTM-dim32 的 encoding state 表示问题。 $g_\\theta$: 4-layer MLP, dim256-256-256-256$f_\\phi$: 3-layer MLP, dim 256-512-159 在 joint training 也就是 20 个任务一起训练一个 QA 模型的情况下，通过了 18/20 bAbI test。DNC 在 path finding 任务上表现不错，但在 basic induction 上误差达到 55.1%，而 RN 达到了 2.1% 的误差水平。","tags":"relational-reasoning"},{"title":"论文笔记 - 从神经图灵机 NTM 到可微分神经计算机 DNC","url":"/2018/01/20/论文笔记 - 从神经图灵机 NTM 到可微分神经计算机 DNC/","text":"Neural Turing Machine(NTC) 和 Differentiable Neural Machine(DNC) 的相关笔记。 涉及论文： Neural Turing MachineNeural Turing Machine(2014) Differentiable Neural MachineHybrid computing using a neural network with dynamic external memory (2016) Introduction当今所有的计算机体系都源自冯诺依曼体系(Von Neumann, 1945)，三大要素： elementary operations基本操作，如加减乘除 logical flow control (branching)逻辑流程控制，如 if-else-then, for, while external memory外部存储器，内存和硬盘 RNN 被认为是 Turing-complete 的，理论上可以拟合任何函数，有模拟流程的能力，然而理论上可以，实际实现并没有那么简单。NTM/DNC 的重点是 存储管理，它能够通过一个大的、可寻址的外部存储器来扩展标准 RNN 能力，大大简化算数等任务。 Turing MachineNTM/DNC 的灵感来自于图灵机。图灵机就是一种简单的计算机模型，摘一段概念： A Turing machine is a simple model of the computer. Like modern computers, it encapsulates the idea of having an external memory as well as some sort of processor. Essentially, a Turing machine consists of a tape with instructions written on it and the device that can read up and down the tape. Based on what it reads on the tape, it can decide to move in a different direction to write a new symbol or erase a symbol, and so on. 很简单，由 外部存储器（写有指令的磁带）和存储器（能够沿着磁带读取的设备） 组成，根据磁带上读取到的指令，计算机能够决定在磁带上不同的方向上移动来进行写入或者擦除新符号等操作。 神经图灵机的灵感就来自图灵机的架构，也有 控制器（神经网络）和外部存储器（memory） 构成，试图去解决一些计算机能够解决的很好但机器学习模型很难解决的问题，比如说算法，或者说上面提到的冯诺依曼体系的一些要素。 NTM/DNC vs. TMNTM/DNC 灵感来自于 TM，最关键的区别是神经图灵机是 可微分的（differentiable） 图灵机。计算机/图灵机的计算是绝对的，要么是 0 要么是 1，计算机在非此即彼的逻辑或者整数中运作。然而大多数的神经网络和机器学习更多会使用实数，使用更平滑的曲线，这样会更容易训练（如 BP，可以通过输出追踪回去调整参数以得到希望的输出）。神经图灵机采用基本的图灵机思想，但同时找到了平滑的模拟函数，也就是说，在图灵机磁带上，神经图灵机 NTM 可以决定“稍微”向左或者向右移动，而不是单纯的向左跳一个或者向右跳一个。 Application Learn simple algorithms(Copy, repeat, recognize simple formal languages)能够学习简单的算法（夸张一点，本质上就是尝试着取代程序员）NTM/DNC 能够接受输入和输出，并且学习得到能够从输入映射到输出的算法如说复制任务，它能够学会接受相对短的序列，并重复几次。这让 LSTM 来做它就会崩溃，因为 LSTM 并不是在学习算法，而是试图一次性解决一个整体问题，它意识不到前两次所做的事情就是它们之后应该做的再比如说识别平衡的括号，这涉及到了栈（stack）的算法，NTM/DNC 可以像程序员一样完成这个任务 GeneralizeNTM/DNC 的计算图是对所有任务通用的 Do well at language modeling擅长语言建模比如做完型填空，能够猜测一个单词在句子或者文档语境中的意思 Do well at bAbI擅长推理在 bAbI 数据集上效果很好 Problems Architecture dependent实现的时候需要谨慎做出如对每一时刻的输入能读取/写入多少向量这类的决策，否则很有可能永远都得不到一个合理的结果 Large number of parameters参数量非常大 =&gt; RAM 压力很大 Dosen’t benefit much from GPU acceleration序列输入，每一步输入都依赖之前的输入，也就很难并行化，不能受益于 GPU 加速 =&gt; 很难训练 很难训练还表现在： Numerical Instability数值不稳定性。在试图学习算法时会更倾向于犯大错误，而如果在算法中犯了一个错误，所有的输出结果都会是不正确的。换言之，训练时神经图灵机总是很难找到需要的算法 Using memory is hard大量数据+足够时间，大多数神经网络都会得到一些结果，而神经图灵机经常会卡住，它们经常一遍又一遍地一味地产生那些经常重复的值因为使用记忆是很困难的，不仅要学会记住之后解决问题需要的东西，还不能意外的忘记它 Need smart optimization1+2 =&gt; 需要很好的优化如 gradient clipping, loss clipping, RMSprop, Adam, try different initialization, curriculum learning… 上面这些问题会让神经图灵机很难在实际中应用。 NTM/DNC vs. MemNN异：DNC 侧重记忆管理。MemNN 侧重 memory 查询，在记忆管理上非常简单，一般以 QA 为例，就是每句话 encode 成 vector，然后保存下来，所谓的更新大多是把不重要的 memory 清出去空个位出来给新的 memory。而 DNC 花更多努力在记忆管理上，注重更新 memory 和 memory 的时间关系，包含更多的操作，更新、删除、添加等。另外，NTM/DNC 侧重算法任务，能够自动从数据中学习算法，而一般而言 MemNN 侧重的是 QA 任务。 同：都是从 model architecture 层面，将多个 machine learning model 联合起来处理复杂的任务，比如 LSTM 通常是来处理线性数据，MemNN/NTM 可能包含多个 LSTM，能够处理多个线性结构（类似图结构） Neural Turing Machines(NTM)Basic Idea主要创新是将神经网络与外部存储器（external memory）结合来扩展神经网络的能力（通过注意力机制进行交互），可以类比图灵机，不过 NTM 是端到端可微的，所以可以使用梯度下降进行高效训练。 两个 主要元件 是 controller 和 memory bank。类比计算机来看 基本思路，实际是把神经网络看成是 CPU，把 memory 看做是计算机内存。CPU 根据任务来确定到内存的哪个位置读写信息，不过计算机的内存位置是离散数据，而 NTM 里是连续可导的。 Architecture一张图读懂架构，取 DeepMind DNC Slides 做了部分修改。最重要的概念还是那句话，每个组件都是可微分的，所有操作皆可导，这就可以直接用梯度下降训练来训练。 主要来研究读写操作。 Read Heads读操作和普通的 MemNN 相似，使用 attention 原理计算每个 memory vector 的权重向量，然后对 memory vector 进行加权生成读操作的结果。$$r_t \\leftarrow \\sum^N_{i=1} w_t(i)M_t(i)$$ $M_t$ 是一个 NxM 的矩阵，表示 t 时刻的 memory，N 是 memory 的数量，M 是 memory vector 的维度。$w_t$是 t 时刻产生的权重向量，和 memory 数量相同，进行了归一化，$\\sum_iw_t(i)=1, \\ \\ 0 \\le w_t(i) \\le 1, \\forall i$ Write HeadsErase and Add写操作包含两个步骤：先擦除（erase） 后添加（add） Eraseinput + controller 产生 erase vector $e_t \\in R^M$, $e_t(d) \\in (0,1)$input + memory 产生 $M_t^{erased}(i) \\leftarrow M_{t-1}(i)[1-w_t(i)e_t]$和读操作一样，需要由 attention 机制得到 weight vector，表示每个 memory vector 被改动的幅度的大小，有多少个 memory 就有多少个 $w_t$将上一时刻每个 memory vector 都乘上一个 0-1 之间的 vector，就是擦除操作，相当于 forget gate如果 $w_t$ 和 $e_t$ 都为 1，memory 就会被重置为 0，如果两者有一个为 0，那么 memory 保持不变。多个 erase 操作可以以任意顺序叠加 Addinput + controller 产生 add vector $a_t \\in R^M$ ，$a_t(d) \\in (0,1)$input + memory 产生 $M_t(i) \\leftarrow M_t^{erased}(i) + w_t(i)a_t$相当于 update gate同样的，多个 add 操作的顺序并没有关系 所有的 memory vector 共享 $e_t, \\ a_t$，erase 和 add 操作中的 $w_t$ 也是共享的。再次注意 erase vector 和 add vector 都是由 controller 对 input 做编码得到的。擦除和添加动作都有 M 个独立的 component，使得对每个 memory location 的修改可以在更细的粒度上进行。 Addressing知道了怎么读写，现在来看看权重是如何产生的。主要通过两种方式来进行寻址，一是 content-based addressing，基于 controller 提供的状态向量 key vector 和当前 memory vector 的相似度来决定对内存地址的聚焦程度，另一个是 location-based addressing，通过地址来寻址，可能还会伴随权重的位移（rotational shift）。 整个 Addressing 过程的流程图： Content-based addressingController 会产生一个长度为 M 的状态向量 key vector $k_t$，基于每一个 memory vector $M_t(i)$ 和 controller 状态向量 $k_t$ 的相似程度 K[·,·]，计算每个 memory vector 的 attention 权重。其中相似度可以用 cosine similarity 计算，$K(u,v)={u v \\over ||u|| ||v||}$ 使用 softmax 将相似度转化为概率分布：$$w^c_t(i) \\leftarrow {exp(\\beta_tK[k_t, M_t(i)]) \\over \\sum_j exp(\\beta_tK[k_t, M_t(j)])}$$ 其中，$\\beta_t$ 可以放大或减弱聚焦的程度。$\\beta_t=1$ 时就是标准的 softmax，而 $\\beta$ 的值越大，越会强化最大相似度分数的 memory vector 的优势，可以看做赢者通吃。要注意的是 $\\beta$ 不是超参数，而是 controller 预测得到的。举个具体的例子，在对话领域，如果输入时“呵呵”这类没有太多信息量的句子，那么 controller 就会产生一个非常接近 0 的 $\\beta$，表示没有明确倾向去访问某个特定的信息；反之，如果是包含很多信息的输入，产生的 $\\beta$ 值会很大。 content addressing 完成的下面一个流程，$k_t$ 可以看做是 controller 对输入进行编码产生的状态向量，$\\beta_t$ 是标量，一个 concentration 参数。 Location-based addressing不是所有的问题都可以通过 content-based addressing 来解决的。在一些特定任务尤其是有 variable-binding 的任务中，变量的内容是任意的，但变量还是需要一个可识别的名字/地址来 refer。比如说算数任务，x, y 代表任意值，要计算 $f(x,y)=x * y$，这时候 controller 就会把 x,y 存到对应的地址上，然后通过地址而不是数值内容来获取它们并进行乘法操作。 Content-based addressing 比 location-based addressing 更为通用，因为 Content-based addressing 本身可能包含地址信息。然而 location-based addressing 对某些形式的通用化很有必要，所以论文同时引入了两种寻址机制。 1. Interpolation Gate第一步要进行插值计算。$$w_t^g \\leftarrow g_tw^c_t + (1-g_t)w_{t-1}$$ 基于内容的 weight vector $w^c_t$ 和上一个时间的 weight vector $w_{t-1}$ 的线性组合，线性组合的参数 $g_t$ 是一个 （0, 1）之间的标量，由 controller 产生，表示多大程度上使用当前时刻基于内容的寻址，多大程度上使用上一时刻产生的 $w_{t-1}$ 如果 g=0，那么 content-weighting 整个就被忽略了，只用上一时刻的权重；如果 g=1，那么上一时刻的权重就被忽略了，只使用 content-based addressing。 2. Shifting and Sharpening基于地址的寻址机制既可以用做简单的 memory bank 遍历，也可以用于随机访问，通过对 weighting 的旋转位移操作来实现。如果当前 weight 全力聚焦在一个单一地址上，那么一个为 1 的旋转可以把部分焦点位移到下一个地址，一个负的位移则相反。 具体是在 Interpolation 之后进行。controller 产生的 shift weighting $s_t$ 定义了所有允许的整数位移值上的归一化分布。如果 -1 到 1 间的位移是被允许的，那么 $s_t$ 就有三个对应位移值 -1，0，1 上的概率分布。最简单是用 softmax 来预测 shift weighting，不过这里用了另一种方法，controller 产生一个 single scalar 表示均匀分布的下界（the lower bound of a width one uniform distribution over shifts），也就是如果 shift scalar=6.7，那么 $s_t(6)=0.3$，$s_t(7)=0.7$，剩下的 $s_t(i)$ 都是 0。 Shift attention:$$\\hat w_t \\leftarrow \\sum^{R-1}_{j=0}w^g_t(j)s_t(i-j)$$$s_t$ 其实相当于一个 convolution filter，每一个元素表示当前位置和对应位置的相关程度，像是定义了一个滑动窗里的权重，shift attention 将滑动窗里的 vector 做加权平均。如果位移权重不是 sharp 的，也就是说权重分布相对均匀，那么这个卷积操作会使权重随时间变化更加发散。例如，如果给 -1，0，1 的对应的权重 0.1，0.8 和 0.1，旋转位移就会将聚焦在一个点上的权重轻微分散到三个点上。 controller 还会给出一个标量 $\\gamma_t$ 用来 sharpen 最终的权重，作用和之前讲过的 $\\beta_t$ 差不多，值越大权重大的越突出。Sharpening:$$w_t(i) \\leftarrow {\\hat w_t(i)\\gamma_t \\over \\sum_j \\hat w_t(i)\\gamma_t}$$ 结合权重插值（weighting interpolation）、内容寻址（content-based addressing）和地址寻址（location-based addressing）的寻址系统可以在三种补充模式下工作： 权重可以完全由 content-based addressing 来自主选择而不受 location system 的影响 由 content-based addressing 产生的权重可以被选择然后进行位移。这使得 focus 能够跳跃到通过内容寻址产生的地址附近而不是具体一个点。在计算方面，这使得 head 可以访问一个连续的数据块，然后访问这个块中的特定数据 来自上一个时刻的权重可以在没有任何 content-based addressing 的输入的情况下被旋转，以便权重可以以相同的时间间隔连续地访问一个地址序列（allows the weighting to iterate through a sequence of addresses by advancing the same distance at each time-step）。 Summaryinput 被 controller 加工产生 key vector 和一些中间变量，基于 key vector 和 memory bank 里的记忆向量的相似程度，用 attention 机制将 memory 检索结果转化成 vector 返回给读操作；基于 controller 加工后的外界输入，把一些信息写到 memory 里面，实现更新 memory 的效果（擦除+更新，都需要 weight vector 来确定 memory vector 的权重，权重由 content-base+location-base 产生，表示输入与记忆的相似程度，记忆与记忆的相似程度）。 NTM 架构有三个 free parameters： size of memory number of read and write heads range of allowed location shifts 但最重要的选择还是用作 controller 的网络模型。来探讨下 recurrent 和 feedforward network 的选择 递归网络像 LSTM 拥有自己的 internal memory，可以对矩阵中更大的存储器起到补充作用。想象 controller 是 CPU，memory 是 RAM，那么 RN 里的 hidden activations 相当于处理器的寄存器（rigisters），允许 controller 跨时间操作时可以共享信息 前馈网络 FN 可以通过每一时刻读写同一个记忆地址来模拟 RN，在网络操作上有更大透明度，读写 memory matrix 的模式比 RNN 的中间状态更容易解释。但局限是并行 read/write heads 的数量有限，在 NTM 计算时会成为瓶颈。单个 read head 在每个时刻只能对单个 memory vector 进行一元变换，而两个 read heads 可以进行二元向量变换，以此类推。递归控制器能够存储上一时刻的读出的向量，不会受到这个限制。 Differentiable Neural Computer(DNC)NTM 的第二个版本。更加复杂一些吧。 和 NTM 一样，controller 由若干个神经网络组成，负责和输入、输出交互，产生一些中间变量（又叫 interface parameter）。根据这些中间变量，可以进行 memory 的读写操作，注意这里是 先写再读！ 绿色的方块表示写操作，可以看到先是会释放某些区域的记忆，然后分配记忆，写入东西，完成后输出，表示 done，可以重新分配记忆了，然后交替，整个是动态分配的过程。 紫色的方块表示读操作，更新完 memory，会从更新过的 memory 里定位和读取信息。有多个互相独立的 read model，互相独立的来从 memory 里读取信息并拼到一起，可以从各个角度来衡量信息的有用程度。 记忆区的右边（d Memory usage and temporal links）有一个附加的链表，追踪上面的箭头能够“回想”最近输入和输出的过程。 和 Seq2seq 类比一下，图中 controller 指向自己的箭头其实相当于 RNN decoder里的 RNN state vector，黄线从 memory 到 controller 的路径其实相当于 attention 提取的 context vector。 Architecture 梳理一下，有三大部分： Controller 产生 interface parameters 和 output parameters$x_t=[x_t;r^1_{t-1};…;r^R_{t-1}]$$(\\xi t, v_t)=NNC([x_1;…;x_t];\\theta)$ 对 memory 的操作，先写再读Content-based writing and reading weightHistory-based writing weight =&gt; final writing weightsHistory-based reading weight =&gt; final reading weights Memory 结果（类比对话系统里的上下文 context vector）和 controller 产生的 $v_t$（类比RNN decoder 的 state vector）拼到一起产生最后的输出$y_t=W_r[r^1_t,…r^R_t]+v_t$ 完整的连续输入的结构图如下，上一时刻读的信息也会作为输入放到 controller 里做预测，也就是说除了 input，controller 还会用到历史信息。 Details下面说一下 memory 读写操作的细节。沿着下图走一遍，图中六角形部分都是控制器的输出也就是 interface parameter 1. Content-based weighting for memory write这一部分 $c^w_t$ 和 NMT.v1 相同。D 是相似度函数，可以取 cosine similarity; $\\beta$ 是 concentration parameter，表示 key strength，是大于 1 的 scalar $$C(M_{t-1}, k^w_t, \\beta^w_t)[i]={exp(D(k^w_t, M_{t-1}[i, ·])\\beta_t^w \\over \\sum_j exp(D(k^w_t, M_{t-1}[j,·])\\beta^w_t))}$$ 2. History-based write weighting(Dynamic memory allocation)对应 NTM 的 remove 和 add 操作。每一个存储单元都是一个等长 vector，里面有若干个 element，只要 element 没有全部被占用，就可以写入新数据。如果被完全占用了，也可以通过一定方法将存储单元释放。 Controller 有三种选择： 不写 写 &amp; 写到新分配的位置（未使用过的/最新释放的存储单元） 写 &amp; 写到内容相似且还没有被完全占用的存储单元也就是更新这个存储单元的信息 如果所有存储空间都用完了，那么控制器必须释放空间才可以进行写操作。每一个时刻的写操作完成后，位置信息会和 L 矩阵也就是 links of association 连接起来，记录信息存储的顺序。 memory retention vector: $\\psi_t = \\prod^R_{i=1}(1-f^i_t \\omega^{r,i}_{t-1})$$\\omega^{w,i}_{t-1}$ 是上一时刻的 write weights，$f^i_t$ 是 controller 产生的 free gates，决定最近读取的位置要不要被释放。i 是 read head 的 index。$\\psi_t \\in [0,1]$ 也就是 memory retention vector，表示每个位置上有多少信息被保留下来 usage vector: $u_t=(u_{t-1}+\\omega^w_{t-1}-(u_{t-1}⊙\\omega_{t-1}^w))⊙ \\psi_t$$u_t$ 是 t 时刻的 usage vector，衡量每一个 memory vector 最近被用到的程度，如果很久没用&amp;需要腾地方，就会优先把它给踢掉$u_t$ 被 $\\psi_t$ 限制，在 0-1 之间，⊙ 表示 element-wise 乘法 least used location: $\\phi_t=SortIndicesAscending(u_t)$升序排序，于是 $\\phi_t[1]$ 表示最少使用到的位置 allocation weighting: $a_t[\\phi_t[j]]=(1-u_t[\\phi_t[j]])\\prod^{j-1}_{i=1}u_t[\\phi_t[j]]$最近读取的 memory 在更新 memory 的时候有更大的权重$a_t$ 是 allocation weighting，提供写操作的新的位置，如果所有的 u 都是 1，那么 $a_t=0$，必须先释放存储空间才能够分配空间 3. Final write weightUsage attention 和 content attention 通过 gate 线性组合, gate 也是 interface parameter, 再做后续 filter。 $\\omega^w_t=g^w_t[g^a_ta_t+(1-g^a_t)c^w_t]$ $g^a_t$ 是线性组合的 allocation gate，$g^w_t$是 write gate，如果 write gate 是 0，那么啥都不写 $M_t=M_{t-1}⊙(E-\\omega^w_te^T_t)+\\omega^w_tv^T_t = M_{t-1}-M_{t-1}⊙\\omega^w_te^T_t+\\omega^w_tv^T_t$ Memory writes，改变 t-1 时刻的 memory bank 4. Content-based weighting for memory read$$C(M_t, k^{r,i}_t,\\beta^{r,i}_t)[k]={exp(D(k^{r,i}_t, M_t[k, ·])\\beta^{r,i}_t) \\over \\sum_j exp(D(k^{r,i}_t,M_t[j, ·])\\beta^{r,i}_t)}$$总共读 R 次（$R\\ge 1,$超参数），从更新过以后的 memory $M_t$ 里读信息 5. History-based reading weights通过有时间信息的历史记录（temporal links），和 content-based read 挑出来的 C，进一步挑选出不直接相关但历史上有间接联系的 memory vector。举个例子理解一下，t 时刻的 input 通过内容的相似程度定位到了第 5 个 memory vector，然后 L 矩阵通过写操作的历史记录，发现第 5 个 vector 和第 2，4，6 个 vector 非常相关，所以尽管 t 时刻的 input 和 vector 2，4，6 在这一时刻表面上不相关，但有了第 5 个 vector 作为中介找到了 2，4，6，就有了间接关系，这可以通过 f, b 挑选出来。 $p_0=0$$p_t=(1-\\sum^N_{i=1}\\omega^w_t[i])p_{t-1}+\\omega^w_t$$L_0[i,j]=0 \\ \\ \\forall i,j $$L_t[i,i]=0 \\ \\ \\forall i $$L_t[i,j]=(1-\\omega^w_t[i]-\\omega^w_t[j])L_{t-1}[i,j]+\\omega^w_t[i]p^w_{t-1}[j]$ $L_t[i,j]$: the degree to which location i was the location written to after location j,the rows and columns of Lt represent the weights of the temporal links going into and out from particular memory slots, respectively 每次修改存储空间时，链接矩阵都会更新，删除旧位置的链接，添加最后写入的位置的新链接。 从 L 中挑选： $b^i_t$ backward weighting$b^i_t=L^T_t\\omega^{r,i}_{t-1}$ $f^i_t$ forward weighting$f^i_t=L_t\\omega^{r,i}_{t-1}$ 这种 temporal links 特别适用于NLP的任务。比如一段文本以单词为单位输入喂给 DNC，每个单词输入下 memory 都会被更新，但根据 L 可以知道上一个单词都影响了哪些 memory，也就是能够去关注单词的时序关系，这对捕捉文本意义有重要作用。 6. Final read weighting $\\omega^{r,i}_t=\\pi^i_t[1]b^i_t+\\pi^i_t[2]c^{r,i}_t+\\pi^i_t[3]f^i_t$$\\pi^i_t$ 表示读的模式，如果 $\\pi^i_t[2]$ 占主导，那么只用 content lookup，如果 $\\pi^i_t[3]$ 占主导，那么就按 memory 写入的顺序来遍历，如果 $\\pi^i_t[1]$ 占主导，按 memory 写入顺序反向遍历 $r^i_t=M^T_t\\omega^{r,i}_t$Read from memory，三个 weight vector 加权相加得到最后的 weight vector，然后从更新过的 memory vector 把 memory 读出来加权平均返回给控制器 小结一下，对于读操作，控制器可以从多个位置读取记忆，可以基于内容读取，也可以基于 associative temporal links 读取（向前/向后以顺序或反序的方式回调依次读取写入的信息）。读取的信息可以用来生成问题答案或者在环境中采取的行为。 Otherscontroller 可以用简单的 RNN，复杂些的 LSTM，也可以用 RL。论文还举了一些 DNC 的应用例子，比如学会找最短路径、伦敦地铁的路径规划、家族树（回答 who is Freya’s maternal great uncle 这类问题）、移动块问题等。 DNC vs. NTMDNC 是 NTM 的第二版，它改进了 NTM 的寻址机制，去掉了 index shift，更好支持了对记忆的 allocate 和 de-allocate 的功能。具体来说表现在下面几个方面： No index shift based addressingNTM 是沿着磁带（或者说记忆）左右移动，而 DNC 则尝试基于输入直接在记忆中搜索给定的 vector Can ‘allocate’ and ‘deallocate’ memoryDNC 可以分配和释放记忆。NTM 不能保证多个存储单元之间互不重叠、互不干扰（=&gt; allocate a free space），也不能释放存储单元，这意味着不能重复使用存储单元，也就很难处理很长的序列（=&gt; free gates used for deallocation）另外，这种机制也很容易能将记忆中的某个区域标记为禁止访问，避免在以后意外地删除它们，这有助于优化 Remembers recent memory useNTM 中，序列信息只能通过连续位置的写操作来顺序保存，并回到 memory 起点将它们读出来。一旦写操作跳跃到一个很远的位置，那么跳跃前和跳跃后的存储顺序就丢失了，读操作是没办法获取的而 DNC 有一个 temporal link matrix 记录了写操作的顺序，也就是说 DNC 有某种形式的 temporal memory，在某个瞬时记忆下 DNC 可以回想起上一步做的事，以及上一步的上一步，以此类推，也就是可以遍历由它们需要做的事组成地一个链表 参考链接DeepMind DNC SlidesNeural Turing Machines: Perils and Promise","tags":"memory-networks"},{"title":"NLP笔记 - 多轮对话之对话管理(Dialog Management)","url":"/2018/01/03/NLP笔记 - 多轮对话之对话管理(Dialog Management)/","text":"开始涉猎多轮对话，这一篇想写一写对话管理（Dialog Management），感觉是个很庞大的工程，涉及的知识又多又杂，在这里只好挑重点做一个引导性的介绍，后续会逐个以单篇形式展开。–持续更新中– 放一张多轮语音对话流程图，理解下 DM 在整个对话流程中处于什么地位。 简单描述一下这个流程图常见的一种信息流动方式，首先是语音识别 ASR，产生语音识别结果也就是用户话语 $u_u$ ；语义解析模块 NLU 将 $u_u$ 映射成用户对话行为 $a_u$；对话管理模块 DM 选择需要执行的系统行为$a_m$；如果这个系统行为需要和用户交互，那么语言生成模块 NLG 会被触发，生成自然语言或者说是系统话语 $u_m$；最后，生成的语言由语音合成模块 TTS 朗读给用户听。 这一篇第一部分介绍下对话管理及重要的几个小知识点，第二部分介绍对话管理的一些方法，主要有三大类： Structure-based Approaches Key phrase reactive Tree and FSM … Principle-based Approaches Frame Information-State Plan … Statistical Approaches 这一类其实和上面两类有交叉…不过重点想提的是： Reinforcement Learning 方法不等于模型，这里只介绍一些重要概念，不会涉及模型细节。最后一部分会介绍一下 DM 设计工程上的一些 tips。 Dialog Management对话管理（Dialog Management, DM）控制着人机对话的过程，DM 根据对话历史信息，决定此刻对用户的反应。最常见的应用还是任务驱动的多轮对话，用户带着明确的目的如订餐、订票等，用户需求比较复杂，有很多限制条件，可能需要分多轮进行陈述，一方面，用户在对话过程中可以不断修改或完善自己的需求，另一方面，当用户的陈述的需求不够具体或明确的时候，机器也可以通过询问、澄清或确认来帮助用户找到满意的结果。 总的来说，对话管理的任务大致有下面一些： 对话状态维护（dialog state tracking, DST）维护 &amp; 更新对话状态t+1 时刻的对话状态 $s_{t+1}$，依赖于之前时刻 t 的状态 $s_t$，和之前时刻 t 的系统行为 $a_t$，以及当前时刻 t+1 对应的用户行为 $o_{t+1}$。可以写成 $s_{t+1} \\leftarrow s_t+a_t+o_{t+1}$ 生成系统决策（dialog policy）根据 DST 中的对话状态（DS），产生系统行为（dialog act），决定下一步做什么dialog act 可以表示观测到的用户输入（用户输入 -&gt; DA，就是 NLU 的过程），以及系统的反馈行为（DA -&gt; 系统反馈，就是 NLG 的过程）DA 的具体介绍将在 NLU 系列中展开 作为接口与后端/任务模型进行交互 提供语义表达的期望值（expectations for interpretation）interpretation: 用户输入的 internal representation，包括 speech recognition 和 parsing/semantic representation 的结果 本质上，任务驱动的对话管理实际就是一个决策过程，系统在对话过程中不断根据当前状态决定下一步应该采取的最优动作（如：提供结果，询问特定限制条件，澄清或确认需求…）从而最有效的辅助用户完成信息或服务获取的任务。 如图，DM 的输入就是用户输入的语义表达（或者说是用户行为，是 NLU 的输出）和当前对话状态，输出就是下一步的系统行为和更新的对话状态。这是一个循环往复不断流转直至完成任务的过程，其中，语义输入就是流转的动力，DM 的限制条件（即通过每个节点需要补充的信息/付出的代价）就是阻力，输入携带的语义信息越多，动力就越强；完成任务需要的信息越多，阻力就越强。 一个例子 实际上，DM 可能有更广泛的职责，比如融合更多的信息（业务+上下文），进行第三方服务的请求和结果处理等等。 Initiative对话引擎根据对话按对话由谁主导可以分为三种类型： 系统主导系统询问用户信息，用户回答，最终达到目标 用户主导用户主动提出问题或者诉求，系统回答问题或者满足用户的诉求 混合用户和系统在不同时刻交替主导对话过程，最终达到目标有两种类型，一是用户/系统转移任何时候都可以主导权，这种比较困难，二是根据 prompt type 来实现主导权的移交Prompts 又分为 open prompt（如 ‘How may I help you‘ 这种，用户可以回复任何内容 ）和 directive prompt（如 ‘Say yes to accept call, or no’ 这种，系统限制了用户的回复选择）。 Basic conceptsGround and Repair对话是对话双方共同的行为，双方必须不断地建立共同基础（common ground, Stalnaker, 1978），也就是双方都认可的事物的集合。共同基础可以通过听话人依靠（ground）或者确认（acknowledge）说话人的话段来实现。确认行为（acknowledgement）由弱到强的 5 种方法（Clark and Schaefer 1989）有：持续关注（continued attention），相关邻接贡献（relevant next contribution），确认（acknowledgement），表明（demonstration），展示（display）。 听话人可能会提供正向反馈（如确认等行为），也可能提供负向反馈（如拒绝理解/要求重复/要求 rephrase等），甚至是要求反馈（request feedback）。如果听话人也可以对说话人的语段存在疑惑，会发出一个修复请求（request for repair），如 123A: Why is that?B: Huh?A: Why is that? 还有的概念如 speech acts，discourse 这类，之前陆陆续续都介绍过一些了。 Challenges人的复杂性（complex）、随机性（random）和非理性化（illogical）的特点导致对话管理在应用场景下面临着各种各样的问题，包括但不仅限于： 模型描述能力与模型复杂度的权衡 用户对话偏离业务设计的路径如系统问用户导航目的地的时候，用户反问了一句某地天气情况 多轮对话的容错性如 3 轮对话的场景，用户已经完成 2 轮，第 3 轮由于ASR或者NLU错误，导致前功尽弃，这样用户体验就非常差 多场景的切换和恢复绝大多数业务并不是单一场景，场景的切换与恢复即能作为亮点，也能作为容错手段之一 降低交互变更难度，适应业务迅速变化 跨场景信息继承 Structure-based ApproachesKey Pharse Reactive Approaches本质上就是关键词匹配，通常是通过捕捉用户最后一句话的关键词/关键短语来进行回应，比较知名的两个应用是 ELIZA 和 AIML。AIML （人工智能标记语言），XML 格式，支持 ELIZA 的规则，并且更加灵活，能支持一定的上下文实现简单的多轮对话（利用 that），支持变量，支持按 topic 组织规则等。 123456789101112131415&lt;category&gt;&lt;pattern&gt;DO YOU KNOW WHO * IS&lt;/pattern&gt; &lt;template&gt;&lt;srai&gt;WHO IS &lt;star/&gt;&lt;/srai&gt;&lt;/template&gt; &lt;/category&gt;&lt;category&gt;&lt;pattern&gt;MOTHER&lt;/pattern&gt;&lt;template&gt; Tell me more about your family. &lt;/template&gt; &lt;/category&gt;&lt;category&gt;&lt;pattern&gt;YES&lt;/pattern&gt;&lt;that&gt;DO YOU LIKE MOVIES&lt;/that&gt; &lt;template&gt;What is your favorite movie?&lt;/template&gt; &lt;/category&gt; 附上自己改写的 aiml 地址，在原有基础上增添了一些功能： 支持 python3 支持中文 支持 * 扩展 Trees and FSM-based ApproachesTrees and FSM-based approach 通常把对话建模为通过树或者有限状态机（图结构）的路径。 相比于 simple reactive approach，这种方法融合了更多的上下文，能用一组有限的信息交换模板来完成对话的建模。这种方法适用于： 系统主导 需要从用户收集特定信息 用户对每个问题的回答在有限集合中 这里主要讲 FSM，把对话看做是在有限状态内跳转的过程，每个状态都有对应的动作和回复，如果能从开始节点顺利的流转到终止节点，任务就完成了。 FSM 的状态对应系统问用户的问题，弧线对应将采取的行为，依赖于用户回答。 FSM-based DM 的特点是： 人为定义对话流程 完全由系统主导，系统问，用户答 答非所问的情况直接忽略 建模简单，能清晰明了的把交互匹配到模型 难以扩展，很容易变得复杂 适用于简单任务，对简单信息获取很友好，难以处理复杂的问题 缺少灵活性，表达能力有限，输入受限，对话结构/流转路径受限 对特定领域要设计 task-specific FSM，简单的任务 FSM 可以比较轻松的搞定，但稍复杂的问题就困难了，毕竟要考虑对话中的各种可能组合，编写和维护都要细节导向，非常耗时。一旦要扩展 FSM，哪怕只是去 handle 一个新的 observation，都要考虑很多问题。实际中，通常会加入其它机制（如变量等）来扩展 FSM 的表达能力。 Principle-based ApproachesFrame-based ApproachesFrame-based approach 通过允许多条路径更灵活的获得信息的方法扩展了基于 FSM 的方法，它将对话建模成一个填槽的过程，槽就是多轮对话过程中将初步用户意图转化为明确用户指令所需要补全的信息。一个槽与任务处理中所需要获取的一种信息相对应。槽直接没有顺序，缺什么槽就向用户询问对应的信息。 Frame-based DM 包含下面一些要素： Frame： 是槽位的集合，定义了需要由用户提供什么信息 对话状态：记录了哪些槽位已经被填充 行为选择：下一步该做什么，填充什么槽位，还是进行何种操作行为选择可以按槽位填充/槽位加权填充，或者是利用本体选择 基于框架/模板的系统本质上是一个生成系统，不同类型的输入激发不同的生成规则，每个生成能够灵活的填入相应的模板。常常用于用户可能采取的行为相对有限、只希望用户在这些行为中进行少许转换的场合。 Frame-based DM 特点： 用户回答可以包含任何一个片段/全部的槽信息 系统来决定下一个行为 支持混合主导型系统 相对灵活的输入，支持多种输入/多种顺序 适用于相对复杂的信息获取 难以应对更复杂的情境 缺少层次 槽的更多信息可以参考填槽与多轮对话 | AI产品经理需要了解的AI技术概念 Agenda + Frame(CMU Communicator)Agenda + Frame(CMU Communicator) 对 frame model 进行了改进，有了层次结构，能应对更复杂的信息获取，支持话题切换、回退、退出。主要要素如下： product树的结构，能够反映为完成这个任务需要的所有信息的顺序相比于普通的 Tree and FSM approach，这里产品树（product tree）的创新在于它是动态的，可以在 session 中对树进行一系列操作比如加一个子树或者挪动子树 process agenda相当于任务的计划（plan）类似栈的结构（generalization of stack）是话题的有序列表（ordered list of topics）是 handler 的有序列表（list of handlers），handler 有优先级 handler产品树上的每个节点对应一个 handler，一个 handler 封装了一个 information item 从 product tree 从左到右、深度优先遍历生成 agenda 的顺序。当用户输入时，系统按照 agenda 中的顺序调用每个 handler，每个 handler 尝试解释并回应用户输入。handler 捕获到信息就把信息标记为 consumed，这保证了一个 information item 只能被一个 handler 消费。 input pass 完成后，如果用户输入不会直接导致特定的 handler 生成问题，那么系统将会进入 output pass，每个 handler 都有机会产生自己的 prompt（例如，departure date handler 可以要求用户出发日期）。 可以从 handler 返回代码中确定下一步，选择继续 current pass，还是退出 input pass 切换到 output pass，还是退出 current pass 并等待来自用户输入等。handler 也可以通过返回码声明自己为当前焦点（focus），这样这个 handler 就被提升到 agenda 的顶端。为了保留特定主题的上下文，这里使用 sub-tree promotion 的方法，handler 首先被提升到兄弟节点中最左边的节点，父节点同样以此方式提升。 系统还能处理产品树中节点之间的依赖关系。典型的依赖关系在父节点和子节点之间。通常父节点的值取决于其子节点。每个节点都维护一个依赖节点的列表，并且会通知依赖节点值的变化，然后依赖节点可以声明自己是无效的并成为当前对话的候选主题。 给一个例子，能够回应用户的显式/隐式话题转移（A1-A3, U11），也能够动态添加子树到现有的 agenda（A8-A10）。 具体还是看论文吧AN AGENDA-BASED DIALOG MANAGEMENT ARCHITECTURE FOR SPOKEN LANGUAGE SYSTEMS Information-State ApproachesInformation State Theories 提出的背景是： 很难去评估各种 DM 系统 理论和实践模型存在很大的 gap理论型模型有：logic-based, BDI, plan-based, attention/intention实践中模型大多数是 finite-state 或者 frame-based即使从理论模型出发，也有很多种实现方法 因此 Information State Models 作为对话建模的形式化理论，为工程化实现提供了理论指导，也为改进当前对话系统提供了大的方向。Information-state theory 的关键是识别对话中流转信息的 relevant aspects，以及这些成分是怎么被更新的，更新过程又是怎么被控制的。idea 其实比较简单，不过执行很复杂罢了。理论架构如下： 介绍下简单的一些要素：Statics Informational components包括上下文、内部驱动因子（internal motivating factors）e.g., QUD, common ground, beliefs, intentions, dialogue history, user models, etc. Formal representationsinformational components 的表示e.g., lists, records, DRSs,… Dynamics dialog moves会触发更新 information state 的行为的集合e.g., speech acts update rules更新 information state 的规则集合e.g., selection rules update strategy更新规则的选择策略，选择在给定时刻选用哪一条 update rules 意义在于可以遵循这一套理论体系来构建/分析/评价/改进对话系统。基于 information-state 的系统有： TrindiKit Systems– GoDiS (Larsson et al) – information state: Questions Under Discussion– MIDAS – DRS information state, first-order reasoning (Bos &amp;Gabsdil, 2000)– EDIS – PTT Information State, (Matheson et al 2000)– SRI Autoroute –Conversational Game Theory (Lewin 2000) Successor Toolkits– Dipper (Edinburgh)– Midiki (MITRE) Other IS approaches– Soar (USC virtual humans)– AT&amp;T MATCH system Plan-based Approaches一般指大名鼎鼎的 BDI (Belief, Desire, Intention) 模型。起源于三篇经典论文： Cohen and Perrault 1979 Perrault and Allen 1980 Allen and Perrault 1980 基本假设是，一个试图发现信息的行为人，能够利用标准的 plan 找到让听话人告诉说话人该信息的 plan。这就是 Cohen and Perrault 1979 提到的 AI Plan model，Perrault and Allen 1980 和 Allen and Perrault 1980 将 BDI 应用于理解，特别是间接言语语效的理解，本质上是对 Searle 1975 的 speech acts 给出了可计算的形式体系。 官方描述（Allen and Perrault 1980）： A has a goal to acquire certain information. This causes him to create a plan that involves asking B a question. B will hopefully possess the sought information. A then executes the plan, and thereby asks B the question. B will now receive the question and attempt to infer A’s plan. In the plan there might be goals that A cannot achieve without assistance. B can accept some of these obstacles as his own goals and create a plan to achieve them. B will then execute his plan and thereby respond to A’s question. 重要的概念都提到了，goals, actions, plan construction, plan inference。理解上有点绕，简单来说就是 agent 会捕捉对 internal state (beliefs) 有益的信息，然后这个 state 与 agent 当前目标（goals/desires）相结合，再然后计划（plan/intention）就会被选择并执行。对于 communicative agents 而言，plan 的行为就是单个的 speech acts。speech acts 可以是复合（composite）或原子（atomic）的，从而允许 agent 按照计划步骤传达复杂或简单的 conceptual utterance。 这里简单提一下重要的概念。 信念（Belief）基于谓词 KNOW，如果 A 相信 P 为真，那么用 B(A, P) 来表示 期望（Desire）基于谓词 WANT，如果 S 希望 P 为真（S 想要实现 P），那么用 WANT(S, P) 来表示，P 可以是一些行为的状态或者实现，W(S, ACT(H)) 表示 S 想让 H 来做 ACT Belief 和 WANT 的逻辑都是基于公理。最简单的是基于 action schema。每个 action 都有下面的参数集： 前提（precondition）为成功实施该行为必须为真的条件 效果（effect）成功实施该行为后变为真的条件 体（body）为实施该行为必须达到的部分有序的目标集（partially ordered goal states） 计划推理（Plan Recognition/Inference, PI）：根据 B 实施的行为，A 试图去推理 B 的计划的过程。 PI.AE Action-Effect Rule（行为-效果规则） PI.PA Precondition-Action Rule（前提-行为规则） PI.BA Body-Action Rule（体-行为规则） PI.KB Know-Desire Rule（知道-期望规则） E1.1 Extended Inference Rule（扩展推理规则） 计划构建（Plan construction）： 找到从当前状态（current state）达到目标状态（goal state）需要的行为序列（sequence of actions） Backward chaining，大抵是说，试图找到一个行为，如果这个行为实施了能够实现这个目标，且它的前提在初始状态已经得到满足，那么计划就完成了，但如果未得到满足，那么会把前提当做新的目标，试图满足前提，直到所有前提都得到满足。（find action with goal as effect then use preconditions of action as new goal, until no unsatisfied preconditions）backward chaining 在 NLP 笔记 - Meaning Representation Languages 中提到过。 还有个重要的概念是 speech acts，在 NLP 笔记 - Discourse Analysis 中提到过，之后会细讲。 更多见 Plan-based models of dialogue 值得一提的是，基于 logic 和基于 plan 的方法虽然有更强大更完备的功能，但实际场景中并不常用，大概是因为大部分的系统都是相对简单的单个领域，任务小且具体，并不需要复杂的推理。 Statistical ApproachesRL-Based Approaches前面提到的很多方法还是需要人工来定规则的（hand-crafted approaches），然而人很难预测所有可能的场景，这种方法也并不能重用，换个任务就需要从头再来。而一般的基于统计的方法又需要大量的数据。再者，对话系统的评估也需要花费很大的代价。这种情况下，强化学习的优势就凸显出来了。RL-Based DM 能够对系统理解用户输入的不确定性进行建模，让算法来自己学习最好的行为序列。首先利用 simulated user 模拟真实用户产生各种各样的行为（捕捉了真实用户行为的丰富性），然后由系统和 simulated user 进行交互，根据 reward function 奖励好的行为，惩罚坏的行为，优化行为序列。由于 simulated user 只用在少量的人机互动语料中训练，并没有大量数据的需求，不过 user simulation 也是个很难的任务就是了。 对话仿真的整体框架如下图： DM 设计一般在冷启动阶段，会先用规则方法打造一个 DM，快速上线并满足业务需求，收集数据之后再转换成模型。 DM 的设计理念： 完整性具备建模各种类型对话的能力（不仅仅是slot filling） 独立性当设计（变更）一个场景时，不需要考虑当前场景跳转到其他场景的情况 模块化一些常用的业务组件(如：确认，slot filling，翻页等)，能呈模块化复用(同时允许业务自定义内部的多种属性) DM 里可以有很多小的 dialogs，这些 dialogs 的特点是： 可以重用（reusable modules） 完成一个简单操作（Perform a single operation） 可以被其他 dialog 调用（callable from other dialogs） 可以是全局的（”global”） Global dialog 的特点是： 在 recognizer 能够匹配时 trigger 可以提供一些 conversation support，像是 help/cancel 这些全局功能 应对各种话题切换（Tangents） 通常只有一个 root dialog，在满足下面两个条件的情况下被唤醒 dialog stack 里没有其他的 dialog 剩余了 当前时刻 recognizer 并不能 trigger 其他的 dialog dialog stack 会存放目前已经被激活但还没完成的 dialog。dialog 一旦完成就会被 pop 出去。 参考链接：多轮对话 multi-turn dialog for task-oriented systemDialog Management in Bot FrameworkAN AGENDA-BASED DIALOG MANAGEMENT ARCHITECTURE FOR SPOKEN LANGUAGE SYSTEMSThe Information State Approach to Dialogue ManagementPlan-based models of dialogue对话管理的一些思考填槽与多轮对话 | AI产品经理需要了解的AI技术概念","tags":"nlp nlu dialog-management dm slot-filling fsm"},{"title":"论文笔记 - Learning to Remember Translation History with a Continuous Cache","url":"/2017/12/20/论文笔记 - Learning to Remember Translation History with a Continuous Cache/","text":"介绍一种 cache-like memory network。 涉及论文： Learning to Remember Translation History with a Continuous Cache 相关博客： NLP 笔记 - Neural Machine Translation 论文笔记 - Memory Networks 比较传统的 NMT 把文档当做一系列独立的句子来进行翻译，忽略了句子之间的关系，或者说是忽略了篇章信息，这样会带来两个问题： 一致性问题（inconsistency）如时态一致性问题，以及术语选择的一致性问题，这些通常都需要联系上下文/篇章信息 歧义问题（ambiguity）NMT 基本的翻译单位是词向量，也是通过 word-by-word 的方式产生翻译的。向量表示的泛化问题会导致歧义进一步放大，如机遇/挑战，教师/培训这些词在空间里比较靠近，很容易导致翻译错误 在 SMT 中，引入 cross-sentence 的作用对解决上面两个问题非常有效，因此 NMT 方面也有人做了一些尝试，比如说用分层 RNN 来总结前 K 个 source sentences 的语境信息（Wang et al. 2017a），或者用额外的 encoder 和 attention model 来动态选择聚焦前一个 source sentence 的某个部分 （Jean et al. 2017），这些方法有一定效果，但是都只考虑了单语的信息，没有用到目标端的信息，并且仍然是从 discrete lexicon 中产生 context，词级别的错误会继续传递下去，这在口语字幕的语料上表现的更为明显（不能得到多大改善）。另外，这两个模型计算量也很大，不利于 scale。 这篇论文用到了 cache-like memory networks 的思想，用一个额外的 cache model 把源端表示作为 KEY，目标端表示作为 VALUE，从 memory 里定位相关的信息，然后把相关信息也作为输入，翻译时能得到更多方面比如说时态的信息。这样的好处 一是可以规模化，通过 cache 获得更长的历史信息，二是因为用的是 internal representation （并且是 attention 后的片段信息）而不是单词，能缓解错误传播的问题，也考虑进了目标端的信息。 与 Standard NMT 的对比如下： 主要还是读取/写入 cache 的过程。 Reading from CacheKey Matchingcache lookup 最简单用点积来做，也可以加中间转换矩阵或者用 attention 方法，不过点积最简单高效，不用学新的参数也能学到相似度 $$P_m(c_i|c_t)={exp(c^T_tc_i)\\over \\sum^I_{i’=1}exp(c^T_tc_i’)}$$ $c_t$ 是 t step 的 attention context，$c_i$ 是 cache 里第 i 个位置的 representation，I 是 cache slots 的总量 Value Reading得到概率分布后对每个 value 进行加权 $$m_t=\\sum_{(c_i, s_i) \\in cache} P_m(c_i|c_t)s_i$$ $P_m(c_i|c_t)$ 可以解释为给定 source side context $c_t$，从 cache 里检索得到相似的 target-side info $m_t$，答案是和过去产生的相似的 target words 相关的语境 Representation Combining用原始的 decoder state $s_t$ 和当前的 output vector $m_t$ 进行线性组合，相当于 GRU 里的 update gate 其中 lambda 是一个动态调节的 weight vector，在每个 decoding step 都要重新计算 $$\\lambda_t = \\sigma (Us_t + Vc_t+Wm_t)$$ U(dxd), V(dxl), W(dxd) 是参数矩阵 Writing to Cache在整个句子翻译完后，再写入 cache，写入 cache 的内容包括 generated translation sentence {$y_1,…,y_t…,y_T$} attention vector sequence {$c_1,…,c_t,…c_T$} decoder state sequence {$s_1,…,s_t,…,s_T$} 如果 $y_t$ 在 cache 里不存在，那么会选择一个空的 slot 或者覆盖一个 LRU(least recently used) slot，key 是 $c_t$，value 是 $s_t$，indicator 是 $y_t$ 如果 $y_t$ 已经存在，那么更新 key, value，$k_i=(k_i+c_t)/2, \\ v_i=(v_i+s_t)/2$，像是一个 exponential decay，每一次更新之前的 key, value 都会减半，基本逻辑是最近的历史会有更高的重要性。通过可视化图可以看一下效果： 小结理解下来还是非常简单的。亮点还是 cache 的设计，一方面用到了历史信息，另一方面用到了源端和目标端的信息，并且是单词粒度之上的信息（attention context vector）。","tags":"memory-networks"},{"title":"论文笔记 - Memory Networks","url":"/2017/12/04/论文笔记 - Memory Networks/","text":"Memory Networks 相关笔记。 这一篇会覆盖下面三个版本的 Memory Networks Memory Network with strong supervision End-to-End Memory Network Dynamic Memory Network 涉及下面一些论文： Memory Networks (2015) End-To-End Memory Networks (2015) Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (2016) Dynamic Memory Networks for Visual and Textual Question Answering (2016) 首先要明确的是，Memory Networks 只是一种思想或者说一个框架，像一个 base class，里面的各个 module 都可以自己定制。其中基本的一些思路： 分层 RNN 的 context RNN与 context RNN 类似，Memory Network 同样以句子为单位来提取、保存语境信息 Attention 原理使用多个 state vector 来保存信息，并从中寻找有用的记忆，而不是寄希望于 final state 存储的信息 Incorporate reasoning with attention over memory(RAM): Memory Network使用记忆以及记忆上的 attention 来做推理 Memory Networks (2015)对应论文：Memory Networks (2015) Memory Networks 提出的基本动机是我们需要 长期记忆（long-term memory）来保存问答的知识或者聊天的语境信息，而现有的 RNN 在长期记忆中表现并没有那么好。 组件4 个重要组件： I: input feature map把输入映射为特征向量（input -&gt; feature representation）通常以句子为单位，一个句子对应一个向量 G: generalization使用新的输入数据更新 memories O: output给定新的输入和现有的 memory state，在特征空间里产生输出类比 attention RNN decoder 产生 outputs/logits R: response将输出转化为自然语言 流程 上面的 4 个 component 就对应了整个工作流程： 把输入 x 映射为特征向量 I(x)可以选择多种特征，如 bag of words, RNN encoder states, etc.如果用 embedding model 来表达文本的话，一个郁闷的地方是 embdding 的参数在不断变化，所以训练时保存的 vector 也要变化……当然这在测试时就成了优势，因为测试时 embedding 参数就固定啦 更新 memory mi，$m_i = G(m_i, I(x), m), \\forall i.$将输入句子的特征 x 保存到下一个合适的地址 $m_n$，可以简单的寻找下一个空闲地址，也可以使用新的信息更新之前的记忆简单的函数如 $m_{H(x)}=I(x)$，H(x) 是一个寻址函数（slot choosing function），G 更新的是 m 的 index，可以直接把新的输入 I(x) 保存到下一个空闲的地址 $m_n$，并不更新原有的 memory，当然更复杂的 G 函数可以去更新更早的 memory 甚至是所有的 memory 给定新的输入和 memory，计算 output feature o: o=O(I(x),m)Addressing，寻址，给定 query Q，在 memory 里寻找相关的包含答案的记忆$qUU^Tm$： 问题 q 和事实 m 的相关程度，当然这里的 q，m 都是特征向量，可以用同一套参数也可以用不同的参数U：bilinear regression 参数，相关事实的 $qUU^Tm_{true}$ 分数高于不相关事实的分数 $qUU^Tm_{random}$n 条记忆就有 n 条 bilinear regression score回答一个问题可能需要寻找多个相关事实，先根据 query 定位到第一条最相关的记忆，再用第一条 fact 和 query 通过加总或拼接等方式得到 u1 然后一起定位第二条$o_1 = O_1(q,m) = argmax_{i=1,…N} \\ s_o(q, m_i)$$o_2 = O_2(q,m) = argmax_{i=1,…N} \\ s_o([q, o_1], m_i)$ 对 output feature o 进行解码，得到最后的 response: r=R(o)将 output 转化为自然语言的 response$r = argmax_{w \\in W} \\ s_R([q, o_1, o_2], w)$$s_R(x,y)=xUU^Ty$可以挑选并返回一个单词比如说 playground在词汇表上做一个 softmax 然后选最有可能出现的单词做 response，也可以使用 RNNLM 产生一个包含回复信息的句子，不过要求训练数据的答案就是完整的句子，比如说 football is on the playground Huge Memory 问题如果 memory 太大怎么办？ 可以按 entity 或者 topic 来存储 memory，这样 G 就不用在整个 memories 上操作了 如果 memory 满了，可以引入 forgetting 机制，替换掉没那么有用的 memory，H 函数可以计算每个 memory 的分数，然后重写 还可以对单词进行 hashing，或者对 word embedding 进行聚类，总之是把输入 I(x) 放到一个或多个 bucket 里面，然后只对相同 bucket 里的 memory 计算分数 损失函数损失函数如下，选定 2 条 supporting fact (k=2)，response 是单词的情况： (6) 有没有挑选出正确的第一句话(7) 正确挑选出了第一句话后能不能正确挑出第二句话(6)+(7) 合起来就是能不能挑选出正确的语境，用来训练 attention 参数(8) 把正确的 supporting fact 作为输入，能不能挑选出正确的答案，来训练 response 参数 Performance在 bAbI QA 部分数据集上的结果 部分 QA 实例： 局限 需要很强的标记信息bAbI 提供了 supporting fact 的 ID，但对大多数 QA 数据而言，并不存在明确的 supporting fact 标记 Loss2 无法 backpropagate 到模型的左边部分，BP 过程到 m 就停了，并不能 end-to-end 进行训练这相当于一个链状的贝叶斯网络，考虑 A-&gt;B-&gt;C 的有向图，B 对应 m，B 不确定的时候，C 依赖于 A，但是当 B 确定的时候，C 就不依赖于 A 了。 也就是说，在给定 m 的情况下，loss2 和前面的参数是独立的，所以优化 loss2 并不能优化左边的参数 End-to-End learning对应论文：End-To-End Memory Networks (2015) End-to-End learning 用了 soft attention 来估计每一个 supporting fact 的相关程度，实现了端到端的 BP 过程。 Single Layer一张图就解决了： 模型输入: Input: $x_1, …, x_n$，会被存储到 memory 中 Query: q Answer: a 具体过程（以单层为例）： 映射到特征空间{$x_i$} $\\xrightarrow{A}$ {$m_i$}$q \\xrightarrow{B} u$ 计算 attention，得到 query 和 memory 的匹配度，有多少个 memory 就有多少个 $p_i$$p_i = Softmax(u^Tm_i)$ 得到 context vector$o = \\sum_ip_ic_i$和 Memory Networks with Strong Supervision 版本不同，这里的 output 是加权平均而不是一个 argmax context vector 和 query 一起，预测最后答案，通常是一个单词$\\hat a=Softmax(W(o+u))$ 对 $\\hat a$ 进行解码，得到自然语言的 response$\\hat a \\xrightarrow{C} a$ 其中，A: intput embedding matrixC: output embedding matrixW: answer prediction matrixB: question embedding matrix 损失函数是交叉熵，用 SGD 训练。 Multi-hop Architecture多层结构（K hops）也很简单，相当于做多次 addressing/多次 attention，每次 focus 在不同的 memory 上，不过在第 k+1 次 attention 时 query 的表示需要把之前的 context vector 和 query 拼起来，其他过程几乎不变。$u^{k+1}=u^k + o^k$ 一些技术细节通常来说 encoding 和 decoding 的词向量参数是不一样的，因为一个是单词-词向量，一个是 隐状态-词向量。 Adjacent前一层的输出是这一层的输入$A^{k+1}=C^k$$W^T=C^L$$B=A^1$ Layer-wise(RNN-like)不同层之间用同样的 embedding$A^1=A^2=…=A^K$$C^1=C^2=…=C^K$可以在 hop 之间加一层线性变换 H 来更新 $\\mu$$u^{k+1}=Hu^k+o^k$ Dynamic Memory Networks对应论文：Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (2016) Input Module这一部分像是一个 semantic memory。输入可以是一个/多个句子，一篇/几篇文章，包含语境信息和知识库等，使用 RNN 进行 encoding，每一个句子编码成固定维度的 state vector。具体做法是把句子拼到一起（每个句子结尾加标记符 EOS），用 GRU-RNN 进行编码，如果是单个句子，就输出每个词的 hidden state；如果是多个句子，就输出每个句子 EOS 标记对应的 hidden state，其实相当于分层 RNN 的下面一层。 $$h_t=GRU(L[w_t], h_{t-1})$$ $L[w_t] $ 是 word embedding。 Question Module输入是 question 对应的词序列，同样用 GRU-RNN 进行编码。 $$q_t=GRU([L[w_t^Q], q_{t-1})$$ 同样的，L 是词向量参数，和 input module 的 L 相同。输出是 final hidden state Episodic Memory Module由 internal memory, attention mechansim, memory update mechanism 组成。 输入是 input module 和 question module 的输出。 把 input module 中每个句子的表达（fact representation c）放到 episodic memory module 里做推理，使用 attention 原理从 input module 中提取相关信息，同样有 multi-hop architecture。 Attention Mechanism觉得论文里的 attention mechanism 和 memory update mechanism 描述的有点问题，个人以为 attention mechanism 的目的还是生成 context vector，memory update mechanism 的目的是更新 memory，所以把部分公式按自己的理解移动了下，便于理解。 计算 query 和 fact 的分数，query 和上一个 memory $m^{i-1}$ 作为输入产生输出 episode $e^i$。要注意的是，End-to-End MemNN 的 attention 用的是 linear regression，DMN 用的是 gating function，一个两层的前向神经网络。 在每一轮迭代中，都有输入： $c_t$（input module 中第 t 个位置的 fact vector) 上一轮迭代得到的 memory $m_{i-1}$ question q 利用 gating function 计算第 t 个位置的得分 $g^i_t=G(c_t, m_{i-1}, q)$。G 是一个两层的前向神经网络的 score function，不过描述 input, memory, question 相似度的 feature vector z(c,m,p) 是人工定义的，这也成为了之后 DMN+ 的一个优化点。 计算完每一次迭代每一个位置的分数后，来更新 episode $e^i$，或者说产生 context vector。输入是 $c_1, …, c_{T_C}$，和它们的 gate score $g^i_t$。 $$ h^i_t=g^i_tGRU(c_t, h^i_{t-1})+(1-g^i_t)h^i_{t-1}$$ $$e^i=h^i_{T_C}$$ 总结一下，这部分 attention mechanism 的目的是生成 episode $e^i$，$e^i$ 是第 t 轮迭代的所有相关 input 信息的 summary。与 End-to-End MemNN 不同的是，End-to-End 用了 soft attention，也就是加权和来计算 context，而这里用了 GRU。 Memory Update Mechanism上一步算的 episode $e^i$ 以及上一轮迭代的 memory $m^{i-1}$ 作为输入 来更新 episodic memory $m^i$。 $$m^i=GRU(e^i, m^{i-1})$$ 输出是最后一次迭代的 $m=m^{T_M}$ End-to-End MemNN 的 memory update 过程里，第 k+1 次 query vector 直接是上一个 context vector 和 query 的拼接，$u^{k+1}=u^k + o^k$。而 DMN 里，采用了 RNN 做非线性映射，用 episode $e^i$ 和上一个 memory $m^{i-1}$ 来更新 episodic memory，其 GRU 的初始状态包含了 question 信息，$m^0=q$。 Episodic Memory Module 需要一个停止迭代的信号。一般可以在输入中加入一个特殊的 end-of-passes 的信号，如果 gate 选中了该特殊信号，就停止迭代。对于没有显性监督的数据集，可以设一个迭代的最大值。 总结一下，这部分 memory update mechanism 的目的是生成 t 时刻的 episode memory $m^t$，最后一个 pass 的$m^T$ 将包含用于回答问题 q 的所有信息。 Example Understanding来用例子解释下 Episodic Memory Module 上面那张图，question 是 where is the football? 第一次迭代找到的是第 7 个句子，John put down the football，第二次找到第 6 个句子 John went to the hallway，第三次找到第 2 个句子 John moved to the bedroom。 多次迭代第一次找到的是字面上最相关的 context，然后一步步迭代会逐渐定位到真正语义相关的 context，这感觉上就是一个推理的过程。 Answer Module使用了 GRU-RNN 作为 decoder。输入是 question module 的输出 q 和上一时刻的 hidden state $a_{t-1}$，初始状态是episode memory module 的输出 $a_0=m^{T_M}$ $$ \\begin{aligned} y_t=Softmax(W^{(a)}a_t) \\\\ a_t=GRU([y_{t-1}, q], a_{t-1}) \\\\ \\end{aligned}$$ 训练使用 cross-entroy 作为目标函数。如果数据集有 gate 的监督数据，还可以将 gate 的 cross-entroy 加到总的 cost上去，一起训练。训练直接使用 backpropagation 和 gradient descent 就可以。 小结总的来说，DMN 在 addressing，memory 提取，query/memory update 部分都用了 DL 手段，相比于 End-to-End MemNN 更为复杂。 DMN+对应论文：Dynamic Memory Networks for Visual and Textual Question Answering (2016) DMN 存在的两个问题： 输入模块只考虑了过去信息，没考虑到将来信息 只用 word level 的 GRU，很难记忆远距离 supporting sentences 之间的信息 这一部分重点讲与 DMN 不同的地方。 Input ModuleDMN+ 把 single GRU 替换成了类似 hierarchical RNN 结构，一个 sentence reader 得到每个句子的 embedding，一个 input infusion layer 把每个句子的 embedding 放入另一个 GRU 中，得到 context 信息，来解决句子远距离依赖的问题。HRED 相关思路见 论文笔记 - HRED 与 VHRED。这里还做了一些微调，sentence reader 用的是 positional encoding，input fusion layer 用了双向 GRU，兼顾了过去和未来的信息。 用 positional encoding 的原因是在这里用 GRU/LSTM 编码句子计算量大而且容易过拟合（毕竟 bAbI 的单词量很小就几十个单词。。），这种方法反而更好。 除了处理文本信息，作者也提出了图像信息的方案，CNN+RNN，把局部位置的图像信息当做 sentence 处理，在这不多介绍。 Episodic Memory Module Attention Mechanism仍然是人工构造特征向量来计算 attention，但与之前版本的 DMN 相比更为简化，省去了两项含有参数的部分，减少了计算量。另外与 DMN 不同的是，gate 值不是简单的二层前馈网络的结果，而是接着计算了一个 sofmax 评分向量。 也就是说，从公式上看，相对于 DMN，式 8 更为简洁，式 9 不变（结果就是 DMN 的 gate 值），增加了式 10。 进行到下一步关于 context vector 的计算，两种方案，一种是 soft attention，简单的加权求和，另一种是 attention based GRU。 AttnGRU 考虑了输入 facts 的位置和顺序信息（position and ordering），或者说是时序信息。在得到 attenion 后，把 attention 作为 gate，如上图，把传统 GRU 中的 update gate $u_i$ 替换成了 attention 的输出 $g^t_i$，这样 gate 就包含了 question 和前一个 episode memory 的知识，更好的决定了把多少 state 信息传递给下一个 RNN cell。同时这也大大简化了 DMN 版本的 context 计算。 $\\hat h$ 是更新的 state，$h_{i-1}$ 是传入的上一时刻的 state，$g^t_i$ 是 attention value，是一个由 softmax 产生的标量（scalar）而不是 sigmoid 激活产生的 vector $u_i \\in R^{n_H}$，context vector 是 GRU 的 final hidden state。 AttnGRU 要优于 weighted sum，因为使用了一些时间上的关系，比如小明在操场，小明回了家，小明进了卧室，这些事实实际上有先后关系，而 weighted sum 不一定能反映这种时序关系。 Memory Update MechanismDMN 中 memory 更新采用以 q 向量为初始隐层状态的 GRU 进行更新，用同一套权重，这里替换成了一层 ReLU 层，实际上简化了模型。 $$m^t = ReLU(W^t[m^{t-1};c^t;q]+b)$$ 其中 ; 表示拼接，这能进一步提高近 0.5% 的准确率。 Performance最后上一个不同模型的 performance 比较图。","tags":"memory-networks"},{"title":"机器学习策略(Andrew Ng. DL 笔记)","url":"/2017/11/26/机器学习策略(Andrew Ng. DL 笔记)/","text":"Andrew Ng. Deep Learning Course 3 Structuring Machine Learning Projects 的重点笔记。 常用策略及考虑问题常用的 ML 策略： 收集更多数据（collect more data） 收集更多样化的训练集（collect more diverse training set） 梯度下降训练更长时间（train algorithm longer with gradient descent） 尝试 Adam 算法（try Adam instead of gradient descent） 尝试更大的网路（try bigger network） 尝试小一点的网络（try smaller network） 尝试 dropout（try dropout） 加 L2 正则（add L2 regularization） 改善网络结构（network architecture） 激活函数（activation functions） 隐藏单元数量（number of hidden units） … 要考虑的几个问题： 训练集上拟合良好 fit training set well on cost function 训练开发集上拟合良好 fit training-dev set well on cost function在训练集和开发/测试集来自不同分布时考虑 开发集上拟合良好 fit dev set well on cost function 测试集上拟合良好 fit test set well on cost function 现实世界中表现良好 performs well in real world 另外，调优要注意的是，尽量用 正交化（Orthogonalization） 的手段，比如说 early stopping 其实不是一个优先的选择，因为它不那么正交化，会同时影响模型对训练集的拟合以及开发集的表现，同时影响了两件事情，对误差分析造成干扰。 评价指标单实数评价指标（Using a single number evaluation metric）用单实数评价指标，能够提高比较各种模型的效率，便于优化模型。 一个简单的例子是用 precision 和 recall，我们知道二者不可兼得，也就是比较哪个模型好的时候我们会发现 A 的 precision 高，B 的 recall 高，选哪个呢？这时候不妨引入 F1 来综合 precision 和 recall。 满足和优化指标如果有多个评价指标，可以选择线性组合，如 cost = accuracy - β*time，也可以选其中一个为 optimizing metric，其他为 satisfying metrics。 例子：1234分类器 | 准确率 | 耗时 A | 90% | 80ms B | 92% | 95ms C | 95% | 1500ms 我们更关心准确率，所以准确率是优化目标，同时希望耗时不要太长，所以运行时间是满足指标，最后整体指标就是在 100ms 运行时间的条件下准确率的大小。12maximize accuracysubject to running time &lt;= 100ms 什么时候改变评价指标？模型在 metric + dev/test 上表现很好，但是在实际应用中表现不好的时候，就应该考虑改变 metric 了。 假设现在有两个算法: 算法 A: 喵咪图片识别误差是 3%，但是会把少儿不宜的图片分类为猫 算法 B：误差是 5%，但是不会给用户推送不健康的图片 我们的 dev + metric 偏好 A，但我们的用户偏好 B，两者存在分歧，这时我们就需要改变评价指标了。根据上面的例子，假设原来的评价指标是： 那么现在可以给“把少儿不宜的图片分类为猫”这个错误一个大的惩罚权重，当然前提是先把这些少儿不宜的图片标注好。 训练/开发/测试集机器学习通常会把数据集分为训练/开发/测试集，这一篇讲一讲这三个子集扮演的角色。 最重要的一点是：dev set + single metric =&gt; target（瞄准的目标） 开发集和测试集的选择通常是现实中希望去处理的数据，很重要的一点是 开发集和测试集必须服从同一分布。举个例子，复习考试，训练集是复习资料，开发集像是考试前的模拟试卷，测试集则是真实考卷，我们最终目标是在真实考卷（测试集）中取得好成绩，准备过程中优化的是模拟试题（开发集）上的成绩，而复习资料（训练集）的选择会影响我们逼近这个目标有多快。而如果开发集和测试集来自不同分布，比如说在英语模拟试卷上考了 99 分，但最后你去参加了语文考试，这不是白复习白训练了么~ 训练/开发/测试集的大小之前传统 ML 时代数据集比较小， 一般 &lt; 10,000，所以 train/dev/test 的划分通常是 60%/20%/20%，而现在的数据量很大，动辄百万级，划分 40% 的数据处理做开发/测试集显然是浪费，所以比例可以是 98%/1%/1%。 可避免偏差 available bias 和Human-level performance Humans error 与 Training Error之间的差距是 Avoidable bias，Training Error 与 Dev Error之间的差距是 Variance，提到过好多次啦，具体见 会议笔记 - Nuts and Bolts of Applying Deep Learning，这里简单附个图吧。 误差分析误差分析 的作用在于弄清楚误差最主要来自哪个部分，然后给未来的工作指明优化方向，便于解决主要矛盾，节省时间。 还是猫分类器的例子，假设我们分析模型的预测结果后发现，预测错误的数据中有一部分狗的图片被错误标成了猫。这时可能会想着设计一些处理狗的特征/分类的算法功能来提高猫分类器。然而，假如 100 个错误标记的开发集样本中，只有 5 个是狗，那么这意味着你针对狗的算法提高最终也只能优化误差的 5%，比如原来误差是 10%，最好的情况也只是优化到 9.5%，这是优化上限。 把误差的来源以及在总误差的占比列个表统计，就能清楚的发现解决哪类误差对模型优化帮助最大。这个过程中可能会发现新的错误类型，比如滤镜导致的误差。 统计完成后根据误差占比、问题难度、团队的时间精力，来选择其中优先级高的几个进行优化。 如果训练数据中有一些标记错误的例子怎么办？ 如果这种误差是 随机误差，人没有注意而随机产生的，那么不用花太多时间修复它们，只要数据集足够大，对最后的结果不会有太大影响，因为深度学习算法对随机误差有一定健壮性（robustness）。 但如果这种误差是 系统性误差，比如把把所有白色的狗都标注成了猫，那么问题就大了，学习之后所有白色的狗都会被分类成猫，这就需要重新标记了。 如果开发/测试集中有一些标记错误的例子怎么办？在误差分析中加一列 incorrectly labeled，然后看是否值得修正这些标记错误的例子 如果人工错误标记引起的错误样本比例是 0.6%，而总体开发集误差是 10%，那么应该集中精力解决剩下的 9.4%，而如果总体开发集误差是 2%，那么就应该考虑去纠正这些人为错误了。 但要注意的是，不管要不要纠正人为误差，都要同时作用在开发集和测试集上，确保两者服从同一分布。同时，也可以考虑再次检查那些分类正确的例子，因为本来 no 的例子可能被标记成了 yes，不过正常情况下判断错的次数比判断对的次数要少的多，所以检查这部分数据花的时间也长的多。 训练/测试集来自不同分布如果训练集的分布和开发/测试集不一样怎么办？ 这种情况并不少见。比如说，我们有网上爬取的猫的图片 20w，但只有用户在手机 APP 上传的图片 1w。 这时候，可能会想到把这 21w 条数据 shuffle 然后来划分，这样的好处是训练/开发/测试集来自同一分布，但是！你会发现开发/测试集上的很多图片都来自网页下载，这并不是我们真心关心的数据分布，也就是说，只有一小部分的数据是我们的模型真心要瞄准、要优化的目标，而实际上我们大部分精力都在优化网页下载的图片！ 再回顾一下核心思想，开发集/测试集是真正关心的要优化的目标数据。所以更恰当的做法是，把手机上传的一半图片 5k 条划给训练集，剩下的 5k 条全部划分为开发/测试集。 要注意的是，训练/测试集来自不同分布会对 方差/偏差分析 造成影响，因为这不再是正交化的分析了。比如说 training error 1% dev error 10% 如果训练集和开发集来自同一分布，很简单，这是出现了高方差的问题。但如果训练集和开发集来自不同的分布，那么可能这里就不是高方差的问题了，造成这种情况的原因有两种： 算法看不到开发集数据，难以泛化 训练集和开发集来自不同的分布 我们需要知道哪个因素影响更大，才能判断是不是高方差的原因。这时需要定义一个新的数据集 training-dev set，通过随机打散训练集，分出一部分训练集和开发集一起作为训练-开发集，这样的话，training-dev set 和 training set 来自同一分布，同时 trainging-dev set 和 dev/test set 也来自同一分布。 现在只在训练集上训练模型 training error 1% training-dev error 9% dev error 10% 这就是方差问题，模型泛化能力差。 training error 1% training-dev error1.5% dev error10% 这时候就是 数据不匹配问题（data mismatch problem ）了。 也就是说，当训练集和开发/测试集来自不同分布的时候，我们需要考虑下面 5 种 error： human error: 0% training error: 10% training-dev error: 11% dev error: 20% test error: 20% 这个例子就是 高方差+数据不匹配 问题。 如果误差分析显示有数据不匹配的问题该怎么办 可以人工做误差分析，了解训练集和开发测试集的差异 收集更多与开发集、测试集相似的训练数据，人工数据合成比如 clear audio + car noise =&gt; synthesized in-car audio","tags":"deep-learning 过拟合 overfitting"},{"title":"论文笔记 - HRED 与 VHRED","url":"/2017/11/17/论文笔记 - HRED 与 VHRED/","text":"介绍一下经典的 HRED 和 VHRED。 主要涉及到下面几篇论文 Building end-to-end dialogue systems using generative hierarchical neural network models A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues Generating Sentences From a Continuous Spaces motivation HREDHRED 在之前经典的端到端聊天模型 提到过，这里拎出来再具体分析一下。 传统 Seq2Seq 在对话任务上对上下文依赖考虑有限，Building end-to-end dialogue systems using generative hierarchical neural network models 论文提出了一种 分层 RNN 结构 - HRED（Hierarchical Recurrent Encoder-Decoder），能同时对句子和对话语境（上下文）进行建模，来实现多轮对话。 先来看一下如果不使用分层 RNN，在传统 Seq2Seq 模型基础上，如果我们想得到 context 信息应该怎么做。 第一个想法是将上一个句子的 final state 作为下一个句子的 initial state，然后将句子信息不断传递下去，这样的话 context vector 里的信息会在 propagation 的过程中会被新句子的词语逐步稀释，对信息/梯度的传播极不友好。 因此为了让信息更好的传递，我们可能会考虑把 final state 传递到下一个句子的 last state，而不是 initial state，然后用拼接或者非线性的方法来表达之前的和当前的句子信息。 更干脆的，直接将语境中的多个 utterance vector 提取出来再用一个 RNN 来处理，捕捉 context 信息，这就有了分层 RNN。 简单来说，HRED 在传统 encoder-decoder 模型上，额外增加了一个 encoder，相比于普通的 RNN-LM 来说，考虑了 turn-taking nature，能够对上下文进行建模，减少了相邻句子间的计算步骤，有助于信息/梯度的传播，从而实现多轮对话。整个过程有下面三个阶段： encoder RNN第一个 encoder 和标准的 seq2seq 相同，将一句话编码到固定长度的 utterance vector，也就是 RNN 的 last hidden stateencoder RNN 或者说 utterance RNN 记忆的是对话的细节 context RNNn 个句子的 utterance vector 作为第二个 encoder 也就是 context-level encoder 各个时间上的的输入，对应长度为 n 的 sequence，产生一个 context vector 实现对语境的编码，也就是 RNN 的 output (注意这里不是 last hidden state)context RNN 记忆的是更为全局的语义信息 decoder RNN上一个句子的 utterance vector 作为 response 的初始状态，目前为止产生的 context vector 和上一个单词的 word embedding 拼接作为 decoder 的输入 然而 HRED 相对于传统的 Seq2Seq 模型的提高并不明显，bootstrapping 的作用更加明显。一方面可以用 pre-trained word embedding，另一方面可以使用其他 NLP 任务的数据预训练我们的模型，使得模型的参数预先学到一些对自然语言的理解，然后再来学习聊天任务。 VHRED先简单看一下 auto-encoder 的两个变体 dAE 和 VAE。 Denoising auto-encoder(dAE) 在输入数据引入一些随机噪声，要求 auto-encoder 去重构加噪声之前的原始观测值，来增加模型鲁棒性，避免过拟合。 而 Variational Autoencoder(VAE) 则是在中间层（hidden layer）引入噪音，来重构输入数据，因此 auto-encoder 出来的样本具有更高的全局性。 VHRED(Latent Variable Hierarchical Recurrent Encoder-Decoder Model)，就是在 HRED 基础上引入了 VAE 的思想，不同的是在 reconstruction 时生成的是下一个 utterance 而不是原来的 input。 VHRED 是为了解决 RNNLM 和 HRED 很难产生有意义的、高质量的回复而提出的。传统 Seq2Seq 倾向于产生短的安全回答（safe response），因为它有确定性的编码和解码过程，着重拟合具体、有限的回复样本，缺少对 response 语义信息的理解。另外 decoder 时两个目标，一是生成下一个 token，二是占据控制真实输出路径的 embedding space 的一个位置，来影响之后 token 的生成，而由于梯度衰减的影响，模型会更聚焦第一个目标，response 的产生更容易限于 token level，尤其对于 high-entropy 的句子，模型更偏好短期预测而不是长期预测，所以模型很难产生长的、高质量的回复。 VHRED 针对这个问题引入了全局（语义层面）的随机因素，一是能增强模型的 robustness，二是能捕捉 high level concepts。Latent variable 使得 response 不再和一个/几个固定的句子绑定，鼓励了回复的多样性。 和 HRED 不同的是，VHRED 在第二个 context RNN 产生 context vector c 后，由 c sample 了一些高斯随机变量 z（latent variable），期望值和标准差由 c 决定（前向网络+矩阵乘法得到 $\\mu$，+矩阵乘法和 softplus 得到 $\\Sigma$），高斯变量和 context vector 拼接就得到了包含全局噪声的 vector，作为每个时间的观测值，和 query vector 一起放到 decoder 里产生 response。 训练时，z 从后验采样，测试时由于 KL 已经把分布拉近，z 可以从先验采样。模型的训练技巧如 KL annealing 等借鉴了 Generating Sentences From a Continuous Spaces motivation 这篇论文的思想。 因为 z 是从 context state 计算出来的，latent variable 的期望值和标准差包含一些 high-level 的语义信息，更鼓励模型抽取抽象的语义概念。实验表明，HRED 能产生更长的回复，更好的 diversity。","tags":"nlp chatbot 多轮对话"},{"title":"关于微信公众号和知乎专栏的开通","url":"/2017/11/11/关于微信公众号和知乎专栏的开通/","text":"终于等到你~ 贵有恒何必五更起三更眠，最无益只怕一日曝十日寒 写博客也有一年多了，回国后忧伤的遇到了 GitPage 加载速度慢、CodingNet 容量限制、百度收录速度慢（收录条目不及谷歌的一半）等诸多问题。入乡随俗，大刀阔斧租了服务器，上了 CDN，注册了域名，折腾了好一番。想要喘口气的时候想到之前有小伙伴嫌弃我博客不能主动推送（嗯，她不用 RSS），于是就干脆趁热打铁，开个 公众号/专栏 吧。 欢迎关注。名字是不变的，谷歌搜索徐阿衡，不出意外第二条应该是知乎专栏地址，公众号的话二维码在文末。主题 也是不变的，依然是 自然语言处理 与 深度学习 的相关内容，只是 定位 可能会有所不同。 公众号 的定位是 短文，可能是零散的知识点，新的 idea，也可能是论文的分享，总之，是便于碎片时间阅读的内容，许多个短文串联才可能覆盖一篇完整的博文。更新频率大概会是 2-3 天。除分享外，也在计划上线部分自己正在做的项目，比如说带个人风格的机器人等，在这立个 FLAG 先~ 知乎和博客 则是 长文，是相关知识的一个框架性整理。更新频率 大概是 1-2 周。 大胆假设，小心求证。不能保证我对知识的理解、我的 idea、我的代码是完全准确无 bug 的，欢迎讨论，欢迎批评指正，但希望各位客观评论，以礼相待。 学习之路，道阻且长。道阻且长，行则将至。希望和小伙伴们一起，每天进步一点点，嗯，话不多说，就这样。 公众号： xu_a_heng知乎专栏： 徐阿衡-自然语言处理","tags":"公众号 知乎 专栏"},{"title":"论文笔记 - Copy or Generate","url":"/2017/10/25/论文笔记 - CopyNet or Generate/","text":"关于 Point Network &amp; CopyNet 的几篇论文笔记。 普通的 Seq2Seq 的 output dictionary 大小是固定的，对输出中包含有输入单词(尤其是 OOV 和 rare word) 的情况很不友好。一方面，训练中不常见的单词的 word embedding 质量也不高，很难在 decoder 时预测出来，另一方面，即使 word embedding 很好，对一些命名实体，像人名等，word embedding 都很相似，也很难准确的 reproduce 出输入提到的单词。Point Network 及 CopyNet 中的 copy mechanism 就可以很好的处理这种问题，decoder 在各 time step 下，会学习怎样直接 copy 出现在输入中的关键字。 涉及到的论文： Pointer Networks. NIPS 2015 Incorporating Copying Mechanism in Sequence-to-Sequence Learning. ACL 2016. Get To The Point: Summarization with Pointer-Generator Networks. ACL 2017 Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning. ACL 2017 Pointer Network(Ptr-Net)主要来解决传统 Seq2Seq 中 output dictionary 大小固定(fixed prior)的问题。思路非常简单，实际上就是 attention Seq2Seq 的一个简化版本，不过产生的不是输出序列，而是指向输入序列的一堆指针(或者从输入序列中挑选一个元素进行输出)。论文解释了这种结构可以用来解决 旅行商(Travelling Salesman Problem)、凸包(convex hulls) 等问题。 结构对比: 还是先来看一下经典的 attention-based seq2seq， 在每一个 decoder step，先计算 $e_{ij}$ 得到对齐概率(或者说 how well input position j matches output position i)，然后做一个 softmax 得到 $a_{ij}$，再对 $a_{ij}$ 做一个加权和作为 context vector $c_i$，得到这个 context vector 之后在固定大小的 output dictionary 上做 softmax 预测输出的下一个单词。 经典 Attention: 而 Ptr-Net 不过是简化了后面的步骤，有了 $e_{ij}$ 后直接做 sofmax，可以得到一系列指向输入元素的指针 $a_{ij}$，最直观的用法就是对输入元素进行排序输出了。 CopyNetCopyNet 实现的是能够把输入中的部分信息原封不动的保留到输出中，相当于一个 refer back。一个简单的例子： 12Q: 你好呀，我叫毛毛A: 毛毛，你好，很高兴认识你 这个”毛毛”，可能是 OOV，也可能是其他实体或者是日期等很难被 decoder “还原” 出来的信息，CopyNet 可以更好的处理这类的信息。 那么问题主要有两个： What to copy: 输入中的哪些部分应该被 copy? Where to paste: 应该把这部分信息 paste 到输出的哪个位置？ 框架还是基于 attention-based encoder-decoder，不过在 decoder 的时候，做了部分改进，总的来说，下一个单词的预测是由一个 generate-mode g 和 copy-mode c 的混合概率模型决定的。 $$p(y_t|s_t, y_{t-1}, c_t, M) = p(y_t, g|s_t, y_{t-1}, c_t, M) + p(y_t, c|s_t, y_{t-1}, c_t, M) $$ 要实现 CopyNet 需要有两个词汇表，一个是通常意义的高频词词汇表 V={$v_1,…,v_N$} 加上 OOV，另一个是在输入中出现的所有 unique words X={$x_1, …, x_{T_S}$}，这部分可能会包含没有在 V 里出现的单词，也就是 OOV 单词，第二个词汇表用来支持 CopyNet，最终输入的词汇表是三者的并集 $V ∪ UNK ∪ X$。 对 encoder 部分(双向 RNN) 的输出 $h_1, …, h_{T_S}$，记做 M，M 其实同时包含了 语义 和 位置 信息。decoder 部分对 M 的读取有两种形式： Content-baseAttentive read from word-embedding location-baseSelective read from location-specific hidden units 两种模式对应的 score function $$ \\begin{aligned} φ(y_t=v_i) &amp;= v_i^TW_os_t, \\ \\ \\ \\ v_i ∈ V ∪ UNK \\\\ φ(y_t=x_j) &amp;= σ(h_j^TW_c)s_t, \\ \\ \\ \\ vi ∈ V ∪ UNK \\\\ \\end{aligned}$$ $φ(y_t=v_i)$ 和普通的 RNN encoder-decoder 计算相同，$φ(y_t=x_j)$ 将 $h_t$ 和 $s_t$ 映射到了同一个语义空间，$\\sigma$ 发现用 tanh 比较好，注意 $p(y_t, c|・)$ 的计算加总了所有 $x_j=y_t$ 的情况。 $s_t$ 的更新：在用 $y_{t-1}$ 更新 t 时刻的状态 $s_t$ 时，CopyNet 不仅仅考虑了词向量，还使用了 M 矩阵中特定位置的 hidden state，或者说，$y_{t-1}$ 的表示中就包含了这两个部分的信息 $[e(y_{t-1}); ζ(y_{t-1})]$，$e(y_{t-1})$ 是词向量，$ζ(y_{t-1})$ 和 attention 的形式差不多，是 M 矩阵中 hidden state 的加权和 K 是 normalization term，直观上，是去找输入中也出现 $y_{t-1}$ 的单词对应的 hidden state，考虑到 $y_{t-1}$ 可能在输入中出现多次，$ρ_{tT}$ 更关注这些多次出现的词。 整条路径： $$ζ(y_{t-1}) \\longrightarrow{update} \\ s_t \\longrightarrow predict \\ y_t \\longrightarrow sel. read \\ ζ(y_t)$$ 一些结果： Get To The Point: Summarization with Pointer-Generator NetworksCopy 机制在文本摘要中的应用。传统 attention-based seq2seq 存在下面两个问题 无法正确产生文中的事实细节e.g. Germany beat Argentina 3-2尤其是对 OOV 或者 rare word。在训练中不常见的单词的 word embedding 质量也不高，很难 reproduce，而即使 word embedding 很好，对一些命名实体，像是人名之类的，含义都很相似，也很难准确的 reproduce 出来所以作者引入了一个 pointer-generator network，在 generation 的基础上，加入了 copy 输入中的一些词的能力来提高摘要的准确性，相当于引入了部分 extractive summary 的能力 倾向重复一些词组e.g. Germany beat Germany beat Germany beat…主要是因为 decoder 过程太过依赖于上一个单词，而不是 longer-term 的信息，所以一个重复的单词会 trigger 出死循环，比如上面这个例子就陷入了 Germany beat Germany beat Germany beat… 的死循环，产生不出 Germany beat Germany 2-0 这样的句子所以有了 coverage，来追踪哪些部分已经被 summarize 过了，之后的 attention 就不会注意这些部分 Pointer-generation network 上图展示了 decoder 的第三个 step，预测 Germany beat 后面一个单词，像之前一样，我们会计算一个 attention distribution 和 vocabulary distribution，不过同时，也会计算一个产生概率 $p_{gen}$，是 0-1 间的一个值，表示从 vocabulary 中产生一个单词的概率，相应的 $1-p_{gen}$ 就是从输入中 copy 一个单词的概率 $$ \\begin{aligned} P(w) &amp;= p_{gen}P_{vocab}(w) + (1-p_{gen})\\sum_{i:w_i=w}a_i^t \\\\ p_{gen} &amp;= \\sigma(w^T_{h^*}h^*_t + w^T_ss_t+w^T_xx_t+b_{ptr}) \\\\ \\end{aligned}$$ 其中 $h^*_t$ 是 context vector，在前面我们用的是 $c_i$ 来表示。如果 w 是 OOV， 那么 $P_{vocab}=0$，如果 w 没有在输入中出现，那么 $\\sum_{i:w_i=w}a_i^t=0$。 Coverage用 attention distribution 来记录哪些部分已经总结过了，来惩罚再次加入计算的部分。decoder 的每个时刻，有一个 coverage vector $c_t$ 来将记录之前所有时刻 attention 的总和。 $$c^t=\\sum^{t-1}_{t’=0}a^{t’}$$ 这个 coverage 会作为 attention 计算的一个输入$$e^t_i=v^Ttanh(W_hh_i+W_ss_t+w_cc^t_i+b_{attn})$$ 对应的，有一个 coverage loss$$covloss_t=\\sum_imin(a^t_i,c^t_i)$$ 整体的 loss 就是$$loss_t=-logP(w^*_t)+\\lambda \\sum_i min(a^t_i, c^t_i)$$ Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence LearningCopy 机制在问答系统中的应用。论文的模型用三种不同模式获取词汇并进行选取：用拷贝方式取得问句中的实体、用预测方式产生让答案更自然的连接词、用检索方式获取相关事实 并结合多个相关事实产生复杂问句的自然形式的答案。 123Q: Do you know where was Jet Li from ?A1: Beijing.A2: Jet Li was born in Beijing. He is now a Singaporean citizen. 传统的 QA 系统只会返回 A1，一个孤零零的实体，这对用户并不友好，A2 才是自然语言形式的答案。COREQA 利用 拷贝(copy)、检索(retrieval)和预测(prediction) 从不同来源获取不同类型的词汇，产生复杂问句的自然答案。 具体过程，以 Do you know where was Jet Li from 这个问题为例来说明： 知识检索: 首先识别问题中的包含的 topic entities。这里我们识别出的 topic entity 是 Jet Li 。然后根据 entity 从知识库中检索出相关的三元组(subject, property, object)。针对李连杰这个实体，我们可以检索出(Jet Li, gender, Male)，(Jet Li, birthplace, Beijing)，(Jet, nationality, Singapore) 等三元组。 编码(Encoder): 将问题和检索到的知识编码成向量问题编码: 双向 RNN(Bi-RNN)，把前向和后向对应的 hidden state 拼接起来形成每一时刻的 short-term memory $M_Q={h_t}$，两个方向 RNN 的最后一个向量拿出来拼在一起就得到向量 q 来表示整个问题知识编码: 使用了记忆网络(Memory Network)，对知识检索阶段得到的知识三元组 spo 分别进行编码得到 $e_s, e_p, e_o$，拼接成一个 $f_i$ 来表示这个三元组，所有这些三元组向量形成一个 list，用 $M_{KB}$ 表示分数计算: $S(q, s_t, f_j) = DNN_1(q, s_t, f_j)$ 解码(Decoder): 根据 $M_Q$ 和 $M_{KB}$ 来生成自然答案。单词预测有三种模式，predict-mode, copy-mode 和 retrieve-mode，predict-mode 和普通 seq2seq 原理相同，生成词汇表中的单词，copy-mode 从问句中复制单词，retrieve-mode 从知识库中选取单词。过程和 CopyNet 差不多，也有两种读取方式，一种是读取语义，一种是读取位置。 $p_{pr}, p_{co}, p_{re}$ 以及对应的 score function 和前面的 CopyNet 非常相似，包括之后的 state update 部分也和 CopyNet 差不多，不过是多了 $r_{kb}$ 而已。 参考链接：让问答更自然 - 基于拷贝和检索机制的自然答案生成系统研究 | 论文访谈间 #02","tags":"text-summarization copynet pre-net"},{"title":"经典的端到端聊天模型","url":"/2017/10/05/经典的端到端聊天模型/","text":"介绍一下经典的 End-to-end 聊天模型及应用，包括检索式模型、生成式模型，以及 Google 邮件自动回复的应用。 主要涉及到下面几篇论文 The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems A Neural Conversational Model Smart reply, automated response suggestion in email How NOT To Evaluate Your Dialogue System Zhengdong Lu &amp; Hang Li, 2013, A Deep Architecture for Matching Short Texts Zongcheng Ji, et al., 2014, An Information Retrieval Approach to Short Text Conversation Baotian Hu, et al., 2015, Convolutional Neural Network Architectures for Matching Natural Language Sentences Aliaksei Severyn, et al., 2015, Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks Building end-to-end dialogue systems using generative hierarchical neural network models Modular system vs end-to-end system第一部分先简单比较一下对话系统中 modular system 和 end-to-end 的不同。 如上图，传统的一个对话系统由 Speech Recognizer, Language Interpreter, State Tracker, Response Generator, Natural Language Generator, Speech Synthesizer 这么多个子模块拼接而成，这种系统称为 Modular system，在系统中每个组件单独训练，来优化一个单独的中间目标(如 slot-filling)。而 end-to-end system 相当于用一个系统替代了上图中框起来的四个组件，来比较一下 Modular system vs end-to-end system 目标函数modular system 有两个及以上的目标函数end-to-end 通常只有一个目标函数 所需数据modular system 更容易训练，需要的数据少end-to-end 需要大量数据 人工标注modular system 需要大量的人工的特征工程，需要预先定义 state, action spaces 等等end-to-end 不需要预先定义的 state/action spaces 效果modular system 在 highly structured tasks/narrow domain 上的效果更出色，但泛化能力有限end-to-end 在 general purpose 的效果上比较好 Retrieval-based models vs Generative models对话模型分 检索式(Retrieval-based models ) 和 生成式(Generative models) 两种，检索式的聊天模型有一个预先定义好的模板库，给定一个 query，来从模板库里选择最好的 response。回复的产生依赖于模板库，不可能产生模板库没有的句子。而生成式模型不依赖于模板库，而是直接产生的，生成式模型的方法大多依赖于机器翻译的技术，但不是从一个语言翻译到另一个语言，而是从一个输入映射到回复。 两种方法都有利有弊，检索式模型得到的回复不会产生语法错误，但没法处理在模板库里不存在回复的用户输入，另外，检索式模型也很难结合上下文信息。而生成式模型更加的“聪明”，可以结合语境，然而更难训练，也更容易犯语法错误(尤其是长句)，需要的训练数据也很大。 Retrieval-Based Models可以看做是一个 检索/排序/匹配 问题，有一个预先定义好的模板库(看做是检索系统的文档集)，给定一个 query，来从模板库里选择最好的 response，这里需要计算一个 score(query, response) 来衡量 query 和 response 的匹配程度，score 越高，response 越可能是一个合适的回复。response 也可以替换成标准 query，这就把问题转换为用户 query 和标准 query 的一个相似度计算问题，这里的 score 就是相似度分数。 需要学习的一个是语义表达，一个是 score 的计算。score 可以单独用传统方法做，也可以在神经网络的 MLP 层做，还可以在语义表达产生的过程中做。 有下面一些经典的论文，(Q, Q’)，(Q, A) 或 (Q, D) 的匹配在这里统一表示为 (Q, D)，D 可以是标准 query，可以是 answer，也可以是标准 query + answer Zhengdong Lu &amp; Hang Li, 2013, A Deep Architecture for Matching Short TextsDeepMatch，先用 (Q, D) 语料训练 LDA 主题模型，得到其 topic words，这些主题词被用来检测两个文本是否存在语义相关性(Localness)；每次指定不同的 topic 个数分别训练 LDA 模型，得到几个不同分辨率的主题模型(Hierarchy)，高分辨率的 topic words 更具体，低分辨率的更抽象，这可以避免短文本词稀疏带来的问题，并得到不同的抽象层级 Zongcheng Ji, et al., 2014, An Information Retrieval Approach to Short Text Conversation从不同角度构造匹配特征，作为 ranking 模型的特征输入，构造的特征包括：1）Query-ResponseSimilarity；2）Query-Post Similarity；3）Query-Response Matching in Latent Space；4）Translation-based Language Model；5）Deep MatchingModel；6）Topic-Word Model；7）其它匹配特征 Baotian Hu, et al., 2015, Convolutional Neural Network Architectures for Matching Natural Language Sentences基于 CNN，Q 和 D 分别经过多次一维卷积和池化，得到的固定维度的两个 sentence embedding，然后输入到 Siamese 结构的 MLP 层，得到文本的相似度分数。这种方法的监督信号在最后的输出层才出现，在这之前，Q 和 D 的 embedding 相互独立生成，可能会丢失语义相关信息，所以有第二种结构，在第 1 层卷积后就把 Q 和 D 做融合，融合方式是分别对 Q 和 D 做 1D 卷积，然后针对两者卷积得到的 feature map，构造其所有可能的组合(在两个方向上拼接对应的 feature map)，这样就构造出一个 2D 的 feature map，然后对其做 2D MAX POOLING，多次 2D 卷积和池化操作后，输出固定维度的向量，接着输入 MLP 层，最终得到文本相似度分数。实验表明优于 DeepMatch Aliaksei Severyn, et al., 2015, Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks分别对 Q 和 D 做 wide 1D 卷积和 MAX 池化，得到文本的语义向量，接着通过 M 矩阵变换得到语义向量的相似度，然后把 Q 语义向量、Q&amp;D 的语义相似度、D 语义向量、外部特征拼接成 n 维向量，输入一个非线性变换隐层，最终用 softmax 做概率归一化。用 softmax 的输出作为监督信号，采用 cross-entropy 作为损失函数进行模型训练 这里介绍的是 Dual-Encoder 模型(Ryan Lowe, et al., 2016, The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems)，通过对偶的 RNN 模型分别把 context 和 response 编码成语义向量，然后通过 M 矩阵变换计算语义相似度，相似度得分作为监督信号在标注数据集上训练模型。 句子表达先来看一下怎么表达 query 和 response。语义特征方面很容易想到 TFIDF，然而它忽略了词序，表达效果没那么强，所以考虑用 sentence embedding。sentence embedding 可以用 RNN/LSTM 来获取。还是 Encoder-decoder 的思想，不过这里把 decoder 给替换了成了另一个 encoder，也就成了 Dual-RNN 的结构。两个独立的 RNN 分别对 context/ query和 response 进行编码，每个 RNN 最后一个 hidden state 相当于是对整个 input(context/response) 的一个总结。 分数计算模型的学习目标其实是一个 binary 分类器$\\sigma (score(Query, Response_true)) -&gt; 1$$\\sigma (score(Query, Response_false)) -&gt; 0$ 先来看下如何计算分数。$$p(flag=1|c,r,M)=\\sigma(c^TMr+b)$$ 这个过程可以看做是一个产生模型，给定 input response，用 $c’=Mr$ 产生一个 context (M 是 dxd 的参数矩阵)，然后利用点乘来及计算这个产生的 context 和真实 context 的相似度分数，再用 sigmoid 将这个分数转化为概率，最小化交叉熵损失函数来将进行训练。 简单一个例子来理解这个过程，假设下图 5x5 的表格，i 行 j 列代表 $(query_i, response_j)$，我们希望对角线的 probability 最大，因为对角线对应着正确的 (query, response)，真实的 label 是一个 identity matrix，我们的 prediction 是 5x5 的 score，现在对每一行进行 softmax cross-entropy 损失函数的计算，其实就相当于直接优化 retrieval metrics (Recall@k)，即 (query, response) 在所有 pair 里的排名。 从代码角度理解一下，下面是训练阶段的一个 minibatch 过程，假设 minibatch 大小为 5 123456789101112131415161718192021222324if self.is_training: # 训练阶段, 使用 minibatch 内其他样本的 response 作为 negative response # 用 LSTM 做 encoding，query/response 都是 5x128 的表达 # W: 128x128 response_final_state = tf.matmul(response_final_state[-1].h, W) # 得到 5x5 的 score matrix logits = tf.matmul( a = query_final_state[-1].h, b = response_final_state, transpose_b = True) self.losses = tf.losses.softmax_cross_entropy( onehot_labels = self.labels, logits = logits) self.mean_loss = tf.reduce_mean(self.losses, name=&quot;mean_loss&quot;) train_loss_summary = tf.summary.scalar(&apos;loss&apos;, self.mean_loss) self.training_summaries = tf.summary.merge( inputs = [train_loss_summary], name=&apos;train_monitor&apos;) opt = tf.train.AdamOptimizer( learning_rate=self.args.learningRate, beta1=0.9, beta2=0.999, epsilon=1e-08 ) self.optOp = opt.minimize(self.mean_loss) 测试阶段，计算的是 Recall@k (给定一个 query，选择 k 个最有可能的 response，看正确的 response 在不在这 k 个里)。举个例子，从整个 test data/validation data 随机抽取 19 个错误答案，对每一个样本，计算 20 个 response 的 score，看真实回复的 score 是否排名前 k。response 矩阵连续的 20 行对应一个 query，第 1 行、21行、41行…对应真实的 response，其他是错误 response。将 query 复制 20 次，就得到 100x128 的 query 和 100x128 的 response (假设 rnn_dim=128)，点乘得到每个 (query, response) 的 score，也就是 100x100 的矩阵，然后再 reshape 成 5x20 的矩阵，再计算 Recall@k 代码123456789101112131415161718192021222324252627282930313233343536373839else: # 测试阶段，每一个样本的response是固定的 # query: [batch_size, rnn_dim]# respones: [batch_size x 20, rnn_dim] # [batch_size x 20, rnn_dim] response_final_state = tf.matmul(response_final_state[-1].h, W) query_final_state = tf.reshape( tf.tile(query_final_state[-1].h, [1, 20]), [-1, self.args.hiddenSize]) # [batch_size, batch_size x 20] logits = tf.reduce_sum( tf.multiply( x = query_final_state, y = response_final_state), axis = 1, keep_dims = True) logits = tf.reshape(logits, [-1, 20]) # top_k percentage self.response_top_1 = tf.reduce_mean( tf.cast(tf.nn.in_top_k( predictions = logits, targets = self.targets, k = 1, name = &apos;prediction_in_top_1&apos;), dtype = tf.float32)) self.response_top_3 = tf.reduce_mean( tf.cast(tf.nn.in_top_k( predictions = logits, targets = self.targets, k = 3, name = &apos;prediction_in_top_3&apos;), dtype = tf.float32)) self.response_top_5 = tf.reduce_mean( tf.cast(tf.nn.in_top_k( predictions = logits, targets = self.targets, k = 5, name = &apos;prediction_in_top_5&apos;), dtype = tf.float32)) Generative Models产生模型并不是从模板库里选一个分数最高的 response 出来，而是去自动生成这样一个 response。 将 MT 问题中引入的 seq2seq 模型应用到对话任务上。给出 (query, response) 以后，seq2seq 对 query 进行编码，最后一个 hidden state 包含 query 的所有信息，结合开始标记 EOS 进行解码，得到 response。不过这种方法对上下文依赖考虑有限，HRED(Hierarchical Recurrent Encoder-Decoder) 为解决这个问题做了改进。 HRED 在传统 encoder-decoder 模型上，额外增加了一个 encoder，相比于普通的 RNN-LM 来说，考虑了 turn-taking nature，能够对上下文进行建模，有助于信息/梯度的传播，从而实现多轮对话。有下面三个阶段： encoder RNN第一个 encoder 和标准的 seq2seq 相同，将一句话编码到固定长度的 utterance vector，也就是 RNN 的 last hidden state context RNNn 个句子的 utterance vector 作为第二个 encoder 也就是 context-level encoder 各个时间上的的输入，对应长度为 n 的 sequence，产生一个 context vector 实现对语境的编码，也就是 RNN 的 output (注意这里不是 last hidden state) decoder RNN上一个句子的 utterance vector 作为 response 的初始状态，目前为止产生的 context vector 和上一个单词的 word embedding 拼接作为 decoder 的输入 然而 HRED 相对于传统的 Seq2Seq 模型的提高并不明显，bootstrapping 的作用更加明显。一方面可以用 pre-trained word embedding，另一方面可以使用其他 NLP 任务的数据预训练我们的模型，使得模型的参数预先学到一些对自然语言的理解，再来学习聊天任务。 看上面的例子，可以发现 seq2seq 模型可以在一定程度上记住知识，理解语境，进行简单的推理(图左)，然而并不能保留记忆和性格，对相同语义的不同表达会返回不同的答复(图右)。另外要注意的是，这个场景下 seq2seq 的训练目标和真实目标实际是不一样的，尤其在闲聊场景中。训练阶段关注的是真实 response 出现的概率和怎么最大化这个概率，而测试阶段或者说真实场景下，对话侧重于交流信息，以及长时间的连贯性，考虑到回复的灵活性(如一个 query 可以有多种合适的回复)，以及经产生模型的自由度(并不需要在模板库里面选择回复，可以是全新的句子)，因此使用合适的 Metric 来衡量产生的句子实际是非常困难的问题。 objective function being optimized does not capture the actual objective achieved through human communication, which is typically longer term and based on exchange of information rather than next step prediction MetricsMetrics 的设计目标是使得 metric 的判断和人为判断尽量相似。 Retrieval Metrics: Recall@kRecall@k 是信息检索里的评估方法，给定一个 query，选择 k 个最有可能的 response，看正确的 response 在不在这 k 个里。 Generative Metrics 相对于机器翻译，对话中回复的选择空间大很多； 看起来完全无关的两句话都可以是合适的回复 而这两个正确的回复如果不看context的话，无论是从词频 还是语义来看都是不相关不想似的句子 Word Overlap-based Metrics主要有 BLEU，ROUGE 和 METEOR，最初用于衡量机器翻译的效果。BLEU 主要看人为/测试的句子里的单词的 overlap (机器产生的待评测句子中的 ngram 正确匹配人工产生的参考句子中 ngram 与机器产生的句子中所有 ngram 出现次数的比值)，加入 BP(Brevity Penalty) 惩罚因子可以评价句子的完整性。然而 BLEU 不关心语法，只关心内容分布，适用于衡量数据集量级的表现，在句子级别的表现不佳。 “BLEU is designed to approximate human judgement at a corpus level, and performs badly if used to evaluate the quality of individual sentences.”——wikipedia ROUGE 是一种基于召回率的相似性度量方法，与 BLEU 类似，但计算的是 ngram 在参考句子和待评测句子的共现概率，包含 ROUGE-N, ROUGE-L(最长公共子句, Fmeasure), ROUGE-W(带权重的最长公共子句, Fmeasure), ROUGE-S(不连续二元组, Fmeasure) 四种，具体不多说。 METEOR 改进了 BLEU，考虑了参考句子和待评测句子的对齐关系，和人工判断的结果有更高的相关性。 Embedding-based Metrics侧重比较生成的句子和真实样本的语义相似度。 Embedding average score将句中每个单词的词向量作平均来作为句子的特征，计算生成的句子和真实句子的特征的 cosine similarity Greedy matching score寻找生成的句子和真实句子中最相似的一对单词，把这对单词的相似度近似为句子的距离 Vector extrema score对句中单词词向量的每一个维度提取最大(小)值作为句子向量对应维度的数值，然后计算cosine similarity Human judgement “We ﬁnd that all metrics show either weak or no correlation with human judgements, despite the fact that word overlap metrics have been used extensively in the literature for evaluating dialogue response models” 在 How NOT To Evaluate Your Dialogue System 这篇论文中，宣称和人工判断相比，上述的所有 metric 都是垃圾 在闲聊性质的数据集上，上述 metric 和人工判断有一定微弱的关联 (only a small positive correlation on chitchat oriented Twitter dataset) 在技术类的数据集上，上述 metric 和人工判断完全没有关联(no correlation at all on the technical UDC) 当局限于一个特别具体的领域时，BLEU会有不错的表现 Learning to Evaluate Dialogue Responses可以尝试使用机器学习的方法来学习一个好的 metric，用语境 c，真实回复 r，机器回复 $\\hat r$，训练一个 regression 模型，使得 score 和人工打分的 score 接近。 Application讲一个生成式模型的具体应用，然而用预先定义好的模板库对生成的 response 做了一个限制。具体任务是如何对邮件进行自动回复。来自 Smart reply, automated response suggestion in email 达到的目标是收到一封邮件，系统发现这个邮件适合 Smart Reply，就会自动推荐 3 个回复语句给用户选择。 框架面临的几个挑战是 Response quality怎么保证生成的回复的质量，如果质量不高，根本没有推荐的必要 Utility怎样选择推荐的回复，能最大化用户选中的概率 Scalability怎样提高效率，大规模处理 Privacy在开发系统的过程中怎么保护隐私，加密 如何应对上面的挑战，也是文章的亮点 Response selection对应 Scalability 问题将模板库里的句子组织成一个 trie，从左到右用 beam search 的方法进行每次遍历，只保留在 trie 中出现的 hypothese，这样对每个 response candidate 评分的复杂度就由 O(Rl) 降到了 O(bl)，R 是模板库的大小，l 是最长回复的长度，b 是 beam size Response set generation对应 Response quality, Scalability, 以及 Utility 问题生成一个带 intent 标记的模板库，回复只从这个模板库里产生 Diversity对应 Utility 问题去掉 generic 的回复，兼顾正面、负面回复，在得分最高的回复中，每个 intent 只选择一个回复 Triggering model对应 Utility 问题Binary 分类器判断是否要 trigger 自动回复，不需要回复的，不适合短回复的 具体过程是，来一封邮件，首先看是否 trigger Smart Reply(采用一个 feedforward neural network)，如果是，就跑一遍 LSTM，生成候选的 n 个 response。 特征方面，预处理后的邮件采取的特征有 unigram, bigram，发件方是否在收件方的地址簿里，是否在收件方的社交网络里，收件方是否在过去回复过发件方等等。稀疏特征类型(如 unigram, bigram)的 embedding 是单独训练的，然后每个稀疏类型特征下的 embedding 进行加总，再和 dense feature(如数值、布尔类型的特征)拼接作为输入。 重点看一下模板库的生成。 Response set generation模板库的存在可以限制产生的 response 的范围，提高 response 的质量以及选择回复的速度。另外，这里模板库里的句子都有一个 intent 标记，而标记了 intent 类别的回复模板库可以增加回复的 diversity。 产生模板库用了 Expander graph learning approach，是一种半监督的方法。搜集邮件数据后用传统 nlp 方法进行预处理，包括 去掉非英语的样本 Tokenization 将内容分割成句子为单位 使用特殊符号替换不常用的单词(e.g. 人名，url，邮件地址） 去掉引用和转发的邮件部分 去掉问候和致敬部分 处理好的数据中只选择短的、最常出现的、匿名的回复。 首先利用 dependency parser 将类似的句子如 “Thanks for your kind update”,“Thank you for updating!”, , “Thanks for the status update” 等转换为 canonical 形式，即 “Thanks for the update.”然后进行做语义聚类，每个 cluster 对应一个意图（intent）. 过程： 初始化: 标记～100个类别(cluster)，每个类别～3个人工选择的样本 使用 (original, response), (response1, response2, feature) 对模板库里的样本建立关系 使用 Expander 算法给未标记的句子打标记 对于新的类别的发现，Iteration：Inference: 用 label propagation 算法迭代 5 次推测未标记样本的 cluster 类别Update: 从图中剩下的未标记的样本中随机 sample 100 个作为潜在的新类别，用 canonicalized representation 来标记​ 重新运行 label propagation 直到收敛(不再发现新的类别，或者每个类的成员不再变化) 最后进行 Validation: 提取每个 cluster 的 top-k 个回复样本，人工验证 参考链接PaperWeekly 第37期 | 论文盘点：检索式问答系统的语义匹配模型（神经网络篇）","tags":"nlp chatbot 多轮对话"},{"title":"NLP 笔记 - Discourse Analysis","url":"/2017/09/20/NLP 笔记 - Discourse Analysis/","text":"CMU 11611 笔记。讲语篇分析的一些概念，包括 coreference, cohesion, speech acts 等。 Introduction Discourse is the coherent structure of language above the level of sentences or clauses. A discourse is a coherent structured group of sentences. Discourse Analysis 中文对应过来通常是语篇/篇章分析。前面讲到了语素级别的(morphemes)、词汇级别的(lexical)、短语级别的(segmentation)、句子级别的(syntactic parsing)种种概念及分析，现在到了 beyond sentences 这一级别，只有两句或两个句子/从句以上的句子，才被称为 discourse。广义来讲，discourse 其实有很多含义，大多都能归到下面三类。 Language beyond sentences语言学家(Linguistists)关注的概念，分析句子之间是怎么联系/衔接的，也是本篇的重点 Language in use可以理解为实际发生的对话(conversation)，这是应用语言学家(Applied Linguistists)会关注的，比如说他们会来研究医患人员的对话来看医生是怎么在对话过程中建立权威的(结合 speech acts) A broader range of social practice that includes nonliguistic and nonspecific instances of language不止是语言学的内容，而是 linguistic + social practice + ideological assumption 结合的产物，社会学家对这个更感兴趣，会关注特定时间特定场景下的行为，比如来研究种族歧视等社会现象(结合 contexts) 具体见The Handbook of Discourse Analysis 语篇分析的应用很广泛，比如说自动文摘、自动作文评分、会议理解、对话系统等。 Coreference一个重要的概念是 coreference，表示共指关系。自然语言的所指现象非常丰富，有不定名词短语(indefinite noun phrase)、有定名词短语(definite noun phrase)、代词(pronoun)、指示词(demonstrative)、单个复指(one-anaphora)等，所指对象类型有推理对象(inferrable)、不连续集(discontinuous set)和类属(generic)。下面主要以代词指代来讲共指的概念。 先来看下两个概念，anaphora 和 cataphora，两者都是指代，不同的是 referent 和 referring expression 出现的先后顺序 anaphora: the use of a word referring to or replacing a word used earlier in a sentence cataphora: the use of a word or phrase that refers to or stands for a later word or phrase E.g., Anphora 123I went to see my grandfather at the hopital.The old man has been there for weeks.He had surgery a few days ago. the old man 和 he 是 referring expression，在这个场景下也是 anaphora，都指代前面的 my grandfather，my grandfather 又称为先行词(antecedents)。 Referring expressions: the old man, heAntecedents: my grandfather E.g., Cataphora 先出现 She，再出现 She 指代的 Mary。1234567– R: She didn’t like it!– D: What do you mean?– R: She didn’t like it!– D: Who didn’t like what?– R: Mary.– D: What didn’t Mary like?– R: She didn’t like the article I read in the *New Yorker*. 指代问题在单个句子或者多个句子中都会出现，这一章讲 discourse，只讨论多个句子中的指代消解问题(Reference Resolution)。 Pronoun reference resolution看一个简单的代词指代消解的例子。1John saw Mary in the park. As every morning, she was walking her dog. 我们需要来判断 she 指代谁。第一步，找到所有的 candidate referents，也就是名词短语。12345- John- Mary- The park- Every morning- Her dog 直觉上看，She 必须是 Person，所以 morning, park 删除，John 是男性，gender 不符，删除，her dog 难以确定 gender，最有可能的是 Mary。这个例子非常简单，仅仅通过一致性约束就判断出了正确的 referent，很多场景比这复杂的多。下面先来看一下代词指代消解相关的一些规则/模型。 Filters: 句法和语义约束根据下面的一些规则约束可以 排除 一些 candidate referents。 Agreement constraints (一致性)gender, number, person, animacy Binding theory: reflexive required/prohibited (反身代词)反身代词可以用于同指包含它的最近邻从句的主语，而非反身代词不能同指该主语– John bought himself a new Ford. [himself=John]– John bought him a new Ford. [him≠John]– John said that Bill bought him a new Ford. [him≠Bill]– J said that B bought himself a new F. [himself=Bill]– He said that he bought J a new Ford. [both he≠J] Selectional restrictions选择限制，动词对论元(argument)施加的选择限制John parked his car in the garage after driving it around for hours.动词 drive 要求直接宾语是能够驾驶的事物，比如说 car Preferences: 优先级下面的一些偏好规则说明哪些 referents 有更大的可能性是正确的。 Parallelism Sentence ordering: Recency 邻近话段引入的实体比较远话段引入的显著性更高 Grammatical Role: subj&gt;obj&gt;others Repeated mentionBilly had been drinking for days.He went to the bar again today. Jim went with him. He ordered rum. Verb semantics有些动词的出现会对其中一个论元的位置产生语义上的强调，这会造成对其后代词的理解偏差John phoned/criticized Bill. He lost the laptop.如果是 phone，明显应该是 John 丢了电脑，如果是 criticize，应该是 Bill 丢了。这被认为是动词的“隐含因果关系”，criticize 事件的隐含因果被认为是动词宾语，而 phone 被认为是动词主语 Discourse model很多指代消解算法的第一步是建立 discourse model，discourse model 包含了 discourse 所指实体的表示以及它们所承担的关系，模型有两个基本操作，如下图所示，当第一次提到所指对象时，我们称它的表示为被唤起(evoke)而进入模型，之后当再次提及时，我们称从模型中访问(access)它的表示。 Computational approaches to pronouns reference resolution有了前面的知识储备，现在可以来看一下代词指代消解的传统算法。 Hobbs Algorithm非常早期的，1978 年 Hobbs 提出一种不依赖任何语义知识或语篇信息，只利用语法规则和完全解析树信息的指代消解算法，又叫树查询算法(Tree Search Algorithm)。算法会遍历当前句子和先行句(preceding sentences)的解析树，根据 binding theory, recency, 和 grammatical role preferences 选择合适的 NP 作为 referent，这种方法需要 parser，需要 gender 和 number 信息，也需要用于确定 NP gender 的 head rule 和 wordnet。现在实际系统中很少直接使用，一般只会拿来做 baseline。 算法过程: Resolution of Anaphora Procedure(RAP)1994 年 Lappin 和 Lease 提出的，综合考虑了 recency 和基于句法的优先关系的影响。使用 McCord 提出的 Slot Grammar 获得文档的句法结构，根据过滤规则过滤掉不合适的 referent，然后通过手工加权的各种语言特征计算剩下的 referent 重要性，确定 referent。1996 年 Kennedy 等人对 RAP 做了修改和扩展，避免了构建完整的解析树，只用 NLP 工具预处理得到词性标注和句法功能标注等浅层信息，2005 年 Luo 等人继续做了改进，尝试用最大熵模型来自动确定各种语言特征的权值。下面来看一下基础版本的 RAP 算法。 两个步骤，discourse model 的更新和代词的判定。遇到一个唤起的新的实体的名词短语时，必须为它添加一个表示以及用于计算的显著度(salience)，显著度由一组显著因子(salience factor)所指派的权值综合来计算。每处理一个新句子，discourse model 中的每个因子为实体所指派的权重就减一半。 显著因子及其权重： RAP 过程: Example: =&gt; he 指代 John Halve 加入 he 的分数 根据规则 =&gt; it 指代 Integra，加入 it 的分数 加入 Bill Halve …… Centering theoryCentering algorithm 和 Lappin &amp; Leass 算法一样都采用了 discourse model 的表示，但同时引入了 center 的概念，center 表示语段中心成分，在语篇中联系不同语段的实体(entity)，在话语中的任何定点都有一个单独的实体被作为 center。center 细分为语段潜在中心 (forward-looking center $C_f$) 和语段现实中心(backward-looking center $C_b$)。 对于由 $U_1, …, U_t$ 构成的语篇，语段 $U_n$ 的 $C_f$ 和 $C_b$ 由下面的制约条件： $C_f(U_n)$ 是当前语段中的所有实体组成的集合，在下一语段中至少会部分实现(realize) $C_b(U_n)$ 是 $C_f(U_{n-1})$ 中的一个，而且是 rank 最高的那个 $C_b = \\ most \\ highly \\ ranked \\ C_f \\ used \\ from \\ prev. \\ S$Rank: Subj &gt; ExistPredNom &gt; Obj &gt; IndObj-Obl &gt; DemAdvPP语法角色层级和 Lappin &amp; Leass 算法相似，但并没有给实体附加权重值，只是简单的相互排序 每一个 $U_n$ 都可以有一组 $C_f$，但最多只能有一个 $C_b$，一般来说，篇章的第一个语段没有 $C_b$ 在 $C_f$ 集合里，rank 最高的称为 Preferred Center $C_p$ 转换规则： 有了上面的概念和规则，再来看一下基于 Center 的指代消解算法Step1： 为每个语段中的实体生成可能的 Cb-Cf组；Step2： 通过各种约束条件来过滤（比如：句法位置约束、语义选择限制，等等）；Step3： 通过转换顺序来给出排序：如果一个代词 R 的指代成分为 A 所得到的篇章连贯性高于指代成分为 B 时得到的篇章连贯性，则将 R 的指代成分确定为 A。 Centering 和 Hobbs 都假设输入时正确的句法结构。和 Lappin &amp; Leass 算法相似，中心算法的主要显著因子包括 Grammatical Role, Recency, Repeated Mention，但不同的是语法层级对显著性影响的方式是间接的，如果低级语法角色的所指对象导致的转换时较高级别的，它会比高级角色的所指对象优先，所以 centering algorithm 可能会将其他算法认为是相对较低显著性的所指对象判定一个代词的所指对象。比如说 12345– Bob opened a new dealership last week– John took a look at the Fords in his lot [Cb=Bob]– He ended up buying oneResults: He=Bob =&gt; CONTINUE, He=John =&gt; SMOOTH Log-linear model监督学习，需要手工标注同指关系，基于规则过滤，还是以上面的语段为例，特征如下： General Coreference Resolution就是转化为一个分类问题，先识别文本中的 NP，然后对每一个 NP pair 进行一个二分类，看他们是否是共指关系，然后合并结果形成共指链(coreferential chain)，Coreference chains 其实是 cohesion 的一个部分，下面会具体讲到 cohesion。所以我们需要的是 a choice of classifier lots of labeled data features 可以选的特征有1234567891011• Edit distance between the two NPs• Are the two NPs the same NER type?• Appositive syntax – “Alan Shepherd, the first American astronaut…”• Proper/definite/indefinite/pronoun• Gender• Number• Distance in sentences• Number of NPs between• Grammatical role• etc. 更多见• Combine best: ENCORE (Bo Lin et al 2010)• ML for Cross-Doc Coref (Rushin Shah et al 2011) Coherence, CohesionCoherence RelationsCohesion 是衔接，强调句子构成成分之间的关联性，Coherence 是连贯，强调句子之间的语义连接关系。看下面三组句子，只有第一组是 make sense 的，而第二第三组的两个句子间没有任何关联。123I saw Mary in the street. She was looking for a bookstore.? I saw Mary in the street. She has a cat.?? I saw Mary in the street. The pistons won. 句子之间的衔接关系有很多种，比如说结果(result)、解释(explanation)、平行(parallel)、详述(elaboration)等。 William Mann 和 Sandra Thompson) 提出了 RST (Rhetorical Structure Theory，修辞结构理论)，可以用来解释这种关系。RST 是基于局部文本之间的关系的文本组织理论，它认为语篇(discourse)的构成具有层次关系，通过修饰结构可以表示语篇结构。RST 在文本生成(text generation)、文本摘要(text summarization) 等场景下都有应用。 两个概念是 核心(nucleus) 和 外围(satellite)。RST 一般将文本的中心片段称为 核心(nucleus)，文本的周边片段称为 外围(satellite)，比如说下面的段落1The carpenter was tired. He had been working all day. 第二个句子详细描述了(elaborate)第一个句子，解释了 carpenter 为什么会 tired。更明显的是第二个句子以代词 He 开头，对第一个句子的依赖性很强，相对来说句子重要性更低，所以第一个句子是 Nucleus，第二个句子是 Satellite。 Nucleus 和 Satellite 的关系 The satellite increases the belief in the relation described in the nucleus Some relations have only a nucleus, others have two nuclei, yet others have on nucleus and one satellite 再看一组 RST 关系的定义 RST 是通过层级进行组合的，也就是说，我们可以采用一对相关文本作为其他高层关系的外围或者核心。和句法结构类似，这可以形成 discourse 的结构，可以看下几个例子，在下面的树里，代表一组局部连贯话段的节点被称为 discourse segment，相当于句法中的 consitute。 12345S1: John went to the bank to deposit his paycheckS2: He then took a bus to Bill’s car dealershipS3: He needed to buy a carS4: The company he works for now isn’t near a bus lineS5: He also wanted to talk with Bill about their soccer league 更多例子 Automatic Coherence Assignment给定句子/从句的序列，我们希望能自动的 决定句子之间的衔接关系(coherence relation assignment) 抽取能够表示整个 discourse 的树/图结构(discourse parsing) Use cue phrases/discourse markersAutomatic Coherence Assignment 是一个很难的任务，现有的一种方法是利用线索型的短语(cue phrases)，具体过程如下： 12John hid Bill’s car keys because he was drunk.The scarecrow came to ask for a brain. Similarly, the tin man wants a heart. Identify识别文本中的 cue phrases，如第一句中的 because，第二句中的 similarly Segment将文本分成 discourse segments Classify对每组相邻的 discourse segment 进行关系分类 Marcu and Echihabi 2002 最早提出了关于文本结构的完全确定性的形式化模型，用无监督方法来自动识别 4 种 RST 关系(contrast, cause-explanation-evidence, condition, elaboration + non-relation)，利用 Word co-occurrence，训练了 Naive Bayes 关系分类器，取得了不错的结果，论文值得一看，是当时 discourse analysis 的一个重大突破，不过这种模型过度依赖 cue phrases，匹配模式也很简单，只能对文本进行颗粒度较粗的分析。 除了 cue phrases/discourse markers，还可以利用的是推理关系。 Use abduction/defeasible inference基于推理的判定算法主要是通过推理来约束连贯关系。之前在NLP 笔记 - Meaning Representation Languages中讲过取式推理(modus ponens)，是演绎(deduction)的规则，也是 sound inference 的一种形式，如果前提为真，结论必为真。 然而很多 NLU 依赖的推理是不可靠的，比如说 abduction(溯因推理)，中心规则如下： 这其实相当于 Peter Lipton 说的 Inference to the Best Explanation(IBE)，从结果中找最可能的原因。比如说我们知道 All Acuras are fast.，还知道 John’s car is fast，想来解释为什么 John’s car is fast，发现最合理的理由是 John’s car is an Acura。 123All Acuras are fast.John&apos;s car is fast.Maybe John&apos;s car is an Acura. 然而这可能是一个不正确的推理，John 的汽车可能是由其他制造商生产同时速度很快。一个给定的结果 $\\beta$ 可能会有很多潜在的原因 $\\alpha$，要找到 BE，可以采用概率模型(Charniak and Goldman, 1988; Charniak and Shimony, 1990)，或者启发式方法(Charniak and McDermott)。 下面看一个具体的例子，下面两个句子应该是 Explanation 的关系。1John hid Bill&apos;s car keys. He was drunk. 推理图: 下面看一下具体的过程。首先需要关于 cohesion 本身的公理，表示要确定两个事件有连贯关系，一种可能性是假定两者是解释(explanation)关系$∀ e_i, e_j \\ Explanation(e_i, e_j) =&gt; CoherenceRel(e_i, e_j)$ 然后是需要关于解释(explanation)的公理，要求第二个话段是第一个话段的原因$∀ e_i, e_j \\ cause(e_j, e_i) =&gt; Explanation(e_i, e_j)$ 再然后是代表世界常识的公理，第一条，如果某人喝醉了，我们就不让他开车$∀ x, y, e_i \\ drunk(e_i, x) =&gt; ∃ e_j, e_k diswant(e_j, y, e_k) ∧ drive(e_k, x) ∧ cause(e_i, e_j)$ 第二条，如果某人不想让其他人开车，那么他们就不愿意让这个人拿到他的车钥匙$∀ x, y, e_j, e_k diswant(e_j, y, e_k) ∧ drive(e_k, x) =&gt; ∃ z, e_l, e_m diswant(e_l, y, e_m) ∧ have(e_m, x, z) ∧ carkeys(z, x) ∧ cause(e_j, e_l)$ 第三条，如果某人不想让其他人拥有某件东西，那么他可以将东西藏起来$∀ x, y, z, e_i, e_j diswant(e_l, y, e_m) ∧ have(e_m, x, z) =&gt; ∃e_n hide(e_n, y, x, z) ∧ cause(e_l, e_n) $ 最后一个公理，原因是可传递的$∀e_i, e_j e_k cause(e_i, e_j) ∧ cause(e_j, e_k) =&gt; cause(e_i, e_k)$ 开始假设连贯关系是 explanation，根据公理最后能得到$diswant(e_3, John, e_5) ∧ have（e_5, Bill, carkey)$$diswant(e_4, John, e_6) ∧ drive（e_6, Bi)$=&gt; 推测出$drunk(e_2, Bill)$ 通过 coreference 可以把 he 和 Bill 绑定，这就确立了句子的连贯。然而要注意的是，Abduction 是非可靠的推理，是可废止的(defeasible)。比如说如果紧跟上面句子的下面的句子，那么我们不得不撤销连接之前两个句子的推理连，然后用事实(藏钥匙是恶作剧的一部分)来替代。 1Bill&apos;s car isn&apos;t here anyway; John was just playing a practical joke on him. Discourse Segmentation还有一个任务是 discourse segmentation，目标是将文本切分为一个子话题(subtopics)的线性序列，比如说 常用的方法是 TextTiling，通过词汇层面的共现和分布模式(lexical co-occurrence and distribution)来寻找 subtopic 的边界。它的假设是认为描述 subtopic 的词会局部共现，从一个 subtopic 到另一个 subtopic 的 switch 以一个共现词集合的结束和另一个共现词集合的开始为标志。 步骤: Tokenization进行 tokenization 得到 ABCDE 等 term 以及以句子为单位的词汇单元(sentence-sized units)，如上图 1-8，每一列都是一个 unit Lexical score determination方法有 blocks, vocabulary introductions 和 chains上图表示 blocks 方法，把 k 个句子 group 成 block (一般 K=2)，计算 block lexical score，一般就是向量內积，比如第一个 block 的 score 就是 8=2x1(for A)+1x1(for B)+2x1(for C)+1x1(for D)+1x2(for E)Block 其实就相当于一个 moving window Boundary identification如果一个较低的 lexical score 前面和后面都跟着一个高的 lexical score，那么较低的 lexical score 所在的位置可能就代表了一个 shift，或者说 subtopic change 更多戳论文TextTiling: A Quantitative Approach to Discourse Segmentation 另外还有监督学习的方法，可以训练一个 binary classifier，在句子之间放个 marker，标注这是不是 discourse boundary，使用到的 feature 有1234• Discourse markers or cue words• Word overlap before/after boundary• Number of coreference chains that cross boundary... Context, Speech Acts最后来看一下 context 和 speech acts。 Context同一个句子在不同的情境(context)下的含义可能是不同的。需要考虑的情境： Social contextSocial identities, relationships, and setting Physical contextWhere? What objects are present? What actions? Linguistic contextConversation history Other forms of contextShared knowledge, etc. Speech Acts A speech act in linguistics and the philosophy of language is an utterance that has performative function in language and communication. 语言行为理论(Speech Acts)最初由语言哲学家 Austin 提出，后来由其学生 Searle 进一步发展。核心理论是 Sentences perform actions，说话人只要说出了有意义的，可以被听众理解的话，就可以说他实施了某个行为，这个行为就是 Speech Act。 AustinAustin 最初把言语分为两类，言有所述(constatives)和言有所为(performatives)。判断一个句子是不是 performative 的方法是加上 hereby 来验证，如果句子依然通顺，这个句子就含有 performative verb。1234– I hereby name this ship the Queen Elizabeth.– I hereby take this man to be my husband.– I hereby bequeath this watch to my brother.– I hereby declare war. 加上 hereby 之后，上面的句子依旧 make sense，然而下面这两个句子就不能12– Birds hereby sing.– There is hereby fighting in Syria. 然而后来 Austin 发现用 hereby 来判读一个句子是不是有 performative 有点牵强，于是提出了一个新的模式，一个人说话的时候，同时实施了三种行为，言内行为(locutionary act), 言外行为(illocutionary act), 和言后行为( perlocutionary act) Locuion: say some words通过说话表达字面意义，包括说话时所用的发出的语音、音节、单词、短语、句子 Illocution: an action performed in saying words​ 通过字面意义表达说话人的意图，比如说发出命令​ Ask, promise, command Perlocution: an action performed by saying words, probably the effect that an illocution has on the listener.说话人的话语作用在听众身上所带来的效果Persuade, convince, scare, elicit an answer, etc. SearleSearle进一步说明了人类交际的基本单位不是句子或其他任何表达手段，而是完成一定的行为，并提出了言外行为的几个分类 同时提出了间接言语行为理论(indirect speech acts)，通过某一个言语行为来做另一个言外行为，比如陈述句不是陈述，祈使句不是祈使，疑问句不是疑问的情况等。Indirect speech acts:12– Can you pass the salt?​ • Has the form of a *question*, but the effect of a *directive*. 言语行为理论评述 应用Speech acts 的主要应用应该是对话系统，如下面是任务导向型对话系统的 speech acts 示例 谈判的 speech acts","tags":"nlp discourse-analysis"},{"title":"Neo4j Cypher Cheetsheet","url":"/2017/09/11/Neo4j Cypher Cheetsheet/","text":"内容主要来自 Coursera 课程 Big Data Graph Analytics，在这对 Cypher 语句做个整理，方便查阅。包括基本语句、以及路径分析、链接分析样例。 Neo4j 使用 Cypher 查询图形数据，Cypher 是描述性的图形查询语言，语法简单功能强大，由于 Neo4j 在图形数据库家族中处于绝对领先的地位，拥有众多的用户基数，Cypher 成为图形查询语言的事实上的标准。和 SQL 很相似，Cypher 语言的关键字不区分大小写，但是属性值，标签，关系类型和变量是区分大小写的。 看一下基本的概念 变量(Variable)变量用于对搜索模式的部分进行命名，并在同一个查询中引用，在小括号()中命名变量，变量名是区分大小写的，示例代码创建了两个变量：n 和 b，通过 return 子句返回变量 b； 12MATCH (n)--&gt;(b)RETURN b 访问属性(Property)在 Cypher 查询中，通过点来访问属性，格式是：Variable.PropertyKey，通过 id 函数来访问实体的 ID，格式是 id(Variable)。 123match (n)--&gt;(b)where id(n)=5 and b.age=18return b; 节点(Node)节点模式的构成：(Variable:Lable1 {Key1:Value1,Key2,Value2})每个节点都有一个整数 ID，在创建新的节点时，Neo4j 自动为节点设置 ID 值，在整个数据库中，节点的 ID 值是递增和唯一的。下面的 Cypher 查询创建一个节点，标签是 Person，具有两个属性 name 和 born，通过 RETURN 子句，返回新建的节点： 1create (n:Person &#123; name: &apos;Tom Hanks&apos;, born: 1956 &#125;) return n; 匹配(Match)通过match子句查询数据库，match子句用于指定搜索的模式（Pattern），where子句为match模式增加谓词（Predicate），用于对Pattern进行约束； 1match(n) return n; 关系(Relation)关系的构成：StartNode - [Variable:RelationshipType {Key1:Value1, Key2:Value2}] -&gt; EndNode创建关系时，必须指定关系类型 1234MATCH (a:Person),(b:Movie)WHERE a.name = &apos;Robert Zemeckis&apos; AND b.title = &apos;Forrest Gump&apos;CREATE (a)-[r:DIRECTED]-&gt;(b)RETURN r; 本篇数据集：链接: http://pan.baidu.com/s/1dEHWQch密码: 00v4 Create and Delete建图要求1234567891011121314151617181920212223==============Five NodesN1 = TomN2 = HarryN3 = JulianN4 = MicheleN5 = JosephineFive Edgese1 = Harry ‘is known by’ Tome2 = Julian ‘is co-worker of’ Harrye3 = Michele ‘is wife of’ Harrye4 = Josephine ‘is wife of’ Tome5 = Josephine ‘is friend of’ Michele==============A simple text description of a graphN1 - e1 -&gt; N2N2 - e2 -&gt; N3N2 - e3 -&gt; N4N1 - e4 -&gt; N5N4 - e5 -&gt; N5============== 创建完整的 graph123456create (N1:ToyNode &#123;name: &apos;Tom&apos;&#125;) - [:ToyRelation &#123;relationship: &apos;knows&apos;&#125;] -&gt; (N2:ToyNode &#123;name: &apos;Harry&apos;&#125;),(N2) - [:ToyRelation &#123;relationship: &apos;co-worker&apos;&#125;] -&gt; (N3:ToyNode &#123;name: &apos;Julian&apos;, job: &apos;plumber&apos;&#125;),(N2) - [:ToyRelation &#123;relationship: &apos;wife&apos;&#125;] -&gt; (N4:ToyNode &#123;name: &apos;Michele&apos;, job: &apos;accountant&apos;&#125;),(N1) - [:ToyRelation &#123;relationship: &apos;wife&apos;&#125;] -&gt; (N5:ToyNode &#123;name: &apos;Josephine&apos;, job: &apos;manager&apos;&#125;),(N4) - [:ToyRelation &#123;relationship: &apos;friend&apos;&#125;] -&gt; (N5); ToyNode is a node type and ToyRelation is an edge type. ToyNode can have properties, so can ToyRelation. //View the resulting graph1match (n:ToyNode)-[r]-(m) return n, r, m //Delete all nodes and edges1match (n)-[r]-() delete n, r //Delete all nodes which have no edges1match (n) delete n //Delete only ToyNode nodes which have no edges1match (n:ToyNode) delete n //Delete all edges1match (n)-[r]-() delete r //Delete only ToyRelation edges1match (n)-[r:ToyRelation]-() delete r //Selecting an existing single ToyNode node1match (n:ToyNode &#123;name:&apos;Julian&apos;&#125;) return n Adding or ModifyMerge 子句的作用：当模式（Pattern）存在时，匹配该模式；当模式不存在时，创建新的模式，功能是 match 子句和 create 的组合。在 merge 子句之后，可以显式指定 on create 和 on match 子句，用于修改绑定的节点或关系的属性。 通过 merge 子句，可以指定图形中必须存在一个节点，该节点必须具有特定的标签，属性等，如果不存在，那么 merge 子句将创建相应的节点。 //Adding a Node CorrectlyFirst find a node you wanna add to, then add the node.12match (n:ToyNode &#123;name:&apos;Julian&apos;&#125;)merge (n)-[:ToyRelation &#123;relationship: &apos;fiancee&apos;&#125;]-&gt;(m:ToyNode &#123;name:&apos;Joyce&apos;, job:&apos;store clerk&apos;&#125;) //Adding a Node Incorrectly1create (n:ToyNode &#123;name:&apos;Julian&apos;&#125;)-[:ToyRelation &#123;relationship: &apos;fiancee&apos;&#125;]-&gt;(m:ToyNode &#123;name:&apos;Joyce&apos;, job:&apos;store clerk&apos;&#125;) //Correct your mistake by deleting the bad nodes and edge1match (n:ToyNode &#123;name:&apos;Joyce&apos;&#125;)-[r]-(m) delete n, r, m //Modify a Node’s Information12match (n:ToyNode) where n.name = &apos;Harry&apos; set n.job = &apos;drummer&apos;match (n:ToyNode) where n.name = &apos;Harry&apos; set n.job = n.job + [&apos;lead guitarist&apos;] Import//One way to “clean the slate” in Neo4j before importing (run both lines):12match (a)-[r]-&gt;() delete a,rmatch (a) delete a //Script to Import Data Set: test.csv (simple road network)//[NOTE: replace any spaces in your path with %20, “percent twenty” ]1234LOAD CSV WITH HEADERS FROM &quot;file:///test.csv&quot; AS lineMERGE (n:MyNode &#123;Name:line.Source&#125;)MERGE (m:MyNode &#123;Name:line.Target&#125;)MERGE (n) -[:TO &#123;dist:line.distance&#125;]-&gt; (m) //Script to import global terrorist data123456LOAD CSV WITH HEADERS FROM &quot;file:///terrorist_data_subset.csv&quot; AS rowMERGE (c:Country &#123;Name:row.Country&#125;)MERGE (a:Actor &#123;Name: row.ActorName, Aliases: row.Aliases, Type: row.ActorType&#125;)MERGE (o:Organization &#123;Name: row.AffiliationTo&#125;)MERGE (a)-[:AFFILIATED_TO &#123;Start: row.AffiliationStartDate, End: row.AffiliationEndDate&#125;]-&gt;(o)MERGE(c)&lt;-[:IS_FROM]-(a); When you are loading CSVs you get an error like “Couldn’t load the external resource at: file: […]”, put your csv file in the right path like /Users/shuang/Documents/Neo4j/default.graphdb/import/, the problem will be solved. Basic Graph Operations//Counting the number of nodes12match (n:MyNode)return count(n) //Counting the number of edges12match (n:MyNode)-[r]-&gt;()return count(r) //Finding leaf nodes:Leaf node: the node which have no outgoing edges123match (n:MyNode)-[r:TO]-&gt;(m)where not ((m)--&gt;())return m //Finding root nodes:Root node: the node which have no incoming edges123match (m)-[r:TO]-&gt;(n:MyNode)where not (()--&gt;(m))return m //Finding triangles:Triangle: a three cycle, consisting of three nodes and three edges where the beginning and end node are the same12match (a)-[:TO]-&gt;(b)-[:TO]-&gt;(c)-[:TO]-&gt;(a)return distinct a, b, c //Finding 2nd neighbors of D:2nd neighbor: two nodes away from D123match (a)-[:TO*..2]-(b)where a.Name=&apos;D&apos;return distinct a, b Some nodes appear to be only one node away from the node D but we can get to those nodes indirectly through another node, which means that they’re not only a first neighbor but they’re also a second neighbor. //Finding the types of a node:123match (n)where n.Name = &apos;Afghanistan&apos;return labels(n) //Finding the label of an edge:12match (n &#123;Name: &apos;Afghanistan&apos;&#125;)&lt;-[r]-()return distinct type(r) //Finding all properties of a node:12match (n:Actor)return * limit 20 //Finding loops:12match (n)-[r]-&gt;(n)return n, r limit 10 //Finding multigraphs:Multigraph: any two nodes which have two or more edges between them123match (n)-[r1]-&gt;(m), (n)-[r2]-(m)where r1 &lt;&gt; r2return n, r1, r2, m limit 10 remember to apply a constraint in which the edges must be different for the same pairs of nodes //Finding the induced subgraph given a set of nodes:123match (n)-[r:TO]-(m)where n.Name in [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;] and m.Name in [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;]return n, r, m Path Analytics//Viewing the graph12match (n:MyNode)-[r]-&gt;(m)return n, r, m //Finding paths between specific nodes:Use the match command to match p which is a variable we’re using to represent our path, = node a, going through an edge to node c. There’s something slightly different about this edge, and that is that we’re using a star to represent an arbitrary number of edges in sequence between a and c, and we’ll be returning all of those edges that are necessary to complete the path. And in this case we only want to return a single path.123match p=(a)-[:TO*]-(c)where a.Name=&apos;H&apos; and c.Name=&apos;P&apos;return p limit 1 *Your results might not be the same as the video hands-on demo. If not, try the following query and it should return the shortest path between nodes H and P:1match p=(a)-[:TO*]-(c) where a.Name=&apos;H&apos; and c.Name=&apos;P&apos; return p order by length(p) asc limit 1 //Finding the length between specific nodes:123match p=(a)-[:TO*]-(c)where a.Name=&apos;H&apos; and c.Name=&apos;P&apos;return length(p) limit 1 //Finding a shortest path between specific nodes:Use a built-in command shortestPath123match p=shortestPath((a)-[:TO*]-(c))where a.Name=&apos;A&apos; and c.Name=&apos;P&apos;return p, length(p) limit 1 //All Shortest Paths:Use a built-in command allShortestPaths123MATCH p = allShortestPaths((source)-[r:TO*]-(destination))WHERE source.Name=&apos;A&apos; AND destination.Name = &apos;P&apos;RETURN EXTRACT(n IN NODES(p)| n.Name) AS Paths //All Shortest Paths with Path Conditions:123MATCH p = allShortestPaths((source)-[r:TO*]-&gt;(destination))WHERE source.Name=&apos;A&apos; AND destination.Name = &apos;P&apos; AND LENGTH(NODES(p)) &gt; 5RETURN EXTRACT(n IN NODES(p)| n.Name) AS Paths,length(p) //Diameter of the graph:Diameter: the longest shortest path between two nodes in the graphReturned in the form of an array. We’re using a new term, extract, which is based on the following. Assuming we have matched our path p, we want to identify all of the nodes in p and extract their names. And we’ll return these names as a listing, which we’ll call the variable paths. If there’s more than one shortest path, we’ll get multiple listings of node names.123456match (n:MyNode), (m:MyNode)where n &lt;&gt; mwith n, mmatch p=shortestPath((n)-[*]-&gt;(m))return n.Name, m.Name, length(p)order by length(p) desc limit 1 //Extracting and computing with node and properties:Returned as the variable pathLength.Reduce line begins by setting a variable s equal to 0. And then define a variable e, which represents the set of relationships in a path that’s returned,or in other words, the edges. And we pass that into this variable s, and add to it, the value of the distance that we’ve assigned to that edge.1234match p=(a)-[:TO*]-(c)where a.Name=&apos;H&apos; and c.Name=&apos;P&apos;return extract(n in nodes(p)|n.Name) as Nodes, length(p) as pathLength,reduce(s=0, e in relationships(p)| s + toInt(e.dist)) as pathDist limit 1 The path itself, as we know, begins in H and ends in P. And it has a pathLength of 8, but it has a pathDist of 40.So we could interpret this to mean that even though there are 7 towns between the source town and the destination town, or a pathLength of 8,the actual distance in miles would be a value of 40. //Dijkstra’s algorithm for a specific target node:This is not the path in our network with the least weights. It is the weight of the shortest path based on numbers of hops.1234MATCH (from: MyNode &#123;Name:&apos;A&apos;&#125;), (to: MyNode &#123;Name:&apos;P&apos;&#125;),path = shortestPath((from)-[:TO*]-&gt;(to))WITH REDUCE(dist = 0, rel in rels(path) | dist + toInt(rel.dist)) AS distance, pathRETURN path, distance //Dijkstra’s algorithm SSSP:What we’ve calculated is the shortest hop path with the weights added, the sum of the weights of the edges in that path. This is not the least weight path of the entire network.1234MATCH (from: MyNode &#123;Name:&apos;A&apos;&#125;), (to: MyNode),path = shortestPath((from)-[:TO*]-&gt;(to))WITH REDUCE(dist = 0, rel in rels(path) | dist + toInt(rel.dist)) AS distance, path, from, toRETURN from, to, path, distance order by distance desc Problem not solved. Refer to allshortestPaths error start/end nodes the same with cypher.forbid_shortestpath_common_node=false //Graph not containing a selected node:123match (n)-[r:TO]-&gt;(m)where n.Name &lt;&gt; &apos;D&apos; and m.Name &lt;&gt; &apos;D&apos;return n, r, m //Shortest path over a Graph not containing a selected node:123match p=shortestPath((a &#123;Name: &apos;A&apos;&#125;)-[:TO*]-(b &#123;Name: &apos;P&apos;&#125;))where not(&apos;D&apos; in (extract(n in nodes(p)|n.Name)))return p, length(p) //Graph not containing the immediate neighborhood of a specified node:Remember to take leaf and root node into account.12345678910111213141516match (d &#123;Name:&apos;D&apos;&#125;)-[:TO]-(b)with collect(distinct b.Name) as neighborsmatch (n)-[r:TO]-&gt;(m)wherenot (n.Name in (neighbors+&apos;D&apos;))andnot (m.Name in (neighbors+&apos;D&apos;))return n, r, m;match (d &#123;Name:&apos;D&apos;&#125;)-[:TO]-(b)-[:TO]-&gt;(leaf)where not((leaf)--&gt;())return (leaf);match (d &#123;Name:&apos;D&apos;&#125;)-[:TO]-(b)&lt;-[:TO]-(root)where not((root)&lt;--())return (root) The result for first statement. //Graph not containing a selected neighborhood:12345match (a &#123;Name: &apos;F&apos;&#125;)-[:TO*..2]-(b)with collect(distinct b.Name) as MyListmatch (n)-[r:TO]-&gt;(m)where not(n.Name in MyList) and not (m.Name in MyList)return distinct n, r, m Connectivity Analytics Connectivity analytics in terms of network robustness. In other words, a measure of how resistant a graph network is to being disconnectedTwo ways of connectivity analytics: One computed the eigenvalues, and the second computed the degree distribution. For these examples, we’re going to use the second one, degree distributions. //Viewing the graph12match (n:MyNode)-[r]-&gt;(m)return n, r, m // Find the outdegree of all nodes1234567match (n:MyNode)-[r]-&gt;()return n.Name as Node, count(r) as Outdegreeorder by Outdegreeunionmatch (a:MyNode)-[r]-&gt;(leaf)where not((leaf)--&gt;())return leaf.Name as Node, 0 as Outdegree // Find the indegree of all nodes1234567match (n:MyNode)&lt;-[r]-()return n.Name as Node, count(r) as Indegreeorder by Indegreeunionmatch (a:MyNode)&lt;-[r]-(root)where not((root)&lt;--())return root.Name as Node, 0 as Indegree // Find the degree of all nodes123match (n:MyNode)-[r]-()return n.Name, count(distinct r) as degreeorder by degree // Find degree histogram of the graph123match (n:MyNode)-[r]-()with n as nodes, count(distinct r) as degreereturn degree, count(nodes) order by degree asc //Save the degree of the node as a new node property1234match (n:MyNode)-[r]-()with n, count(distinct r) as degreeset n.deg = degreereturn n.Name, n.deg // Construct the Adjacency Matrix of the graphPhilosophical issue：Every database will allow you some analytical computation and the remainder of the analytical computations must be done outside of the database. However, it is always a judicious idea to get the database to achieve an intermediate result formatted in a way that you would need for the next computation. And then, you use that intermediate result as the input to the next computation. We’ve seen that a number of computations in graph analytics start with the adjacency matrix. So we should be able to force Cypher to produce an adjacency matrix123456match (n:MyNode), (m:MyNode)return n.Name, m.Name,casewhen (n)--&gt;(m) then 1else 0end as value // Construct the Normalized Laplacian Matrix of the graph1234567match (n:MyNode), (m:MyNode)return n.Name, m.Name,casewhen n.Name = m.Name then 1when (n)--&gt;(m) then -1/(sqrt(toInt(n.deg))*sqrt(toInt(m.deg)))else 0end as value Scale View可以调整显示区的大小，浏览器调到 inspect 模式，在 d3 代码区域添加 scale 函数，如下。 References: Neo3j Cypher Refcard 3.2Neo4j Cypher查询语言详解","tags":"knowledge-graph 知识库 neo4j"},{"title":"项目实战--知识图谱初探","url":"/2017/09/05/项目实战-知识图谱初探/","text":"实践了下怎么建一个简单的知识图谱，两个版本，一个从 0 开始(start from scratch)，一个在 CN-DBpedia 基础上补充，把 MySQL，PostgreSQL，Neo4j 数据库都尝试了下。自己跌跌撞撞摸索可能踩坑了都不知道，欢迎讨论。 CN-DBpedia 构建流程知识库可以分为两种类型，一种是以 Freebase，Yago2 为代表的 Curated KBs，主要从维基百科和 WordNet 等知识库中抽取大量的实体及实体关系，像是一种结构化的维基百科。另一种是以 Stanford OpenIE，和我们学校 Never-Ending Language Learning (NELL) 为代表的 Extracted KBs，直接从上亿个非结构化网页中抽取实体关系三元组。与 Freebase 相比，这样得到的知识更加多样性，但同时精确度要低于 Curated KBs，因为实体关系和实体更多的是自然语言的形式，如“奥巴马出生在火奴鲁鲁。” 可以被表示为（“Obama”, “was also born in”, “ Honolulu”）， 下面以 CN-DBpedia 为例看下知识图谱大致是怎么构建的。 上图分别是 CN-DBpedia 的构建流程和系统架构。知识图谱的构建是一个浩大的工程，从大方面来讲，分为知识获取、知识融合、知识验证、知识计算和应用几个部分，也就是上面架构图从下往上走的一个流程，简单来走一下这个流程。 数据支持层最底下是知识获取及存储，或者说是数据支持层，首先从不同来源、不同结构的数据中获取知识，CN-DBpedia 的知识来源主要是通过爬取各种百科知识这类半结构化数据。 至于数据存储，要考虑的是选什么样的数据库以及怎么设计 schema。选关系数据库还是NoSQL 数据库？要不要用内存数据库？要不要用图数据库？这些都需要根据数据场景慎重选择。CN-DBpedia 实际上是基于 mongo 数据库，参与开发的谢晨昊提到，一般只有在基于特定领域才可能会用到图数据库，就知识图谱而言，基于 json(bson) 的 mongo 就足够了。用到图查询的领域如征信，一般是需要要找两个公司之间的关联交易，会用到最短路径/社区计算等。 schema 的重要性不用多说，高质量、标准化的 schema 能有效降低领域数据之间对接的成本。我们希望达到的效果是，对于任何数据，进入知识图谱后后续流程都是相同的。换言之，对于不同格式、不同来源、不同内容的数据，在接入知识图谱时都会按照预定义的 schema 对数据进行转换和清洗，无缝使用已有元数据和资源。 知识融合层我们知道，目前分布在互联网上的知识常常以分散、异构、自治的形式存在，另外还具有冗余、噪音、不确定、非完备的特点，清洗并不能解决这些问题，因此从这些知识出发，通常需要融合和验证的步骤，来将不同源不同结构的数据融合成统一的知识图谱，以保证知识的一致性。所以数据支持层往上一层实际上是融合层，主要工作是对获取的数据进行标注、抽取，得到大量的三元组，并对这些三元组进行融合，去冗余、去冲突、规范化， 第一部分 SPO 三元组抽取，对不同种类的数据用不同的技术提取 从结构化数据库中获取知识：D2R难点：复杂表数据的处理 从链接数据中获取知识：图映射难点：数据对齐 从半结构化（网站）数据中获取知识：使用包装器难点：方便的包装器定义方法，包装器自动生成、更新与维护 从文本中获取知识：信息抽取难点：结果的准确率与覆盖率 尤其是纯文本数据会涉及到的 实体识别、实体链接、实体关系识别、概念抽取 等，需要用到许多自然语言处理的技术，包括但不仅限于分词、词性标注、分布式语义表达、篇章潜在主题分析、同义词构建、语义解析、依存句法、语义角色标注、语义相似度计算等等。 第二部分才到融合，目的是将不同数据源获取的知识进行融合构建数据之间的关联。包括 实体对齐、属性对齐、冲突消解、规范化 等，这一部分很多都是 dirty work，更多的是做一个数据的映射、实体的匹配，可能还会涉及的是本体的构建和融合。最后融合而成的知识库存入上一部分提到的数据库中。如有必要，也需要如 Spark 等大数据平台提供高性能计算能力，支持快速运算。 知识融合的四个难点： 实现不同来源、不同形态数据的融合 海量数据的高效融合 新增知识的实时融合 多语言的融合 知识验证再往上一层主要是验证，分为补全、纠错、外链、更新各部分，确保知识图谱的一致性和准确性。一个典型问题是，知识图谱的构建不是一个静态的过程，当引入新知识时，需要判断新知识是否正确，与已有知识是否一致，如果新知识与旧知识间有冲突，那么要判断是原有的知识错了，还是新的知识不靠谱？这里可以用到的证据可以是权威度、冗余度、多样性、一致性等。如果新知识是正确的，那么要进行相关实体和关系的更新。 知识计算和应用这一部分主要是基于知识图谱计算功能以及知识图谱的应用。知识计算主要是根据图谱提供的信息得到更多隐含的知识，像是通过本体或者规则推理技术可以获取数据中存在的隐含知识；通过链接预测预测实体间隐含的关系；通过社区计算在知识网络上计算获取知识图谱上存在的社区，提供知识间关联的路径……通过知识计算知识图谱可以产生大量的智能应用如专家系统、推荐系统、语义搜索、问答等。 知识图谱涉及到的技术非常多，每一项技术都需要专门去研究，而且已经有很多的研究成果。Anyway 这章不是来论述知识图谱的具体技术，而是讲怎么做一个 hello world 式的行业知识图谱。这里讲两个小 demo，一个是 爬虫+mysql+d3 的小型知识图谱，另一个是 基于 CN-DBpedia+爬虫+PostgreSQL+d3 的”增量型”知识图谱，要实现的是某行业上市公司与其高管之间的关系图谱。 Start from scratch数据获取第一个重要问题是，我们需要什么样的知识？需要爬什么样的数据？一般在数据获取之前会先做个知识建模，建立知识图谱的数据模式，可以采用两种方法：一种是自顶向下的方法，专家手工编辑形成数据模式；另一种是自底向上的方法，基于行业现有的标准进行转换或者从现有的高质量行业数据源中进行映射。数据建模都过程很重要，因为标准化的 schema 能有效降低领域数据之间对接的成本。 作为一个简单的 demo，我们只做上市公司和高管之间的关系图谱，企业信息就用公司注册的基本信息，高管信息就用基本的姓名、出生年、性别、学历这些。然后开始写爬虫，爬虫看着简单，实际有很多的技巧，怎么做优先级调度，怎么并行，怎么屏蔽规避，怎么在遵守互联网协议的基础上最大化爬取的效率，有很多小的 trick，之前博客里也说了很多，就不展开了，要注意的一点是，高质量的数据来源是成功的一半！ 来扯一扯爬取建议： 从数据质量来看，优先考虑权威的、稳定的、数据格式规整且前后一致、数据完整的网页 从爬取成本来看，优先考虑免登录、免验证码、无访问限制的页面 爬下来的数据务必保存好爬取时间、爬取来源(source)或网页地址(url)source 可以是新浪财经这类的简单标识，url 则是网页地址，这些在后续数据清洗以及之后的纠错(权威度计算)、外链和更新中非常重要 企业信息可以在天眼查、启信宝、企查查各种网站查到，信息还蛮全的，不过有访问限制，需要注册登录，还有验证码的环节，当然可以过五关斩六将爬到我们要的数据，然而没这个必要，换别个网站就好。 推荐两个数据来源： 中财网数据引擎 巨潮资讯 其中巨潮资讯还可以同时爬取高管以及公告信息。看一下数据 换句话说，我们直接能得到规范的实体(公司、人)，以及规范的关系(高管)，当然也可以把高管展开，用下一层关系，董事长、监事之类，这就需要做进一步的清洗，也可能需要做关系的对齐。 这里爬虫框架我用的是 scrapy+redis 分布式，每天可以定时爬取，爬下来的数据写好自动化清洗脚本，定时入库。 数据存储数据存储是非常重要的一环，第一个问题是选什么数据库，这里作为 starter，用的是关系型数据库 MySQL。设计了四张表，两张实体表分别存公司(company)和人物(person)的信息，一张关系表存公司和高管的对应关系(management)，最后一张 SPO 表存三元组。 为什么爬下来两张表，存储却要用 4 张表？一个考虑是知识图谱里典型的一词多义问题，相同实体名但有可能指向不同的意义，比如说 Paris 既可以表示巴黎，也可以表示人名，怎么办？让作为地名的 “Paris” 和作为人的 “Paris” 有各自独一无二的ID。“Paris1”（巴黎）通过一种内在关系与埃菲尔铁塔相联，而 “Paris2”（人）通过取消关系与各种真人秀相联。这里也是一样的场景，同名同姓不同人，需要用 id 做唯一性标识，也就是说我们需要对原来的数据格式做一个转换，不同的张三要标识成张三1，张三2… 那么，用什么来区别人呢？拍脑袋想用姓名、生日、性别来定义一个人，也就是说我们需要一张人物表，需要 (name, birth, sex) 来作composite unique key 表示每个人。公司也是相同的道理，不过这里只有上市公司，股票代码就可以作为唯一性标识。 Person 表和 company 表是多对多的关系，这里需要做 normalization，用 management 这张表来把多对多转化为两个一对多的关系，(person_id, company_id) 就表示了这种映射。management 和 spo 表都表示了这种映射，为什么用两张表呢？是出于实体对齐的考虑。management 保存了原始的关系，”董事”、监事”等，而 spo 把这些关系都映射成”高管”，也就是说 management 可能需要通过映射才能得到 SPO 表，SPO 才是最终成型的表。 可能有更简单的方法来处理上述问题，思考中，待更新—- 我们知道知识库里的关系其实有两种，一种是属性(property)，一种是关系(relation)。那么还有一个问题是 SPO 需不需要存储属性？ 最后要注意的一点是，每条记录要保存创建时间以及最后更新时间，做一个简单的版本控制。 数据可视化Flask 做 server，d3 做可视化，可以检索公司名/人名获取相应的图谱，如下图。之后会试着更新有向图版本。 Start from CN-DBpedia把 CN-DBpedia 的三元组数据，大概 6500 万条，导入数据库，这里尝试了 PostgreSQL。然后检索了 112 家上市公司的注册公司名称，只有 69 家公司返回了结果，属性、关系都不是很完善，说明了通用知识图谱有其不完整性(也有可能需要先做一次 mention2entity，可能它的标准实体并不是注册信息的公司名称，不过 API 小范围试了下很多是 Unknown Mention)。 做法也很简单，把前面 Start from scratch 中得到的 SPO 表插入到这里的 SPO 表就好了。这么简单？因为这个场景下不用做实体对齐和关系对齐。 拓展这只是个 hello world 项目，在此基础上可以进行很多有趣的拓展，最相近的比如说加入企业和股东的关系，可以进行企业最终控制人查询(e.g.,基于股权投资关系寻找持股比例最大的股东，最终追溯至自然人或国有资产管理部门)。再往后可以做企业社交图谱查询、企业与企业的路径发现、企业风险评估、反欺诈等等等等。具体来说： 重新设计数据模型 引入”概念”，形成可动态变化的“概念—实体—属性—关系”数据模型，实现各类数据的统一建模 扩展多源、异构数据，结合实体抽取、关系抽取等技术，填充数据模型 展开知识融合(实体链接、关系链接、冲突消解等)、验证工作(纠错、更新等) 最后补充一下用 Neo4j 方式产生的可视化图，有两种方法。一是把上面说到的 MySQL/PostgreSQL 里的 company 表和 person 表存成 node，node 之间的关系由 spo 表中 type == relation 的 record 中产生；二是更直接的，从 spo 表中，遇到 type == property 就给 node(subject) 增加属性({predicate:object})，遇到 type == relation 就给 node 增加关系((Nsubject) - [r:predicate]-&gt; node(Nobject))，得到下面的图，移动鼠标到相应位置就可以在下方查看到关系和节点的属性。 项目地址","tags":"knowledge-graph 知识库"},{"title":"深度学习-过拟合(Andrew Ng. DL 笔记)","url":"/2017/08/29/神经网络-过拟合(Andrew Ng. DL 笔记)/","text":"Andrew Ng. Deep Learning Course 2 Improving Deep Neural Networks 过拟合部分的笔记。 高方差(high variance) 对应的问题就是 过拟合(overfitting)，模型在训练集上表现的非常完美，然而开发集和测试集却有很高的错误率。这时需要引入正则或者多加些数据来调优。这一篇就来讲过拟合的处理方法。方差/偏差的解释戳会议笔记 - Nuts and Bolts of Applying Deep Learning Regularization正则化(Regularization) 是最常见的方法之一。在深度学习中的正则化中，我们保留所有的 unit，但是会压缩其权重。 Loss function对损失函数加上一个正则化参数，一般形式 其中 $\\Omega(\\theta)$ 是参数范数惩罚，$\\alpha \\in [0,+\\infty)$ 是参数范数惩罚程度的超参数，$\\alpha=0$ 代表没有正则化，$\\alpha$ 越大正则化惩罚越大。 $\\Omega(\\theta)$ 有 L1 和 L2 范式，如果用 L1，W 最终会是稀疏的，也就是说 W 中会有很多 0；L2 参数正则化通常被称为权重衰减(weight decay)，实际过程中一般用的是 L2。 $L1: \\ \\ \\ \\ \\Omega(\\theta)=||w||_1$$L2: \\ \\ \\ \\ \\Omega(\\theta)={1 \\over 2}||w||^2_2$ 在原来的损失函数基础上加上正则因子： 权重更新： $min_{w^{[1]},b{[1]},…w^{[L]},b{[L]}, }J(w,b)={1 \\over m}\\sum^m_{i=1}L(\\hat y_{(i)}, y^{(i)}) + {\\lambda \\over 2m}\\sum^L_{l=1}||w||^2_2$ 发现加入 L2 后，每次梯度更新前权重会先乘以 $1-\\alpha {\\lambda \\over m} $，相当于收缩了权重，因此 L2 正则也叫权重衰减(weight decay)。 这里的正则化参数$\\lambda$通常使用 dev_set 来配置。 Why regularization一个直观上的理解是如果 $\\lambda$ 足够大，由上一部分的计算可以得出 W 接近于 0，也就是说很多 hidden units 的权重被降成了 0，这就消除了很多 hidden units 的影响，实际上就是从下面右图的结构转换到了左图。当然事实上并不能说消除了这些 hidden units 的影响，只能说是减少，网络变得更简单罢了。 从另一个角度考虑，$\\lambda$ 变大 =&gt; $W^{[l]}$ 变小 =&gt; z 变小，看一下激活函数，以 tanh 为例，在 z 小的部分，曲线趋于线性，计算接近线性函数的值。如果每一层都是线性的话，那么无论网络有多少层，输出都是输入的线性组合而已，当然就不会过拟合啦。所以说在需要做复杂的决策的时候，$\\lambda$ 不能设太大。另外使用 L2 正则需要搜索合适的 $\\lambda$，花费很大。 Dropout另一种方法是 Dropout，随机删除一些 unit。Dropout 会遍历网络每一层，设置消除网络中节点的概率，对待删除的节点，删除从该节点进出的连线，得到一个节点更少、规模更小的网络，然后用 BP 对这个新的小的网络训练，持续这个过程。因为丢弃的神经元在训练阶段对 BP 算法的前向和后向阶段都没有贡献，所以每一次训练都像是在训练一个新的网络。 这里要讲的是 Inverted dropout，看下代码，keep_prob 表示保留任意一个 hidden unit 的概率，清除任意一个 hidden unit 的概率是 1-keep_prob，在网络第三层，过程如下 123d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_proba3 = np.multiply(a3, d3)a3 /= keep_prob 没有第三行就只是普通的 dropout，在这种情况下，测试阶段我们必须关闭 dropout 模式，去模拟训练阶段的集成网络模型，因为我们不希望最后结果是随机的，不希望预测结果受到干扰。而加了第三行就变成了 inverted dropout，我们只要在训练阶段缩放激活函数的输出值，而不用在测试阶段改变什么(只用修改一个参数)。举个例子，第三层有 50 个 units，keep_prob=0.8，有 10% 的 units 被消除了，那么在下一层，$z^{[4]}=w^{[4]}*a^{[3]}+b^{[4]}$，$a^{[3]}$ 的大小减少了 20%，为了让 $z^[4]$ 的期望值不变，或者说 $a^{[3]}$ 的期望值不变，需要补上这 20%，所以 $w^{[4]}*a^{[3]}/0.8$。 Why dropout很直接的思路，每次迭代网络都变小了，自然就减少了过拟合的可能。另一种解释是，dropout 使得神经网络不能依靠任何一个特征，因为每个特征都有可能被随机清除，这样的将结果是网络不会给一个 unit 特别大的权重，而是会 spread out weight，给每个 unit 都增加一点权重。而分散所有权重其实就产生了和 L2 类似的压缩权重的效果。 相对于 L2 正则，dropout 可以处理多样化的输入，然而 dropout 方法不会阻止参数过大，参数之间也不会互相牵制，所以有时需要配合使用 L2 或者其他正则化来改变这个情况。 另外提到的一个技巧是，可以对不同层设置不同的 keep_prob。如下图，第一层 W 矩阵是 3x7，过拟合的可能性小一些，可以留下 70% 的 unit，第二层是 7x7，更可能过拟合，所以少保留一些，设 keep_prob=0.5，由此类推，给每一层设定不同的 keep_prob，对不需要担心过拟合的层，直接设为 1。 还有要注意的是，dropout 开启的情况下损失函数不再是定义良好的，也就没法根据损失函数的效果图来 debug，所以一般在看代码有没有 bug 的时候先会关闭 dropout。 Others Data Augmentation解决过拟合的另一个思路是使用更多的数据，所以当数据量不够的时候，会进行数据增强。 数据集的各种变换，如对图像的平移、旋转、缩放、裁剪、扭曲变形。 在输入层注入噪声，如去噪自编码器，通过将随机噪声添加到输入再进行训练能够大大改善神经网络的健壮性。 Early Stopping同时画出 train error 和 dev error，会发现 dev error 先下降然后到某个点会上升，所以在迭代到某次觉得结果不错的时候，提前停止训练。w 在最开始的时候值很小，到后面的时候会很大，在中间的时候可能得到一个中等大小的 Frobenius norm，和 L2 正则相似，我们要选择 W 范数较小的神经网络。找 small, large, middle 几个点，不用像 L2 正则那样尝试很多的 $\\lambda$ 参数，这时 early stopping 的优势，然而过早的停止可能对损失函数 J 的优化不到位，loss 不够小。","tags":"deep-learning 过拟合 overfitting"},{"title":"EMNLP 2017 北京论文报告会笔记","url":"/2017/08/21/EMNLP 2017 北京论文报告会笔记/","text":"16 号在北京举办的，邀请了国内部分被录用论文的作者来报告研究成果，整场报告会分为文本摘要及情感分析、机器翻译、信息抽取及自动问答、文本分析及表示学习四个部分。感觉上次的 CCF-GAIR 参会笔记 写的像流水账，这次换一种方式做笔记。 分为四个部分，并没有包含分享的所有论文。第一部分写我最喜欢的论文，第二部分总结一些以模型融合为主要方法的论文，第三部分总结一些对模型组件进行微调的论文，第四部分是类似旧瓶装新酒的 idea。 I likeMultimodal Summarization for Asynchronous Collection of Text, Image, Audio and Video异步的文本、图像、音视频多模态摘要，一般的文本摘要关注的是 salience, non-redundancy，这里关注的是 readability, visual information，visual information 这里说的就是图片信息，暗示事件的 highlights。考虑一个视频新闻，本身有视觉模态和音频模态，通过 ASR，还可以产生文本模态，问题是如何将这些模态连接起来，产生一个附带精彩图片的文本摘要呢？ 这篇论文就在讨论这个问题，整个模型输入是一个主题的文本以及视频，输出是一段附图片的文本摘要。 1. 预处理：视频产生图片：CV 基本思路，把 Video 切成一个个的 shots(镜头/段落)，每个镜头可以 group(组合) 成一个 story(scene)，每一个镜头还可以细分成 sub-shots，每个 sub-shot 可以用 key-frame 来表示，选择关键帧作为视觉信息，同时认为长镜头的图片相对于短镜头更重要，基于此对图片重要性进行打分。音频产生文字：ASR。一方面语音识别结果并不十分准确，另一方面音频模态会有一些音频信号可以暗示我们哪些内容是重要的，基于这两点会产生两个指导策略，稍后提到。 2. 文本重要性打分：用 LexRank，句子是点，连线是重要性，进行随机游走，针对音频产生文字的两个特性使用两个指导策略: 如果语音识别结果和文本句子语义相同，那么让语音识别结果来推荐文本，反之不然； 如果语音信号比较明显，语音推荐文本，反之不然； 这两条指导策略会提升文本可读性。 3. 图文匹配问题：希望摘要能覆盖视觉信息，能解释图片，所以需要做一个文本图片分类器。图像 vcr 解码接两层前向网络，文本做一个高斯分布再求 fisher rank，也是接两层前向网络，最终将两个文本映射到同一个语义空间，计算匹配度。 一个问题是如何在复杂的句子里提出子句，作者提出了基于传统语义角色标注的方法，利用中心谓词提取匹配的 frame 信息(predicate, argument1, argument2)，好处是可以抽取语义相对独立的部分，还可以通过 frame 的设定(只取施、受、谓词)过滤如时间等图片很难反映的信息。 4. 目标函数：提到了三个目标函数： 针对文本：对文本重要性奖励、冗余性惩罚 针对视觉：图片重要性(镜头时长)，是否被文本摘要覆盖(是否有匹配) 平衡视觉信息和文本信息 下面一篇 Affinity-Preserving Random Walk for Multi-Document Summarization 多文档摘要也用到了图排序模型，这里略过。 Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension聚焦两个问题：如何去获取并且表示常识知识？并且如何应用获取到的常识知识进行推理？ 论文尝试从多个不同来源的异构知识库当中获取了相关的信息，并将这些知识统一表示成了带有推理代价的推理规则的形式，采用一个基于注意力机制的多知识推理模型，综合考虑上述所有的知识完成推理任务。 任务类型： 在 RocStories 数据集上，在给定一个故事的前 4 句话的情况下，要求系统从两个候选句子当中选出一个作为故事的结尾。 推理规则：统一将知识表示成如下的推理规则的形式，在关系 f 下，元素 Y 可以由元素 X 推出，其推理代价是 s。 知识获取主要从不同来源获取三类知识，包括： 事件序列知识(Event Narrative Knowledge)捕捉事件之间的时间、因果关系(去了餐馆 -&gt; 要点餐)采用两个模型来捕捉这个信息，一种是基于有序的 PMI 模型，另外一个基于Skip-Gram的向量化表示模型，本质都是基于事件对在文本当中的有序共现的频繁程度来计算推理规则的代价的。 实体的语义知识(Entity semantic knowledge)捕捉实体之间的语义关系以星巴克为例，捕捉的第一种关系是实体间的共指关系(coreference)，比如说用“咖啡屋”来指代星巴克。从 Wordnet 来获取实体间上下位关系的知识。cost 是 1 当且仅当 X 和 Y 是同义词或者有上下位关系​ 第二种关系是相关关系(associative)，比如说出现星巴克时可能会出现“拿铁咖啡”这一类与之相关的实体。通过 Wikipedia 中实体页面的链接关系来得到实体间的相关关系知识，Cost 是两个实体间的距离(Milne and Witten(2008).) 情感的一致性知识(Sentiment coherent knowledge)捕捉元素间的情感关系故事的结尾和故事的整体的情感应该基本上保持一致，否则结尾就会显得太突兀，那么这样的结尾就不是一个好的结尾。从 SentiWordnet 上来获得这种不同元素之间的情感一致性的知识。cost 为 1 if both subjective and have opposite sentimental polarity; 为 -1 if both subjective and have same sentimental polarity; 否则为 0 上述推理规则代价的计算方式不同，论文使用了一种类似于 Metric Learning的方式，通过在每个类别的推理规则上增加了一个非线性层来自动学习对不同类别的推理规则代价的校准。 另外，由于否定的存在会反转事件关系以及情感关系的推理结果，论文对否定进行了特殊处理。 知识推理如何将规则用到阅读理解之中？换句话说，就是在给定一个文档和候选答案的基础上，如何衡量候选答案是否正确？首先将文档以及候选答案都划分为元素，整个推理的过程就被转化成了一个推理规则选择以及对这个推理的合理性进行评估的过程。 重要假设：一组有效的推理应当要能够覆盖住结尾当中的所有元素。换言之，结尾当中出现的每一个元素，都应当能够在原文当中找到它出现的依据。 对于同样的一个文档和候选答案，我们可以有多种多样不同的推理。上面一个推理就是一组有效的推理，这组推理是很符合人的认知的。因为我们通常会通过 Mary 和 She 之间的实体共指关系、Restaurant 和 order 之间的序列关系以及 restaurant 和 food 之间的相关关系来判断这个结果是不是成立的。 这个就不怎么合理，因为我们不太会去考虑一个人和一个事件之间是不是有时序关系，以及考虑 walk to 这样一个动作和 food 之间的联系。 采用每一种推理的可能性是不同的，用 $P(R|D, H)$ 来对这种推理的选择建模，基于元素独立性假设，得到下面的式子 是否选择一条推理规则参与推理一个假设元素 $h_i$，取决于对于原文当中推理得到 $h_i$ 的元素 $d_j$ 的选择，以及对于 $d_j$ 到 $h_i$ 之间推理关系的选择。然后将这个概率分布重新定义了一个重要性函数，与三个因子相关: s(h,d)文档中的元素与候选答案中元素的语义匹配程度 a(h,f) 以及 a(d,f)一个元素与这条推理规则的关系的一个关联程度，使用一个注意力函数来建模这种关联程度 将原文到候选的推理代价定义成其所有有效的推理的期望代价 使用一个 softmax 函数来归一化所有候选的代价值，并且使用最大后验概率估计来估计模型当中的参数。 实验三个 Baseline 进行了比较： Narrative Event Chain (Chambers and Jurafsky, 2008)仅仅考虑是事件与事件之间的关联信息 DSSM (Huang et al., 2013)将文档和候选答案各自表示成了一个语义向量，并且计算它们之间的语义距离 LSTM 模型 (Pichotta and Mooney, 2015)通过对先前的事件进行序列建模来预测后面发生事件的概率。 不同知识的影响每一种知识都能够起到作用，移除任何一种知识都会导致系统的performance显著地降低。 推理规则选择方式加入 attention 机制的影响 其他一是推理规则怎样产生更多更复杂的推理？二是训练数据，一方面，常识阅读理解数据还是很缺乏，可能需要半监督或远程监督的方法来拓展训练数据；另一方面，可能需要扩展更多的数据源。 Neural Response Generation via GAN with an Approximate Embedding Layer生成式聊天系统可以看作是一个特殊的翻译过程，一个 question-answer pair 等价于 SMT 需要处理的一条平行语料，而 SMT 的训练过程实际上也就等价于构建问题和答案当中词语的语义关联过程。NMT 作为 SMT 高级版可以用来实现聊天回复的自动生成。这种新的自动聊天模型架构命名为 Neural Response Generation(NRG)。 而现在 NRG 存在问题是生成的答案严重趋同，不具有实际价值，如对于任何的用户 query，生成的结果都有可能是“我也觉得”或“我也是这么认为的”，这种生成结果被称为 safe response。safe response 产生原因如下： The data distribution of chat corpus The fundamental nature of statistical models 聊天数据中词语在句子不同位置的概率分布具有非常明显的长尾特性，尤其在句子开头，相当大比例的聊天回复是以“我”“也”作为开头的句子，词语概率分布上的模式会优先被 decoder 的语言模型学到，并在生成过程中严重抑制 query 与 response 之间词语关联模式的作用，也就是说，即便有了 query 的语义向量作为条件，decoder 仍然会挑选概率最大的“我”作为 response 的第一个词语，又由于语言模型的特性，接下来的词语将极有可能是“也”……以此类推，一个 safe response 由此产生。 常见的解决方案包括：通过引入 attention mechanism 强化 query 中重点的语义信息；削弱 decoder 中语言模型的影响；引入 user modeling 或者外部知识等信息也能够增强生成回复的多样性。这些其实是对于模型或者数据的局部感知，如果从更加全局的角度考虑 safe response 的问题，就会发现产生 safe response 的 S2S 模型实际上是陷入了一个局部的最优解，而我们需要的是给模型施加一个干扰，使其跳出局部解，进入更加优化的状态，那么最简单的正向干扰是，告知模型它生成的 safe response 是很差的结果，尽管生成这样的结果的 loss 是较小的。这样就开启了生成式对抗网络（Generative Adversarial Networks, GAN）在生成式聊天问题中的曲折探索。 将 GAN 引入聊天回复生成的思路：使用 encoder-decoder 架构搭建一个回复生成器G，负责生成指定 query 的一个 response，同时搭建一个判别器 D 负责判断生成的结果与真正的 response 尚存多大的差距，并根据判别器的输出调整生成器 G，使其跳出产生 safe response 的局部最优局面。 一个重要的问题是如何实现判别器 D 训练误差向生成器 G 的反向传播(Backpropagation)。对于文本的生成来说，一个文本样本的生成必然伴随 G 在输出层对词语的采样过程，无论这种采样所遵循的原则是选取最大概率的 greedy思想还是 beam searching，它实际上都引入了离散的操作，这种不可导的过程就像道路上突然出现的断崖，阻挡了反向传播的脚步，使对于 G 的对抗训练无法进行下去。这篇论文就针对文本生成过程中的采样操作带来的误差无法传导的实际问题提出了解决方案。 论文为生成器 G 构建了一个 Approximate Embedding Layer(AEL 如图中红色矩形框中所示，其细节在图右侧部分给出)，这一层的作用是近似的表达每次采样过程，在每一个 generation step 中不再试图得到具体的词，而是基于词语的概率分布算出一个采样向量。这个操作的具体过程是，在每一个 generation step 里，GRU 输出的隐状态 $h_i$ 在加入一个随机扰动 $z_i$ 之后，经过全连接层和 softmax 之后得到整个词表中每个词语的概率分布，我们将这个概率分布作为权重对词表中所有词语的 embedding 进行加权求和，从而得到一个当前采样的词语的近似向量表示（如图中右侧绿框所示），并令其作为下一个 generation step 的输入。同时，此近似向量同样可以用来拼接组成 fake response 的表示用于 D 的训练。不难看出，这种对于采样结果的近似表示操作是连续可导的，并且引入这种近似表示并不改变模型 G 的训练目标。 取得了不错的效果。 详细戳首发！三角兽被 EMNLP 录取论文精华导读：基于对抗学习的生成式对话模型浅说 模型融合把传统模型和神经网络相结合。 Translating Phrases in Neural Machine Translation目前的 NMT 里 decoder 一次生成一个单词，不能进行 one-many 以及 many-many 的翻译，也就是没法做目标语言 phrase 的翻译，而 SMT 能做，所以想法是把两者结合。结合方法一般来说有两种，一是 shallow，NMT 作为 feature 放到传统框架进行预调；二是 deep，SMT 给 NMT 做推荐，NMT 用神经网络的方式接收 SMT 的东西。这篇论文用的是第二种方式。 SMT 先翻译一遍，把 relevant target phrases 扔到 NMT 的 Phrase Memory 里，NMT 从 Phrase Memory 里读取 target phrases 并进行打分，然后系统同时看 target phrase 和 word predictor 的结果，用一个 balancer 将 SMT 和 NMT 的优势结合起来，来判断下一个是单词还是短语的概率，来决定选哪个。所以其实产生的翻译 $y={y_1, y_2, …, y_{T_u}}$其实有两个碎片(fragments)组成，NMT 的 word predictor $w={w_1, w_2,…,w_K}$ 以及 phrase memory 里存的相关短语 $p={p_1,p_2,…p_L}$ (这里的relevant target phrases 要满足两个条件：与原文相关(adequacy)；不重复翻译(coverage)) 另外一点是作者还提出了基于 chunk 的翻译，SMT 对 source 提取 Chunk 信息，把布什总统、美国政府这些作为 chunk 让 SMT 预翻，然后把它们写到 phrase memory 里，后续步骤不变。chunk 的实现主要是由 sequence tagging 完成，相同 tag 表示同一个 chunk，开始符号另外标记，比如 “information security” 被标注成 “NP _B NP”，然后新的输入就变成原来的 word embedding 以及 chunking tag embedding。chunk 的好处在于限定了 source-side phrase 的信息，一方面减少了短语间的 overlap，另一方面提高了 decoding 的准确性。 机器翻译相关戳NLP 笔记 - Machine TranslationNLP 笔记 - Neural Machine Translation 问题是 SMT 没那么强(很难保证准确率)，NMT 也没那么弱(一个单词一个单词的翻译也能把正确的短语翻译出来) Incorporating Relation Paths in Neural Relation Extraction提出了对文本中的关系路径进行建模，结合 CNN 模型 (Zeng, et al. (2014). Relation classification via convolutional deep neural network. CGLING) 完成关系抽取任务。传统基于 CNN 的方法，通过 CNN 自动将原始文本映射到特征空间中，以此为依据判断句子所表达的关系 这种 CNN 模型存在的问题是难以理解多句话文本上的语义信息。比如说 A is the father of B. B is the father of C. 就没法得出 A 和 C 的关系，基于此，论文提出了在多样例学习机制的基础上引入关系路径编码器的方法，其实就是原来的 word embedding 输入加上一层 position embedding，position embedding 将当前词与 head entity/tail entity 的相对路径分别用两个 vector 表示。然后用 $\\alpha$ 来平衡 text encoder(E) 和 path encoder(G)。$$L(h,r,t)=E(h,r,t|S)+\\alpha G(h,r,t|P)$$ Encoder 用的是多样例学习机制(Multi-instances Learning)，也就是用一个句子集合联合预测关系，这样可以捕获更广泛的上下文。句子集合的选择方法有随机方法(rand)，最大化方法(max, 选最具代表性的)，选择-注意力机制(att)，注意力机制的效果最好。 实验结果： 之后可以继续的两个改进方向，一是对多步关系路径进行建模，使得模型可以处理更复杂的语义情况，而是将文本中的关系路径和知识图谱中的关系路径有机地结合，更好地完成关系抽取和知识图谱补全的任务。 零件调整对已有模型零部件的一些调整改造。 Towards a Universal Sentiment Classifier in Multiple languages这里我觉得有意思的一点是作者模仿了 skip-gram 模型提出了一种同时训练多语言的 embedding 的方法。一句话解释就是通过中心词来预测自身/其他语言周围的前后词。比如说双语预料中，需要使中文能预测中文自身的周围词，英文能学习英文自身的周围词，还要通过对齐来学习中文来预测英文、英文来预测中文。skip-gram 相关戳 词向量总结笔记（简洁版）。 C 作为 source language S 和 target language T 之间的平行语料，语料库可以分为 $C_S$ 和 $C_T$ 两部分，目标函数如下 然后就用一个 LR 模型进行情感分类。 Neural Machine Translation with Word Predictions 我们知道在 NMT 中，训练成本主要来自于输出层在整个 target vocabulary 上的 softmax 计算，为了减小这种 cost，各位学者做出了各种努力，比如说 Devlin et al. (2014) 从计算角度提出了 self-normalization 技术，通过改造目标函数把计算整个 matrix 的步骤优化为只计算输出层每一行的值(NLP 笔记 - Neural Machine Translation)，而在 Neural Machine Translation with Word Predictions 这篇论文中，作者提出了一种减小 target vocabulary 的方法，主要用到了词预测机制(word predictor)。 之前 MT 的目标是生成一个词序列(ordered sequence)，而现在 word predictor 的目标是生成 y1..yn 的词，但是不考虑词序(no order)。 和上图一样的 idea，word prediction 中，initial state($WP_E$)要包含 target sentence 里的所有信息，hidden state(WP_D)要包含没有被翻译的词的所有信息。 $$P_{WP_E}(y|x)=\\prod^{|y|}_{j=1}P_{WP_E}(y_j|x)$$$$P_{WP_D}(y_j,y_{j+1},…,y_{|y|}|y_{&lt;j},x)=\\prod^{|y|}_{k=j}P_{WP_D}(y_k|y_{&lt;j},x)$$ 这样无论是效果和效率上都有了显著提升 这个方法很好的一点是目标中的词对词预测来说是天然的标注，构造简单。然而要注意的两个点是 预测要准&amp;预测要快，否则就失去了意义。还有个问题是，按理来说较大词表质量更好然而翻译效率低，较小的词表，像这篇论文提出的，翻译某句话提前先预测生成一个新的小的词表交给 decoder，效率毫无疑问会提升，但是质量，为啥会更好？不是很理解，坐等论文。 Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation对传统 tree-based encoder 的一个改进。传统的 tree-based encoder 是 bottom-up 的结构，能抓局部信息却捕捉不了全局信息 这篇论文对 tree-based encoder 做了改造，让它既能捕捉局部的语义信息，又能捕捉全局的语义信息。 bottom-up encoding 取得局部信息，top-down encoding 取得全局信息。对于 OOV(out-of-vocabulary) 问题，基于 sub-word 思想，这里单独建立一个二叉词法树并将其融入原来的句法树里。这样如下图所示，模型囊括了句子、短语、词、sub-word 各种全局/局部信息，表达力 max。然而同样带来的问题是会产生重复信息，进而可能会造成重复翻译。 为解决重复翻译的问题，或者说词/短语向量的 balance，这里还引入了 attention 机制 效果有了一定提升。举个例子说明 tree-based encoder 的优势。用普通的 sequence encoder 翻译 PP 时会产生错误，普通的 tree-based 能翻译好 PP，不过 境外 和 以外的地区 还是有一点差距的，新版 tree-decoder 翻译就无压力。 迁移 idea其实就是用已有的但可能用在别的方面的模型/思路解决现在的问题。 A Question Answering Approach for Emotion Cause Extraction这一部分之前木有研究过，先来看一下什么是 emotion cause extraction 1234Document: 我的手机昨天丢了，我现在很难过。 (I lost my phone yesterday, and I feel sad now. )Emotion：Sad Emotional Expression: 很难过Emotion Cause: 我的手机昨天丢了 任务目标是根据文本信息及其中包含的情感表达抽取出情感原因。论文作者之前发过论文，用的是基于 dependency parsing 的方法，把情感原因转化为树的分类任务，但结果依赖 dependency parsing 的准确性，而且只能处理对子句／句子级别的原因，不能处理细粒度的短语级别的原因。所以这一篇转换了思路，把 emotion cause extraction 问题转化为 question-answering 问题，提出了一种基于卷积的多层 memory network 方法，结果比之前基于树的方法提升了 2 个点。 123Emotional Text =&gt; Reading TextEmotional Words =&gt; Question/QueryEmotion Cause Binary Classification Results =&gt; Answer 用传统的 memory network 作为基础模型，reading text 用词向量 embedding 表达，存到记忆单元，待判断的情感词的词向量作为注意力单元，将 query 和 text 每个词进行内积操作，softmax 归一化作为词权重，用注意力的加权和作为整个句子的表达。为了引入词语的上下文，用了类似卷积的注意力加权方法，每个词的注意力由当前词、前文词、后文词共同决定，加权过程中根据上下文注意力对不同位置的词语进行加权，获得以短语窗口为单位的加权结果，然后进行输出。同时对记忆网络做了多层的堆叠，以学习更深的特征。最后效果得到了提升，并且在短语级别的情感原因抽取上也取得了不错的效果。 问题来了，query 是怎么产生的呢？=&gt; 数据集标注好了情感表达词！ Earth Mover’s Distance Minimization for Unsupervised Bilingual Lexicon Induction主要研究无监督的双语对齐方法，也就是能无监督地联系两个词向量空间，本质上是需要词向量空间之间，或者说词向量分布之间距离的度量。用的 EMD 思想，目标就是寻找一个映射G，使得映射后的源语言词向量分布和目标语言词向量分布的 EMD 或者说 Wasserstein 距离最小化。具体等论文发表再研究了。 Chinese Zero Pronoun Resolution with Deep Memory Network解决中文的零指代消解问题。主要思路，用上下文来表示 ZP，使用两个 LSTM，一个对前文建模(left-to-right)，一个对后文建模(right-to-left)，然后连接两边最后一个隐层的向量作为 AZP 的表达(也可以尝试平均／求和) 接着，给定一个 AZP，会有一个 NP 集合被抽出来作为 candidate antecedents，根据每个 candidate antecedent 的重要性产生一个额外的 memory，通过对两个 LSTM(一个前向一个反向) 产生的 hidden vectors 各自进行减法操作然后连接产生最后的 vector 作为最终 candidate antecedents 的表达，并存入外部的 memory 中。 这样我们的 memory 里就有了一堆的候选 candidate antecedents，接着要对 candidate antecedents 的重要性做一个排序，选择合适的 NP 来 fill in the gap (ZP)。这里用了 attention 机制，并加入了一些人工特征(Chen and Ng (2016))，表示为 $v_t^{(feature)}$ 模型用到了人工特征，能不能改进？ZP 位置必须事先指定，能不能自动检测？还有是对 OOV 怎么处理。 小结整场报告会听下来，收获还是有很多的，只是不如想象中那么惊艳，替换零部件，加个 attention，融入传统特征，有很多的套路，最大一个收获可能是再次意识到了 attention 机制的强大，大部分论文用了 attention 结果都有大幅的改善。anyway，能提高准确率/训练效率的模型就是好模型！大家都是棒棒哒！学习！ 周三开完会，周四飞深圳，周五上班，周六日去了澳门浪，好不容易开始笔记，发现好多内容都快忘了，有点难过 TAT，虽然我也有长短期记忆，也禁不起这么折腾… 最后叨叨一句，大部分论文都没发表出来，如果有错误，各位多包容，也热切欢迎大家批评指正～ 文末彩蛋(其实还有张 Wu &amp; Tang 喝着喜茶打农药的高清大图，我先犹豫下要不要发～)","tags":"ai nlp machine-translation relation-extraction"},{"title":"深度学习-学习优化(Andrew Ng. DL 笔记)","url":"/2017/08/15/深度学习-加快学习速度/","text":"Andrew Ng. Deep Learning Course 2 Improving Deep Neural Networks 笔记，讲加快学习速度的几种方法，包括 input normalization，batch normalization，mini-batch，Momentum，RMSprop，Adam，learning rate decay 等。 归一化输入神经网络训练开始前，一般需要对输入数据做归一化处理，把数据归一化为 0 均值、方差为 1 的数据，步骤如下： 零均值化$u={1\\over m} \\sum^m_{i=1}x^{(i)}$$x=x-u$ 方差归一化$\\sigma^2={1\\over m}\\sum^m_{i=1}x^{(i)}**2$$x/=\\sigma^2$ 归一化后的数据分布： 问题是为什么要归一化？或者说什么时候需要归一化？ 一方面是可以提高学习速率，主要考虑 代价函数，左图代表未归一化的代价函数，右图代表归一化的代价函数，未归一化的代价函数是狭长的，需要更小的学习率，更多的迭代才能到最小值，而归一化后的函数是偏球形的，无论从哪个位置开始，梯度下降法都能够更直接的找到最小值，这样就可以在梯度下降中使用较大步长，优化代价函数 J 更简单快速。 另一个角度是从数据分布角度来看，如果训练数据和测试数据的分布不同，网络的泛化能力会大大降低，另一方面，如果每个 mini-batch 的数据分布不同，网络就需要去学习适应不同的分布，这也会影响学习速度。 当然有些时候并不需要归一化，比如说如果数据本身特征值就在相似范围内，那么归一化就不是很重要，相反，如果特征值的取值范围差别很大，有些特征值从 0 到 1，有些从 1 到 1000，归一化特征就很重要了。 只有输入特征归一化很多时候是不够的，因为除了输入层，后面隐藏层每一层的输入数据分布是一直在发生变化的，比如第二层输入就是由第一层的参数和原始输入计算得到的(z=wx+t, a=g(z))，而第一层的参数在整个训练过程中一直在变化，这必然会引起后面每一层输入数据分布的改变，这种现象(中间层在训练过程中数据分布的改变)又叫做 “Internal Covariate Shift”。 一个直觉就是把归一化不只应用到输入层，也应用到深度隐藏层，这就有了 batch normalization。不过一个区别是，我们不希望 hidden unit value 必须是均值 0 方差 1 的分布(以 sigmoid 为例，如果 z 的均值为 0 方差为 1，就永远处于 sigmoid 线性部分，相当于把这一层网络学到的特征分布给搞坏了，我们不希望这样)，所以对每个 mini-batch 求均值、方差、归一化、并学习缩放参数： $$\\begin{aligned}u &amp;= {1\\over m} \\sum^m_{i=1}z^{(i)} \\\\\\sigma^2 &amp;= {1\\over m}\\sum^m_{i=1}z^{(i)}**2 \\\\z^{(i)}_{norm} &amp;= z^{(i)}-{\\mu \\over \\sqrt{\\sigma^2 + \\epsilon} } \\\\z^{N(i)} &amp;= \\gamma z^{(i)}_{norm} + \\beta \\\\ \\end{aligned}$$ $\\gamma, \\ \\beta$ 都是需要学习的参数，每一层都不同，可以用 gradient descent 来学习，$\\beta^{[i]}=\\beta^{[i]}-\\alpha d\\beta^{[i]}$。在深度学习框架，一般是把 batch norm 应用于 batch norm layer，直接一行代码就搞定啦。 在测试阶段，每次只有一个样本，$\\mu, \\sigma$ 哪里来？这需要我们进行估算，可以在网络训练完后运行整个训练集得到 $\\mu, \\sigma$，也可以在训练时做指数加权平均，来粗略估算 $\\mu, \\sigma$，然后在测试中使用。 最后提一点，由于 Norm 对 z 加了噪音，所以有轻微的 regularization effect 的效果，迫使后面的单元不会过分依赖前面任何一个单元， 当然越大的 mini-batch size 会减小这种效果。 优化算法Mini-batch对整个训练集进行梯度下降时，必须处理完整个训练集后，才能将进行一步梯度下降法，如果把训练集分割为小一点的子训练集(mini-batch)，每次同时处理单个 mini-batch，那么 1个 epoch 虽然只遍历了一次训练集，却能够做 5000 个(如下图)梯度下降 Mini-batch 梯度下降法比 batch 梯度下降运行更快，那么一个问题是 怎么选择 mini-batch size? size=mBatch gradient descent(BGD)每一次迭代都对 m 个样本进行计算，计算量大，耗时长 size=1如果 minibatch 的 size 为 1，就称为 随机梯度下降(stochastic gradient descent, SGD)，每次迭代仅对一个样本计算梯度，随机梯度下降永远不会收敛，只会在最小值附近波动，但并不会达到并在最小值处停下，也就很容易陷入局部最优解另外，每次处理一个样本，SGD 并没有利用 vectorization 的优势 1 &lt; size &lt; m介于 BSD 和 SGD 之间，每次选取一定量的训练样本将进行迭代，速度比 BGD 快，比 SGD 慢，精度比 BGD 低，比 SGD 高 另外还有一种方法是 带 mini-batch 的 SGD，用来缓解 SGD 每次用一个样本容易陷入局部最优解的问题，过程是样本分为 mini-batch，然后在对每个 mini-batch 里计算单个样本的梯度然后求和取平均作为该 mini-batch 的梯度来更新参数。 最后还有一种 Online GD，应对线上实时的、有不间断的训练数据产生的应用。在线学习(Online Learning) 算法就是充分利用实时数据的一个训练算法。与 mini-batch GD/SGD的区别在于，所有训练数据只用一次，然后丢弃。这样做的好处是可以追踪模型的变化趋势。比如搜索广告的点击率(CTR)预估模型，网民的点击行为会随着时间改变。用batch算法(每天对所有历史数据重新训练更新模型)，耗时长，也无法及时反馈用户的点击行为迁移。 Momentum比标准的 gradient descent 要快，基本想法是，计算梯度的 指数加权平均数(exponentially weighted average of gradients)，并利用该梯度更新权重。 直观上讲，希望横轴学习更快，纵轴学习更慢(不希望有那么剧烈的波动)，Momentum 的过程如下： On iteration t: Compute dw, db on current mini-batch$$\\begin{aligned}​ v_{dw} &amp;= \\beta v_{dw}+(1-\\beta)dw \\\\​ v_{db} &amp;= \\beta v_{db}+(1-\\beta)db \\\\​ w &amp;= w-\\alpha v_{dw} \\\\​ b &amp;= b-\\alpha v_{db} \\\\ \\end{aligned}$$​平均这些梯度，纵轴上的波动平均值接近于 0，平均过程中，正负抵消，纵轴方向摆动变小，而所有的的微分都指向横轴，横轴的平均值仍然很大，横轴方向运动更快，相当于走了更直接的路径。把代价函数想象成碗状函数，那么微分项提供了加速度，momentum v 像速度，$\\beta$ 表现出摩擦性，所以球不会无限加速下去，原来的 gradient descent 每一步独立于上一步，而现在球可以从向下滚获得动量。 初始化的 $V_{dw}=0，V_{db}=0$，两个矩阵分别和 dw、db 有相同维数。也有做法会把 $1-\\beta$ 去掉，这样的话其实 $\\alpha$ 就需要根据 $1 \\over 1-\\beta$ 做相应变化，会影响到学习率 $\\alpha$ 的最佳值。 最常见的 $\\beta$ 是0.9，平均了前10次迭代的梯度，效果不错。 另外关于指数加权平均，各数值的加权而随时间而指数式递减，越近期的数据加权越重，这个过程实际上是一个递推的过程，不像普通求解平均值需要保留所有的数值然后求和除以n，这种方法只需要保留 n-1 时刻的平均值和 n 时刻的数值就好，这样可以减少内存和空间的做法。 优点是积累的速度v可以让我们越过局部最小点，但也可能造成在全局最优点来回震荡。 RMSpropRMSprop 用的是 moving average of squared gradients，它会联系之前的每一次梯度变化情况来更新学习步长。如果当前得到的梯度为负，那学习步长就会减小一点点；如果当前得到的梯度为正，那学习步长就会增大一点点。 On iteration t:​ Compute dw, db on current mini-batch$$\\begin{aligned}​ s_dw &amp;= \\beta s_dw + (1-\\beta)s_dw^2 \\ square, elementwise \\\\​ s_db &amp;= \\beta s_db + (1-\\beta)s_db^2 \\\\​ w &amp;= w-\\alpha {dw \\over \\sqrt{s_{dw}+\\epsilon}} \\\\​ b &amp;= b-\\alpha {db \\over \\sqrt{s_{db}+\\epsilon}} \\\\ \\end{aligned}$$ 我们希望 $s_dw$ 相对很小，$s_db$ 相对很大，这样就可以减缓纵轴上的变化，就可以用更大的学习率。在实践过程中，分母不能为 0，所以要加上个很小的 $\\epsilon$ AdamAdam(Adaptive Moment Estimation)，将 Momentum 和 RMSprop 结合到一起，并加入了 bias correction(指数加权平均刚开始计算时, $v_t$ 与 $\\theta_t$ 偏差很大, bias correction 用于解决该问题)，优点是在经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。 $v_dw=0, s_db=0, v_db=0, s_db=0$ On iteration t:​ Compute dw, db on current mini-batch$$\\begin{aligned}​ v_dw &amp;= \\beta_1 v_{dw} + (1-\\beta_1)dw, \\ \\ v_db = \\beta_1 v_{db} + (1-\\beta_1)db \\\\​ s_dw &amp;= \\beta s_{dw}+(1-\\beta_2)dw^2, s_db = \\beta s_{db}+(1-\\beta_2)db^2 \\\\​ v^{corrected}_{dw} &amp;= {v_{dw} \\over (1-\\beta^t_1)}, \\ \\ v^{corrected}_{db}={v_{db} \\over (1-\\beta^t_1)} \\\\​ s^{corrected}_{dw} &amp;= {s_{dw} \\over (1-\\beta_2^t)}, \\ \\ s^{corrected}_{db}={s_{db} \\over (1-\\beta_2^t)} \\\\​ w &amp;= w - \\alpha {v^{corrected}_{dw} \\over \\sqrt{s_{dw}+\\epsilon}}, \\ \\ b = b - \\alpha {v^{corrected}_{dw} \\over \\sqrt{s_{dw}+\\epsilon}} \\\\ \\end{aligned}$$ $\\beta_1: 0.9 $ -&gt; dw$\\beta_2: 0.999$ -&gt; $dw^2$$\\epsilon: 10^{-8}$ Learning rate decay在学习初期，你能承受较大的步伐，但当开始收敛的时候，小的学习率能让你步伐小一点，下面列举了几种 decay 的方法，$\\alpha$ 是初始学习率。$$\\begin{aligned}\\alpha &amp;= {1 \\over 1 + decay-rate * epoch-num}\\alpha_0 \\\\\\alpha &amp;= 0.95^{epoch-num}\\alpha_0 \\\\\\alpha &amp;= {k \\over \\sqrt{epoch-num}}\\alpha_0 \\\\\\alpha &amp;= {k \\over \\sqrt t}\\alpha_0 \\\\\\end{aligned}$$ 或者也可以使用离散下降的学习率，开始的 5000 step 用这个学习率，之后的 5000 step 把原来的学习率降低一半…… 还有一种更朴实的，人工来控制学习率，像 babysitting 一样，不断观察着训练效果，人工来调整。","tags":"deep-learning"},{"title":"论文笔记 - A Neural Attention Model for Abstractive Sentence Summarization","url":"/2017/08/08/论文笔记 - A Neural Attention Model for Abstractive Sentence Summarization/","text":"接之前的NLP 笔记 - Text Summarization，介绍一种 abstractive summarization 方法 textsum。 BackgroundSummarization Phenomena先来观察下文本摘要的一些现象，一般是通过对源文本进行泛化(generalization)、删除(deletion)、改写(paraphrase)等操作来产生目标文本，也就是文本摘要。看一下例子 GeneralizationSource: Russian Defense Minister Ivanov called Sunday for the creation of a joint front for combating global terrorism.Target: Russia calls for joint front against terrorism. DeletionSource: Russian Defense Minister Ivanov called Sunday for the creation of a joint front for combating global terrorism.Target: Russia calls for joint front against terrorism. ParaphraseSource: Russian Defense Minister Ivanov called Sunday for the creation of a joint front for combating global terrorism.Target: Russia calls for joint front against terrorism. Types of Sentence Summary对于上面等一些操作，产生了文本摘要的几类技术模型。 Compressive: deletion-only:压缩，通过对源文本的删除操作产生目标文本。 Extractive: deletion and reordering:抽取式，摘要句子完全从源文档中抽取形成，详细见 NLP 笔记 - Text Summarization Abstractive: arbitary transformation合成式，从源文档中抽取句子并进行改写形成摘要。 看下几种方法的比较 Related work目前已经有的一些相关工作 Syntax-BasedDorr, Zajic, and Schwartz 2003; Cohn and Lapata 2008; Woodsend, Fend, and Lapata 2010 Topic-BasedZajic, Dorr, and Schwartz 2004 Machine Translation-basedBanko, Mittal, and Witbrock 2000 Semantics-BasedLiu et al 2015 TextsumTextsum，论文戳 A Neural Attention Model for Abstractive Sentence Summarization，tensorflow 代码戳 tensorflow/models/textsum。Textsum是一种 abstractive model，主要有下面四个组件构成： Neural language model Attention-based encoder model Generation model Beam-search decoder &amp; additional features model extractive elements 下面逐个进行讨论。 Neural language model借鉴了机器翻译的思想，在 A Neural Probabilistic Language Model (Bengio et al. 2013)的基础上，加了一个 attention-based encoder(Bahdanau et al. 2014) 来学习输入文本的 latent soft alignment。 先看一下整体逻辑，看图说话，下面左图圈出来的部分是一个feed-forward neural network language model(NNLM)，详情戳NLP 笔记 - Machine Translation(Neuron models)，它的输入是当前 output 已经产生的上下文 $y_c$(注意这个 context 窗口的长度是固定的)，与词向量矩阵 E 做个映射，经过线性变化以及激活函数得到得分矩阵 U，再经过一个 softmax 层得到概率分布形式的输出，也就是下一个单词 $y_{i+1}$，现在我们要加上左边的 attention-based encoder，对输入 source text 和当前我们拥有的 context $y_c$ 做一个 encode，放大的话就是右图。对 context embedding 和 source 的每个单词做一个加权的点乘(weighted dot product)得到 attention distribution 也就是 P，对 source text 做一个局部的平滑(local smoothing)，然后对 source 的 smoothing 版本和 attention distribution 做一个点乘，就得到了我们要的 enc，最后把两边的东西一起扔到 softmax 里得到输出。 看个例子，如下图，行是 source text，列是 output text，假定我们已经产生了 “russia calls”，现在目标是产生下一个单词 for，我们的模型将利用 attention distribution of source 以及 embedding of context，来得到 for 这个 next word。因为我们用了 bag of words 的 smoothing 版本，也就是说我们对 called 周围的单词进行了加权，attention 很大程度上会指向 called，具体逻辑见下一部分 encoders。 上面说到了，这里选择的 encoder 是 attention-based encoder，下面来看一下为什么选这个 encoder。 EncodersBag-of-words EncoderBoW encoder 把 encoder 参数估计看作是一个 uniform distribution，赋予了每个词相同的权重，同时忽略了单词词序。 Convolutional EncoderConvolutional Encoder 通过局部卷积来考虑邻近单词的互动，单词/词组权重由网络训练产生。 Attention-Based Encoder灵感来自 Bahdanau et al. (2014) attention-based contextual encoder。和 BoW 相似的一个简单的模型，只不过把 BoW 的 uniform distribution 替换成一个 input 和 summary 之间的 soft alignment P (如下图)，是一个机器翻译的思路。之后用学习到的这个 soft alignment 来给输入的平滑版本进行加权。比如说，如果当前的上下文和位置 i 能很好的对齐，那么单词 $x_{i-Q},…,x_{i+Q}$ 就会被 encoder 赋予更高的权重。与 NNLM 结合的话这个模型可以看作是 attention-based neural machine translation model 的精简版。 $G \\in R_{D*V}$: embdding of the context$P \\in R_{H*(CD)}$: new weight matrix parameter mapping between the context embedding and input embedding$Q$: smoothing window Generating Summaries用 beam-search decoder 来寻找最好的 summary，这是机器翻译模型的标准化方法(Bahdanau et al., 2014; Sutskever et al., 2014; Luong et al., 2015) ，这里做了一点改进。 算法如上，我们需要维护一个词库 V 以及前 k 个最好的 context，复杂度是 O(KNV)。 Tuning最后论文提到了一个 tuning，这其实是在 word embedding 维度太低，语义表示不完全时，去人工添加一些特征，这可以 handle 一些 rare/unseen words 的问题，让系统的 extractive/abstractive 趋势更为平衡。通过修改评分函数来直接估计 summary 概率，使用对数线性模型。","tags":"textsum"},{"title":"递归神经网络 RNN 笔记","url":"/2017/07/21/递归神经网络 RNN 笔记/","text":"介绍 RNN 及其变种。Stanford cs231n Lecture 10: Recurrent Neural Networks 的部分笔记。 引入传统的神经网络中间层每一个神经元和输入的每一个数据进行运算得到一个激励然后产生一个中间层的输出，并没有记忆能力，在输入为序列的情况下的效果有限。而很多东西是受到时域信息影响的，某一时刻产生的激励对下一时刻是有用的，递归神经网络就具备这样的记忆能力，它可以把这一刻的特征与上一刻保存的激励信息相结合(并不只是上一刻 s2 是由 s1、s2 产生的，$s_n$ 不仅有 $s_{n-1}$ 的信息，还包括 $s_{n-2}$、$s_{n-3}$…$s_1$ 的信息。 CNN vs RNN: CNN 需要固定长度的输入、输出，RNN 的输入可以是不定长的 CNN 只有 one-to-one 一种结构，而 RNN 有多种结构，如下图具体在下一部分再做介绍。 One-to-one: Vanilla Neural Networks 最简单的结构，然而效果不怎么好 One-to-many: Image Captioning, image -&gt; sequence of works ​输入一个图片，输出一句描述图片的话 Many-to-one: Sentiment Classification, sequence of words -&gt; sentiment ​输入一句话，判断是正面还是负面情绪 Many-to-many: Machine Translation, seq of words -&gt; seq of words ​有个延时的，譬如机器翻译。 Many-to-many: Video classification on frame level ​输入一个视频，判断每帧分类。 Applications: language models translation caption generation program execution RNN基础以 (Vanilla) Recurrent Neural Network 为例 Forward(前向传播) $$h_t=f_W(h_{t-1},x_t)$$ Notice: the same function and the same set of parameters are used at every time step. $$h_t=tanh(W_{hh}h_{t-1}+W_{xh}x_t+b)$$$$y_t=Softmax(W_{hy}h_t+c)$$ 就是多加上 $h_{t-1}$，activation function 用的是 tanh Backwards: Backpropagation Through Time(BPTT)(请原谅我的字～) U 最大特征值(Largest singular value)大于 1 的时候，梯度爆炸，小于 1 的时候，则可能发生梯度消失。&gt; 1 的时候还比较容易察觉，&lt; 1 的时候往往难以发现了。梯度爆炸可以采用Gradient clipping的方式(设个天花板)避免，如梯度大于 5 的时候就强制梯度等于5。梯度消散可以通过改变 RNN 结构如采用LSTM的方式抑制。 Loss function(损失函数)Cross-entropy$$E_t(y_t,\\hat y_t)=-y_tlog \\hat y_t$$$$E(y_t,\\hat y_t)=-\\sum_t y_tlog \\hat y_t$$ 其他结构经典 RNN 结构，输入和输出序列等长，适用范围比较小，比如 Char RNN，视频每一帧的分类任务等。 双向 RNN：输入信息一个正向，一个反向，原因是信息等依赖关系顺序不定。 输入是序列，输出是单个值，通常处理序列分类问题，比如句子分类任务。 输入是值，输出是序列，decoder 时，可以把原始输入信息 X 作为序列输出开始的输入 ，也可以把 X 作为每个阶段的输入，可以处理 从图像/类别生成文字/语音/音乐 的问题，输入可以是 CNN 的 FC 层特征。 经典的 Encoder-Decoder 或者说 Seq2Seq 模型，先用一个 Many-to-one 将输入编码成一个上下文向量 c，这个 c 可以是 Encoder 最后一个隐状态，也可以是这个隐状态的变换，还可以是所有隐状态的一个变换。有了 c，另一个 One-to-many 会对其进行解码，把 c 作为初始状态 $h_0$ 输入到 Decoder 中。这一部分也有各种变换，比如说把 c 当做 decoder 时每一步的输入。Seq2Seq 结构应用非常广泛，在机器翻译、文本摘要、问答系统中都很常见。 Example: Character-level Language Model SamplingVocabulary: [h, e, l, o]Exaple training sequence: “hello” At test-time sample characters one at a time, feed back to model Backpropagation through time:Foward through entire sequence to compute loss, then backward through entire sequence to compute gradient. Truncated Backpropagation through time:Run forward and backward through chunks of the sequence instead of whole sequence.Carry hidden states forward in time forever, but only backpropagate for some smaller number of steps. Image Captioning 可参考的 paper:xplain Images with Multimodal Recurrent Neural Networks, Mao et al.Deep Visual-Semantic Alignments for Generating Image Descriptions, Karpathy and Fei-FeiShow and Tell: A Neural Image Caption Generator, Vinyals et al.Long-term Recurrent Convolutional Networks for Visual Recognition and Description, Donahue et al.Learning a Recurrent Visual Representation for Image Caption Generation, Chen and Zitnick 下一篇重点解释。 RNN 局限RNN 前后依赖的特性导致两个输入距离比较远的时候作用会非常弱，比如说下面的例子， China 对 Chinese 起决定作用，然而距离太远难以产生关联。 一个解决方案就是设计 Gate，保存重要记忆，也就是下面要讲的 LSTM，LSTM 网络模型解决了 RNN 梯度消散问题，同时保留了长时序列的相关性。 RNN 变种: LSTMRNN 中重复的模块只有一个非常既简单的结构 tanh 层，而 LSTM 将重复模块改成了一个相对复杂的结构，这样可以有效避免梯度消失的问题。LSTM 要理解的核心是 GATE，它就是靠这些 gate 的结构让信息有选择性的影响 RNN 中每个时刻的状态。所谓 gate 的结构就是一个使用 sigmoid 神经网络和一个 elementwise multiplication 的操作，这两个操作合在一起就是一个门的结构，sigmoid 作为激活函数的全连接神经网络层会输出一个 0-1 之间的数值，描述当前输入有多少信息量可以通过这个结构，类似于门，门打开时(sigmoid 输出为1时)，全部信息都可以通过；当门关上时(sigmoid 输出为0)，任何信息都无法通过。 Vanilla RNN$$\\begin{aligned} h_t &amp; = tanh(W_{hh}h_{t-1}+W_{xh}x_t) \\\\ &amp; = tanh((W_{hh} W_{hx})\\binom{h_{t-1}}{x_t}) \\\\ &amp; = tanh(W \\binom{h_{t-1}}{x_t}) \\\\ \\end{aligned}$$ 看一下 Vanilla RNN 到 LSTM 前向传播的变化 LSTM 网络结构图 分步：f: Forget gate, Whether to erase celli: Input gate, whether to write to cellg: Gate gate (?), How much to write to cello: Output gate, How much to reveal cell Step 1:decide what information we’re going to throw away from the cell state新输入 $x_t$ 和前状态 $h_{t-1}$ 通过 sigmoid 变换决定 $c_{t-1}$ 的哪些信息可以舍弃，$f_t$ 与 $C_{t-1}$ 做 elementwise multiplication 运算，对部分信息进行去除 Step 2:decide what new information we’re going to store in the cell state新输入 $x_t$ 前状态 $h_{t-1}$ 通过 sigmoid 变换告诉 $c_t$ 哪些新信息想要保存，通过 tanh 变换建一个新的侯选值向量。$i_t:$ 新信息添加时的系数(对比 $f_t$)，$g_t$ 单独新数据形成的控制参数，用于对 $C_t$ 进行更新。 Step 3:update the old cell state根据旧的控制参数 $C_{t-1}, f_t, i_t, g_t$ 组合生成最终生成该时刻最终控制参数 Step 4:decide what we’re going to output新输入 $x_t$ 和前状态 $h_{t-1}$ 通过 sigmoid 变换决定 cell state 的哪些信息需要输出，与 cell state 通过 tanh 变换后的值相乘，产生此刻的新的 LSTM 输出 核心内容 $C_t$，信息流控制的关键，参数决定了 $h_t$ 传递过程中，哪些被保存或舍弃，参数被 Gate 影响。怎样实现 Gate 对 C 影响？ Sigmoid 函数系数据定 $C_t$ 参数的变化，而 Sigmoid 函数决定于输入。整个过程：$C_t$ 信息舍弃 =&gt; $C_t$ 局部生成 =&gt; $C_t$ 更新 =&gt; $C_t$ 运算 Backpropagation: LSTM 变种: Peephole connection$C_t$ 受到 Gate 参数影响 =&gt; 二者相互影响$f_t=\\sigma(W_f[C_{t-1},h_{t-1},x_t]+b_f)$$f_t=\\sigma(W_i[C_{t-1},h_{t-1},x_t]+b_i)$$f_t=\\sigma(W_o[C_{t-1},h_{t-1},x_t]+b_o)$ LSTM 变种: 遗忘/更新互为补充Gate 的 遗忘/更新 不再独立，而是互为补充。 $C_t = f_t * C_{t-1} + i_t * g_t$ =&gt; $C_t = f_t * C_{t-1} + (1-f_t) * g_t$ LSTM 变种: GRU(Gated Recurrent Unit) 遗忘，更新 Gate 结合(不是独立，也不是互补)形成更新门 控制参数 $C_t$ 与输出 $h_t$ 结合，直接产生带有长短记忆能力的输出 link 小结 RNN 应用在 language model 中，学习的实质是 P(下个词|前面多个词) Vanilla RNNs 非常简单，但效果不好，通常会使用 LSTM 和 GRU，这两种结构能提高 gradient flow 在一层 RNN 中不同时间序列中激励函数和权值参数都一致 RNN 也可以是多层 RNN，其网络是整个一模型一起训练的 RNN 存在着梯度爆炸和梯度消散的问题。梯度爆炸可以采用Gradient clipping的方式避免，梯度消散可以采用 LSTM 的网络结构抑制 中间层的特征带有前后时间特征，对一些任务很有用 额外参数：单双向/梯度上限/梯度计算范围","tags":"deep-learning rnn lstm"},{"title":"CCF-GAIR 参会笔记","url":"/2017/07/15/CCF-GAIR 参会笔记/","text":"回国后参加的第一场大规模的人工智能峰会，感觉收获还是很多的，对部分之前学过的东西做了一遍梳理，对当前工业界的发展现状有了一定了解，对学术界的最新进展有了些体会，最后还结识了一批志同道合的朋友，值回票价。这一篇作为峰会的笔记，记录一些我认为重要的东西，有些零散，参加的场次有限，看官们见谅～ AI 发展前沿这一部分各位演讲嘉宾从宏观角度概括了下 AI 的发展现状。 AI 的典型任务和应用 潘云鹤——中国工程院院士，国务院学位委员会委员、中国科学技术协会顾问、中国图象图形学学会名誉理事长、中国计算机学会理事、中国人工智能学会副理事长。中国智能CAD领域的开拓者，创造性地将人工智能引入CAD技术。 主要介绍了 AI 行业的一些基本情况，像人工智能的典型任务、应用、重点方向之类，毕竟是刚开场的演讲，听的比较仔细。人工智能应用的 7 个基本领域： 机器定理证明(逻辑和推理) — 仿解题者主要是研究计算机进行逻辑推理 机器翻译(自然语言理解) — 仿译者研究计算机自然语言理解 专家系统(问题求解和知识表达) — 仿专家(医生，维修者)研究问题求解和知识表达 博弈(树搜索) — 仿弈者最早的时候研究搜索，后来逐渐转化为神经网络 模式识别(多媒体认知) — 仿认知者主要用于视觉、听觉或者各种各样媒体的认知 学习(神经网络) — 仿初学者主要是研究神经网络 机器人和智能控制(感知和控制) — 仿生物动作主要是研究和模拟人的感知和控制 形成了符号学派、连接学派、行为学派。AI 从萌芽到现在的蓬勃发展期间出现了三次低谷，得到的教训大致是驱动 AI 的发展主要是靠创新、软件和知识，而非硬件，知识不能靠专家手工表达，要靠从环境中自动学习 一些新的技术已经初露端倪，表现在近几年 AI 技术的前沿中，主要有 大数据智能DeepMind 已为谷歌挣钱，提高了谷歌 15% 的用电效率 基于网络的群体智能群智计算按难易程度分为三种类型：实现任务分配的众包模式(Crowd-sourcing)，较复杂、支持工作流模式的群体智能(Complex workflows)，以及最复杂的协同求解问题的生态系统模式(Problem solving ecosystem)大规模个体通过互联网参与和交互，可以表现出超乎寻常的智慧能力，是解决开放复杂问题的新途径，成功的如 AppStore，Wiki 百科等 跨媒体推理在语言、视觉、图形和听觉之间语义贯通，是实现联想、推理、概括等智能的重要关键 无人系统无人系统迅猛发展的速度远快于机器人，因为类人和类动物的机器人，往往不如机械进行智能化和自主化升级来的高效如 (海康)智能分拣机器人，泊车机器人 ​AI 的基础和目标: 模拟人的智能 =&gt; 人机融合 =&gt; 群体智能 直接上图了 The Rise of AI And The Challenges of Human-Aware AI Systems Subbarao Kambhampati——AAAI主席，亚利桑拿州立大学教授，同时也在很多的国际机构任职，主要研究自动化的决策机制，特别是在人工感知的人工智能领域。 同样讲了 AI 进展，不过划分方式略有不同。 提供了一个很有意思的视角， AI 系统的发展过程和人的学习过程是截然相反的。为什么呢？因为在有 conscious theories 的基础上编程更容易，毕竟 cognitive/reasoning intelligence 一直在发展嘛，还因为我们并没有特别意识到/了解 perceptual intelligence，为什么当今的 AI 能够走入千家万户的视野呢？正是因为 perceptual abilities 让 AI 不再是瞎的聋的，现在的 AI 可以更加的智能，可以存在在各种载体之上，如智能手机，智能音箱，汽车等等。 教授还指出了几个研究方向：从小数据中学习、机器的常识、不完整性和交互。 模式识别研究回顾与展望 谭铁牛——中国科学院院士、英国皇家工程院外籍院士、发展中国家科学院院士、巴西科学院外籍院士，发表专著11部、文章500多篇，还有100多项发明。获得了一系列的国家级的奖，现在是中国图象图形学会理事长、中国人工智能学会副理事长。 主要讲了模式识别的 基本概念／发展现状／研究方向。深深的觉得 ppt 做的实在很棒，讲的也很棒，感觉最棒的！直接上图！ 模式识别的现状： 面向特定任务的模式识别已经取得突破性进展，有的性能已可与人类媲美； 统计与机遇神经网络的模式识别目前占主导地位，深度学习开创了新局面； 通用模式识别系统依然任重道远； 鲁棒性、自适应性和可泛化性是进一步发展的三大瓶颈。 现有模式识别的局限性: 鲁棒性​ 容易收到对抗样本的攻击​ 如 CV 中的局部形变／旋转变化／光照变化／遮挡／背景凌乱／多样性／尺度变化 自适应性差​ 不能自适应开放环境下数据分布的快速变化 可解释性差​ 人在判别过程中可以轻易使用具有逻辑关系的规则；机器特别是深度学习常作为黑箱模型，无法为高风险应用提供具有说服力的决策 在人工智能非常火爆的时候，模式识别领域有如下值得关注的研究方向： 从神经生物学领域获得启发的模式识别神经元(类型、发放特性、突触可塑性)／神经回路(前向、侧向、后向连接)／功能区域(多任务协同、注意、记忆机制)／学习机制(人的学习特性和学习过程)学习过程：发育学习、强化学习学习方法：迁移学习、知识学习学习效果：生成学习、概念学习(e.g., Bayesian Program Learning) 面向大规模多源异构数据的鲁棒特征表达考虑如何在跨景跨媒、多源异质的视觉大数据中找到具有较好泛化性和不变性的表达e.g., 定序测量特征(Ordinal Measure) 结构与统计相结合的模式识别新理论 数据与知识相结合的模式识别 以互联网为中心的模式识别 AI 学术前沿这一场主要分析了学术界的各位的最新研究进展 Smart Robotic Systems that Work in Real Outdoor Environments 金出武雄——机器人领域的鼻祖级专家，卡耐基梅隆大学的创始人，同时也是非常著名的荣誉教授，主要研究机器人工、机器人学，享誉全世界的指路者。 虽然是自家学校的，还是木有认真听。开头主要讲了一个例子，在车上加一个 smart headlight，使得雨滴在图片里面的成像变得很淡，可以毫无障碍在雨雪天的夜晚出行， 因为他一开始就在讲汽车灯光在下雨天各种反射怎么怎么样……然后我就……就没兴趣了TAT…… A society of AI Agents 群体智能的社会 汪军， 伦敦大学学院（UCL）计算机系教授、互联网科学与大数据分析专业主任。主要研究智能信息系统，主要包括数据挖掘，计算广告学，推荐系统，机器学习，强化学习，生成模型等等。他发表了100多篇学术论文，多次获得最佳论文奖。是国际公认的计算广告学和智能推荐系统专家。 讲多智能体怎样竞争怎样协作怎样通讯。从多智体群体的特征切入，介绍多智体的强化学习特性。同一环境下，不同的智体既可以单独处理各自的任务，又可以联合在一起处理优化一个主要的目标方程(一般是长期的 reward 方程)。强化学习的优点就是在没有足够训练数据时，系统会和环境进行交互，得到反馈信息，交互过程中不断学习，在应用上比较灵活 Multi-agent reinforcement learning(MARL) 的应用有互联网广告的机器招标(Machine Bidding in Online Advertising)，通过对投放广告后的用户的反馈的不断学习，就可以帮助企业精准找到目标用户。再如 AI 玩星际游戏(AI plays StarCraft)等，主要考虑的是智体的通讯问题，多个智体之间怎么合作，达到双向联通。 其他的应用比如宜家的商场设计，需要模拟人的行为流向，同时让环境跟着用户的变化而变化，把路径安排最优，来优化用户的停留时长(stay)和购买金额(purchase) ，再比如迷宫的设计，一方面给定一个环境，让智体通过强化学习找到最优的策略走出来，另一方面是当智体的智能水平不再提高时，就可以来优化环境，使它更难出去。 多智能强化学习的研究仍然处于非常初步的阶段，主要有两个问题 Problem1: current research is limited to only less than 20 agents许多现实场景中的多智体数量可以达到百万、甚至千万级，比如 uber 的场合怎么办？共享单车怎么办？ Problem2: the environment is assumed to be given and not designable不是去学环境的设计，而是让人工智能更加适应环境，而很多情况下，很多环境也需要有适应的过程，比如说宜家，强化学习的环境，根据用户的变化，变化环境。用随机 agents 模拟人在店铺走的情况，收集人力图，反馈到铺面设计，来最大用户停留时间/用户消费 怎么处理百万级的 agent，一种方法是从自然界中找灵感，可以学习生态学／生物学的 self-organisation(自组织)理论，当一些小的智体遵循这个规则的时候，就会体现一个种群的特质。这些模型可以用宏观的事情解决宏观的问题，但是缺少一种微观的方法去观察这个世界。老虎和羊的模型 Lotka-Volterra model the dynamics of the artificial population 描述了相互竞争的两个种群数量之间的动态关系。汪军教授在此模型上做了一个创新，提出了老虎-羊-兔子模型(Tiger-sheep-rabbit model)，给智体强化学习能力以后，就和 LV 模型中的猞猁抓兔子的动态显现十分相似。当智体之间联合一起优化某一个目标或单独优化自己的目标，作为一个群体，他们就有了内在的规律。如果找到这些规律，对开发智体模型是非常有帮助的。 计算机视觉专场Video Content 3C: Creation, Curation, Consumption 梅涛，微软亚洲研究院资深研究员。 CV understanding 问题分为几个层次(or 不同粒度)： 从图像到视频的变换，实际是从二维到三维的变换，除了要理解每一帧的图片的 object，还要理解帧/物体在 cross, multiple-frame的动态运动。 视频内容的生命周期大致可以分为三个部分，即视频的创作(creation)、处理(curation)和消费(consumption)。 Creation先来看一下视频是怎么产生的。首先把 Video 切成一个个的 shots(镜头/段落)，每个镜头 group(组合) 成一个 story(scene)，每一个镜头还可以细分成 sub-shots，每个 sub-shot 可以用 key-frame 来表示。通过这种分层的结构可以把 video 这样一个非线性的东西分成一个 structure data，这就是做 video summarization 的前提。 Video summarization 分两种，static summary 和 dynamic summary。 static summary: automatic selection of representative video keyframes(e.g., 5 keyframes)主要是选择具有高度代表性的 keyframe 来表示视频，一个 5 分钟的 video 给你 5 个 keyframe 你就知道这个视频讲了什么 dynamic summary: automatic generation of a short clip for fast preview(e.g., 30 second)8 分钟的 video 生成 30 秒的 highlight，概括 video 的所有内容。spots video 知道哪些 segment 是最 hightlight 最精彩的，你最应该看哪部分 Video Creation 的涉及的技术还有 stabilization and photography，怎么把拍的抖动的 video 变得平稳，怎么分辨 video 中的物体哪些是静止的哪些是动态的，然后产生 animation；另外和文字结合的技术/应用如 video generation，给出文字，来产生一个 video，像给一个动作，video 能展示这个动作。 Curation Curation 涉及的技术还有 pose estimation from RGB video，应用比如说智能健身教练，通过把动作分解来告诉你哪一个动作是不准确的；还有在 video captioning 方面的应用，可以把视频描述做的更生动，比如说原来只能识别一群人(a group of people)，加上 pose estimation 可以识别一群人在跳舞(a group of people are dancing)。还有auto-commenting，给视频自动评论，把原有的 caption 变成有人的情感对话的 comments，比如说棒球比赛的动图，可以产生1234I love baseballthat&apos;s how to play baseballThat&apos;s an amazing play- [Li, Yao, Mei, MM&apos;16] Video caption 的经典方法是2D/3D CNN 学一个 video 的表达，然后做一个 embedding，把 embedding 的结果加上 text embedding 放到 rnn 去学。如果加上一个 relevant loss，结果还会与内容相关 Consumption最后一个环节是 Video Consumption，应用像 video instagram，可以给 video 加上 style，或者说滤镜，变成 stylist video；也可以做 style transfer，比如说把油画的 style transfer 到自拍/风景照中；还有的应用像 segmentation，把人抠出来放到另一个场景里，把异地情侣放到一个房间里聊天；更难一点的还可以做 storytelling，把很多视频中的图像组合成一个吸引人的故事讲给观众听；另外还有 video advertising，来分析广告应该放什么位置，什么时间段选什么广告(是不是和插入点信息相关)，比如说广告和内容可以无缝衔接，也可以在故事高潮的时候/最 boring 的时候放广告。视频广告主要有两种度量方式，一个是 discontinuity，来衡量一个广告插入点的故事情节是否连续；另一个是 attractiveness，来衡量一段原始视频的内容是否精彩。这两者的权衡同事也就是广告商(advertiser)或用户(viewer)需求的权衡。 产业落地和产业化路径下一个是演讲者是中山大学教授、商汤科技执行研发总监林倞老师，又是母校，主题是 深度驱动的人工智能：从学术创新到产业落地，主要还是介绍了下商汤现在的主要业务。再下一个演讲者是魏京京，图麟科技 CEO，主题是 计算机视觉的产业化路径，也就不多说了。 X 数据驱动的 Seeta 视觉引擎与平台 山世光，中科院计算所研究员、博导，基金委优青，CCF青年科学奖获得者，现任中科院智能信息处理重点实验室常务副主任，中科视拓创始人、董事长兼CTO，任IEEE，TIP，CVIU， PRL，Neurocomputing，FCS等国际学术刊物的编委。 主要记录几个点，原文可以看 中科视拓CTO山世光：如何用X数据驱动AI成长 | CCF-GAIR 2017&amp;version=12020610&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=fYv8LK1dmtHud6qxDzyk0NQoTcNdpkYbWuD9vGD4pepNxlPLVOKnmpPFU3ig4ZlD) 增强学习适合：可以自动判断对错的领域例如：棋类、游戏类视觉、听觉、理解、情感，通通不太行 深度学习适合：好数据肥沃、可以归纳学习的领域 数据采集、获取、标注便利的领域，例如视觉，语音，互联网+行业 需要演绎推理的领域非常困难，理解需要演绎和引申，没有太多可作为的地方 X 数据有五个含义： 大数据大数据驱动的视觉引擎的设计； 小数据在很多场景下，我们获得智能的能力并不是依赖于大量的数据学习，反而是一些小数据，所以要考虑的十四，怎样在小数据的情况下使得我们的算法也能够有效果。通常的思路自然是迁移学习，最简单的是做 finetune 模型，把一个已经训练好的模型，再用小量的数据做调整和优化，使得它适应这些小数据所代表的应用场景。另一个思路是多模态的数据，实现跨模态的比对和融合利用； 脏数据很好理解了，现在的数据都有大量的噪声，要雇人在大量的数据中把它们标注出来太不容易了，干脆就基于有噪声的数据实现机器学习。所以山世光等人在今年提出具有“自纠错学习”能力的深度学习方法，在深度学习的过程中，一边去学习算法，一边去估计哪些样本的标签可能是错误的，把一些可能错误的标签修正过来，从而得到更好的算法。这里的脏可能还有另一层含义，比如说图像识别中有遮挡的情况，山世光等人也提出了一个算法，能够把面部的遮挡部分、脏的部分补出来，补出来之后再去实现感知。把这两个过程迭代起来，形成联合的学习，这个工作发表在去年的 CVPR 上面，取得了非常不错的效果。 无监督数据比如说特定的物体没有标注数据，怎样利用没有标签的数据来训练模型。解决方法如 Bi-shifting 深度模型，实现从源域到无监督目标域到知识迁移。(M.Kan, et al, ICCV2015) 增广数据通过对已有少量数据进行修改的方式，来生成大量数据。有两类方法，一种是模型方法，比如说 3D 重建，另一种是 GAN 方法。 AI 未来发展需要注意的三个问题： 鲁棒性鲁棒性可能是 AI 和视觉智能一个最致命的问题 多模态数据协同对于人来说，除了眼睛之外，我们有很多其它信息来对我们的智力发育提供帮助，包括语音、姿态、动作、以及背后有大量的知识库作支撑。因此，人本身是需要一个多模态系统协同工作的鲁棒AI，这带给我们一个思路，AI的成长和发育也需要多模态 基于小样本的自主学习AI 发育的非常重要的一点，就是如何基于小数据甚至是 0 数据完成智能的发育和后天的学习。比如说我跟大家描述一下某个人长成什么样子，你并没有见过这个人，你并没有见过这个人的照片，我们称为0数据，你如何能够识别这个人，是对AI的一个挑战。类似这样的应用场景，将来会有非常多的研究空间。 圆桌对话五位圆桌嘉宾包括：中科院计算所研究员、中科视拓董事长兼 CTO 山世光、阅面科技 CEO 赵京雷、图麟科技 CEO 魏京京、瑞为智能 CEO 詹东晖以及臻识科技 CEO 任鹏。感觉最有意义的一个问题是：你觉得人工智能技术在落地过程中最大的难点是什么。几位嘉宾一致同意说是闭环。最核心的是市场需求和当前技术达到的闭环，产品结果和客户需求有差距，要怎么迭代。做产品的时候有很多取舍的东西，要去平衡你的功能、性能，满足客户的指标、期望，最后在产品设计和成本相关的这些方面，其实一个核心就是闭环。创业过程中最关键的不是你有什么技术，而是你把已有的技术跟他的痛点结合，这个问题不是技术的问题，基本上就是商业问题，需要付出的努力不是做技术的来做的，而是你要接地气，围着客户做讨论、设计和服务，让他慢慢接受你，这是很痛苦的，也是做技术创业需要转换的地方。我们所谓的技术完美，当然我们希望「快、准、稳」。快是随便找一个很烂的芯片就可以做；准是什么情况下都能工作；稳是不会出现差错，这样落地和闭环就不会出现难题了，但是我们现在真的做不到。比如刚才说的万分之一，很多时候是达不到的，在这个阶段最难的是怎么去找到客户的需求和技术的边界能够结合的应用，再配合上其他的一些条件，能够满足用户的需求。刚才几位说得都对，技术不完美还是一个很大的障碍。 CV+圆桌对话：算法不是唯一考量，创业公司的商业闭环才是最大难点 机器学习专场AI in games 田渊栋，Facebook 人工智能研究院研究员 游戏平台，作为虚拟环境，是非常好的一个数据来源。因为量大，无穷尽，获取速度快，有科学的平台可以提供重复科研的环境。游戏数据的特点： infinite supply of fully labeled data controllable and replicable low cost per sample faster than real-time less safety and ethical concerns complicated dynamics with simple rules 像围棋，非常简单的规则可以得到一个很有意思的过程，可以从过程中抽取一些概念，得到一些人类推理的知识。然而现实生活中规则太多，不一定是个很好的研究开端。 游戏平台作为数据做研究也存在一些问题： Algorithm is slow and data-inefficient人玩游戏玩几盘就好了，计算机要大量的数据，虽然道最后计算机可以玩的很好 require a lot of resources研究限于比较大的公司 abstract game to real-world游戏能不能扩展到现实世界是个很大的问题让游戏更真实 =&gt; 现在的游戏越来越真实，和现实生活非常接近 hard to benchmark the progress 显而易见，解决方案是：=&gt; better algorithm/system=&gt; better environment 这两个都是目前游戏 AI 的研究方向，还有 domain transfer，也是一个研究方向。 Even with a super-super computer, it is not possible to search the entire space. 很多人以为机器能够搜索游戏的所有可能，所以能胜过人类，其实这是一个误解。我们能做的是有限搜索，从当前局面出发，哪一步是最好的，extensive search =&gt; evaluation 星际这样的游戏，可能的步数是指数级的，怎么做还是个开放性的问题 围棋用深度学习的方法 CNN 学出评估函数。怎么估计下一步怎么走？怎么评估？ How to model policy/value function?traditional approach Many manual steps Conflicting parameters, not scalable有些时候规则是冲突的，大师没办法直观的告诉 ai 什么时候用哪条规则，有的时候是看直觉的，ai 没法学 require strong domain knowledge deep learning End-to-end traininglots of data, less tuning minimal domain knowledge amazing performance ​Case study: AlphaGo 依靠 Monte Carlo Tree Search, aggregate win rates, and search towards the good nodes. 从根节点一路找最大概率走到叶节点，这样的好处是如果发现有些招数很糟糕，那么走了两步就不会继续往下走了，如果发现有些招数不错，可能会一路走下去，走个五六十层，这样可能会发现一些很有意思的招数。 主要策略思想Policy network： 根据大量人类棋谱学出来Value network: 网络自己学，把状态中某个步骤拿出来，给每个状态提供一个标定，拿出来训练 future work richer game scenarios multiple base(expand? Rush? Defending?) ​more complicated units 精细控制每个决定，现在智能控制9个 more realistic action spaceAssign one action per unit model-based reinforcement learningMCTS with perfect information and perfect dynamics also achieves ~70%现在游戏都是慢慢摸索的，然而对复杂的游戏需要对游戏有大致估计 self-play(Trained AI versus Trained AI)自对弈 互联网数据下的模型探索 盖坤博士，阿里，P9,阿里妈妈精准展示广告投放 Learning Piece-wise Linear Models from Large Scale Data for Ad Click PredictionDeep Interest Network for Click-Through Rate Prediction 互联网数据和经典模型互联网数据业界经典的处理方法，典型问题：CTR 预估(点击率预估) 数据特点 样本量大 百亿样本 特征维度大 无损表示id 特征，原始特征，稀疏的鉴别式特征，轻松超十亿级原始特征，用户特征+物料特征加上交叉特征，笛卡尔积之类的，轻松上千亿 稀疏数据 经典做法 简单线性模型 Logistic Regression线性模型+sigmoid一个非线性变换，变成一个概率模式 稀疏正则 L1-Norm 特征筛选压制不太重要的特征 处理非线性：人工特征工程LR 是线性模型，能力有限，要挖掘非线性特征，只能做人工特征，笛卡尔积，做交叉，做种种特征 问题 人工能力有限，很难对非线性模式挖掘完全重复 依赖人力和领域经验，方法推广到其他问题的代价大：不够智能 已有的非线性模型 Kernel 方法(kernel svm)复杂度太高，一般来说光存储 kernel 矩阵就是数据量平方级 Tree base 方法(如 GBDT)在低维强特征上表现非常好，但在大规模弱特征上(如 id 特征)表现不行​实际上是树的缺点，假如说是 user id, item id 两个信息，建树会带来一个灾难，每个叶子节点在一维特征上做 split，意味着来判断某个特征是不是 id，跟到叶子路径：if(user id == useri &amp;&amp; item id == itemj) 条件判断，变成了根到叶子的组合判断，就变成了一个记忆，判断为记忆历史行为，缺乏推广性 矩阵分解(Topic Model, LDA 等)适用于两种 id 的情况，不适合多种 id 输入 Factorization machines只拟合有限次关系(二次关系)无法拟合其他非线性关系：例如三种特征的交叉，值的高阶变换等 我们需要的特性 足够强的非线性拟合能力 良好的泛化能力 规模化能力 分片线性模型和学习算法 MLR 分片数为 1 就是一个线性模型，分片数过多会过拟合，实际过程中是用一个搜索的方法来确定分片数。 分片用 softmax，预测模型用 LR，实际就是一个 MOE 模型，外面再加一个 LR 级联 大规模 ID 特征 + MLR 实践 深层用户兴趣分布网络 认知分析-透过机器重新审视商业本质 杨洋，商业认知分析平台iPIN创始人兼CEO。创办iPIN前，杨洋曾在美国国家旅游与电子商务实验室（NLTeC）从事搜索引擎研究，曾师从世界著名信息科学家Rajiv Banker和Pei-yu Chen从事多年大规模众包集智数据分析和研究，并获得博士学位，曾任哈尔滨工业大学管理学院副教授。此外还有过多次互联网创业经历，并曾在NASDAQ上市公司YY Inc.担任全球化负责人。 人对信息的处理过程，感知 -&gt; 认知 -&gt; 分析 -&gt; 决策。人类对认知的理解还不是很成熟，这也是人工智能的天花板之一，如何让机器去掌握人类常识。 从生物学／物理学／哲学／社会学／经济学／市场心理学／神经科学各个角度阐述了什么是认知。比如说在我们看来，信任/不信任是同一个维度的问题，然而神经科学发现不是，你可以同时信任一个人，不信任一个人，可以爱一个人，同时恨一个人。无论哪个领域，整体的逻辑差不多是： 认知是真相在具体场景下的投影 实现机器认知的条件 信息可靠 信息充分 精细建模如何对小规模数据敏感，dl 很难达到 不懂就“问”机器能主动发问 还讲了一些具体应用，个人发展应用类的如完美志愿，涉及到生涯规划，用机器学习的方法来看人是怎么发展的，让机器去学习总结大量的(潜)规则，再如前程导航，SCCT 理论来规划你的人生；企业发展应用如人才分析引擎，把不可矢量的东西都矢量化，从认知层面去做计算，等等。 用人工智能打造教学机器人提升十倍教育效率 栗浩洋 「非你莫属」BOSS，社交APP「朋友印象」创始人，国内第一家人工智能自适应网络教育公司「乂学教育」创始人。黑马会上海会长，黑马连营主任导师，央视二套「实战商学院」导师，第一财经《中国经营者》特约嘉宾，《商界时尚》杂志封面人物。曾先后被福布斯、第一财经、i黑马、36Kr等100多家媒体采访报道。 总体逻辑，实现有教无类，教无定法，因材施教。 MOOC &amp; 传统教学无区别对待所有的学生和所有知识点，每个人的起点和终点不一样，然而老师教的是线性的。智适应系统，能精确侦测不同学生的知识漏洞，利用知识状态空间+知识空间理论来精准定位学生知识点掌握状态，还可以从大量数据中发现强关联的知识点和弱关联知识点。同时，精准把知识点分拆定位；又由于每个学生掌握一个知识点所需的时间是不同的，逻辑方向是不同的，所以要做个性化的匹配和学习内容推荐 个性化匹配 学生画像+内容侧写 机器学习+概率图模型 个性化学习内容和路径匹配 哎，感觉把我们当投资人或者顾客了。。 智能助手专场这一场本来应该是我最感兴趣的一场，无奈嘉宾讲的都很泛，可能是因为中间设计的技术太多，没法展开吧。 远程语音交互的技术挑战和商业思考 陈孝良，北京声智科技有限公司。 人机交互的升级大致来说分三个时代，最开始是PC互联网时代，主要依赖键盘、鼠标，后来是移动互联网时代，以智能机为代表，大量依赖触摸屏，到现在的AI互联网时代，以远程语音交互为主要交互方式，当然这不是唯一的，还有其他的方式辅助。 技术挑战： 远场语音交互技术瓶颈在于声学和场景近场可以近似理解为只是实验室的理想环境，远场要考虑更多 语音识别率 95%，但用户体验不好行业目标：以语音控制模式打造极致(速度、精度)产品体验核心瓶颈：远场语音识别、远场场景适配、NLP 精确反馈 语义理解技术有本质性突破行业目标：拟人化，全功能型产品，实现听你所言，知你所想核心瓶颈：声光电多种传感的融合，NLP 技术的实质性突破 技术挑战： 器件需要升级，然而麦克风的性能、精度，核心技术不在国内，标量麦克风=&gt;矢量麦克风，国内相对落后 芯片 算法如离线关键词识别(语音唤醒)、离线声纹识别(Voice ID)，AEC 回声消除，Adaptive Beamforming, Speech Dereverberation，声源定位技术，孤立样本学习，深度强化学习 商业语音交互产业化的风险在于不确定的启动周期，到了启动周期爆发时间就只有三年产品，内容和服务，标准和知识产权， 对话即应用：过去仍在，未来已来 戴帅湘，蓦然认知 CEO前百度主任架构师，并长期担任百度 Query 理解方向负责人，荣获第一个百度语义技术的最高奖。 感觉讲的更多是 IoT 的内容，讲了未来发展趋势，几个融合 VOI 和 GUI 的融合GUI 人适应机器，处理简单的、特定的任务，VOI，机器适应人，可以处理相对模糊的，复杂的任务 多场景融合关注长尾的需求 设备之间的协同比如说车+家的互联，把家里的空调调到24度 知识和服务的融合 设备时代结束，助手时代到来 刘耀平，暴风TV CEO，被誉为“互联网电视第一人”。 听到(DSP) =&gt; 听清(ASR) =&gt; 听懂(NLP) =&gt; 做到(SKILL) 介绍了暴风家庭助手，感觉像 echo show 的中文版，视频看上去不错，不知道真正体验如何。 讲了未来趋势： 多设备协同计算(多助手)，未来一定是助手与助手之间的联网和协同， 多屏协同服务，服务在多屏呈现，屏幕无处不在 跨空间场景迁移 未来会产生家庭社交平台，人与助手，助手与助手，人与人的交互。 AI+专场机器写稿技术与应用 万小军，北京大学计算机科学技术研究所研究员。 运用到机器写稿技术的主要单位有 媒体：新华社、头条、南都等 互联网企业：微软、百度、腾讯、头条等 科研院所 写稿类型一般有体育、财经、民生、娱乐新闻，以及绝句、诗歌等。 原创 vs 二次创作机器写稿有两种方式，一种是原创，一种是二次创作。原创一般是之前没有稿件，只有结构化的数据，借助结构化的数据去生成新的稿件。比如说写一个天气预报的报道，或者年报、财报都直接可以从数据中生成。而关于一个已经有相关报道的事件，我们可以借助这些报道进行一些拼凑、改写成为新的稿件，这就是二次创作。 基础技术研究 自动文摘 自然语言生成 文本推荐 文本复述 应用技术研究 新闻资讯自动生成 新闻综述自动生成 用户评论自动生成 一些应用： 看明星的微博，判断是否有新闻价值，如果有，结合微博、评论信息、背景信息，生成新闻； 新闻资讯的生成，长短可控，几十字、上千字的简讯／资讯； 新闻综述自动生成：根据同一事件的多篇新闻报道，自动生成篇幅较长的事件综述。用 wikinews 做的实验，主要过程：新闻采集 =》(子话题选择)段落划分 =》段落排序 =》段落选择与合并 用户评论自动生成，根据制定的用户观点数据(产品特性+评分)，自动生成对应的产品评论，基于深度学习模型，根据产品特性和评分，生成自然语言的评论 趋势展望 让稿件具有态度和立场，更加人性化 通过推理与归纳，撰写深度报道 智影：AI 让视频更简单 康洪文，慧川智能 CEO 感觉很酷炫的样子，通过明星识别、场景识别、行为识别以及视频标签化后，可以根据文字来自动生成配套的视频。举个应用的例子，如果微信公众号的很多文章都可以配上配套的短视频，是不是很棒！ 智影 小结结尾引用某嘉宾的话，未来的世界无商业不智能，无智能不商业。从消费和生产两方面来看，消费互联网解决了高效的流通，产业互联网解决了正确的生产。看吧，我们赶上了最好的时代，同志们加油～ (P.S.最后和来自各大高校的童鞋以及雷锋网的小伙伴们面了个基，可惜奕欣姐姐嫌弃合照就不上图了。。)","tags":"ai chatbot iot 物联网 cv"},{"title":"NLP 笔记 - Neural Machine Translation","url":"/2017/07/10/NLP 笔记 - Machine Translation-Neuron models/","text":"持续填坑中– NLP 笔记 - Machine Translation主要讲了机器翻译的传统方法，这一篇介绍基于深度学习的机器翻译方法。 本文涉及的论文原文： Bengio et al. (2003), A Neural Probabilistic Language Model Devlin et al. (2014), Fast and Robust Neural Network Joint Models for Statistical Machine Translation Sutskever et al. (2014), Sequence to Sequence Learning with Neural Networks Bahdanau et al. (2014), Neural Machine Translation by Jointly Learning to Align and Translate Xu et al. (2015) Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. ICML’15 Luong et al. (2015)Effective approaches to attention based neural machine translation Neural MTNeural MT(NMT)的定义： Neural Machine Translation is the approach of modeling the entire MT process via one big artificial neural netowrk. 用一个大的神经网络来给整个机器翻译的过程建模，目前主流的结构是 Neural encoder-decoder architectures，最基本的思想是 encoder 将输入文本转化为一个向量， decoder 根据这个向量生成目标译文，编码解码开始均用 RNN 实现，由于普通 RNN 存在梯度消失/爆炸的问题，通常会引入 LSTM。本篇会介绍 NMT 发展的一些重要节点。 一句话解释 encoder-decoder architectures: Encoder compresses input series into one vector Decoder uses this vector to generate output Big wins of Neural MT End-to-end training所有参数同时被训练优化 Distributed representations share strength分布式表达更好的挖掘了单词／词组之间的相似性 Better exploitation of context可以使用更广泛的上下文，无论是 source 还是 target text More fluent text generation生成的文本质量更高 But… Concerns Black box component models for reordering, transliteration, etc. Explicit use of syntactic or semantic structures没有显性的用到句法／语义结构特征 Explicit use of discourse structure, anaphora, etc.没法显性利用指代消解之类的结果 NNLM: Bengio et al. (2003)A Neural Probabilistic Language Model，这篇论文为之后的 NMT 打下了基础。 传统的 Language model 有一定缺陷： 不能把 ngram 中 n 以外的词考虑进去n 越大句子连贯性越好，但同时数据也就越稀疏，参数也越多 不能考虑单词之间的相似度不能从 the cat is walking in the bedroom 学习到 a dog was running in a room Neural network language model(NNLM) 可以解决上面的两个问题。主要理解上图，先来定义一些参数：h: number of hidden unitsm: number of features associated with each wordb: output biases, with |V| elementsd: hidden layer biases, with h elementsV: word dictionary $w_1, …w_T \\in V$U: hidden-to-output weights, |V|*h matrixW: word features to output weights, |V|*(n-1)m matrixH: hidden layer weights, h*(n-1)m matrixC: word features C, |V|*m matrix 再来看一下目标函数: $$f(w_t,…,w_{t-n+1})=\\hat P(w_t|w_1^{t-1})$$ 目标函数包含了两个部分 Matrix C，用来 map word_id 和 word feature vector，维度是 |V|*m g，用来 map 这个上下文输入的 feature vector 和下一个单词 $w_t$ 在 V 上的条件概率的分布，g 用来估计 $\\hat P(w_t=i|w_1^{t-1})$$$f(i, w_{t-1},…,w_{t-n+1})=g(i,C(w_{t-1}),…,C(w_{t-n+1}))$$ 也就是说 f 是两个 mapping C 和 g 的组合，词向量矩阵 C 所有单词共享。模型有两个 hidden layer，第一部分的输入是上下文单词 $w_{t-1},…w_{t-n+1}$ 的 word_id，每个 word_id 在 C 中寻找到对应的 word vector，vector 相加得到第二部分的输入， 与 H 相乘加一个 biases 用 tanh 激活，然后与 U 相乘产生一个得分向量，再进入 softmax 把得分向量转化成概率分布形式。 前向传播的式子就是：$$y=b+Wx+Utanh(d+Hx)$$ 其中 x 是 word features layer activation vector，由输入词向量拼接而成$$x(C(w_{t-1}), C(w_{t-1}), …, C(w_{t-n+1}))$$ 最后的 softmax 层，保证所有概率加和为 1$$\\bar P(w_t|w_{t-1},…,w_{t-n+1})={e^{y_{w_t}} \\over \\sum_ie^{y_i}}$$ 通过在训练集上最大化 penalized log-likelihood 来进行训练，其中 $R(\\theta)$ 是正则项，如下$$L={1 \\over T}\\sum_tlogf(w_t,w_{t-1},…,w_{t-n+1;\\theta})+R(\\theta)$$ 用 SGD 梯度下降来更新 U 和 W 参数集合$\\theta = (b,d,W,U,H,C)$，参数量： |V|(1+mn+h)+h(1+(n-1)m)，dominating factor 是|V|(nm+h) 最后提一下两个改进，一个是加上图中的曲线部分，直接把词向量和输出连接起来(direct connections from the word features to the output)，另一个是和 ngram 相结合的 mixture model。看一下在 Brown Corpus 上的评估结果: n-gram model(Kneser-Ney smoothing): 321 neural network language model: 276 neural network + ngram: 252 NNJM: Devlin et al. (2014)Fast and Robust Neural Network Joint Models for Statistical Machine Translation，把 Bengio et al. (2003) 的 model 转化为一个 translation model，简单来说就是把 n-gram target language model 和 m-word source window 相结合，来创建一个 MT decoding feature，可以简单的融入任何的 SMT decoder。 Neural Network Joint Models(NNJM)条件概率模型，generate the next English word conditioned on The previous n English words you generated $e_{i-1}, e_{i-2}…$ The aligned source word and its m neighbors $…f_{a_i-1}, f_{a_i}, f_{a_i-2}…$ $$P(T|S) \\approx \\prod^{|T|}_{i=1}P(t_i|t_{i-1},…,t_{i-n+1}, S_i)$$ 假设 target word $t_i$ 只和一个 source word $a_i$ 对齐，我们会关注 source 句子里以 $a_i$ 为中心的一个 window $S_i$，也就是和 target $t_i$ 最相关的 source part。 $$S_i = s_{a_i-{m-1 \\over 2}},…,s_{a_i},…,s_{a_i+{m-1 \\over 2}}$$ 1) 如果 $e_i$ 只和一个 source word 对齐，那么 $a_i$ 就是对齐的那个单词的 index2) 如果 $e_i$ 和多个 source word 对齐，那么 $a_i$ 就是在中间的那个单词的 index3) 如果 $e_i$ 没有对齐的 source word，那么就继承最邻近(右边)的 aligned word 的 affiliation affiliation 用先验的基于规则的 word alignment 来推。 模型的训练过程和 NNLM 相似，不过是多了个 corpus 而已。最大化训练数据的 log-likelihood$$L=\\sum_ilog(P(x_i))$$ Self-normalization论文还提出了一种训练神经网络的新方法 – self-normalized 技术。由于训练的 cost 主要来自输出层在整个 target vocabulary 上的一个 softmax 计算，self-normalization 用近似的概率替代实际的 softmax 操作，思路很简单，主要改造一下目标函数。先来看一下 softmax log likelihood 的计算：想象一下，如果 $log(Z(x))=0$，也就是 $Z(x)=1$，那么我们就只用计算输出层第 r 行的值而不用计算整个 matrix 了，所以改造下目标函数，变成$$\\begin{aligned} \\L =\\sum_i[log(P(x_i))-\\alpha(log(Z(x_i))-0)^2] \\\\&amp; =\\sum_i[log(P(x_i))-\\alpha log^2(Z(x_i))] \\\\ \\end{aligned}$$ output layer bias weights 初始化为 log(1/|V|)，这样初始网络就是 self-normalized 的了，decode 时，只用把 $U_r(x)$ 而不是 $log(P(x))$ 作为 feature score，这大大加快了 decoding 时的 lookup 速度(~15x)。其中 $\\alpha$ 是一个 trade-off 参数，来平衡网络的 accuracy 以及 mean self-normalization error 其他优化如 pre-computing the (first) hidden layer 等。 VariationsMT decoder 有两类，一个是 decoder方法，用的是 string-to-dependency hierarchical decoder (Shen et al., 2010)，一个是 1000-best rescoring 方法，用的 feature 是 5-gram Kneser-Ney LM，Recurrent neural network language model (RNNLM) (Mikolov et al., 2010) 不同模型的影响​网络设置的影响 模型还有一些变种比如说翻译方向(source-to-target S2T, target-to-source T2S)，language model 的方向(left-to-right L2R, right-to-left R2L)，NNTM(Neural Network Lexical Translation Model)，对 many-to-one 问题用 NULL 解决，对 one-to-many 问题用 token concatenated 解决，训练和评估与 NNJM 相似。 Sutskever et al. (2014)Sequence to Sequence Learning with Neural Networks 使用了 encoder-decoder 框架，用多层的 LSTM 来把输入序列映射到一个固定维度的向量，然后用另一个深层的 LSTM 来 decode 这个向量，得到 target sequence，第二个 LSTM 实际上就是一个 NNLM 不过 conditioned on input sequences。主要的改变： fully end-to-end RNN-based translation model two different RNNencode the source sentence using one LSTMgenerate the target sentence one word at a time using another LSTM reverse the order of the words in all source sentence(but not target sentences) Encoder可以看作是一个 conditional language model (Bengio et al. ,2003) ，对原始句子，每个词用相应向量表示，每个词都有一个隐含状态 h1，代表这个词以及这个词之前的所有词包含的信息，当找到句尾标记的时候，对应的隐状态也就是 encoder 层的最后一个隐状态就就代表了整个句子的信息。 然后 decoder 对其进行解码，encoder 最后一层(最后一个时刻)作为 decoder 第一层，LSTM 能保持中期的记忆，那么解码层的每个隐状态，都包含了已经翻译好的状态以及隐状态，然后输出每个词。具体过程如下图： 将输入序列倒转喂给 LSTM，能够在 source 和 target 句子间引入许多 short-term dependencies，使得优化问题更加容易。 recurrent activation function 可以使用： Hyperbolic tangent tanh Gated recurrent unit [Cho et al., 2014] Long short-term memory [Sutskever et al., 2014] Convolutional network [Kalchbrenner &amp; Blunsom, 2013] 主要的贡献 hard-alignment =&gt; soft-alignment 对长句的泛化能力很好 简单的 decoder 关于 Decoder，论文 baseline 用了 rescoring 1000-best 的策略，实验用了一个 left-to-right beam search decoder 结果有一定提升。 还可以提一句的是，另一种做法是把 encoder 的最后一层喂给 decoder 的每一层，这样就不会担心记忆丢失了。 乱入：Decoders在模型能计算 P(T|S) 后，问题来了，怎样才能找出最可能的译文 T 呢？$$\\bar T = argmax_T(P(T|S))$$ Exhaustive Search最开始的想法当然是生成所有翻译，然后用 language model 打分，挑概率最大的了。BUT!! DO NOT EVEN THINK OF TRYING IT OUT!!!译文数量是词表的指数级函数，这还用想么？！ Ancestral Sampling$$x ~ P(x_t|x_1,…,x_n)$$多次取 sample。然而实践中会产生高方差的结果，同一个句子每次翻译结果都不一样，不大好吧？ Greedy Search$$x_t=argmax\\hat x_tP(\\hat x_t|x_1,…,x_n)$$每次选取当前最可能的那个单词，然而，这显然不能达到全局最优，每一步都会影响到后面的部分。 Beam Search 每个时刻记录 k 个最可能的选项，相当于剪枝，然后在这些选项中进行搜索 Results Attention: Bahdanau et al. (2014)Neural Machine Translation by Jointly Learning to Align and Translate，之前的 encoder-decoder 模型是将 source sentence 编码成一个固定长度的 vector，然后 decoder 产生 target sentence，这就要求 neural network 要能够把 source sentence 所有必要信息都压缩到一个 fixed-length vector 里，这对长句并不友好。我们希望在产生一个 target word 的时候只关注部分的 source word。这一篇提出了一个自动搜寻这样一个要关注的 source word window 的方法，换句话说，每次产生一个单词时，模型会从 source sentence 中搜索到相关信息所在的位置，基于包含了这些位置特征的 context vector 和 previous generated words，来生成下一个单词。这也就是注意力模型在机器翻译中的应用。 一句话解释： Attention Mechanism predicts the output $y_t$ with a weighted average context vector $c_t$, not just the last state 再通俗一点理解，attention 的作用可以看作是一个对齐模型，传统 SMT 我们用 EM 算法来求解对齐，这里做一个隐式的对齐，将 alignment model 用一个 feedforward neural network 参数化，和其他部分一起训练，神经网络会同时来学习 翻译模型(translation) 和 对齐模型(alignment)。attention 效果： 具体过程：用一个感知机公式将 source 和 target 的每个词联系起来，$a(h_{i-1},\\bar h_j)=v^T_atanh(W_ah_{i-1}+U_ah_j)$，然后通过 softmax 归一化得到一个概率分布，也就是 attention 矩阵，再进行加权平均得到 context vector(可以看作是 annotation 的期望值)。 模型将 input sentence 编码成一系列 vector，然后在 decode 时自适应的选择这些 vector 的一个子集。$a_{ij}$，或者说对应的 $e_{ij}$，反映了 annotation $\\bar h_j$ 关于前一个隐状态 $h_{i-1}$ 在决定下一个隐状态 $h_i$ 以及产生 $y_i$ 的重要性。直观的说，这在 decoder 里执行了 attention 机制。decoder 来决定应该对 source sentence 的哪一部分给予关注。通过这个 attention 机制，encoder 不用再将 source 的所有信息压缩到一个定长的 vector 里，信息可以在 annotation 序列中传播，然后由 decoder 来选择性的检索。 Encoder 还可以用双向 RNN 来做，这样每个单词的 annotation 不仅概括了前面单词的信息，还包括了后面单词的信息。 Attention 优化More Score Functions怎么算 alignment score 有下面集中不同的方式，实验表示第二种效果最好。compute alignment weight vector Global vs. Local论文Xu et al.2015 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. ICML’15 提到了 attention 可以分为 hard 和 soft 两种模型，简单理解，hard attention 就是从 source sentence 里找到一个能与产生单词 $t^{th}$ 对齐的特定单词，把 $s_{t,i}$ 设为 1，source 里的其他单词硬性认为对齐概率为 0；soft attention 就是之前 Bahdanau et al. (2014) 提到的，对 source sentence 每个单词都给出一个对齐概率，得到一个概率分布，context vector 每次是这些概率分布的一个加权和，整个模型其实是平滑的且处处可分的。 Effective approaches to attention based neural machine translation 提出了一个新的 attention 机制 local attention，在得到 context vector 时，我们不想看所有的 source hidden state，而是每次只看一个 hidden state 的子集(subset)，这样的 attention 其实更集中，也会有更好的结果。 Global attention 其实就是 soft attention， local model 实际相当于 hard 和 soft attention 的一个混合或者说折中，主要是用来降低 attention 的花费，简单来说就是每次计算先用预测函数得到 source 相关信息的窗口，先预估得到一个 aligned position $p_t$，然后往左往右扩展得到一个 focused window [$p_t-D$,$p_t+D$] 取一个类似于 soft attention 的概率分布。和 global attention 不同，这里 $a_i$ 的维度是固定的。 那么关于 local attention 有两个问题。第一个问题是怎么产生 aligned position，之前在 Devlin et al. (2014) 里是用规则，这里用 sigmoid function $p_t = S•sigmoid(v^T_p tanh(W_ph_t))$，其中 S 是 source sentence。第二个问题是怎么来学习这些 position parameters，像 $W_p$、$h_t$ 这些参数和网络结构中其他参数没有任何关联，怎么学习呢？方法是像 global attention 一样先计算对齐分数 $score(h_t, \\bar h_s)$，然后 normalize，这里有一个 trick 是将得到的 $a_t$ 与一个 truncated Gaussian distribution 结合，也就是 $a_t(s)=align(h_t, \\bar h_s)exp(-{(s-p_t)^2 \\over 2 \\sigma^2})$，$\\sigma={D \\over 2}$，这样我们会只有一个 peak，现在可以用 BP 来学习预测 position，这个模型这时候几乎是 处处可分的(differentiable almost everywhere)，这种对齐称为 predictive alignment(local-p) local attention 的训练花费更少，且几乎处处可分(differentiable) Coverage: Doubly attention论文Xu et al.2015 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. ICML’15提到的思路，用到机器翻译里就是同时注意原文和译文。 Linguistic ideas [Tu, Lu, Liu, Liu, Li, ACL’16]: NMT model with coverage-based attention [Cohn, Hoang, Vymolova, Yao, Dyer, Haffari, NAACL’16]: More substantive models of attention using: position (IBM2) + Markov (HMM) + fertility (IBM3-5) + alignment symmetry (BerkeleyAligner) 一般一个单词最多翻译为两三个单词，如果生成了五六个单词，那么模型可能在重复生成。 Current Research Direction on Neural MT Incorporation syntax into Neural MT Handling of morphologically rich languages Optimizing translation quality (instead of corpus probability) Multilingual models Document-level translation 到目前为止，我们都是假设在两种语言 F 和 E 之间训练一个模型。但是，世界上有许多种语言，一些研究已经证明能够利用所有语言的数据去训练一个模型。也可以跨语言执行迁移，先在一个语言对上训练模型，然后将其微调用于其他语言对。","tags":"nlp machine-translation 机器翻译"},{"title":"AWS Lambda + API Gateway + DynamoDB 添加 slash command 待办清单","url":"/2017/07/04/AWS Lambda + API Gateway + DynamoDB 添加 slash command 待办清单/","text":"接上一篇AWS API Gateway + Lambda + Slack App - 新建 slash command，这一篇介绍怎么用 aws lambda + api gateway + dynamodb 添加 slash command /todo，完成 to-do list 的增、删、查等任务。两个重点，一是连接 dynamodb，二是创建 slack interactive message，具体到这篇的例子，是实现 message button。 DynamoDB configurationAmazon DynamoDB 属于 NoSQL 数据库，支持文档和 key-value 存储模型。每一行是一个 item，item 时属性(attributes) 的集合，每个 attribute 都有各自的名称(name)和值(value)。DynamoDB 提供了 item 的 4 项基本操作，创建(PutItem)/读取(GetItem)/更新(UpdateItem)/删除(DeleteItem)。 Create table第一步，完成 todolist table 的创建，aws console 进入dynamodb，选 create table，做如下设置，primary key 设为 user，一个 user 一个 item，item 有属性 todos，类型是 list，一个 user 当然可以有多个 to-do item，都保存在 todos 的 list 中。当然，之后会有更多的属性，比如说 channel, priority 等，后面再做设置。 建表完成后在 Items 标签下 Create item，做如下设置，方便后面的测试。 Attach policy to IAM role接下来是测试 lambda function 能否连接数据库，默认情况下，lambda function 是没有这个权限的，我们需要创建一个 role，或者在已有的 role 上 attach 相应的 policy，再对 lambda function 采用这个 role，才可以访问数据库。所以，先从aws console 进入IAM，选择 Roles 以及 lambda configuration 中的 role，比如说 lambda_basic_execution(这里以 kmsDecrypt role 为例)，选择 inline policy 来创建并且 attach policy。 Step 1: create inline policy Step 2: generate policy Step 3: edit permissions ARN 在 DynamoDB 页面 table overview 下可以找到，这里的 permission 表示使用了这个 role 的 lambda function 只可以对 todolist 这张表进行操作，Actions 是操作类型，这里选 All Actions，表示增删改查所有操作都允许。 Step 4: review and apply policy Policy 的具体内容 123456789101112131415&#123; &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ &#123; &quot;Sid&quot;: &quot;Stmt1498896886000&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;dynamodb:*&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:dynamodb:us-west-2:XXXXXXXXXXX:table/todolist&quot; ] &#125; ]&#125; Lambda configuration写一个简单的 lambda function 看看能不能读取表中内容123456import boto3todo_table = boto3.resource(&apos;dynamodb&apos;).Table(&apos;todolist&apos;)def lambda_handler(event, context): print todo_table.get_item(Key=&#123;&apos;user&apos;: &apos;testuser&apos;&#125;) 连接成功 连接不成功可能是因为地区不一致，可以显性指定 region 来连接。123456import boto3todo_table = boto3.resource(&apos;dynamodb&apos;, &apos;us-west-2&apos;).Table(&apos;todolist&apos;)def lambda_handler(event, context): print todo_table.get_item(Key=&#123;&apos;user&apos;: &apos;testuser&apos;&#125;) 下一部分附上 debug 过程，提供可能的 debug 思路。 Possible error/Debug process有可能出现 “module initialization error”，具体错误信息是1module initialization error: An error occurred (AccessDeniedException) when calling the GetItem operation: User: arn:aws:sts::xxxxxxxxxxxxx:assumed-role/kmsDecrypt/todolist is not authorized to perform: dynamodb:GetItem on resource: arn:aws:dynamodb:us-east-1:xxxxxxxxxxxxxx:table/todolist: ClientError 把上一步的 policy 改的 less restrict 一些，方便调试123456789101112131415&#123; &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ &#123; &quot;Sid&quot;: &quot;Stmt1498896886000&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;dynamodb:*&quot; ], &quot;Resource&quot;: [ &quot;*&quot; ] &#125; ]&#125; 再重新 test 一下 lambda，发现错误变成了 Requested resource not found 根本没这个 table，怎么办？那干脆把所有 table 列出来看看喽，修改 lambda function，1234import boto3def lambda_handler(event, context): print boto3.client(&apos;dynamodb&apos;).list_tables() 发现 table list 为空。 这时候熟悉 aws 的朋友就知道，Region! Region! Region! 一定要一致！ 再来回顾下 dynamodb table overview，发现 table 所在 region 是 US WEST，而我们的 lambda ARN 是在 US EAST，所以办法是在连接 table 的时候直接指定地区。 123456import boto3todo_table = boto3.resource(&apos;dynamodb&apos;, &apos;us-west-2&apos;).Table(&apos;todolist&apos;)def lambda_handler(event, context): print todo_table.get_item(Key=&#123;&apos;user&apos;: &apos;testuser&apos;&#125;) 连接成功。 Slash command configuration在 slack app 页面新建 slash command /todo，command 以及 api gateway 的设置，具体参照AWS API Gateway + Lambda + Slack App - 新建 slash command，非常简单的过程。 Slack Message Button先来看一下 message button 的运作流程，slack app 的 interactive messages 下有一个 Request URL，专门用来响应 message button 事件。一个 slack app 只能配置一个 action URL，它会接收所有 channel/team 下的 message button 的所有点击操作，这相当于一个 dispatch station。当用户点击 button 时，action URL 会收到一个 URL encoded request，request 的 body 参数中会包含一个 payload，记录相应的 user action，我们可以通过 payload 来获取用户的点击行为，然后做出响应。 Slack 官方教程 Making messages interactive 提供了多种响应 message action 的方法，主要说来一是直接对 action URL 的 request 进行 response，要求是 3 秒内必须做出响应；二是通过 response_url 进行对原消息的更新等，三是用 chat.update 来更新原始信息。 经尝试，发现在使用 python 以及 slackclient package 的情况下，并不能用 chat.postMessage, chat.update 来实现 message button。slackclient 作为 slack api 的一个 wrapper，确实可以实现 chat.postMessage，但只能提供 basics 的一些 response，并不能处理请求中加 attachments 的情况。 这里采用的是直接响应的方法。首先需要在 API Gateway 中配置 request url，对应的 integration 还是选 todolist lambda function，mapping templates 还是要改成 x-www-form-urlencoded 的形式。 deploy 后记录下 Invoke URL，在 slack app 下修改 request URL message button format:12345678910111213141516171819202122232425262728293031def _respond_button(err, res=None): return &#123; &quot;text&quot;: res, &quot;attachments&quot;: [ &#123; &quot;callback_id&quot;: &quot;todo&quot;, &quot;color&quot;: &quot;#3AA3E3&quot;, &quot;attachment_type&quot;: &quot;default&quot;, &quot;actions&quot;: [ &#123; &quot;name&quot;: &quot;subtask&quot;, &quot;text&quot;: &quot;Remind me&quot;, &quot;type&quot;: &quot;button&quot;, &quot;value&quot;: &quot;reminder&quot; &#125;, &#123; &quot;name&quot;: &quot;subtask&quot;, &quot;text&quot;: &quot;Set priority&quot;, &quot;type&quot;: &quot;button&quot;, &quot;value&quot;: &quot;priority&quot; &#125;, &#123; &quot;name&quot;: &quot;subtask&quot;, &quot;text&quot;: &quot;Set project&quot;, &quot;type&quot;: &quot;button&quot;, &quot;value&quot;: &quot;project&quot;, &#125; ] &#125; ] &#125; 上面的 message format 会产生下图的三个 button 如果用户点击 Remind me，这个行为对应的信息会发送到 request url，由于 request url 还是绑定了 todolist 这个 lambda function，所以可以在 lambda 中判断 request 是否包含 payload 参数，如果包含，说明这是一个 button 响应事件，就读取 user action 信息，并响应，否则，就响应 command 命令。 完整的 lambda function 代码，role 用 kmsDecrypt，环境变量设置好 kmsEncryptedToken，参照AWS API Gateway + Lambda + Slack App - 新建 slash command， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165# -*- coding: UTF-8 -*-import boto3import jsonimport loggingimport osfrom base64 import b64decodefrom urlparse import parse_qstodo_table = boto3.resource(&apos;dynamodb&apos;, &apos;us-west-2&apos;).Table(&apos;todolist&apos;)ENCRYPTED_EXPECTED_TOKEN = os.environ[&apos;kmsEncryptedToken&apos;]kms = boto3.client(&apos;kms&apos;)expected_token = kms.decrypt(CiphertextBlob=b64decode(ENCRYPTED_EXPECTED_TOKEN))[&apos;Plaintext&apos;]logger = logging.getLogger()logger.setLevel(logging.INFO)def _respond_text(err, res=None): return &#123; &quot;text&quot;: res &#125;def _respond_button(err, res=None): return &#123; &quot;text&quot;: res, &quot;attachments&quot;: [ &#123; &quot;callback_id&quot;: &quot;todo&quot;, &quot;color&quot;: &quot;#3AA3E3&quot;, &quot;attachment_type&quot;: &quot;default&quot;, &quot;actions&quot;: [ &#123; &quot;name&quot;: &quot;subtask&quot;, &quot;text&quot;: &quot;Remind me&quot;, &quot;type&quot;: &quot;button&quot;, &quot;value&quot;: &quot;reminder&quot; &#125;, &#123; &quot;name&quot;: &quot;subtask&quot;, &quot;text&quot;: &quot;Set priority&quot;, &quot;type&quot;: &quot;button&quot;, &quot;value&quot;: &quot;priority&quot; &#125;, &#123; &quot;name&quot;: &quot;subtask&quot;, &quot;text&quot;: &quot;Set project&quot;, &quot;type&quot;: &quot;button&quot;, &quot;value&quot;: &quot;project&quot;, &#125; ] &#125; ] &#125;def _respond_button_action(params): params = json.loads(params[0]) token = params[&apos;token&apos;] user = params[&apos;user&apos;][&apos;name&apos;] channel = params[&apos;channel&apos;][&apos;name&apos;] action = params[&apos;actions&apos;][0][&apos;value&apos;] if action == &apos;reminder&apos;: return &quot;&#123;&#125; set a reminder for this to-do item in &#123;&#125;&quot;.format(user, channel) elif action == &apos;priority&apos;: return &quot;&#123;&#125; set a priority for this to-do item in &#123;&#125;&quot;.format(user, channel) else: return &quot;&#123;&#125; set a project for this to-do item in &#123;&#125;&quot;.foramt(user, channel) returndef _get_todo_list(user, todos): if &apos;Item&apos; not in todos or &apos;todos&apos; not in todos[&apos;Item&apos;] or not todos[&apos;Item&apos;][&apos;todos&apos;]: return _respond_text(None, &quot;&#123;&#125; has nothing in to-do list!&quot;.format(user)) msg = &apos;&apos; for i, item in enumerate(todos[&apos;Item&apos;][&apos;todos&apos;]): msg += &apos;&#123;&#125; &#123;&#125; \\n&apos;.format(i, item) return _respond_text(None, msg)def _remove_from_list(user, index, todos): if not index.isdigit(): return _respond_text(None, &quot;Sorry, I didn’t quite get that. This usually works: `/todo done [to-do item index]`. Try `/todo todolist` to get to-do item index.&quot;) todo_item = todos[&apos;Item&apos;][&apos;todos&apos;][int(index)] response = todo_table.update_item( Key=&#123; &apos;user&apos;: user &#125;, UpdateExpression=&quot;REMOVE todos[&quot; + index + &quot;]&quot;, ReturnValues=&quot;UPDATED_NEW&quot; ) if response[&apos;ResponseMetadata&apos;][&apos;HTTPStatusCode&apos;] != 200: return response return _respond_text(None, &quot;&#123;&#125; has done &#123;&#125; &#123;&#125;&quot;.format(user, index, todo_item))def _clear(user, channel): response = todo_table.delete_item( Key=&#123; &apos;user&apos;: user, &#125; ) if response[&apos;ResponseMetadata&apos;][&apos;HTTPStatusCode&apos;] != 200: return response return _respond_text(None, &quot;&#123;&#125; has cleared his/her to-do list in &#123;&#125;&quot;.format(user, channel))def _send_button(user, command, channel, command_text, todos): # insert items into database if &apos;Item&apos; not in todos: response = todo_table.put_item(Item=&#123; &apos;user&apos;: user, &apos;channel&apos;: channel, &apos;todos&apos;: [command_text] &#125;) else: response = todo_table.update_item( Key=&#123; &apos;user&apos;: user &#125;, UpdateExpression=&quot;SET todos = list_append(todos, :val)&quot;, ExpressionAttributeValues=&#123;&quot;:val&quot; : [command_text]&#125;, ReturnValues=&quot;UPDATED_NEW&quot; ) if response[&apos;ResponseMetadata&apos;][&apos;HTTPStatusCode&apos;] != 200: return response return _respond_button(None, &quot;&#123;&#125; added &apos; &#123;&#125; &apos; to the to-do list in &#123;&#125;&quot;.format(user, command_text, channel))def lambda_handler(event, context): params = parse_qs(event[&apos;body&apos;]) # with payload, which means user clicks a button if &apos;payload&apos; in params: return _respond_button_action(params[&apos;payload&apos;]) # without payload token = params[&apos;token&apos;][0] if token != expected_token: logger.error(&quot;Request token (%s) does not match expected&quot;, token) return respond(Exception(&apos;Invalid request token&apos;)) user = params[&apos;user_name&apos;][0] command = params[&apos;command&apos;][0] channel = params[&apos;channel_name&apos;][0] command_text = params[&apos;text&apos;][0] # get todo list from database todos = todo_table.get_item(Key=&#123;&apos;user&apos;: user&#125;) if command_text.startswith(&apos;todolist&apos;): return _get_todo_list(user, todos) elif command_text.startswith(&apos;done &apos;): return _remove_from_list(user, command_text.split(&apos; &apos;, 1)[1], todos) elif command_text.startswith(&apos;clear&apos;): return _clear(user, channel) return _send_button(user, command, channel, command_text, todos) # return respond(None, &quot;%s added %s to the to-do list in %s to to-do list %s&quot; % (user, command_text, channel, command_text, response, todo))","tags":"chatbot iot alexa slack 物联网"},{"title":"卷积神经网络 CNN 笔记 - 目标探测","url":"/2017/06/20/卷积神经网络-目标探测/","text":"介绍目标探测的基本方法，传统方法 DPM，神经网络分类 R-CNN 系列方法和神经网络回归 YoLo 系列方法。 目标探测先来看下什么是目标探测，下图矩形框(running box)表示的物体都可以作为目标探测的对象。不止矩形框，椭圆形框在某些场合更适合做目标探测，因为它能更好的捕捉对象，并对物体朝向做相应调整，机变性更好。 目标探测的任务一般分为单目标探测和多目标探测。目的一是找到目标的位置坐标，二是判定目标类别。 目标探测的应用场景有安防、自动驾驶等。从技术方面讲，目标探测传统方法用的是DPM，虽然目前已经被神经网络超越，但是很多思想可以借鉴。神经网络大体上有两类方法，一类是分类方法主要是RCNN系列方法 ，先找到若干候选区，然后一个区域一个区域排查，判断有没有要找的物体；另一类是回归方法主要是YoLo系列方法，直接找到区域，以及区域有什么物体。 下面来看下目标探测的两个直接思路。 直接思路一：回归问题一类思路是把目标探测看作是一个回归问题。直接生成 class score，也就是判断是该类别(物品)的 confidence value，和 box coordinates，也就是检测框的坐标值。整个任务的损失函数其实是位置差和分类差的一个组合。 直接思路二：局部识别问题另一类思路是在很多位置上尝试识别，能够完成识别的地方就是目标位置。如下图，我们生成潜在的候选区域(proposal)，然后采用分类器逐个判别这些区域内图像是不是目标物体，如果是，可以把候选区域做延展(用 regression)，看有没有更合适的候选框。 一个问题是怎样找到这些候选位置？一种方法是用不同 scale 的 sliding windows 来遍历所有的位置，这种方法代价太高，另一种更有效的方法是直接计算候选区域。现在有很多算法能够有效的产生候选区域，比较常用的是 EdgeBoxes（在 RCNN 中使用）。 传统方法-DPM传统方法主要包括 3 个步骤： 利用不同尺度的滑动窗口在图像上进行区域搜索，定位候选区域； 对候选区域进行特征提取，如sift，hog，haar等； 利用分类器进行分类识别，svm等 主要思路就是提取图像特征，制作出激励模板，在原始图像滑动计算，得到激励效果图，然后根据激励分布确定目标位置。如下图人物识别把人为设计的激励模板和 HOG 特征图结合，如果有人，会得到加强的激励，然而同样的，柱子也会得到激励。 DPM(Deformable Part Model)可以看做是HOG(Histograms of Oriented Gradients)+SVM(Surpport Vector Machine) 方法的扩展，大体思路是一致的 — 先计算梯度方向直方图，然后用 SVM 训练得到物体的梯度模型。有了这样的模板就可以直接用来分类了，简单理解就是模型和目标匹配。DPM 只是在模型上做了很多改进工作。 由于目标可能会形变，之前模型不能很好的适应复杂场景的探测，所以一个改进是各个部分单独考虑，对物体的不同部分单独进行学习，所以DPM把物体看成了多个组成部件(比如说人脸的鼻子，嘴巴等)，用部件间的关系来描述物体，这个特点非常符合自然界许多物体的非刚性特征。基本思路如下: 产生多个模板，整体模板(root filter)以及不同局部模板(part filter)root filter 包含目标的整体信息，而 part filter 采用高分辨率的细节建模，看的梯度会更加精细 不同模板同输入图片“卷积”产生特征图 特征图组合形成融合特征 对融合特征进行传统分类，回归，得到目标位置 模型在图像特定位置和尺度的得分， 等于 root filter 的得分加上各个 part filter 得分的总和。每个 part filter 的得分等于该 part 在所有空间位置的得分的最大值，而部件在某位置的得分等于 part filter 在此位置的得分减去此位置的变形代价(也就是 part 偏离其理想位置的程度) DPM 的优点是方法比较直观、简单，运算速度快，也可以适应运动物体变形，很好的处理遮挡、非刚性可变和视觉变换问题，到 2012 年前，是最好的方法。然而 DPM 也有一些缺点 性能一般 激励特征人为设计，表达能力有限，工作量大，难以进行迁移学习 大幅度旋转无法适应，稳定性差 神经网络分类: R-CNN 系列方法R-CNN(CVPR2014, TPAMI2015)算法神经网络的分类思想是对多个位置，不同尺寸，用卷积神经网络判断区域内图片是不是某物，候选位置(proposal)提出方法一般用 EdgeBox。 R-CNN 最初提出的时候选择 20 类进行探测，是在 ImageNet 模型的基础上，把 1000 类的分类模型变成能识别 21 类(20类+other)的 Fine-tune 分类模型。=&gt; 特征的提取过程: 对图片计算候选区域；对候选区域切分图片，对切分部分进行 resize 变成输入大小；提取相应高级特征；存储特征(大容量，200-300G空间存储图片) 单独目标探测器训练：对每一类进行单独训练，保证每一类训练数据平衡，每一类都是 binary 分类(yes/no)。比如猫的分类器，可能大部分图片没有一个理想的猫，只有一个耳朵，这不算猫，我们要与真值进行比较，看左上右下区域，如果重合(共有区域)比较多，就认为是猫的图片。每一类都有很多的正例反例(1/0)。 单独目标回归器训练-基于候选区域微调: 同样的，每一类单独训练，保证每一类训练数据平衡，这里是每一类做 BBOX 回归。目的是在知道是不是猫以及位置的偏移后，用回归对位置进行 offset，离真值(ground truth)更近，最终的探测精度会更高。 总的来说，R-CNN 的测试过程就是 对每个图像生成 1k-2k 个候选区域 对每个候选区域，使用深度网络进行特征计算 特征喂给每一类的 svm 分类器，判别是否属于该类分类；同时用回归修正候选框位置 后续处理 常用数据集 评估方法 MAP(mean average precision) IoU，真值和预测值多重叠部分与两者的并集的比值，一般大于 0.5 就认为是正确的 R-CNN 结果对比Regionlets(2013) 并没有经过 fine-tune，R-CNN(2014, AlexNet) 用事先训练好的分类器进行了 fine-tune，R-CNN+bbox reg(AlexNet)，用了 regression，加了 offset 对检测框做了范围调整，R-CNN(vgg-16)把 base model 改成了 vgg 总的来说，主要是从下面三个角度进行了模型的调整 Finetune 回归微调 Base 模型 优缺点优点: CNN 用于目标探测，利 用了 CNN 高效识别能力， 大大提高性能 摆脱人为设计物品模版， 方法具有通用性 分类＋回归，有了找到精确位置的可能 缺陷: 为了检测一个目标，所有候选区域计算，大量卷积运算，非常慢对于速度慢这个问题，SPP-NET 给出了解决方案。R-CNN 对图像提完 region proposal(2k 左右)之后将每个 proposal 当成一张图像进行后续处理(CNN提特征+SVM分类)，实际上对一张图像进行了2000次提特征和分类的过程！SPP-NET 对图像提一次卷积层特征，然后将 region proposal 在原图的位置映射到卷积层特征图上，这样对于一张图像只需要提一次卷积层特征，然后将每个 region proposal 的卷积层特征输入到全连接层做后续操作 SVM 训练与CNN 断裂， SVM Loss 没办法用于 CNN Loss，有效信息不能用于优化模型， not end-to-end 每一类单独训练，异常繁琐 Fast R-CNN(ICCV2015)Fast R-CNN 的三个进步 共享卷积计算增加 ROI pooling layer 完整训练(end-to-end)用 softmax 代替 svm 分类，用多目标损失函数加入候选框回归，除 region proposal 提取外实现了 end-to-end 多目标一起学习 共享卷积计算Fast R-CNN 在最后一个卷积层后加了一个 ROI pooling layer，实际上就是上面提到的 SPP-NET 的一个精简版，特点是: 卷积计算保持空间位置 共同区域的卷积计算只需进行一次 切割候选区+提取特征图=计算完整特征图+切割对应候选区把图片的 region proposal 切割出来，resize，提取特征，其实就等同于在原图特征图里找到 region proposal 一个重要的问题是不同区域的特征如何保持一致？全连接层要求接的区域形状一致；所以要特征图里区域的一致性处理，也就是做一个 pooling特征一致化 - Max Pooling 局部区域100x50 =&gt;按 4:2 pooling50x100 =&gt; 按 2:4 pooling=&gt; 25x25 feature=&gt; 225 FC 如果 pooling size 不完美，其实也没有问题，pooling 本身就是填充 pooling 后的图的每一个 pixel，只要从 pooling 前某区域选一个 pixel 值即可，不一定要规整 位置 + 类别联合学习图片 =&gt; cnn feature map计算 =&gt; proposal应用 =&gt; feature map相应区域做 region pooling 得到固定大小的 feature map =&gt; classification &amp; regression用 softmax 代替 svm 分类，使用多任务损失函数(multi-task loss)，将候选框回归直接加入到 cnn 网络中训练，除去 region proposal 的提取阶段，这样的训练过程是端到端的(end-to-end)，整个网络的训练和测试十分方便 性能提升看一下性能提升的情况然而前提是 不考虑候选区域(proposal)的生成，如果加上候选区域(proposal)的时间region proposal 的提取使用 selective search，目标检测时间大多消耗在这上面(提region proposal 2~3s，而提特征分类只需0.32s)，无法满足实时应用，那么，怎么解决候选区域的计算呢？一个方法是也靠神经网络。 Faster R-CNN(NIPS2015)RPN(Region Proposal Network)用神经网络来解决候选区域的生成问题，主要是神经网络特征增加一组输出 RPN(Region Proposal Network)候选区域网络 直接产生候选区域，无需额外生成本质上是 sliding window，RPN 只需在最后的卷积层上滑动一遍，因为 anchor 机制和候选框回归可以得到多尺度多长宽比多 region proposal 直接用于后续特征图切割 最后的特征图中有很多个 pixel，每个 pixel 和卷积核进行计算，生成 k 个可能的 prpoposal(实际中 k 往往=9，一个区域可能同时被多个物体占用，所以尽可能把可能分布的形状都生成)，每个 proposal 有个 score 的计算。如图，左边是 3x3 的卷积网络的特征图，右边是 k 个 anchor box(相当于小的候选生成单元)。我们对特征图进行 sliding window 的计算，每个 pixel 生成 256 长的向量(向量长度其实是自己设计的，vgg 建议 512-d)，这个向量用来生成 k 个 proposal 的值，以及对应的 2k score(是/不是目标物体)，4k 个 coordinates(上下左右坐标)。 网络输出的值： 是不是一个目标 覆盖范围的相对位置 k=9(3种尺寸，3种长宽比)个 anchor，能产生多少个 proposal?特征图 size HxW -&gt; HWx9 in paper 2400x9 如果是 VGG conv5 作为特征图，3x3 区域对应的原始图像区域？经过了 4 个 pooling，往前推，6x6 -&gt; 12x12 -&gt; 24x24 -&gt; 48x48，也就是 16 倍的一个缩放 Anchor的平移不变怎么理解较小的平移 pooling 过程中忽略，3 个 pixel 的移动经过 4 层的 pooling，移动后的位置和原位置相差可以忽略 Anchor 同外接 Proposal 区别数量：1-2个数量级减少；性能：更高效；速度：10x Anchor 设计的借鉴意义？神经网络有能力找到最终量，也有能力找到很多中间量。只用 Anchor 判断是不是目标，会不会存在大材小用，能够判断更多吗？或者说，能在是不是目标的基础上，判断是什么目标吗，也就是直接拟合 为了让RPN的网络和Fast R-CNN网络实现卷积层的权值共享，训练 RPN 和 Fast R-CNN的时候用了4阶段的训练方法: 使用在 ImageNet 上预训练的模型初始化网络参数，微调 RPN 网络； 使用(1)中RPN网络提取 region proposal 训练 Fast R-CNN网络； 使用(2)的 Fast R-CNN 网络重新初始化 RPN, 固定卷积层进行微调； 固定(2)中 Fast R-CNN 的卷积层，使用 (3) 中 RPN 提取的 region proposal 微调网络 Faster R-CNN 用了直接联合学习(joint learning) 的方法，如上图，一个网络有 4 个损失函数 Anchor 是不是目标 Anchor 回归候选区域回归 Fast R-CNN 分类 Fast R-CNN 基于候选位置回归联合学习的方法产生了更少的候选区，但是精度不会受到影响，速度却快了 10 倍，接近于实时处理(@K40 GPU, 12G)。 性能提升 接近于实时处理，然而还是很难实时的目标探测，下面的 YOLO 这类方法可以达到实时性。 神经网络回归: YoLo 系列方法YoLo算法YoLo 将目标探测任务看作目标区域预测和类别预测的回归问题，用单个神经网络直接预测物品边界和类别分数，可以直接找到物体是什么，在哪里。 把图片分成 SxS 的格子(grid cell)，一般是 7x7 的网络，每个网格生成： B 个 Bbox，4 个 coordinates + 1 个 confidence score N 个类别分数 $Pr(Class_i|Object)$与 Anchor 不同的是，这里有 N 个分数，表示属于每一类的分数分别是多少 S=7, B=2, N=20总共的回归目标： SxSx(5B+N)​ 2x5+20=30 个参数，49x30=1470 个数值，用来回归候选区域个数： (B=2) 98 个 &lt;&lt; Faster R-CNN每个小区域生成 2 个候选区，一个小的区域就是一个粗糙的 proposal，对小区域进行大范围的 regression，找到目标 损失函数: 性能性能： 实时运行 精度稍微下降 定位精度较差 经过大量的 pooling，位置的响应会有一定弱化 Limitations YoLo 的每一个网格只预测两个 boxes，一种类别。这导致模型对相邻目标预测准确率下降。因此，YOLO 对成队列的目标（如一群鸟）识别准确率较低。 YoLo 是从数据中学习预测 bounding boxes，因此，对新的或者不常见角度的目标无法识别。 YoLo 的损失函数对small bounding boxes 和 large bounding boxes 的 error 平等对待，影响了模型识别准确率。因为对于小的 bounding boxes，small error影响更大。 SSD: The Single Shot DetectorSSD 分类更细，网络结构有点像 resnet。中间多层特征参与位置、种类计算，在不同 layer 输出的不同尺寸的 feature map 划格子，在格子上提“anchor”，弥补了 Yolo 只在最后一层分 7x7 的框漏掉的部分。和 Yolo 相比，更快更准确。 候选区 98 vs 8732 速度 21:46 (vgg base) 精度 66.4:74.3 参考链接：目标检测方法——从RCNN、Fast-RCNN到Faster-RCNNYOLO：实时快速目标检测","tags":"deep-learning cnn"},{"title":"AWS API Gateway + Lambda + Slack App - 新建 slash command","url":"/2017/06/19/AWS API Gateway + Lambda + Slack App - 新建 slash command/","text":"接之前AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack，介绍怎么在 slack app 的基础上添加 slash command。 slash command 的配置页面需要一个 Request URL，这个 URL 就由 AWS API Gateway 来提供，API Gateway 调用 AWS Lambda 来完成具体的动作，而 Lambda 需要一个 slack token 来验证 slack app 的身份，才能够调用 slack api 来接收/回复信息，这个 token 由 AWS IAM 进行加密保障安全性。下面的教程分别介绍了怎么加密 token，编写 Lambda，配置 API Gateway，来完成一个 slash command 的创建。 Encrypt KMS KeyStep 1: 在 IAM console 创建一个 KMS key，记录下 key-id，后面需要用到。Step 2: 在 slack apps 选择你的 app，然后在 Basic Information 下的 App Credentials 部分找到 Verification Token，记录下来，这就是我们需要加密的 token。 Step 3: 我们的目的是用 Step 1 创建的 key 来对 Step 2 记录的 token 进行加密。如果电脑已经装了 awscli，那么直接在命令行输入下面的命令即可。1$ aws kms encrypt --key-id &lt;key-id&gt; --plaintext &lt;text&gt; 其中 key-id 就是开始记录下的 kms key id，text 就是 verification token，把产生的 CiphertextBlob记录下来，在下一步 Lambda Configuration 里要用。 如果没有安装 aws-cli，OSX 系统直接用 brew 命令安装一下，最好不要用 pip，很大概率会出问题。 1$ brew install awscli 装好后，aws --version 查看是否安装成功， aws configure 命令来配置账户信息，会要求输入 AWS Access Key ID: 在 aws console 的 My Security Credentials 下 AWS Secret Access Key: 现在必须创建一个 IAM user 才能得到，戳 create IAM user) Default region name: 根据实际情况填，如果是 US East (N. Virginia)，就填 us-east-1，注意不要在末尾加 abcd，us-east-1a 类似的格式会出错 Default output format: 可以不填 配置完正常进行加密即可。 Lambda ConfigurationLambda blueprint 选 slack-echo-command，创建 lambda function slashTest，这里要实现的是当用户 [user] 调用 /test 这个 [command] 时(之后会创建)并输入文本 [text] 时，返回 [user] invoked [command,e.g., /test] in [channel,eg., directmessage] with the following text: [text]&quot;。代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&apos;use strict&apos;;/*This function handles a Slack slash command and echoes the details back to the user.Follow these steps to configure the slash command in Slack: 1. Navigate to https://&lt;your-team-domain&gt;.slack.com/services/new 2. Search for and select &quot;Slash Commands&quot;. 3. Enter a name for your command and click &quot;Add Slash Command Integration&quot;. 4. Copy the token string from the integration settings and use it in the next section. 5. After you complete this blueprint, enter the provided API endpoint URL in the URL field. To encrypt your secrets use the following steps: 1. Create or use an existing KMS Key - http://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html 2. Click the &quot;Enable Encryption Helpers&quot; checkbox 3. Paste &lt;COMMAND_TOKEN&gt; into the kmsEncryptedToken environment variable and click encryptFollow these steps to complete the configuration of your command API endpoint 1. When completing the blueprint configuration select &quot;Open&quot; for security on the &quot;Configure triggers&quot; page. 2. Enter a name for your execution role in the &quot;Role name&quot; field. Your function&apos;s execution role needs kms:Decrypt permissions. We have pre-selected the &quot;KMS decryption permissions&quot; policy template that will automatically add these permissions. 3. Update the URL for your Slack slash command with the invocation URL for the created API resource in the prod stage.*/const AWS = require(&apos;aws-sdk&apos;);const qs = require(&apos;querystring&apos;);const kmsEncryptedToken = process.env.kmsEncryptedToken;let token;function processEvent(event, callback) &#123; const params = qs.parse(event.body); const requestToken = params.token; if (requestToken !== token) &#123; console.error(`Request token ($&#123;requestToken&#125;) does not match expected`); return callback(&apos;Invalid request token&apos;); &#125; const user = params.user_name; const command = params.command; const channel = params.channel_name; const commandText = params.text; callback(null, `$&#123;user&#125; invoked $&#123;command&#125; in $&#123;channel&#125; with the following text: $&#123;commandText&#125;`);&#125;exports.handler = (event, context, callback) =&gt; &#123; const done = (err, res) =&gt; callback(null, &#123; statusCode: err ? &apos;400&apos; : &apos;200&apos;, body: err ? (err.message || err) : JSON.stringify(res), headers: &#123; &apos;Content-Type&apos;: &apos;application/json&apos;, &#125;, &#125;); if (token) &#123; // Container reuse, simply process the event with the key in memory processEvent(event, done); &#125; else if (kmsEncryptedToken &amp;&amp; kmsEncryptedToken !== &apos;&lt;kmsEncryptedToken&gt;&apos;) &#123; const cipherText = &#123; CiphertextBlob: new Buffer(kmsEncryptedToken, &apos;base64&apos;) &#125;; const kms = new AWS.KMS(); kms.decrypt(cipherText, (err, data) =&gt; &#123; if (err) &#123; console.log(&apos;Decrypt error:&apos;, err); return done(err); &#125; token = data.Plaintext.toString(&apos;ascii&apos;); processEvent(event, done); &#125;); &#125; else &#123; done(&quot;Token has not been set.&quot;); &#125;&#125;; 配置需要注意的是 Role 的选择，默认从 templates 里选 kmsDecrypt，不用修改，加个名字就好。在 Environment variables 里填写上一部分记录下的加密后的 token。但是！代码里请不要修改！！ API Gateway Configuration关于基础的 API Gateway 教程，见 AWS API Gateway + Lambda 教程 - 生成随机数 在 aws console 页面的 Services -&gt; Application Service -&gt; API Gateway 下新建 API，然后在 Action 下拉框下 Create Resource，名称可以写 /test，然后继续 Create Method ，选 POST，Lambda Function 选择之前我们已经建好的 slashTest，保存后在新页面选择 Integration Request，新建一个 mapping template，如下： Content-Type: application/x-www-form-urlencodedTemplate: { &quot;body&quot;: $input.json(&quot;$&quot;) } 之后部署，Actions -&gt; Deploy API，记下完成页面显示的 Invoke URL。 Slack App Configuration回到 slack app 页面，选择左侧的 Slash Commands，新建一个 Command，Request URL 填写上一部分记录下来的地址，注意将 sub resource name 补充完整，这里是 /test。完成后记得 reinstall app 返回结果：1&#123;&quot;statusCode&quot;:&quot;200&quot;,&quot;body&quot;:&quot;\\&quot;sxu1 invoked /test in directmessage with the following text: hello world\\&quot;&quot;,&quot;headers&quot;:&#123;&quot;Content-Type&quot;:&quot;application/json&quot;&#125;&#125; 如果要返回 plain text，直接修改 lambda function，12345678exports.handler = (event, context, callback) =&gt; &#123; const done = (err, res) =&gt; callback(null, res); //&#123; // statusCode: err ? &apos;400&apos; : &apos;200&apos;, // body: err ? (err.message || err) : JSON.stringify(res), // headers: &#123; // &apos;Content-Type&apos;: &apos;application/json&apos;, // &#125;, // &#125;);","tags":"chatbot iot alexa slack 物联网"},{"title":"AWS API Gateway + Lambda 教程 - 生成随机数","url":"/2017/06/18/AWS API Gateway + Lambda 教程 - 生成随机数/","text":"非常简单的教程，以产生一定范围内的随机数为例，介绍如何用 AWS Lambda + API Gateway 建立一个 serveless API，包括 API 如何传参。 Overview如果要用一句话理解 API Gateway，那必须是 serverless APIs。AWS API Gateway 与 AWS Lambda 紧密集成，开发者可以通过 API Gateway 创建基于 REST 风格的 API，各种 app 应用调用这些 API，而这些 API 可以通过 AWS Lambda 中运行的代码来调用公开提供的 AWS 服务(or anything you like)。下面两幅图给出了更直观的逻辑。 API Gateway 的优势官方说明说了很多，感觉最大优势除了能够创建完全无服务器的 API 外，值得一提的就是能提供 安全控制机制(security) 和 版本控制(versioning)，有兴趣还是看文档吧。 下面来一个简单的例子 randomGenerator，产生 0-10 之间的随机数。网上可以找到一些教程，不过有些并不能 work，有很多坑，感觉是版本问题。主要逻辑就是123456API Gateway =&gt;handle and validate requestpass to lambda functionLambda execution rule =&gt;call other aws service OR do something else 相应的，步骤也就是分别配置好 Lambda function 和 API，然后将两者结合起来，结合方法有两种，一是在 Lambda 界面添加 Trigger，连接 API；二是在 API Gateway 界面添加 Lambda function，绑定 Lambda，两种方法都可以。 Example 1: Basic random-number-generatorLambda Configuration登录AWS console在 Service 下选择 Lambda Step1: Create a Lambda function，选 Node.js.4.3, Blank Function Step 2: Configure Triggers，如果已经配置好了 API Gate，就选择相应的 API name，如果没有，直接默认下一步。 Step 3: Configure Function，进行如下设置，附代码部分 1234567891011&apos;use strict&apos;console.log(&apos;Loading function&apos;)exports.handler = (event, context, callback) =&gt; &#123; let min = 0; let max = 10; let generatedNumber = Math.floor(Math.random() * (max - min)) + min; callback(null, generatedNumber);&#125;; 这里我们不需要验证身份，environment variables 留空就好。Role 如果没有 existing role，可以新建一个。 Step 4: Submit，预览一下如果没问题就 submit，等待一会儿 lambda function 就建好啦。 Step 5: Test，如果在 Step 2 里选择了已经建好的 API Gateway 作为 Trigger，那么可以直接选择 Test 进行测试，也可以通过 url 测试。有可能会遇到 Internal server error，官方说明 response must have statusCode, body, headers，于是把代码改了下，就成功啦。(后来发现好像不改也没关系。。) 12345678910111213141516&apos;use strict&apos;;console.log(&apos;Loading function&apos;);exports.handler = (event, context, callback) =&gt; &#123; let min = 0; let max = 10; let generatedNumber = Math.floor(Math.random() * (max - min)) + min; const response = &#123; statusCode: 200, body: JSON.stringify(generatedNumber) &#125;; callback(null, response);&#125;; 测试结果如下： 相反，如果在 Step 2 里并没有设置 Trigger，我们需要新建 API，请看下一部分 API Gateway Configuration。 API Gateway Configuration在 aws console 页面的 Services -&gt; Application Service -&gt; API Gateway 下新建 API，然后在 Action 下拉框下 Create Resource，名称可以写 /number，然后继续 Create Method ，选 GET，Lambda Function 选择之前我们已经建好的 random-number-generator 填写完毕后可以直接测试一下，产生了随机数 1。 测试通过就可以部署，Actions -&gt; Deploy API 部署完成后会自动跳转到 Stages 页面，把 Invoke URL 记录下来。 浏览器测试一下，注意补充 sub-resource，这里是 /number。 然后在其他应用里就可以直接通过 url 调用 API 啦～ Example 2: Passing information through API GatewayAPI 经常需要传参，那么怎么通过 API Gateway 传递参数呢？比如说我们希望让用户来定义产生随机数的范围，也就是 url 应该是下面这样的 1https://[API id].execute-api.us-east-1.amazonaws.com/prod/number?min=1&amp;max=10 其实做法也很简单，先修改 Lambda function 1234567891011&apos;use strict&apos;console.log(&apos;Loading function&apos;)exports.handler = (event, context, callback) =&gt; &#123; let min = event.min; let max = event.max; let generatedNumber = Math.floor(Math.random() * (max - min)) + min; callback(null, generatedNumber);&#125;; 然后在 method 下选择 integration request 修改 Body Mapping Templates，新建 mapping template，添加下面的代码 1234&#123; &quot;min&quot;: $input.params(&apos;min&apos;), &quot;max&quot;: $input.params(&apos;max&apos;)&#125; 然后 Deploy api，浏览器测试下","tags":"chatbot iot alexa api-gateway lambda"},{"title":"卷积神经网络 CNN 笔记- 目标分类","url":"/2017/06/16/卷积神经网络 CNN - 目标分类/","text":"目标分类的基本框架 + 迁移学习 + 如何设计神经网络 + 实例:基于 VGG 进行人脸表情识别。深度学习的学习笔记。 目标分类基本框架目标分类的应用场景有人脸识别、物体识别、场景识别、文字识别等，先看一下目标分类的基本框架。 数据准备数据足够？不够怎么增加数据量 模型设计用现有模型？直接用复杂模型？数据少的时候，设计简单网络进行简单学习，还是大网络进行特殊任务学习 训练细节神经网络配件，参数等 数据准备数据来源: 现有数据集的子集; 网络采集; 现有数据人工标注现有数据: http://deeplearning.net/datasets/ ，包含各种数据集如自然图片/人工合成图片/人脸/文本/对话… 数据扩充: 原始数据切割; 噪声颜色等像素变化; 旋转平移等姿态变化如下图，一张图片经过了 5x 的像素级变化，包括平均/锐化(unsharp)/动作模糊(motion)等，每种又经过了 6x 的旋转平移，也就是说，原始数据扩充了 30x 旋转平移 R, T 的矩阵变换 数据规范: 均值处理;归一化;大小调整12345678910# 均值处理tr_data = tr_data - MEAN_IMAGE# 归一化trdata/=256# 大小调整for t in range(3): im224[t,:,:] = cv2.resize(imi[:,:,t], (224,224))datablob[i,:,:,:] = im224 模型设计任务类型分类：表情分类，属于什么种类，人群分类分类+回归：表情+程度，种类+信心，什么人+人数多目标分类：面部行为，群体行为，车流预测 模型选取看现有模型(the-state-of-the-art)能否借鉴 偏图像处理，CV：ICCV, ECCV, CVPR 偏理论，机器学习相关：ICML NIPS 偏语言处理，信息挖掘：ACL, KDD 如果能借鉴，是否要做局部更改，从哪里改变；如果不能借鉴，就需要从头设计，那么新结构特点是什么，为什么可行 训练细节要考虑的问题有 GPU-Batch size，是否并行注意 GPU内存-Batch Size 的关系，batch size 设置太小，速度慢，batch 更新效果没那么好，如果设置过大，程序会崩掉 数据循环方式／平衡性考虑 数量较少的类别，数据是否需要补偿 从头到尾多次循环(不利于类别不平衡的情况) 每次随机选取部分数据(更容易处理平衡性) 网络深度宽度确定直接答案当然是深度优先，主要原因是层数变多，能用更少的参数更有效的学习特征如 5x5 一层卷积核相当于两层 3x3 卷积核，然而两层 3x3 只要 18 个参数，而一层 5x5 要 25 个参数 损失函数设计比如分类用 SOFTMAX，还是直接拟合 学习率变化方式模型各层学习率是否一致 评价方式准确率，F1 score比如在 0/1 分类中，评价方式的设计可能会偏向正例，因为很多情况下 0 会 overweight 1，假设分类结果全是 0，precision=90%，看起来很高，然而什么都没学到，所以要用 F1 score。123F1 score： 2*(Recall*Precision)/(Recall+Precison)Recall: 正确的1识别／真值所有1个数Precision:正确的1的识别／所有认为是1的个数 更多见 卷积神经网络 CNN 笔记 功能层部分。 迁移学习问题：ImageNet 上亿参数，数据量百万，是不是参数多的模型都需要大量数据？当然不是啦，我们可以用别人训练好的模型(基础模型)，在训练好的部分参数基础上进行训练。 基础模型的选择往往看是否已有特定任务的模型，另外关于 学习率(learning rate) 的处理，最低卷积层的学习率基本不变，中间卷积层看情况(数据是否类似等)，最后全连接，结构和参数都需要变化。 如何设计神经网络研究问题：如何进行面部行为识别(AU detection) 面部行为识别有很多的应用，比如测试疲劳驾驶等，一个很有意思的应用场景是推荐系统，想象看电视的时候有一个前置摄像头观察观众的反应，通过表情识别可以知道观众喜欢哪个节目，然后可以针对性的给更多高质量的推送，再比如应用到教育上面，如果能自动通过疑惑的表情判别出哪一部分学生不理解，可以针对性的给学生多解释几遍做巩固加强，当然这些都涉及到隐私问题，在这里不讨论。 现有模型看一下已有方法/模型。Deepface，卷积神经网络 CNN 笔记(高级篇) 传统 CNN 用同一个卷积核对整张图片进行卷积运算，卷积核参数共享，不同局部特性对参数影响相互削弱，达不到最优的效果，对应的解决方法是局部卷积，不同的区域用不同参数。Deepface 对每个 pixel 都用单独一个卷积核来学习，这种全局部卷积连接有主要有下面几个缺陷 预处理：大量对准，对对准要求高，原始信息可能丢失 卷积参数数量很大，模型收敛难度大，需要大量数据 模型可扩展性差，基本限于人脸计算 也有人把特征图分成 8x8=64 小份，一小份一个卷积核，但是这并不能彻底解决上面的问题，我们的改进目标是： 不需要预处理，自动进行局部探测 不要所有区域都处理，更多关注在有意义的区域比如额头的信息就比较少，眼睛眉毛嘴巴的信息相对重要的多 重要区域之间不会影响削弱学习效果 注意力网络-attention layer一个想法是注意力网络-attention layer，通过权重来聚焦，如下图，我们的目标是看篮子里有什么，所以篮子给大的权重，其他地方不重要，就给小的权重，极端情况就是篮子给 1，其他部分给 0。 再来看一下注意力网络在面部行为识别上的应用 左图是人脸的肌肉分布，中间的图绿色的点是特征点分布，蓝点是行为单元中心(action unit)，蓝点通过平移变换找到绿点，生成右图的 attention layer。步骤如下： Dlib(或原始数据集)找到人脸关键点 人脸关键点 -&gt; 行为单元中心 由中心生成注意力图中心为 1，往外扩散 这样在 CNN 结构下的注意力网络对误差的容忍度其实是很高的，原来 10 个 pixel 的误差经过几层 pooling 可能就到了 1 个甚至零点几个 pixel。 得到注意力网络后，我们需要对原始模型进行修改，一个问题是添加在哪里？什么方式添加？一个初始想法自然是放到中间做一个大的滤波，但是这样会完全丢掉不重要的区域，而我们希望保留原始结果，只是多加强下注意力，一个想法是采用 Residual net 的思想，将注意力层和之前的特征图层进行融合。 为什么添加在 3,4 层而不是 1,2 层呢？因为在 3,4 层表达会更强一些，1,2 层相对太底层。 注意力网络的效果图： 局部学习网络另一个想法是局部学习网络：针对不同的区域进行针对性学习，不同的区域的学习不会相互干扰，对区域的分布能够自动适应。方法也就是切割局部，形成局部神经网络，中间层可以做 upscaling，也就是反向 pooling，之后也可以做下 deconvolution，如下图： 网络合并网络合并： 这种结构的效果还是非常不错的 再总结下上面这种网络结构的作用： 无需提前进行面部对准就可以对面部行为识别 脸部各个行为单元局部针对学习，局部信息 可以单独用于某个行为单元识别 根据控制肌肉的分布以及人脸特征点检测结 果确定区域，更具有合理性以及可操作性 具体可以看论文EAC-Net: A Region-based Deep Enhancing and Cropping Approach for Facial Action Unit Detection 实例：基于 VGG 进行人脸表情识别数据集：CIFE:Candid image for facial expression在 vgg16 基础上调整模型。 vgg16: 这里选择在中高层更新参数(最后一个卷积群+全连接层)，模型代码如下12345678910111213141516171819202122232425262728293031323334def vgg16(input=None, classes=1000): x = tflearn.conv_2d(input, 64, 3, activation=&apos;relu&apos;, scope=&apos;conv1_1&apos;, trainable=False) x = tflearn.conv_2d(x, 64, 3, activation=&apos;relu&apos;, scope=&apos;conv1_2&apos;, trainable=False) x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool1&apos;) x = tflearn.conv_2d(x, 128, 3, activation=&apos;relu&apos;, scope=&apos;conv2_1&apos;, trainable=False) x = tflearn.conv_2d(x, 128, 3, activation=&apos;relu&apos;, scope=&apos;conv2_2&apos;, trainable=False) x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool2&apos;) x = tflearn.conv_2d(x, 256, 3, activation=&apos;relu&apos;, scope=&apos;conv3_1&apos;, trainable=False) x = tflearn.conv_2d(x, 256, 3, activation=&apos;relu&apos;, scope=&apos;conv3_2&apos;, trainable=False) x = tflearn.conv_2d(x, 256, 3, activation=&apos;relu&apos;, scope=&apos;conv3_3&apos;, trainable=False) x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool3&apos;) x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv4_1&apos;, trainable=False) x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv4_2&apos;, trainable=False) x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv4_3&apos;, trainable=False) x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool4&apos;) x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv5_1&apos;) x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv5_2&apos;) x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv5_3&apos;) x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool5&apos;) x = tflearn.fully_connected(x, 4096, activation=&apos;relu&apos;, scope=&apos;fc6&apos;) x = tflearn.dropout(x, 0.5, name=&apos;dropout1&apos;) # change the structure, now fc only has 2048, leass parameters, which is enough for this task x = tflearn.fully_connected(x, 2048, activation=&apos;relu&apos;, scope=&apos;fc7&apos;, restore=False) x = tflearn.dropout(x, 0.5, name=&apos;dropout2&apos;) x = tflearn.fully_connected(x, classes, activation=&apos;softmax&apos;, scope=&apos;fc8&apos;, restore=False) return x 完整代码emotion_vgg_finetune 环境配置，docker 获取镜像 shuang0420/tensorflow-tflearn-python3-jupyter 运行123$ docker run --name notebooks -d -v /$(pwd):/notebooks -v /$(pwd)/tensorflow/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;$$ docker run --name board -d -v /$(pwd)/tensorflow/logs:/logs -p 6006:6006 shuang0420/tensorflow-tflearn-python3-jupyter tensorboard --logdir /logs /$(pwd): 和 /$(pwd)/tensorflow/logs 是本机目录，它把 container 中的 Jupyter notebooks 以及 logs 匹配到了本机目录，使得 container 和本机可以共享资源。当然首先要保证你的 docker 和 local host 有共享这些目录的权限，在 Docker Preferences 里可以设置。","tags":"deep-learning cnn"},{"title":"使用 Docker 快速配置深度学习(Tensorflow)环境","url":"/2017/06/15/使用 Docker 快速配置深度学习Tensorflow环境/","text":"用 docker 配置 tensorflow 环境(Tensorflow + Python3 + Jupyter Notebook + tflearn)，在 dash00/tensorflow-python3-jupyter 基础上，添加 tflearn package，创建新的 docker image shuang0420/tensorflow-tflearn-python3-jupyter Use Other’s Image我们在 dash00/tensorflow-python3-jupyter 基础上创建自己的新镜像。 Download Image首先获取镜像 1$ docker pull dash00/tensorflow-python3-jupyter 原镜像 dash00/tensorflow-python3-jupyter 包含了 123456789- Jupyter Notebook- TensorFlow- scikit-learn- pandas- matplotlib- numpy- scipy- Pillow- Python 2 and 3 Start ContainerUse basic container如果用下面的启动方式，当结束 container 的时候，jupyter notebook 里的内容也会随之消失。 1$ docker run -it -p 8888:8888 dash00/tensorflow-python3-jupyter Use persistent folder这种启动方式将 notebook 内容存到了本地，本质上是一个 mapping。/$(pwd)/notebooks 就是本机 notebook 目录。 1$ docker run -it -p 8888:8888 -v /$(pwd)/notebooks:/notebooks dash00/tensorflow-python3-jupyter Use Jupyter Notebook and Tensorboard in the same time同时运行 jupyter notebook 和 tensorboard 123$ docker run --name notebooks -d -v /$(pwd)/notebooks:/notebooks -v /$(pwd)/logs:/logs -p 8888:8888 dash00/tensorflow-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;$$ docker run --name board -d -v /$(pwd)/logs:/logs -p 6006:6006 dash00/tensorflow-python3-jupyter tensorboard --logdir /logs 打开浏览器输入 http://&lt;CONTAINER_IP&gt;:8888/ 打开 jupyter notebook，输入 http://&lt;CONTAINER_IP&gt;:6006/ 打开 tensorboard Modify and Create New ImageModify Old Image进入 docker image，注意跟在 root@ 后面的 97748739b45d 就是新的 docker image id。 12$ docker run -it dash00/tensorflow-python3-jupyter /bin/bashroot@97748739b45d:/notebooks# 先看一下是什么系统123456root@97748739b45d:/notebooks# lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 16.04.2 LTSRelease: 16.04Codename: xenial dash00/tensorflow-python3-jupyter 提到装了 python2 和 python3，tf 是装在 python3 下，所以 tflearn 也要装在 python3 下。发现默认 python 进入的是 python212345678910# pythonPython 2.7.12 (default, Nov 19 2016, 06:48:10)[GCC 5.4.0 20160609] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; exit()# python3Python 3.5.2 (default, Nov 17 2016, 17:05:23)[GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; exit() pip install 要在 python3 下，为了使用稳定版本的 tflearn，需要用到 git，尝试下以下命令1234567# python3 -m pip install git+https://github.com/tflearn/tflearn.gitCollecting git+https://github.com/tflearn/tflearn.git Cloning https://github.com/tflearn/tflearn.git to /tmp/pip-u0c73_t1-build Error [Errno 2] No such file or directory: &apos;git&apos; while executing command git clone -q https://github.com/tflearn/tflearn.git /tmp/pip-u0c73_t1-buildCannot find command &apos;git&apos;You are using pip version 8.1.1, however version 9.0.1 is available.You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. 发现没有装 git，就先装一下喽12# apt-get update# apt-get install git 再次 pip 下12345678# python3 -m pip install git+https://github.com/tflearn/tflearn.git# python3Python 3.5.2 (default, Nov 17 2016, 17:05:23)[GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tflearnhdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)&gt;&gt;&gt; 12# python3 -m pip install --upgrade pip# python3 -m pip install h5py 成功123456# python3Python 3.5.2 (default, Nov 17 2016, 17:05:23)[GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import tflearn&gt;&gt;&gt; Commit, test, and upload然后退出当前容器，通过命令 docker commit 来提交容器副本 123# exit$ docker commit -m=&quot;install git and tflearn&quot; -a=&quot;shuang0420&quot; 97748739b45d shuang0420/tensorflow-tflearn-python3-jupyter:latestsha256:97748739b45dc8ce994521fa11d7ad6349bc83762e76139086789e0416560710 各个参数说明： -m:提交的描述信息 -a:指定镜像作者 e218edb10161：容器ID runoob/ubuntu:v2:指定要创建的目标镜像名 使用 docker images 命令来查看我们的新镜像 shuang0420/tensorflow-tflearn-python3-jupyter 12345$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEshuang0420/tensorflow-tflearn-python3-jupyter latest 97748739b45d 20 hours ago 1.28 GBdash00/tensorflow-python3-jupyter latest 34eeac184315 4 weeks ago 1.17 GBhello-world latest 48b5124b2768 5 months ago 1.84 kB 现在的镜像包含了 1234567891011- git- Jupyter Notebook- TensorFlow- tflearn- scikit-learn- pandas- matplotlib- numpy- scipy- Pillow- Python 2 and 3 然后使用新镜像 shuang0420/tensorflow-tflearn-python3-jupyter 来启动一个容器 1$ docker run --name notebooks -d -v /$(pwd)/notebooks:/notebooks -v /$(pwd)/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos; 如果出现下面的错误，说明之前已经启动了一个名为 notebooks 的 container，我们可以直接启动该容器，或者退出并删除原容器，新建一个。通过 docker ps -a 命令查看 container id 并删除该 container，再重新运行命令 123456789101112docker: Error response from daemon: Conflict. The container name &quot;/notebooks&quot; is already in use by container 4602dc6d7f0b8b7756fa31d63a0ecb19bd37147c2af80710294a480587f9eb08. You have to remove (or rename) that container to be able to reuse that name..See &apos;docker run --help&apos;.$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&#123;% imgurl %E4%BD%BF%E7%94%A8%20Docker%20%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Tensorflow%E7%8E%AF%E5%A2%83/kitematic.png ful-image alt:kitematic.png %&#125;$$ docker rm 4602dc6d7f0b4602dc6d7f0b$ docker run --name notebooks -d -v /$(pwd)/notebooks:/notebooks -v /$(pwd)/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;$ docker run --name board -d -v /$(pwd)/logs:/logs -p 6006:6006 shuang0420/tensorflow-tflearn-python3-jupyter tensorboard --logdir /logs$ 浏览器输入 localhost:8888 打开 jupyter notebook 浏览器输入 localhost:6006 打开 jupyter notebook 当然也可以通过 kitematic 来直接控制 container 啦～～ 用 push 命令将 image 上传到 docker hub1$ docker push shuang0420/tensorflow-tflearn-python3-jupyter:latest 已上传至 docker hub，见 shuang0420/tensorflow-tflearn-python3-jupyter UsageRun jupyter and tensorboardshuang0420/tensorflow-tflearn-python3-jupyter 的使用方法，基本用法和 dash00/tensorflow-python3-jupyter 相同。 123$ docker run --name notebooks -d -v /$(pwd):/notebooks -v /$(pwd)/tensorflow/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;$$ docker run --name board -d -v /$(pwd)/tensorflow/logs:/logs -p 6006:6006 shuang0420/tensorflow-tflearn-python3-jupyter tensorboard --logdir /logs /$(pwd): 和 /$(pwd)/tensorflow/logs 是本机目录，它把 container 中的 Jupyter notebooks 以及 logs 匹配到了本机目录，使得 container 和本机可以共享资源。当然首先要保证你的 docker 和 local host 有共享这些目录的权限，在 Docker Preferences 里可以设置。 Monitor用 docker stats 来查看 container 的资源使用状况。123CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDScb7ef0a4afc2 0.02% 8.438 MiB / 1.952 GiB 0.42% 219 kB / 1.2 MB 207 MB / 38.3 MB 20e6a9a715cbd 0.00% 19.51 MiB / 1.952 GiB 0.98% 189 kB / 285 kB 1.24 GB / 2.23 GB 16 或者进入 docker 用 top 查看。1234567891011121314Last login: Mon Jun 19 16:11:32 on ttys000top - 13:38:02 up 1 day, 19:58, 0 users, load average: 0.09, 0.17, 0.11Tasks: 6 total, 1 running, 5 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.1 us, 0.1 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 2046768 total, 1923504 free, 66636 used, 56628 buff/cacheKiB Swap: 1048572 total, 683580 free, 364992 used. 1861204 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 18036 0 0 S 0.0 0.0 0:00.04 bash 7 root 20 0 300448 12820 5268 S 0.0 0.6 0:02.41 jupyter-noteboo 31 root 20 0 18248 1828 1648 S 0.0 0.1 0:00.07 bash 130 root 20 0 591052 688 688 S 0.0 0.0 0:00.78 python3 148 root 20 0 18244 12 12 S 0.0 0.0 0:00.02 bash 170 root 20 0 36644 1252 1032 R 0.0 0.1 0:00.46 top Memory and CPUMac OS 默认给 docker 分配 4 个 CPU 和 2 GB 的内存，因此不管怎么用 docker update 和 docker run 命令来调整 container 的 CPU 和 memory，始终不能超过 docker 的限制，想要用更多的 cpu 和 memory 资源，只用在 Docker Preferences -&gt; Advanced 中调整即可。","tags":"tensorflow docker"},{"title":"AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack","url":"/2017/06/09/AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack/","text":"非常简单的教程，新建一个 Slack Bot 支持购买房/车的功能。主要流程: 编写 Lambda Function =&gt; 调用 Lambda function 创建 Lex bot =&gt; 创建 Slack Application 并与 Lex bot 关联 =&gt; 测试并发布。 Create Lambda FunctionLambda Function 部分的代码 12345678910111213141516171819exports.handler = (event, context, callback) =&gt; &#123; var purchase = event.currentIntent.slots.purchase, price = &quot;free&quot;; if (purchase === &quot;home&quot;) &#123; price = &quot;200000 dollars&quot;; &#125; callback(null, &#123; &quot;dialogAction&quot;: &#123; &quot;type&quot;: &quot;Close&quot;, &quot;fulfillmentState&quot;: &quot;Fulfilled&quot;, &quot;message&quot;: &#123; &quot;contentType&quot;: &quot;PlainText&quot;, &quot;content&quot;: &quot;You have purchased a &quot; + event.currentIntent.slots.purchase + &quot; for &quot; + price &#125; &#125; &#125;);&#125;; 有一个 purchase 的 slot，这段代码返回的是，如果买房，价格 200000 刀，如果买其他东西(slot value 限制下)，都免费。 Lambda 的配置不多说了，和 Alexa 开发新技能 - Lambda的配置相同。 供测试的 input event example1234567891011121314151617181920212223&#123; &quot;currentIntent&quot;: &#123; &quot;name&quot;: &quot;PurchaseIntent&quot;, &quot;slots&quot;: &#123; &quot;purchase&quot;: &quot;home&quot; &#125;, &quot;confirmationStatus&quot;: &quot;Confirmed&quot; &#125;, &quot;bot&quot;: &#123; &quot;name&quot;: &quot;bot-name&quot;, &quot;alias&quot;: &quot;bot-alias&quot;, &quot;version&quot;: &quot;bot-version&quot; &#125;, &quot;userId&quot;: &quot;User ID specified in the POST request to Amazon Lex.&quot;, &quot;inputTranscript&quot;: &quot;Text used to process the request&quot;, &quot;invocationSource&quot;: &quot;FulfillmentCodeHook or DialogCodeHook&quot;, &quot;outputDialogMode&quot;: &quot;Text or Voice, based on ContentType request header in runtime API request&quot;, &quot;messageVersion&quot;: &quot;1.0&quot;, &quot;sessionAttributes&quot;: &#123; &quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot; &#125;&#125; Expect Result: Create Amazon Lex Bot登录 AWS Lex，新建一个 bot(get started =&gt; custom bot)，过程非常简单，设置基本信息包括 bot name, output voice, session timeout 等，然后创建 slot type，设置 intent，基本流程和 Alexa add new skill (尤其是 Skill Builder Beta 界面)差不多，直接上截图了。 Create Lex Bot: Add slot type:保存的 slot type 在之后所有的 bot 设置中都可以重复使用。 Add intent:提供一些 Sample utterances123I would like to purchase a &#123;purchase&#125;​Buy me a &#123;purchase&#125;​I&apos;m going to buy a &#123;purchase&#125;​ Call lambda function: 如果用户输入了除 slot value (这里是 home, car)以外的东西，就会触发 Prompt。 设置好之后选择 save intent，然后选右上角的 build，创建完成后就可以开始测试 bot，这里的测试结果有点不如人意，prompt 并没有起到作用，然而没关系，最后在 Slack 界面是 work 的 Create Slack Application如果没有 Slack 账号，需要先注册注册登录Slack API，选择 start building =&gt; create an app，然后进行相关设置: In the left menu, choose Bot Users. Provide a user name. For Always Show My Bot as Online, choose On.Save the changes. Choose Interactive Messages from the left menu. Choose Enable Interactive Messages. Specify any valid URL in the Request URL box. For example, you can use https://slack.com.NoteFor now, enter any valid URL so that you get the verification token that you need in the next step. You will update this URL after you add the bot channel association in the Amazon Lex console. Choose Enable Interactive Messages. In the Settings section in the left menu, choose Basic Information. Record the following application credentials: Client ID Client Secret Verification Token Integrate the Slack Application with the Amazon Lex Bot找到之前创建的 lex bot，到 Channels 标签页，在左边菜单栏选择 Slack，并提供下面的信息： Type a name. For example, BotSlackIntegration. Choose “aws/lex” from the KMS key drop-down. For Alias, choose the bot alias. Type the Client Id, Client secret, and Verification Token, which you recorded in the preceding step. These are the credentials of the Slack application. 关于 Aliases 的问题，可以在 Settings 的 Aliases 部分进行设置，发现不设置 Alias 的话 Activate Bot 的时候可能会出错，所以还是设置下吧~设置好后 Activate，记录下 Postback URL 和 OAuth URL，然后回到 Slack Application 页面，做如下设置： Update the OAuth &amp; Permissions feature as follows: In the Redirect URLs section, add the OAuth URL that Amazon Lex provided in the preceding step. Choose Add a new Redirect URL, and then choose Save URLs. In the Permission Scopes section, choose two permissions in the Select Permission Scopes drop down. Filter the list with the following text: chat:write:bot team:readChoose Save Changes. Update the Interactive Messages feature by updating the Request URL value to the Postback URL that Amazon Lex provided in the preceding step. Choose Add, and then choose Save URLs. Subscribe to the Event Subscriptions feature as follows: Enable events by choosing the On option. Set the Request URL value to the Postback URL that Amazon Lex provided in the preceding step. Subscribe to the message.im bot event to enable direct messaging between the end user and the Slack bot. Save the changes. 这里没什么 tricky 的地方，要注意的是每一步都要记得 Save Test the Integration Choose Manage Distribution under Settings. Choose Add to Slack to install the application. Authorize the bot to respond to messsages. You are redirected to your Slack team. Choose your bot from the Direct Messages section in the left menu. If you don’t see your bot, choose the plus icon (+) next to Direct Messages to search for your bot. Engage in a chat with your Slack application, which is linked to the Amazon Lex bot. Your bot now responds to messages. 参考链接：Integrating with Slack","tags":"chatbot iot alexa slack 物联网 lex"},{"title":"Alexa 开发新技能 - Lambda","url":"/2017/06/05/Alexa 开发新技能 - Lambda/","text":"非常简单的教程，讲怎么给 Alexa 添加新的 skill，让你的 Echo 更个性化。本篇添加的 skill 是让 Alexa 从 reddit 上读前 10 条热点。 代码戳Alexa-Starter-RedditReader，其他版本如用 python flask 实现，见Alexa 开发新技能 - python flask。这一篇截图比较细，一方面是因为 AWS 版本迭代太快，网上之前的教程可能会过时，另一方面实在是因为一步步做下来踩了很多坑，争取这篇教程可以让大家少走一些弯路。 这一篇会用到 AWS Lambda，Lambda 的优势官方说明描述的很清楚，简单来说最显著的优点就是，与 Alexa 开发新技能 - python flask 相比，我们不再需要后端运行代码并通过 ngrok 等工具将代码部署到公开网络。 通过 AWS Lambda，无需配置或管理服务器即可运行代码。您只需按消耗的计算时间付费 – 代码未运行时不产生费用。借助 Lambda，您几乎可以为任何类型的应用程序或后端服务运行代码，而且全部无需管理。只需上传您的代码，Lambda 会处理运行和扩展高可用性代码所需的一切工作。您可以将您的代码设置为自动从其他 AWS 服务触发，或者直接从任何 Web 或移动应用程序调用。 总结下来 AWS Lambda 有以下几个特点: run code in response to events no maintenance of server, no worry about infrastructure scale automatically never pay for idle 下面介绍怎么来用 Nodejs 和 Lambda 实现 Reddit Reader。 Requirements Nodejs 4.3 Amazon Developer Account Code for new skill (Lambda Function)这里我们使用 Lambda function，get_headlines() 是我们主要的 method，从 Reddit 里返回 10 条热点。逻辑是这样的： (用户呼唤 Reddit Reader) Alexa 问用户 ‘Hello there, would you like the news?’ 用户回答肯定回复: 读 10 headlines否定回复: 回答 ‘I am not sure why you asked me to run then, but okay… bye’ 首先建好 project 框架12345$ mkdir alexaproject$ cd alexaproject/$ npm init$ mkdir src$ touch src/index.js 设置相关依赖12$ npm install alexa-sdk --save$ npm install request --save 版本： “alexa-sdk”: “^1.0.9”, “request”: “^2.81.0” 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&apos;use strict&apos;;var Alexa = require(&quot;alexa-sdk&quot;);var request = require(&apos;request&apos;);exports.handler = function(event, context, callback) &#123; var alexa = Alexa.handler(event, context, callback); alexa.appId = &quot;amzn1.ask.skill.[YOUR_APP_ID]&quot;; alexa.registerHandlers(handlers); alexa.execute();&#125;var handlers = &#123; &quot;LaunchRequest&quot;: function() &#123; var speechOutput = &quot;Hello there, would you like the news?&quot;; var reprompt = speechOutput; this.emit(&apos;:ask&apos;, speechOutput, reprompt); &#125;, &quot;YesIntent&quot;: function() &#123; var self = this; get_headlines(function(headlines) &#123; var speechOutput = &apos;The current world news headlines are &apos; + headlines; self.emit(&apos;:tell&apos;, speechOutput); &#125;); &#125;, &quot;NoIntent&quot;: function() &#123; var speechOutput = &apos;I am not sure why you asked me to run then, but okay... bye&apos; this.emit(&apos;:tell&apos;, speechOutput); &#125;, &quot;AMAZON.StopIntent&quot;: function() &#123; var speechOutput = &quot;Good bye! Thank you for using Reddit Reader&quot;; this.emit(&apos;:tell&apos;, speechOutput); &#125;, &quot;AMAZON.CancelIntent&quot;: function() &#123; var speechOutput = &quot;Good bye! Thank you for using Reddit Reader&quot;; this.emit(&apos;:tell&apos;, speechOutput); &#125;,&#125;function get_headlines(callback) &#123; request(&apos;https://reddit.com/r/worldnews/.json?limit=10&apos;, function (error, response, body) &#123; if (!error &amp;&amp; response.statusCode == 200) &#123; var body=JSON.parse(body)[&apos;data&apos;][&apos;children&apos;]; var res = &quot;&quot;; body.forEach(function(ele)&#123; res = res + ele[&apos;data&apos;][&apos;title&apos;] + &quot; &quot;; &#125;); &#125; return callback(res); &#125;);&#125; 如果不用 alexa-sdk，也可以自己搭一个框架出来，如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197&apos;use strict&apos;;var request = require(&apos;request&apos;);exports.handler = function(event, context) &#123; try &#123; console.log(&quot;event.session.application.applicationId&quot;) + event.session.application.applicationId; /** * Uncomment this if statement and populate with your skill&apos;s application ID to * prevent someone else from configuring a skill that sends requests to this function. */ if (event.session.application.applicationId !== &quot;[YOUR_APP_ID]&quot;) &#123; context.fail(&quot;Invalid Application ID&quot;); &#125; if (event.session.new) &#123; onSessionStarted(&#123;requestId: event.request.requestId&#125;, event.session); &#125; if (event.request.type === &quot;LaunchRequest&quot;) &#123; onLaunch(event.request, event.session, function callback(sessionAttributes, speechletResponse) &#123; context.succeed(buildResponse(sessionAttributes, speechletResponse)); &#125;); &#125; else if (event.request.type === &quot;IntentRequest&quot;) &#123; onIntent(event.request, event.session, function callback(sessionAttributes, speechletResponse) &#123; context.succeed(buildResponse(sessionAttributes, speechletResponse)); &#125;); &#125; else if (event.request.type === &quot;SessionEndedRequest&quot;) &#123; onSessionEnded(event.request, event.session); context.succeed(); &#125; &#125; catch (e) &#123; context.fail(&quot;Exception: &quot; + e); &#125;&#125;/** * called when the user invokes the skill without specifying what they want. */function onLaunch(launchRequest, session, callback) &#123; getWelcomeResponse(callback)&#125;/** * Called when the user specifies an intent for this skill. */function onIntent(intentRequest, session, callback) &#123; var intent = intentRequest.intent var intentName = intentRequest.intent.name; // dispatch custom intents to handlers here if (intentName == &quot;&quot;) &#123; handleResponse(intent, session, callback) &#125; else if (intentName == &quot;YesIntent&quot;) &#123; handleYesResponse(intent, session, callback) &#125; else if (intentName == &quot;NoIntent&quot;) &#123; handleNoResponse(intent, session, callback) &#125; else if (intentName == &quot;AMAZON.StopIntent&quot;) &#123; // not used here // handleGetHelpRequest(intent, session, callback) &#125; else if (intentName == &quot;AMAZON.CancelIntent&quot;) &#123; handleFinishSessionRequest(intent, session, callback) &#125; else if (intentName == &quot;AMAZON.HelpIntent&quot;) &#123; handleFinishSessionRequest(intent, session, callback) &#125; else &#123; throw &quot;Invalid intent&quot; &#125;&#125;/** * Called when the session starts. */function onSessionStarted(sessionStartedRequest, session) &#123; console.log(&quot;onSessionStarted requestId=&quot; + sessionStartedRequest.requestId + &quot;, sessionId=&quot; + session.sessionId);&#125;/** * Called when the user ends the session. * Is not called when the skill returns shouldEndSession=true. */function onSessionEnded(sessionEndedRequest, session) &#123; console.log(&quot;onSessionEnded requestId=&quot; + sessionEndedRequest.requestId + &quot;, sessionId=&quot; + session.sessionId); // Add cleanup logic here&#125;function getWelcomeResponse(callback) &#123; var speechOutput = &quot;Hello there, would you like the news?&quot; var reprompt = speechOutput var header = &quot;news&quot; var shouldEndSession = false var sessionAttributes = &#123; &quot;speechOutput&quot;: speechOutput, &quot;repromptText&quot;: reprompt &#125; callback(sessionAttributes, buildSpeechletResponse(header, speechOutput, reprompt, shouldEndSession))&#125;function handleYesResponse(intent, session, callback) &#123; get_headlines(function(headlines) &#123; var speechOutput = &apos;The current world news headlines are &apos; + headlines; var shouldEndSession = true callback(session.attributes, buildSpeechletResponseWithoutCard(speechOutput, &quot;&quot;, shouldEndSession)) &#125;);&#125;function handleNoResponse(intent, session, callback) &#123; var speechOutput = &apos;I am not sure why you asked me to run then, but okay... bye&apos; var shouldEndSession = true callback(session.attributes, buildSpeechletResponseWithoutCard(speechOutput, &quot;&quot;, shouldEndSession))&#125;function buildSpeechletResponse(title, output, repromptText, shouldEndSession) &#123; return &#123; outputSpeech: &#123; type: &quot;PlainText&quot;, text: output &#125;, card: &#123; type: &quot;Simple&quot;, title: title, content: output &#125;, reprompt: &#123; outputSpeech: &#123; type: &quot;PlainText&quot;, text: repromptText &#125; &#125;, shouldEndSession: shouldEndSession &#125;;&#125;function buildSpeechletResponseWithoutCard(output, repromptText, shouldEndSession) &#123; return &#123; outputSpeech: &#123; type: &quot;PlainText&quot;, text: output &#125;, reprompt: &#123; outputSpeech: &#123; type: &quot;PlainText&quot;, text: repromptText &#125; &#125;, shouldEndSession: shouldEndSession &#125;;&#125;function buildResponse(sessionAttributes, speechletResponse) &#123; return &#123; version: &quot;1.0&quot;, sessionAttributes: sessionAttributes, response: speechletResponse &#125;&#125;function handleFinishSessionRequest(intent, session, callback) &#123; callback(session.attributes, buildSpeechletResponseWithoutCard(&quot;Good bye! Thank you for using Reddit Reader&quot;,&quot;&quot;,true))&#125;function get_headlines(callback) &#123; request(&apos;https://reddit.com/r/worldnews/.json?limit=10&apos;, function (error, response, body) &#123; if (!error &amp;&amp; response.statusCode == 200) &#123; var body=JSON.parse(body)[&apos;data&apos;][&apos;children&apos;]; var res = &quot;&quot;; body.forEach(function(ele)&#123; res = res + ele[&apos;data&apos;][&apos;title&apos;] + &quot; &quot;; &#125;); &#125; return callback(res); &#125;);&#125; 更多方法戳alexa-skills-kit-sdk-for-nodejs Lambda Configuration登录AWS console在 Service 下选择 Lambda Create a Lambda function，选 Node.js.4.3, Blank Function Configure Triggers，选 Alexa Skills Kit Configure Function，如下设置 注意两个点，代码上传后，Handler 的路径设置必须和代码中 handler 文件的路径相一致，建议对文件内所有文件打包，而不是直接对文件夹打包。Role 如果没有 existing role，可以新建一个。 完成后选择新建的 function，在 Action 里选择 Configure test event 选择 Alexa Start Session，修改 Applicatio ID，即 Alexa console 里的 Application ID，在 Deploy 下会讲到。 选择 Save and Test，返回结果 Deploy去Amazon developer 网站上注册用户并登陆，注意这里的用户名和你的 Echo 用户名是一致的。点开 Alexa tab，选择 add skill，开始部署。 Step1:填写 Name 和 Invocation Name，Invocation Name 用来 invoke app，Application ID 可以在保存页面后找到，需要添加到代码以及 Configure test event 里，如果需要对 Lambda 页面进行测试的话。 Step2:主要填写 Intent Schema 和 Sample Utterances Intent Schema: how alexa will traverse your application 123&#123; &quot;intents&quot;: [&#123; &quot;intent&quot;: &quot;YesIntent&quot; &#125;, &#123; &quot;intent&quot;: &quot;NoIntent&quot; &#125;]&#125; Sample Utterances: the words people say to trigger intent12345YesIntent yesYesIntent sureNoIntent noNoIntent go away Step3:选择并填写 Endpoint，即 AWS Lambda 下 function 的 ARN Step4:就可以用 Echo 来 test 啦~ 如果没有 Echo，可以用 Service Simulator 来模拟，可以输入 text，也可以输入 json先给 Alexa 一个关于 Reddit Reader 的指令，然后按照我们的代码，Alexa 会问你要不要读新闻 然后我们回答 yes，Alexa 就开始读新闻啦~","tags":"iot alexa 物联网 echo"},{"title":"NLP 笔记 - Sentiment Analysis","url":"/2017/06/01/NLP 笔记 - Sentiment Analysis/","text":"Stanford Dan Jurafsky &amp; Chris Manning: Natural Language Processing 课程笔记。 Sentiment Analysis 有许多别称，如 Opinion extraction/Opinion mining/Sentiment mining/Subjectivity analysis，都是同一个意思，不过隐含着不同的应用场景。大致来说，情感分析有以下的应用: Products: 产品评价，不仅仅是简单的好评差评，情感分析还能分析人们对具体产品的具体属性的具体评价，如下图，对 product review 抽取 aspects/attributes，判断 sentiment，最后 aggregate 得出结果Public sentiment: 公众意见(public opinion)，比如说分析消费者信息指数，股票指数等。之前就有人做过用 CALM 来预测道琼斯指数(Bollen et al. 2011 Twitter mood predicts the stock market)，算法也应用到了工业场景Politics: 公共政策，看公众对候选人/政治议题的看法Prediction: 预测选举结果，预测市场趋势等等。 一个成熟的产品Twitter Sentiment App，能够通过 Twitter 数据来分析人们对某个品牌/话题的情感 Attitudes: “enduring, affectively colored beliefs, dispositions towards objects or persons” Sentiment analysis 说白了就是来分析人们对一个事物的态度(attitudes)，包含下面几个元素(以 Mary likes the movie 为例) Holder (source) of attitude持有态度的人: Mary Target (aspect) of attitude对象: the movie Type of attitude态度类型: likeFrom a set of types: Like, love, hate, value, desire, etc.Or (more commonly) simple weighted polarity: positive, negative, neutral, together with strength Text containing the attitude文本: Mary likes the movieSentence or entire document 最简单的情感分析任务，或者说在情感分析方向的 baseline model，是分析/预测电影评论是 positive 还是 negative 的。 Baseline Algorithm常用到的语料库 IMDB Polarity Data 2.0，目的： polarity detection: is this review positive or negative?步骤： Tokenization Feature Extraction Classification using different classifiers Naive Bayes MaxEnt SVM Sentiment Tokenization除了正常 tokenization 要注意的问题如处理 HTML/XML markup 外，情感分析还可能需要处理 twitter markup(hashtag 等) Capitalization: 大小写通常会保留，大写字母往往反映强烈的情感 Emotions(表情符号) 有用的 Tokenizer 代码 Christopher Potts sentiment tokenizer Brendan O’Connor twitter tokenizer Extracting Features关于特征提取，两个重要的问题，一是怎么来处理否定词(negation)，二是选什么词作为特征。 Negation12I didn&apos;t like this movieI really like this movie 如果对否定词不做处理，那么上面两条评论的结果都是 positive，这显然不对。一种有效的处理否定词的方案是对否定词后、下一个标点符号前的每个词都加上 NOT_ 的前缀来作为标识，如下123didn&apos;t like this movie, but I=&gt;didn&apos;t NOT_like NOT_this NOT_movie but I 具体见Das, Sanjiv and Mike Chen. 2001. Yahoo! for Amazon: Extracting market sentiment from stock message boards. In Proceedings of the Asia Paciﬁc Finance Association Annual Conference (APFA).Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. EMNLP-2002, 79—86. Words to use一般两种方案，一是仅仅使用形容词(adjectives)，而是使用所有的单词(all words)，通常而言，使用所有的词的效果会更好些，因为动词(verbs)、名词(nouns)会提供更多有用的信息。 Classifier作为 Baseline model，这里会使用 Naive Bayes，没啥悬念，计算如下 $$c_{NB}=argmax_{c_j \\in C} P(c_j) \\prod_{i \\in positions} P(w_i | c_j)$$ Prior: how likely we see a positive movie review Likelihood Function: for every review, how likely every word is expressed by a positive movie review 采用 Laplace/Add-one Smoothing $$\\hat P(w|c)={count(w,c)+1 \\over count(c)+|V|}$$ 一个变种或者改进版是Binarized(Boolean feature) Multinomial Naive Bayes，它基于这样一个直觉，对情感分析而言，单词是否出现(word occurrence)这个特征比单词出现了几次(word frequency)更为重要，举个例子，出现一次 fantastic 提供了 positive 的信息，而出现 5 次 fantastic 并没有给我们提供更多信息。boolean multinomial Naive Bayes 就是把所有大于 1 的 word counts 压缩为 1。 算法 也有研究认为取中间值 log(freq(w)) 效果更好一些，相关论文如下：B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sen+ment Classiﬁcation using Machine Learning Techniques. EMNLP-­‐2002, 79—86.V. Metsis, I. Androutsopoulos, G. Paliouras. 2006. Spam Filtering with Naive Bayes – Which Naive Bayes? CEAS 2006 -­‐ Third Conference on Email and Anti‐Spam.K.-­‐M. Schneider. 2004. On word frequency informa+on and negative evidence in Naive Bayes text classiﬁca+on. ICANLP, 474-­‐485.JD Rennie, L Shih, J Teevan. 2003. Tackling the poor assumptions of naive bayes text classiﬁers. ICML 2003 当然在实践中，MaxEnt 和 SVM 的效果要比 Naive Bayes 好的多 Problems有些句子里并不包含情感词(sentiment word)，如下面一句是 negative 的态度，然而并不能通过情感词来得出 “If you are reading this because it is your darling fragrance, please wear it at home exclusively, and tape the windows shut.” 还有一个问题是排序问题(Order effect)，尽管前面堆砌了很多情感词，但最后来个全盘否定，显然 Naive Bayes 没法处理这种问题 Sentiment Lexicons看一下目前已经有的 Lexicons， The General Inquirer List of Categories Spreadsheet LIWC(Linguistic Inquiry and Word Count) MPQA Subjectivity Cues Lexicon Bing Liu Opinion Lexicon SentiWordNet 看下各个词库的 disagreements between polarity lexicons 那么怎么来分析 IMDB 里每个单词的 polarity 呢？How likely is each word to appear in each sentiment class?likelihood: $$P(w|c)={f(w,c) \\over \\sum_{w \\in c} f(w,c)}$$Make them comparable between words - Scaled likelihood:$${P(w|c)\\over P(w)}$$ 更多见 Potts, Christopher. 2011. On the negativity of negation. SALT 20, 636-­‐659. Learning Sentiment Lexicons除了目前已有的 lexicon，我们还可以根据自己的语料库来训练自己的 sentiment lexicon。 Semi-supervised learning of lexicons基于少量的有标注的数据+人工建立的规则，采用 bootstrap 方法来学习 lexicon Hatzivassiloglou and McKeown intuition for identifying word polarity论文: Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the Semantic Orientation of Adjectives. ACL, 174–181 基于这样的假设: 用 AND 连起来的形容词有着相同的 polarityfair and legitimate, corrupt and brutal 用 BUT 连起来的形容词则相反fair but brutal 论文方法： 对 1336 个形容词形成的种子集合进行标注，657 个 positive，679 个 negative 通过 google 搜索来查询 conjoined 形容词，eg. “was nice and” Supervised classifier 通过 count(AND), count(BUT) 来给每个词对(word pair)计算 polarity similarity 将 graph 分区 这种方法难以处理短语 Turnev Algorithm论文: Turney (2002):Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews 步骤: 从评论中抽取形容词短语(two-word phrase) 学习短语的 polarity如何衡量短语的 polarity 呢？基于下面的假设 Positive phrases co-‐occur more with “excellent” Negative phrases co-­‐occur more with “poor”用 PMI(Pointwise Mutual Information) 来计算 co-occurrenceMutual information between 2 random variables X and Y$$I(X,Y)=\\sum_x \\sum_y P(x,y)log_2{P(x,y) \\over P(x)P(y)}$$Pointwise mutual information: how much more do events x and y co-occur than if they were independent$$PMI(X,Y)=log_2{P(x,y) \\over P(x)P(y)}$$同样通过搜索引擎(Altavista)查询得到概率P(word) = hits(word)/N$P(word_1,word_2)=hits(word_1 \\ NEAR \\ word_2)/N^2$$$P(word_1,word_2)=log_2 {hits(word_1 \\ NEAR \\ word_2) \\over hits(word_1)hits(word_2)}$$ Rate a review by the average polarity of its phrases 一般来说 baseline 的准确率是 59%, Turney algorithm 可以提高到 74% Using WordNet to learn polarity论文:S.M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. COLING 2004M. Hu and B. Liu. Mining and summarizing customer reviews. In Proceedings of KDD, 2004 步骤: 有一小部分 positive/negative seed-words 从 WordNet 中找到 seed-words 的同义词(synonyms)和反义词(antonyms)Positive Set: positive words 的同义词 + negative words 的反义词Negative Set: negative words 的同义词 + positive words 的反义词 重复 2 直到达到终止条件 过滤不合适的词 Summary采用半监督方法来引入 lexicons，好处是: can be domain-specific can be more robust(for more/new words) Intuition: starts with a seed set of words(good,poor) find other words that have similar polarity:• Using “and” and “but”• Using words that occur nearby in the same document• Using WordNet synonyms and antonyms Other Sentiment TasksFinding aspects/attributes/target论文:M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of KDD.S. Blair-­‐Goldensohn, K. Hannan, R. McDonald, T. Neylon, G. Reis, and J. Reynar. 2008. Building a Sen+ment Summarizer for Local Service Reviews. WWW Workshop. 很多时候，一条评论并不能简单的被归为 positive/negative，它可能讨论了多个维度，既有肯定又有否定，如下面这个句子1The food was great but the service was awful! 这条评论就是对食物(food)持肯定态度(positive)，对服务(service)持否定态度(negative)，在这种情况下，我们不能简单的对这条评论进行 positive/negative 的分类，而要对其在 food，service 这两个维度上的态度进行分类。food，service 这些维度，或者说 attributes/aspects/target 从哪里来？ 有两种方法，一种是从文本中抽取常用短语+规则来作为 attributes/aspects，另一种是预先定义好 attributes/aspects Frequent phrases + rules首先找到产品评论里的高频短语，然后按规则进行过滤，可用的规则如找紧跟在 sentiment word 后面的短语，”…great fish tacos” 表示 fish tacos 是一个可能的 aspect Supervised classification对一些领域如 restaurants/hotels 来说，aspects 比较规范，所以事实上可以人工给一些产品评论标注 aspect(aspects 如 food, décor, service, value, NONE)，然后再给每个句子/短语分类看它属于哪个 aspect 具体步骤: 从评论中抽取句子/短语 对句子/短语进行情感分类 得到句子/短语的 aspects 汇总得到 summary 值得注意的是，baseline method 的假设是所有类别出现的概率是相同的。如果类别不平衡(在现实中往往如此)，我们不能用 accuracy 来评估，而是需要用 F-scores。而类别不平衡的现象越严重，分类器的表现可能就越差。有两个办法来解决这个问题 Resampling in training就是说如果 pos 有10^6 条数据，neg 有 10^4 的数据，那么我们都从 10^4 的数据中来划分训练数据 Cost-sensitive learning对较少出现的那个类别的 misclassification 加大惩罚(penalize SVM more for misclassification of the rare thing) How to deal with 7 stars论文: Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. ACL, 115–124 怎样来处理评分型的评论？ Map to binary压缩到 positive/negative。比如说大于 3.5 的作为 negative，其他作为 positive Use linear or ordinal regressionor specialized models like metric labeling Summary on Sentiment通常被建立分类/回归模型来预测 binary/ordinal 类别关于特征提取: negation 很重要 对某些任务，在 Naive bayes 里使用所有的词汇表现更好 对其他任务，可能用部分词汇更好Hand-built polarity lexiconsUse seeds and semi-supervised learning to induce lexicons Computational work on other affective states对其他任务也可以用相似手段 Emotion:• Detecting annoyed callers to dialogue system• Detecting confused/frustrated versus conﬁdent students Mood:• Finding traumatized or depressed writers Interpersonal stances:• Detection of flirtation or friendliness in conversations Personality traits:• Detection of extroverts E.g., Detection of Friendliness Friendly speakers use collaborative conversational style12345678- Laughter- Less use of negative emotional words- More sympathy​ That’s too bad I’m sorry to hear that!- More agreement​ I think so too!- Less hedges​ kind of sort of a little …","tags":"nlp sentiment-analysis 情感分析"},{"title":"论文笔记 - Learning to Extract Conditional Knowledge for Question Answering using Dialogue","url":"/2017/05/24/论文笔记 - Learning to Extract Conditional Knowledge for Question Answering using Dialogue/","text":"论文Learning to Extract Conditional Knowledge for Question Answering using Dialogue提出了 conditional knowledge base(CKB)，存储的信息格式为 (subject, predicate, object|condition)。当用户问句缺少必要条件(condition)时，自动用 dialogue model 来向用户提问获取必要信息，再进行回答。简化版过程，从训练数据的用户问句里抽取实体，频率最高的 50% 作为 subject，剩余的作为 candidate condition。对于每一个 subject，学习用户问句的 pattern 和 condition (类似于关系抽取)，然后学习 pattern 和 condition 的 embedding，并对其进行聚类得到 pattern cluster 和 condition cluster，再从聚类信息和 QA 对中抽取信息组成 (subject, predicate, object|condition) 作为 CKB。 当用户提问并没有清楚的指定条件时，就可以用 dialogue model 向用户提问获取 condition，具体过程如下 用户界面演示 Pattern mining这一步的目的是学习 pattern 和 condition，用 bootstrapping 方法。 input: all questions with the same subjectoutput: question patterns; conditions 123456Eg.,input: windows_xp free upgrade windows_10subject: windows_10candidate condition: windows_xppattern: SLOT0 free upgrade windows_10 输入有两个 entities, windows_xp 和 windows_10，windows_10 被选为 subject，那么 windows_xp 就是 candidate condition，然后我们产生了 pattern “SLOT0 free upgrade windows_10”，当遇到下面新的输入时，win7 就会被抽取作为 candidate condition，因为输入和 pattern 正好匹配 123new input: win7 free upgrade windows_10pattern: SLOT0 free upgrade windows_10new candidate condition: win7 一个问题是怎么来产生初始的种子，方法是 remove question words use special type of words for question chuckingspecial type of words: prepositions, copulas, interrogatives, conjunctions, modal verbs, personal pronouns, verbs, some stop words add remaining parts into seed dictionary Pattern Aggregation这一步非常简单，就是做一个 groupby，把上一步产生的相同 pattern 不同 condition 的输出按 pattern 分组，见 Step2 Condition and Pattern Representation Learning不同的 pattern 可能反应了相同的 user intent，这一步的目的就是对 pattern 进行聚类，目的是希望每一个类别代表一个 user intent。同时，对聚类后的每一个 pattern cluster 的 condition 进行聚类，聚类标准是在当前 condition 下的问题是否拥有相似的 answer。 首先学习 pattern 和 condition 的 embedding。对此论文提出了一种新的算法 patterns and conditions jointly embedding algorithm(PCJE)，由 condition embedding model, pattern embedding model 和 alignment model 三个 model 组成，目标函数是三个 model 的目标函数之和。 Condition embedding model 主要看 $p(c_k, c_m)$，通过 Skip-gram 来学习 question, answer, condition pairs 的嵌入向量，要注意的是，这里 Skip-gram 的目标函数最大化 $J_c = J(\\theta) + \\beta E_c$，其中 $ J(\\theta) $ 是 Skip-gram 原本的目标函数, $E_c$ 是正则化后的 condition pair($c_k,c_m$) 的联合概率，如下 $$p(c_k,c_m) = {1 \\over 1+exp(-c^T_kc_m)}$$$$E_c=\\sum_{(k,m) \\in P_c} w^c_{km}logp(c_k,c_m)$$ Pattern embedding model 主要看 $p(v_k, v_m)$ Alignment model 主要看 $p(c_k, v_m)$，通过 pattern 和 condition 的共现关系来对齐两个向量空间 整体需要优化的目标函数$$J=J_c+J_p+J_\\alpha$$ Conditions and Patterns Clusteringinput: patterns, conditions, embedding representationsoutput: pattern clusters, condition clusters patterns in the same cluster will share the same intent, which is predicate in classical KB. 用了下面的层次聚类算法 Conditional Knowledge Base Constructioninput: pattern clusters, condition clustersoutput: (Subject, Predicate, Object | Condition) triples 要知道并不是所有的 condition 都是重要的，这一步骤会过滤一些不重要的 condition。这里提到了一个概念 missing percentage of slots，指的是能够匹配 pattern 然而却没有 slot 的情况，比如下面的例子，对输入而言，尽管匹配了 pattern，但 SLOT0 是缺失的。12pattern: SLOT0 free upgrade windows_10input: free upgrade windows_10 对每个 slot 计算 missing percentage (of slots)，然后把 slot 分为下面三种类型 只有一个 cluster 的 slots（没有询问的必要） 基本上不会被忽略的 slots 几乎没有用户会在意的 slots 第一种直接过滤，第二种也就是过滤 missing percentage 大于 0.7 的 slot，第三种也就是过滤 missing percentage 小于 0.3 的 slot，剩下的 slots 才是重要的，组成 (Subject, Predicate, Object | Condition) 格式存到 CKB 中。 Subject: 选定的 entityPredicate: 同一 cluster 的若干 pattern，用频率最高的若干个单词/短语作为代表性的 predicateObject: 根据 answer set 与 pattern cluster 的 average embedding 的 cosine similarity 来选择 top answer 作为 objectCondition: 同一 cluster 的若干 condition Dialogue Model Construction两个任务，看 input question 是否匹配 pattern，缺失的 condition 是否重要，如果重要，那么，提问并提供候选项来让用户选择，填充 slot，返回答案","tags":"question-answering"},{"title":"NLP 笔记 - Text Summarization","url":"/2017/05/10/NLP 笔记 - Text Summarization/","text":"Stanford Dan Jurafsky &amp; Chris Manning: Natural Language Processing 课程笔记。文档/会议/邮件摘要，QA 系统回答 what/how 等复杂问题，都需要自动摘要技术。本篇主要讲基于查询的摘要。 Types of Summarization Task单文档 vs 多文档 Single-­‐document summarization给定一个文档，产生 abstract/outline/headline Multiple-­‐document summarization给定主题相关的一组文档，通过摘要来概况同一事件/主题的信息 与单文档相比，多文档任务面临的减小句子冗余度/确定句子顺序/确定压缩比率(从每个文档中抽取句子的比例)/指代消解问题都更加的突出 查询无关 vs 查询相关 Generic summarization对一个文档的内容做整体性的摘要 Query-­‐focused summarization根据用户查询语句表达的信息需求(information need)来对一篇文档做出摘要总结，如 Google snippets用于 QA 系统，根据提问产生文档摘要来回答一个复杂的问题 查询相关的文本摘要对句子重要性的衡量需要同时考虑主题性以及查询相关性 抽取式 vs 合成式 Extractive summarization摘要句子完全从源文档中抽取形成 Abstractive summarization: our own words从源文档中抽取句子并进行改写形成摘要 目前来看，大多数的系统是抽取式，合成式的技术还不够成熟。 本章主要讨论 Extractive summarization Baseline Model好的作者常常会在标题和第一句话就表达主题，因此最简单的 baseline 就是抽取文档中的首句作为摘要。 Generating snippets: query-focused summaries看一下 Google snippets Single-­‐document summarization Query-­‐focused summarization Extractive summarization Main Stages产生 snippets 的主要步骤(Stages): content selection选择需要抽取的句子(segment/moving window) information ordering对抽取的句子进行排序 sentence realization形成摘要 Base Summarization Algorithm对一个 base summarization algorithm 而言，其实只需要做第一步 conent selection，之后的 information ordering 即保留句子在源文档的位置，sentence realization 即保留原句。 Unsupervised content selection我们需要选择的是salient or informative的句子，一般来说，salient words 有两种选择方法 tf-idf也就是找在该文档中经常出现，并且在其他文章中很少出现的单词 topic signature通过计算 log-likelihood ratio(LLR) 并设置 threhold 来过滤并选择重要的单词$weight(w_i)=1 \\ if -2log \\lambda(w_i)&gt;10 \\ else \\ 0$ 这里主要介绍下Topic signature-based content selection with queries Step1: choose wordssalient words 有下面两个来源: 计算每个单词的 log-likelihood ratio(LLR) ，根据 threshold 进行选择 选择所有出现在 query 里的单词 Step2: weigh a sentence(or window)在上一步计算的单词分数基础上，计算每个句子/短语窗口的分数$$weight(s)={1 \\over |S|} \\sum_{w \\in S} weight(w)$$选择 top k 个句子。 Supervised content selection其实是一个二分类问题，对文档中的每一个句子，用分类器进行二值分类，1 代表这个句子可以作为摘要输出句子，0 代表不能。 监督学习方法难点是获得训练集，很有可能摘要句子并不是文档中的完整句子，所以需要事先把文档句子和摘要句子对齐，才能得到分类标签。然后对文档句子抽取特征将句子映射为特征向量，再训练分类器，可以用的算法如 Naive Bayes/Decision Tree/HMM/CRF/LR/SVM/SVM-HMM等 Summary上面提到的只是最基础的方法，对非监督方法而言，还有下面的方法 线性组合方法：利用手工构建的评分函数，采取若干重要特征并手工设定特征权重，以此来对句子重要性进行得分计算。 词汇链方法：通过文章中相邻句子的语义相似性来判断文章主题，引入Wordnet等语言资源中的同义词和近义词信息，分析文章中相邻句子的语义相似性。寻找若干最长的词汇链来确定文章包含主题，并依此来构建文摘句子集合；[6,7] 图模型方法：将文章中每个句子作为图中的节点，利用句子之间内容相似性构建图中节点之间的边。构建好文章图后，利用PageRank或者HITS算法来迭代计算图中节点的权值，按照权值大小作为句子重要性的评分依据来对文摘句子进行抽取。[3,4] 子主题分析方法：通过聚类或者语义块分析等手段，发现文章包含的子主题，并从不同的子主题中抽取句子来构造摘要句子集合。LSA，PLSA等方法属于这一类[8,10,12]。 一些研究工作 Document Summarization using Conditional Random Fields 和 Enhancing Diversity, Coverage and Balance for Summarization through Structure Learning对主流的一些自动文摘方法做了对比，对于非监督方法来说，基于 HITS 的图模型方法明显优于其他方法，对于监督方法来说，SVM-HMM 和 CRF 方法效果最好，其中 SVM-HMM 方法在一般测试集合上稍微优于CRF，在难度高的测试集合上效果明显好于CRF方法。这两个方法优于HITS图模型方法，不过优势并非特别明显；从测试结果来看，方法效果排序如下 SVM-HMM&gt;CRF&gt;HITS&gt;HMM&gt;SVM&gt;LR&gt;NB&gt;LSA 1234567891011121314151617181920212223242526271. 简单特征线性组合方法(非监督方法) 即确定一些主要特征，然后设定特征权重后根据线性组合方式来进行句子打分和排序输出； 优点： 方法简单； 无需训练数据； 执行速度快； 缺点： 由于手工拟合评分函数，只能采取部分主要特征； 权重设定需要手工设置并不断调试； 效果一般；2. 基于HITS的图模型方法(非监督方法) 考虑到目前的研究表明，基于 HITS 的图模型方法是非监督方法中效果最好的，如果采取非监督方法，则优先考虑 HITS 的图模型方法； 优点: 无需训练集合； 基本与语言和领域无关； 效果好； 缺点： 由于存在任意句子相似性计算和迭代计算，所以运行速度相对比较慢；需要改进速度提出改进方法； 该方法没有考虑信息冗余的问题，可能需要有针对性的改进；3. 基于 CRF 或者 SVM-HMM 的监督学习方法 目前研究表明，CRF 和 SVM-HMM 在所有监督和非监督方法中是效果最好的，其中 SVM-HMM 效果略好于 CRF，CRF 略好于 HITS 图模型方法；所以如果采取监督学习思路，可以考虑CRF或者SVM-HMM的方法； 优点： 效果好； 缺点： 需要训练数据； 效果依赖于训练数据质量和领域等方面的情况； 执行速度慢；尤其是融合HITS模型等复杂特征，需要首先计算复杂特征，所以速度应该是最慢的； 这部分的总结来自文本摘要技术调研 [1] .Jie Tang, Limin Yao, and Dewei Chen . Multi-topic based Query-oriented Summarization.W.-T.Yih, J. Goodman, L. Vanderwende, and H. Suzuki. Multi-document summarization by maximizing informative content-words.In Proceedingsof IJCAI’07, 2007.[2] Dou Shen1,Jian-Tao Sun.etc DocumentSummarization using Conditional Random Fields. InProceedingsof IJCAI’07, 2007.[3] GunesErkan. Dragomir R. Radev. LexRank: Graph-based LexicalCentrality as Salience in Text Summarization. Journal of ArtificialIntelligence Research 22 (2004) 457-479[4] Rada Mihalcea. Language Independent Extractive Summarization.[5] Liangda Li, Ke Zhou†,Gui-Rong Xue etc Enhancing Diversity, Coverage and Balance for Summarization through Structure Learning. WWW 2009.[6] Gregory Silber and Kathleen F. McCoy Efficient Text Summarization Using Lexical Chains.[7] Barzilay,Regina and Michael Elhadad. Using Lexical Chainsfor Text Summarization. in Proceedings of the IntelligentScalable Text Summarization Workshop(ISTS’97), 1997.[8] Shanmugasundaram Hariharan Extraction Based Multi Document Summarization using Single Document Summary Cluster Int. J.Advance. Soft Comput. Appl., Vol. 2, No. 1, March 2010[9] ShanmugasundaramHariharan, “Merging Multi-Document Text Summaries-A Case Study”, Journal of Scienceand Technology, Vol.5, No.4,pp.63-74, December 2009.[10] JinZhang etc AdaSum: An Adaptive Model for Summarization. CIKM 2008.[11] Varadarajan and Hristidis. A System forQuery-Specific Document Summarization CIKM2006.[12] LeonhardHennig Topic-based Multi-Document Summarization with Probabilistic Latent Semantic Analysis Complex Questions: Summarizing Multiple Documents自动摘要还可以用于回答复杂的问句(如 how/what)，有两大类方法，自底向上的 snippet 方法，以及自上而下的信息抽取方法。 Bottom-up snippet method: 找到相关文档集合 从文档集合中抽取 informative sentences 对句子进行排序并形成回答 Top-down information extraction method: 根据不同的问题类型建立特定的信息抽取框架 抽取信息 形成回答 属于研究热点，有很大提升空间。 Bottom-up snippet method处理框架： Sentence Simplification首先简化句子，可以删除 同位语/定语从句/没有命名实体的介词短语/句子开头的状语 等 Sentence ExtractionMaximal Marginal Relevance(MMR)MMR 是一种从多个文档中进行选择的递归(iterative)方法，递归的从文档中选取最合适的句子插入到 summary/answer 中，两个指标是相关性(relevant)，以及 新颖度(novel)。这在Search Engines笔记 - Diversity也提到过。 Relevant与 query 最相关的句子，high cosine similarity to the query Novel减少 summary/answer 的冗余程度，low cosine similariy to the summary$\\hat S_{MMR}=max s \\in D \\lambda sim(s,Q) - (1-\\lambda)max s \\in S sim(s,S)$ 不断添加句子到 summary 中，直到 summary length 到达预期要求 LLR + MMR: choosing informative yet non-redundant sentences1. 根据 LLR 对每个句子进行打分2. 选择 top k 个句子作为候选的摘要句3. 迭代的从候选集里选取高分并且还不在当前摘要里的句子，添加进摘要 Information Ordering 时间顺序(Chronological ordering)根据时间对句子进行排序，主要用于新闻类的摘要(Barzilay, Elhadad, and McKeown 2002) 一致性(Coherence)根据 cosine similarity 对句子排序，使得摘要中相邻的句子更相似，或者相邻句子讨论同一个实体(Barzilay and Lapata 2007) 专题排序(Topical ordering)从源文档中学习主题排序 Information Extraction Method用信息抽取(IE)的方法来回答，比如说一个人物传记类的问题答案通常包含人物的 生卒年月，国籍，教育程度，名望/荣誉等，一个定义类问题(definition)通常包括 属(genus)或者上位词(hypernym)，如 The Hajj is a type of ritual，一个关于用药的医学类问题通常包括 问题(medical condition)、治疗(intervention, the drug or procedure)和结果(outcome) 上图是课程提到的 IE 方法框架，暂时不是很理解 predicate identification 这一步，感觉 Multidocument Summarization via Information Extraction这篇文档的框架更加 straight-forward 一些。 Evaluating summaries: ROUGEROUGE 是内部评价指标，以 BLEU 为基础，虽然比不上人工评价，但是用起来很方便 给定一个文档 D，以及一个自动生成的文本摘要 X： 由 N 个人产生 D 的 reference summaries 运行系统，产生自动文本摘要 X 计算 reference summaries 中的 bigram 在 X 里出现的比例 举个例子，问句是 “What is water spinach?”，Human 1, Human 2, Human 3 是人工产生的 reference summaries，System answer 是自动摘要，计算如下","tags":"nlp text-summarization 文本摘要"},{"title":"Alexa 开发新技能 - python flask","url":"/2017/05/02/Alexa 开发新技能/","text":"非常简单的教程，讲怎么给 Alexa 添加新的 skill，让你的 Echo 更个性化。本篇添加的 skill 是让 Alexa 从 reddit 上读前 10 条热点。 代码戳Alexa-Starter-RedditReader，其他版本如用 Lambda Function 实现，见Alexa 开发新技能 - Lambda Requirements Python Amazon Developer Account ngrok Code for new skill这里我们用 Flask 来建一个简单的 web application，代码如下，get_headlines() 是我们主要的 method，从 Reddit 里返回 10 条热点。逻辑是这样的： (用户呼唤 Reddit Reader) Alexa 问用户 ‘Hello there, would you like the news?’ 用户回答肯定回复: 读 10 headlines否定回复: 回答 ‘I am not sure why you asked me to run then, but okay… bye’ 注意要确保有上面的 python package，如果没有，先安装 flask == 0.12.1 flask_ask == 0.9.3 unidecode == 0.4.20 123$ pip install flask$ pip install flask_ask$ pip install unidecode 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from flask import Flask, render_templatefrom flask_ask import Ask, statement, question, sessionimport jsonimport requestsimport timeimport unidecode# define Flask appapp = Flask(__name__)# give basic endpoint, can be flask skill/program endpointask = Ask(app, &quot;/reddit_reader&quot;)def get_headlines(): sess = requests.Session() # just change user-agent sess.headers.update(&#123;&apos;User-Agent&apos;: &apos;I am testing Alexa&apos;&#125;) time.sleep(1) # get first 10 headlines url = &apos;https://reddit.com/r/worldnews/.json?limit=10&apos; html = sess.get(url) data = json.loads(html.content.decode(&apos;utf-8&apos;)) titles = [unidecode.unidecode(listing[&apos;data&apos;][&apos;title&apos;]) for listing in data[&apos;data&apos;][&apos;children&apos;]] titles = &apos;...&apos;.join([i for i in titles]) return titles# set home url path@app.route(&apos;/&apos;)def homepage(): return &apos;hi there, how ya doin?&apos;@ask.launchdef start_skill(): # it will say welcome_message = &apos;Hello there, would you like the news?&apos; # question expect response return question(welcome_message)# handle user input yes or no response# user input is intent@ask.intent(&quot;YesIntent&quot;)def share_headlines(): # grab the headline headlines = get_headlines() headline_msg = &apos;The current world news headlines are &#123;&#125;&apos;.format(headlines) # statement tell you sth return statement(headline_msg)@ask.intent(&quot;NoIntent&quot;)def no_intent(): bye_text = &apos;I am not sure why you asked me to run then, but okay... bye&apos; return statement(bye_text)if __name__ == &apos;__main__&apos;: app.run(debug=True) Set endpoint这里我们用 ngrok，将本地 web 服务部署到公共网络。如果没有下载，先从这下载并解压，然后运行，端口就是 Flask 运行的端口1$ ./ngrok http 5000 Deploy去Amazon developer 网站上注册用户并登陆，注意这里的用户名和你的 Echo 用户名是一致的。点开 Alexa tab，选择 add skill，开始部署。 Step1:填写 Name 和 Invocation Name，Invocation Name 用来 invoke app Step2:主要填写 Intent Schema 和 Sample Utterances Intent Schema: how alexa will traverse your application 123&#123; &quot;intents&quot;: [&#123; &quot;intent&quot;: &quot;YesIntent&quot; &#125;, &#123; &quot;intent&quot;: &quot;NoIntent&quot; &#125;]&#125; Sample Utterances: the words people say to trigger intent12345YesIntent yesYesIntent sureNoIntent noNoIntent go away Step3:选择并填写 Endpoint，这里我们用的是 HTTPS，可以在 ngrok 的命令行找到 endpoint url Step4:这里我们就选 My development endpoint is a sub-domain of a domain that has a wildcard certificate from a certificate authority，作为测试的话不选也没有关系 Step5:就可以用 Echo 来 test 啦~ 如果没有 Echo，可以用 Service Simulator 来模拟先给 Alexa 一个关于 Reddit Reader 的指令，然后按照我们的代码，Alexa 会问你要不要读新闻 然后我们回答 yes，Alexa 就开始读新闻啦~ 一个简单的实例PNC_Virtual_Assistant 参考链接Intro and Skill Logic - Alexa Skills w/ Python and Flask-Ask Part 1Flask Building Responses","tags":"iot alexa 物联网 echo"},{"title":"NLP 笔记 - Machine Translation","url":"/2017/05/01/NLP 笔记 - Machine Translation/","text":"CMU 11611 的 guest lecture 笔记。重点讲机器翻译传统 Noise Channel 模型以及目前流行的几个神经网络模型。 一张图看机器翻译历史。 Noise Channel我们想要一个 p(e|f) 的模型，f 代表源语言(confusing foreign sentence)，e 代表目标语言(possible English translation)，noise channel 前面讲过了，如下图 $$ \\begin{aligned} \\hat e &amp; = argmax_e p(e|f) \\\\ &amp; = argmax_e {p(e) p(f|e) \\over p(f)} \\\\ &amp; = argmax_e p(e) p(f|e) \\\\ \\end{aligned}$$ 其中 p(e): language model判断产生的句子是否通顺，是否符合语法，是否地道(fluent, grammatical, idiomatic)一般会用 ngram 模型 p(f|e): translation model/channel model其实是一个翻转的翻译概率(reverse translation probability)，看把目标语言(English sentence)翻译成源语言(foreign sentence)的概率，通常用 MLE 估计，需要注意泛化问题保证足够多的翻译可能 p(e) language model 的问题很好解决，见NLP 笔记 - Language models and smoothing，难点是怎样确定 p(f|e)，第一个想法自然是直接用 MLE，然而问题是句子实在太多，这种方法很难泛化。 $$P(f|e)={count(f,e) \\over count(e)}$$ 所以想到的是能不能从 lexical 层面着手，先进行词对词的翻译，然后再进行词的排序，也就是下面要讲的 Lexical Translation Model。 Lexical Translation我们怎样翻译一个单词？最简单粗暴的方法当然是从字典(dictionary)里找它！然而一个单词可能有不同的 sense/registers/inflections，也就会有不同的翻译，怎么办？用单词频率来计算 MLE p(e|f,m)其中， e: 完整的目标句(English sentence)e = {$e_1, e_2, … ,e_m$} f: 完整的源句(Foreign sentence)f = {$f_1, f_2, …, f_n$} 我们作出以下假设 e 的每个单词 $e_i$ 从 f 的某个单词(exactly one word)产生 我们需要找词与词之间的对应关系，才能进行词的翻译，把对应关系看做语料里的隐变量(latent alignment)，用 $a_i$ 表示 $e_i$ 来自于 $f_{e_i}$ 这个对应关系 给定对齐 a，翻译决策是条件独立(conditionally independent)的，仅依赖于 aligned source word $f_{e_i}$ 于是就有下面这个公式 Representing Word Alignment如何表示单词的对齐？ 上图的表示就是 $a = (1,2,3,4)^T$ Reorder 当然在翻译过程中单词的顺序可能会被打乱，上图的表示就是 $a = (3,4,2,1)^T$ Word Dropping有些源语言的单词可能根本不会被翻译 =&gt; $a = (2,3,4)^T$ Word Insertion有些时候，翻译过程中我们需要添加单词，然而这些单词必须是可以被解释的，所以通常我们会再源语句上加一个 NULL token =&gt; $a = (1,2,3,0,4)^T$ One-to-many Translation一个源单词可能被翻译成多个目标单词的组合 =&gt; $a = (1,2,3,4,4)^T$ Many-to-one Translation多个源单词的组合也可以被翻译成一个目标单词，然而！ 在 lexical translation 中，并不支持这种翻译 =&gt; $a = ??? a = (1,2,(3,4)^T)^T ?$ Learning - EM algorithm怎样来训练得到词对齐呢 P(e|f)？可以用 EM 算法 选择 random(or uniform) 的初始参数对模型进行初始化 用现有参数，计算训练数据中每个 target word 的 alignments $p(a_i|e,f)$ 的期望值 计算 MLE，得到更好的参数，对模型进行更新 反复迭代直至收敛 1. 假设对齐概率分布是均匀的2.发现 la 和 the 的对应关系更明显3.更新参数4.反复迭代直至收敛 举一个简单的中译英的例子(pls forgive my poor handwriting : ( ) IBM Model1IBM Model 1 是最为基本的翻译模型，也是一个最简单的基于词汇的翻译模型，除了上面提到的假设外，该模型还做出了其他假设 m 个词的对齐决策是相互独立的 每个 $a_i$ 在所有源单词和 NULL 上的对齐分布是 uniform 的 得到翻译概率后 Log-linear model还有一种模型是把上面提到的各种概率/模型作为特征，用对数线性模型(如逻辑回归，最大熵模型等)将各种特征结合起来，利用最小错误率调参等方法照到合适的特征权重。其实就是基于各种特征，看哪种翻译组合更好的问题。这是后来整理阿里巴巴骆卫华讲座内容时看到的方法。除了 noisy model 提到的对齐模型和语言模型，讲座还讲到了调序模型，调序模型也就是把两个词/短语之间是否要换序的问题看做二分类问题，如下 ExtensionsPhrase-based MT基于词的翻译模型没有考虑上下文，也不支持 many-to-one 的对齐，基于短语的翻译模型可以解决这个问题。短语模型需要引入多一层的隐含变量，叫做 source segmentation。 短语模型首先需要确定短语，注意短语既不能超过源语言的范围也不能超过目标语言的范围，可以用 MLE 计算源短语与目标短语的共现关系，同时要考虑的是源端到目标端之间是多对多的关系，源语言 -&gt; 目标语言可能有多种翻译，目标语言 -&gt; 源语言也可能有多种翻译，所以需要计算一个双向的概率。由于有些短语出现的概率非常低，所以可以把短语概率退化成词的概率来进行计算，如下 也就是 big house 大房子 的概率可以用 lex=p(大|big)p(房子|house) 来进行计算。 之后将正向概率和反向概率合并，就可以得到短语表。 Alignment Priors初始化参数时我们假定对齐概率的分布是 uniform 的，然而事实上我们可以加个先验概率 Syntactic structure加入句法结构，也可以改善结果 Neuron models用神经网络来做翻译模型需要考虑的问题 How to represent inputs and outputs?input 的表示可以用 one-hot vector 或者 distributed representations(通常 word vector) Neural architecture?How many layers? (Requires non-linearities to improve capacity!)How many neurons?Recurrent or not?What kind of non-linearities? 详细戳 NLP 笔记 - Neural Machine Translation","tags":"nlp machine-translation 机器翻译"},{"title":"NLP笔记 - NLU之意图分类","url":"/2017/04/27/NLP笔记 - NLU之意图分类/","text":"阿里巴巴水德的关于意图分类的讲座笔记。 引言自然语言理解(NLU) Natural language understanding (NLU) is a subtopic of natural language processing in artificial intelligence that deals with machine reading comprehension. NLU is considered an AI-hard problem. [1] 从概念定义可以得出的信息 属于 NLP 的一个分支 属于人工智能的一个部分 用来解决机器理解人类语言的问题 属于人工智能的核心难题 补充一句，什么是 AI-complete 或 AI-hard 问题？其实就是说解决这个问题的难度等同于让计算机和人类一样智能，或者说实现它就相当于实现了 strong AI，基本标志 AI 革命的完美结束。 语义表示(Semantic representation)语义表示(Semantic representation) 有三种典型形式: 分布语义表示（distributional semantics representation)​ 把语义表示成一个向量，如 word2vec、LSA、LDA 及各种神经网络模型(如 LSTM)​ 基于Harris的分布假设：semantically similar words occur in similar contexts​ 对人机交互而言，这种表示方法缺少一个细节性/可解释的表示，不能说出第 n 维表示什么​ NLP 笔记 - 再谈词向量 模型论语义表示（model-theoretic semantics representation）​ 把自然语言映射成逻辑表达式(logic form)​ 在计算方法上，典型的就是构建一个semantic parser​ 难度比较大，见NLP 笔记 - Meaning Representation Languages的一阶谓词演算和 lambda reduction。 框架语义表示（frame semantics representation）​ 这种表示方法对人机交互非常有帮助​ 比如说 “订一张上海飞北京的头等舱，下午5点出发，国航的”，把语义用一个frame表示出来，如图所示： 在智能语音交互中，普遍采用frame语义表示，比如飞机票，第一层是 domain，确定是 flight_ticket 这一领域，下一层是这一领域下的 intent，比如说 search_flight_ticket，最下面一层是 intent 下的 slots。自然语言理解的核心过程，第一步就是对 domain/intent 分类，然后接着对 slot 进行填充。 基本概念来理解一下上面所说到的 domain 和 intent 的概念。 domain领域，同一类型的数据或者资源，以及围绕这些数据或资源提供的服务；比如“地图”，“酒店”，“飞机票”、“火车票”等；领域的目的其实是为了界定要解的 intent 范围，因为泛领域的 NLU 目前还做不到 intent意图，对于领域数据的操作，表示用户想要完成的任务，一般以动宾短语来命名；比如飞机票领域中，有“查询机票”、“退机票”等意图； 然后就到了本篇重点，意图分类(intent classification)，意图分类是一个典型的文本分类问题，所有传统的分类方法都可以使用，比如SVM/Decision Tree/Maximum Entropy 等等，数学形式来表示就是给定一个标注数据集合，$U={(u_1,c_1),…,(u_n,c_n)}$，其中，$c_i \\in C$ 是具体的 intent，$u_i$ 是输入的 utterance，求解目标是$$c_k = argmax_{c \\in C}p(c|u_k)$$ 主要难点语言多样性12345678• 我要听大王叫我来巡山• 给我播大王叫我来巡山• 我想听歌大王叫我来巡山• 放首大王叫我来巡山• 给唱一首大王叫我来巡山• 放音乐大王叫我来巡山• 放首歌大王叫我来巡山• 给大爷来首大王叫我来巡山 语言歧义性12345• 我要去拉萨 – 火车票？ – 飞机票？ – 音乐？ – 还是查找景点？ 解决语言歧义性的方法一般有下面 3 种 选一个 top intent，通常可能就选最常见的 intent 给一个 intent list 让用户来选 综合上下文信息来确定一个最优的 intent，这是最好的方法 语言鲁棒性12345678910111213• 错字 – 大王叫我来新山• 多字 – 大王叫让我来巡山• 少字 – 大王叫我巡山• 别称 – 熊大熊二（指熊出没）• 不连贯 – 我要看那个恩花千骨• 噪音 – 全家只有大王叫我去巡山咯• … 知识依赖要知道语言是对现实世界的描述，很多词是有多种含义的，如果没有对现实世界的知识会难以分类。看下面的例子，大鸭梨可以是水果也可以是餐厅，七天可以是天数也可以是酒店。12345– 大鸭梨– 七天– 总参– 天气预报– 晚安 上下文依赖(context)上下文的概念包含了很多内容，比如说 对话上下文​ 多轮对话 设备上下文​ 指硬件设备，如手机/电视/汽车/… 应用上下文​ 用户在哪个 app 里进行对话 用户画像​ 用户的个性化信息，尤其是地理位置等 …… 如下面两段对话，上下文不同，宁夏的含义也就不同。123456U：买张火车票A：请问你要去哪里？U：宁夏U：来首歌听A：请问你想听什么歌？U：宁夏 基本方法 基于规则（rule-based）CFGJSGF…… 传统机器学习方法SVMME…… 深度学习方法CNNRNN/LSTM…… 融合规则和深度学习的方法 基于规则的意图分类实际上是基于上下文无关语法(CFG)，以上面提到的飞机票领域为例123456789101112131415FRAME: flight_ticketNETS:[search_flight_ticket][refund_flight)ticket][search_flight_ticket] [flight_range] [flight_ticket] [from] [to] (的 (飞机票)) (从 [city]) (去 [city])[city](北京)(上海)... 从北京到上海的飞机票 基于统计模型的意图分类给定输入 utterance u 和类别 c，我们要求的是 P(c|u)，核心问题就是: 如何表示 u，也就是 text representation 如何学习 P(c|u)，也就是 classifer Text Representation Bag of Words (BOW)– 优点：简单– 缺点：没有考虑语言结构，相似关系等 Hand-crafted features– 优点：精准– 缺点：领域依赖，扩展性差 Learned feature representation– 优点：能够学到所有相关的信息– 缺点：需要学习 Classifier两类模型任君选择 生成式模型Generative (joint) models，计算 P(c,u)– Naive Bayes– HMM– … 判别式模型Discriminative (conditional) models, 计算 P(c|u)– logistic regression– maximum entropy– conditional random fields– support vector machines– … 实现方案一种简单的实现方案，首先用 bag of words 提取基本特征，接着人工定义规则来提取一些高质量的特征(提取意图词，过滤 stopwords 等)，然后将这些特征用 one-hot 或者 tf-idf 方式表示为向量，再将特征向量喂给 svm 分类器。如下：123456789101112131415161. Text Representation – Bag of Words (BOW) &gt;&gt; unigram &gt;&gt; bigram &gt;&gt; pos – Hand-crafted features &gt;&gt; 意图词，用来表达意图的有限词集合，比如“飞机票/机票/餐厅/美食/火车…” &gt;&gt; 无效词比例，定义一个有效词的集合，然后计算 utterance 中无效词的比例 &gt;&gt; pattern特征，比如“从[city]”，“去[city]”，… &gt;&gt; … – feature vector &gt;&gt; One-hot &gt;&gt; TF-IDF2. Classifier – svm, 比如可以采用开源的libsvm/liblinear实现 基于深度学习的意图分类两种典型策略 RNN（recurrent neutral network）序列化、有记忆模型 CNN（convolutional neutral network）非序列化、无记忆模型 一般我们把 RNN/CNN 是特征学习方法，分类器可以有多种选择。 RNN(Recurrent Neutral Network)从 language model 理解，$$\\begin{aligned}p(W_1=w_1, W_2=w_2,…,W_{L+1}=stop) &amp; = p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)…p(w_n|w_1,w_2,…w_{n-1}) \\\\ &amp; = (\\prod^L_{l=1}p(W_l=w_l|W_{1:l-1}=w_{1:l-1}))p(W_{L+1}=stop|W_{1:L}=w_{1:L}) \\\\ &amp; = (\\prod^L_{l=1}p(w_l|history_l))p(stop|history_L) \\end{aligned} $$ 其实也就是下图的 RNN 最后要加一层，一般是 softmax 分类。 由于 RNN 的训练存在梯度消失/梯度爆炸问题，实际中往往采用 LSTM/GRU 等结构，Classifier 采用 softmax 函数，和网络一起训练 CNN(Convolutional neutral network)之前讲过啦，见实习总结之 sentence embedding，一张图简单回顾。这里要说的是怎么将其用于意图分类。如果能够融入知识(如下图的语义标签)，将 word vector 和 knowledge vector 结合起来，效果可能会有所提升。 阿里巴巴做了实验，发现在他们自己 4k+ 的测试集上能带来 3% 的效果提升，并且，越是知识依赖严重的领域，效果越是明显，比如说在音乐、地图领域的提升比天气领域的提升明显很多。 融合规则和深度学习的系统 规则解决哪些问题？冷启动解bug解业务特有意图 模型解决哪些问题？海量数据下把问题解决的更加深入和彻底解通用的意图 产品意图分类在阿里产品中的使用，如汽车/阿里云/YunOS手机助理/支付宝/天猫魔盒/机器人等等。","tags":"nlp information-extraction intent-classification nlu"},{"title":"卷积神经网络 CNN 笔记(高级篇)","url":"/2017/04/25/卷积神经网络 CNN 笔记(高级篇)/","text":"对应 深度学习知识框架，学习更先进的 CNN，包括 AlexNet, VGG, GooLeNet, ResNet, DeepFace, U-Net。 AlexNet: 现代深度卷积网络起源Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “Imagenet classification with deep convolutional neural networks.” Advances in neural information processing systems. 2012. AlexNet 在 2012 年提出，是 LeNet 更深更宽的版本。AlexNet 由 5 个卷积层，以及部分卷积层后跟着的 max-pooling 层，和 3 个全连接层，还有最后的 1000-way 的 softmax 层组成，共有 6000 万个参数(用全连接层的参数来估算)和 650,000 个神经元。为了加快训练速度，使用了线性修正单元 ReLU 和 多 GPU 加速并行；为了减少全连接层的过拟合，采用了 dropout, data augmentation 和 LRN。网上可能会看到两个版本的 AlexNet，因为在 ImageNet LSVRC-2010 大赛后，论文作者又输入了该模型的一个变体，参加了 ILSVRC-2012。AlexNet 确立了深度卷积网络在计算机视觉的统治地位。 来看一下总体架构： 结构及参数计算：12345678910111213141516171819202122[227x227x3] INPUT[55x55x96] CONV1: 96 11x11 filters at stride 4, pad 0--- OUTPUT VOLUME SIZE = (227-11)/4+1 = 55 ------ TOTAL NUMBER OF PARAMETERS = 11*11*3*96 = 35K ---[27x27x96] MAX POOL1: 3x3 filters at stride 2--- OUTPUT VOLUME SIZE = (55-3)/2+1 = 27 ---[27x27x96] NORM1: Normalization layer[27x27x256] CONV2: 256 5x5 filters at stride 1, pad 2[13x13x256] MAX POOL2: 3x3 filters at stride 2[13x13x256] NORM2: Normalization layer[13x13x384] CONV3: 384 3x3 filters at stride 1, pad 1[13x13x384] CONV4: 384 3x3 filters at stride 1, pad 1[13x13x256] CONV5: 256 3x3 filters at stride 1, pad 1[6x6x256] MAX POOL3: 3x3 filters at stride 2--- TOTAL NUMBER OF PARAMETERS = 6*6*256 ---[4096] FC6: 4096 neurons--- TOTAL NUMBER OF PARAMETERS = 4096*36*256=37,748,736 ---[4096] FC7: 4096 neurons--- TOTAL NUMBER OF PARAMETERS = 4096*4096=16,777,216 ---[1000] FC8: 1000 neurons (class scores)--- TOTAL NUMBER OF PARAMETERS = 1000*4096=4,096,000 ---=== TOTAL NUMBER OF PARAMETERS =&gt; 37,748,736 + 16,777,216 + 4,096,000 =&gt; 6000W === 上图明确显示了两个GPU之间的职责划分。一个 GPU 运行图中顶部的层次部分，另一个 GPU 运行图中底部的层次部分。GPU 之间仅在某些层互相通信。 为了防止过拟合，AlexNet 用了以下三种技术 数据增强a. 由生成图像转化和水平反射组成 如从 256×256 的图像中随机提取 224×224 的碎片(以及水平反射的镜像)，并在这些提取的碎片上训练网络，相当于增加了 ((256-224)^2)*2=2048 倍的数据量b. 改变训练图像中RGB通道的强度 在整个 ImageNet 训练集的 RGB 像素值集合中执行PCA。对每个训练图像，成倍增加已有主成分，比例大小为对应特征值乘以一个从均值为 0，标准差为 0.1 的高斯分布中提取的随机变量 Dropout以一定的概率(如 0.5)将每个隐层神经元的输出设置为零。AlexNet 主要是最后几个全连接层使用了 dropout LRN 层LRN (Local Response Normalization 局部响应归一化)，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。 一些细节：1234567891011Details/Retrospectives:- first use of ReLU- used Norm layers (not common anymore)- heavy data augmentation- dropout 0.5- batch size 128- SGD Momentum 0.9- Learning rate 1e-2, reduced by 10manually when val accuracy plateaus- L2 weight decay 5e-4- 7 CNN ensemble: 18.2% -&gt; 15.4% AlexNet 的学习过程，用随机梯度下降法和一批大小为 128、动力为 0.9、权重衰减为 0.0005 的样例来训练网络。用一个均值为 0、标准差为 0.01 的高斯分布初始化每一层的权重，用常数 1 初始化第 2、第 4 和第 5 个卷积层以及全连接隐层的神经元偏差，在其余层用常数 0 初始化神经元偏差。对所有层都使用了相等的 learning rate，并在整个训练过程中手动调整。当 validation error 在当前 learning rate 下不再提高时，就将 learning rate 除以 10。learning rate 初始化为 0.01，在终止前降低三次。训练该网络时大致将这 120 万张图像的训练集循环了 90 次，在两个 NVIDIA GTX 580 3GB GPU 上花了五到六天。 AlexNet 在 ILSVRC-2010 大赛上实现了top-1测试集误差率 37.5%，top-5测试集误差率 17.0% ，在 ILSVRC-2012大赛上实现了测试集误差率 top-5 15.3%。 VGG: AlexNet增强版Simonyan, Karen, and Andrew Zisserman. “Very deep convolutional networks for large-scale image recognition.” arXiv preprint arXiv:1409.1556 (2014). VGG 相当于 AlexNet 的增强版，有着结构简单且深度、精度增强的优势。这里一个 tricky 的地方是，VGG 不是模型的缩写，而是 Visual Geomety Group，也就是牛津大学计算机视觉组(Department of Engineering Science, University of Oxford)的简称。 VGG 与 AlexNet 最鲜明的对比是卷积层、卷积核设计的变化。VGGNet 探索了卷积神经网络的深度与其性能之间的关系，通过反复堆叠 3x3 的小型卷积核和 2x2 的最大池化层，成功构筑了 16~19 层深的卷积神经网络。 结构变化: 卷积层转化为卷积群(如下图) =&gt; 参数变化: 60m =&gt; 138m =&gt; 识别率变化(TOP5): 15.3% =&gt; 7.3% VGGNet 有 5 个卷积群，每一群内有 2~3 个卷积层，每个群连接一个 max-pooling 层来缩小图片尺寸。每个卷积群内的卷积核数量一样，越靠后的卷积群的卷积核数量越多：64 – 128 – 256 – 512 – 512。其中经常出现多个完全一样的 3x3 的卷积层堆叠在一起的情况，为什么呢？看下图，可以发现两个 3x3 的卷积层串联其实相当于 1 个 5x5 的卷积层，也就是说一个像素会跟周围 5x5 的像素产生关联。类似的，3 个 3x3 的卷积层串联的效果则相当于 1 个 7x7 的卷积层。为什么要堆叠卷积层而不直接用 7x7 的呢？一是因为 3 个串联的 3x3 的卷积层的参数比 1 个 7x7 的卷积层更少，二是因为 3 个 3x3 的卷积层比 1 个 7x7 的卷积层有更多的非线性变换（前者可以用三次 ReLU 激活函数，而后者只有一次），对特征的学习能力更强。 网络结构及参数计算: VGG的作用： 结构简单：同 AlexNet 结构类似，都是卷积层、池化层、全连接层的组合 性能优异：同 AlexNet 提升明显，同 GoogleNet, ResNet 相比，表现相近 选择最多的基本模型，方便进行结构的优化、设计，SSD, RCNN，等其他任务的基本模型(base model) GooLeNet: 多维度识别Szegedy, Christian, et al. “Going deeper with convolutions.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. GoogLeNet，ILSVRC 2014 winner，TOP5 的错误率为 6.7%。特点是结构复杂、多分辨率融合。GooLeNet 主要目标是找到最优的稀疏结构单元，也就是 Inception module。Inception 结构是将不同的卷积层通过并联的方式结合在一起，它主要改进了网络内部计算资源的利用率，让我们能在固定计算资源下增加神经网络深度和宽度，另外，Inception 结构还遵循了 Hebbian 原则并增加了多尺度处理。 先看一下 GoogLeNet 的整体结构，其实是由 9 个相似的 Inception module 构成的。 Inception 结构发展 All we need is to find the optimal local construction and to repeat it spatially. GooLeNet 的 Inception 对特征图进行了三种不同的卷积(1x1, 3x3, 5x5)来提取多个尺度的信息，也就是提取更多的特征。举个例子，一张图片有两个人，近处一个远处一个，如果只用 5x5，可能对近处的人的学习比较好，而对远处那个人，由于尺寸的不匹配，达不到理想的学习效果，而采用不同卷积核来学习，相当于融合了不同的分辨率，可以较好的解决这个问题。把这些卷积核卷积后提取的 feature map (再加多一个 max pooling 的结果)进行聚合操作合并(在输出通道数这个维度上聚合)作为输出，也就是左图的结构，会发现这样结构下的参数暴增，耗费大量的计算资源。 所以有了右图的改进方案，在 3x3，5x5 之前，以及 pooling 以后都跟上一个 1x1 的卷积用以降维，就可以在提取更多特征的同时，大量减少参数，降低计算量。1x1 的卷积核性价比很高，很小的计算量就能增加一层特征变换和非线性化(如果后面接 ReLU 等 activation layer)，另外，这也是一种降维(dimension reductionality)的方式，可以减少过拟合。具体的作用见1x1大小的卷积层的作用 Inception v1 有 22 层，但只有 500w 的参数量，是 AlexNet 的 1/12。为什么要减少参数量？一是因为参数越多，需要喂给模型的数据量就越大，二是因为参数越多，耗费的计算资源就越大。InceptionNet 为什么参数少而且效果好？一是因为用平均池化层代替了最后的全连接层，二是因为上面解释的 Inception Module 的作用。 Inception v2 学习了 VGG，用两个 3x3 的卷积替代了 5x5 的大卷积(降低参数&amp;减少过拟合)，并提出了 Batch Normalization 方法，另外根据 BN 对其他部分做了一些调整，比如增大 learning rate，加快学习衰减速度，去除 dropout 减轻L2 正则，去除 LRN，更彻底的对训练样本进行 shuffle 等等。 Inception v3 优化了 Inception Module 的结构，同时引入了 Factorization into small convolutions 思想，把一个较大的二维卷积拆分成两个较小的一维卷积，如将 7x7 卷积拆成 1x7 卷积核 7x1 卷积，进一步节约参数减轻过拟合，此外，Inception v3 还增加了一层非线性扩展模型表达能力。 Inception v4 则结合了微软的 ResNet，在 TOP5 error 上反超了 ResNet 3.1%。 Inception 网络就是由多个上面所说的 inception model 堆叠起来的，Inception model 之间可能再通过 max pulling 减小 feature map，论文作者提出，为了 memory efficiency，最好前几层按正常 CNN 套路来，在深层的时候使用 Inception model。 网络结构图: 参数总数约为 5m，最后用 average pooling 层代替了全连接层。顺带讲一下全卷积结构(FCN)，一般的神经网络是卷积层(CNN)+全连接层(FC)，全卷积网络没有全连接层(全连接层一会需要大量的参数，二会引起过拟合)，这样的特点是: 输入图片大小无限制 空间信息有丢失 参数更少，表达力更强 不适合分类，适合做数据生成 ResNet: 机器超越人类识别Deep Residual Learning for Image Recognition Deep Residual Learning for Image Recognition Abstract: Deeper neural networks are more difficult to train. We present a residual learning framework to ease the…arxiv.org 由微软提出，最初灵感出自神经网络层数不断加深导致的训练集上误差增大的问题(Degradation)，也就是随着网络层数增加，准确率会先上升然后达到饱和，再持续增加深度会导致准确率下降的现象。相比于 AlexNet 和 VGG，ResNet 层数更多，训练用了 8GPU，三周完成。 下图描述了 ResNet 的结构特性，ResNet 允许原始输入信息传输到后面的层中。特征图经过卷积层和非线性层后和之前的特征图进行数据融合，融合结果再往后面的网络推进。看最右边的部分，发现网络有很多“支线”来将输入直接连到后面的层，使得后面的层可以直接学习残差，这种结构也被称为 shortcut 或者 skip connections，它能够保护信息的完整性，整个网络只需要学习输入、输出差别的那一部分，简化了学习目标和难度。具体来说，假定某段神经网络的输入是 x，期望输出是 H(x)，如果直接把输入 x 传到输出作为初始结果，那么此时需要学习的目标就是 F(x)=H(x)-x，这就是一个 ResNet 的残差学习单元(Residual Unit)，ResNet 的学习目标不再是学习一个完整的输出，而是学习输出和输入的差别，也就是残差。 为什么 ResNet 有效？ 前向计算：低层卷积网络高层卷积网络信息融合；层数越深，模型的表现力越强 反向计算：导数传递更直接，越过模型，直达各层 Benefits of depth in neural networks by Matus Telgarsky DeepFace: 结构化图片的特殊处理Taigman Y, Yang M, Ranzato M A, et al. Deepface: Closing the gap to human-level performance in face verification 由 Facebook 提出。广义的人脸识别是说看到这个人脸，确定它是谁，而落在应用/产品层面，更多的是 verification，先拿到别人的照片，做一个 model，再拿一张新的照片，来判断是不是这个人，也就是人脸身份确认。 先来看一下人脸图片的数据特点： 结构化：所有人脸的组成相似，理论上可以实现对齐 差异化：相同的位置，形貌(appearance)不同 DeepFace 在训练神经网络前，使用了对齐(frontalization)，论文认为神经网络能够 work 的原因在于一旦人脸经过对齐后，人脸区域的特征就固定在某些像素上了，所以就可以用卷积神经网络来学习特征。之后的 DeepID 和 FaceNet 并没有对齐这个步骤。 传统 CNN 用同一个卷积核对整张图片进行卷积运算，卷积核参数共享，不同局部特性对参数影响相互削弱，达不到最优的效果，对应的解决方法是局部卷积，不同的区域用不同参数。 人脸识别的基本流程：1detect -&gt; aligh -&gt; represent -&gt; classify 结构: 经过 3D 对齐后，形成的图像都是 152×152 的图像，输入到上述网络结构中，该结构的参数如下：12345678- Conv：32 个 11×11×3 的卷积核- max-pooling: 3×3， stride=2- Conv: 16个9×9 的卷积核- Local-Conv: 16 个 9×9 的卷积核，参数不共享- Local-Conv: 16 个 7×7 的卷积核，参数不共享- Local-Conv: 16 个 5×5 的卷积核，参数不共享- Fully-connected: 4096 维- Softmax: 4030 维 前三层的目的在于提取低层次的特征，比如简单的边和纹理。其中 Max-pooling 层使得卷积的输出对微小的偏移情况更加鲁棒。但没有用太多的 Max-pooling 层，因为太多的 Max-pooling 层会使得网络损失图像信息。 后面三层都是使用参数不共享的卷积核，之所以使用参数不共享，有如下原因： 对齐的人脸图片中，不同的区域会有不同的统计特征，卷积的局部稳定性假设并不存在，所以使用相同的卷积核会导致信息的丢失 不共享的卷积核并不增加抽取特征时的计算量，而会增加训练时的计算量 使用不共享的卷积核，需要训练的参数量大大增加，因而需要很大的数据量，然而这个条件本文刚好满足。 全连接层将上一层的每个单元和本层的所有单元相连，用来捕捉人脸图像不同位置的特征之间的相关性。其中，第7层（4096-d）被用来表示人脸。 全连接层的输出可以用于Softmax的输入，Softmax层用于分类。 全局部卷积连接的缺陷： 预处理：大量对准，对对准要求高，原始信息可能丢失 卷积参数数量很大，模型收敛难度大，需要大量数据 模型可扩展性差，基本限于人脸计算 U-Net: 图片生成网络Noh, H., Hong, S. and Han, B., 2015. Learning deconvolution network for semantic segmentation. In Proceedings of the IEEE International Conference on Computer Vision (pp. 1520-1528). 通过卷积神经网络生成特殊类型的图片，基本结构 CONV-FC-CONV VGG U-Net: 主要要理解的概念是池化-反池化(Pooling-Unpooling),卷积-逆卷积(Convolution-Deconvolution)。 上采样/反池化实际是在池化的时候记住原本的位置，然后在上采样的时候对应回去放回原本的位置，前后空间位置保持一致，其他的地方可以直接补 0。而逆卷积实际上是有学习能力的上采样，它在生成图像有更好的连贯性，更好的空间表达能力。 参考链接： CNN浅析和历年ImageNet冠军模型解析 DeepFace–Facebook的人脸识别","tags":"deep-learning cnn"},{"title":"NLP 笔记 - Compositional Semantics","url":"/2017/04/13/NLP-笔记---Compositional-Semantics/","text":"CMU 11611 的课程笔记。主要讲了两种语义分析的方法: Lexicalized CFG 及 CCG，补充介绍了词汇语义学的一些概念。比较基础，网上参考资料较少，具体需要研究相关论文。 Semantics Road Map Lexical semantics Vector semantics Meaning representation languages and semantic roles Compositional semantics, semantic parsing Discourse and pragmatics 上一章讲了 FOL，它是定义良好表现良好易于理解，然而也存在一些 Issues “Meanings” of sentences are truth values. Only first-order (no quantifying over predicates). Not very good for “fluents” (time-varying things, real-valued quantities, etc.) Brittle: anything follows from any contradiction(!) Goedel incompleteness: “This statement has no proof”!• (Finite axiom sets are incomplete w.r.t. the real world.) So: Most systems use its descriptive apparatus (with extensions) but not its inference mechanisms. Stages of Semantic ParsingSemantic Analysis/Parsing 的目的是把自然语言转化成机器可以理解的逻辑语言如 FOL 12345678Input- SentenceSyntactic Analysis- Syntactic structureSemantic Analysis- Semantic representation Goal:Learn f: sentence -&gt; logical form Example12345Input- Javier likes pizzaOutput- like(Javier, pizza) Syntax-driven semantic analysis句法驱动的语义分析(Syntax-driven semantic analysis)仅仅以词典和语法中的静态知识为输入语句指派意义表示(meaning representation)，这是一个贫瘠的表示，上下文独立(context-independent)，推理无关(inference-free)，视野有限。然而，在某些领域，这样的表示足以产生有用的结果，另一方面，这些表示也可以作为后续处理的输入，进而产生更丰富、更有用的意义表示。 基于组合性原则的语义(Compostitional Semantics)假定一个句子的意义可以由它的几个部分(subparts)的意义组成(这显然有些例外，如 hot dog, straw man, New York 等)。 要注意的是，这个思想并不是说句子的意义仅仅依赖于句子中的词汇，而是还依赖于句中词汇的顺序、词汇所形成的群组和词汇之间的关系。也就是说，在句法驱动的语义分析中，意义表示的组成是由句法成分和关系来引导的。 给上下文无关语法规则扩充语义基本思路是给 CFG 规则添加语义附着。从 parse tree 开始，使用 FOL 和 lambda 表达式来建立语义，过程 Parse the sentence syntactically Associate some semantics to each word Combine the semantics of word and non-terminals recursively Until the root of the sentence 最简单的例子 稍复杂的例子，bottom-up 当然还有一种对应的是从上往下，follow SLP 歧义由于句法和词汇都存在歧义，因此句法驱动的语义分析将产生成倍的歧义意义表示，解决这些歧义并不是语义分析器的工作，而是通过使用领域知识和上下文知识在候选项中进行选择的后续理解处理。当然也可以通过使用鲁棒的词性标注器、介词短语附着机制以及词义排歧原理，以减少歧义表示的数量。 Using CCG(Steedman 1996)CCG(Combinatorial Categorial Grammar)的基本思路是先将词/短语和类别(categories)配对，然后逐步的对类别进行组合，通过 logical form 来捕捉句子的完整含义。 CCG assigns a category to each word and constructs a parse by combining pairs of categories to form an S. Not all pairs of categories can combine. A pair is allowed to combine if one category(e.g. A) is contained within the category next to it(e.g. B/A) and lies on the side indicated by the slash(\\ for left, / for right). When two categories combine, the result is a new category, taken from the left of the slash(B in this example) CCG Category 由两部分组成，左边是句法(syntax)，右边是语义(semantics)Syntax 包含基本符号和运算符 Primitive symbols: N, S, NP, ADJ and PP Syntactic combination operator (/,)Slashes specify argument order and direction CCG: Five (5) grammar rules! Application:– Forward: A/B + B = A A/B:S + B:T = A:S.T– Backward: B + A\\B = A B:T + A\\B:S = A:S.T Composition:– Forward: A/B + B/C = A/C– Backward: B\\C + A\\B = A\\C Coordination:– X CONJ X’ = X” Type raising:– A = X/(X\\A) Semantics 包含逻辑语言，如 lambda calculus，将 syntax 和 semantics 匹配起来就形成了 CCG Category，如(S\\NP)/ADJ: $\\lambda f.\\lambda x.f(x)$ 一个简单的例子 CCG 的优点 简化了组合规则(combinatory rules) 将复杂性从 rule 身上转移到了 (categorial) lexical entries 上 更紧密的与语义融合 句法和语义成分之间是一对一的关系 Handling CoordinationConstituent Coordination12- John likes Mary and dislikes Bob. NP (VP and VP) 如上面的例子可以直接通过 coordination rule 来 parse Non-constituent coordination1- John likes and Mary dislikes Bob. 然而这个例子就只能通过 Type raising 来解决 完整的例子 UW SPFUW 有一个开源项目 University of Washington Semantic Parsing Framework (UW SPF)，将语义分析的任务分成了三个子问题 Parsing -&gt; Learning -&gt; Modeling Parsing choiceNote: 项目中用了 Combinatory Categorial Grammars LearningNote: 项目中用了 Unified learning algorithm Semantic Modeling 更多见 Semantic Parsing with Combinatory Categorial Grammars CCGs vs. CFGs 补充：词汇语义学(Lexical Semantics)词汇语义学方面的知识可以用于基于 CFG 的语义分析。先看一下词位之间以及词位的含义之间的各种关系 同形关系(homonymy) 指词形(包括字形和音形)相同但意义不同的词之间的关系 多义关系(polysemy) 指单个词位具有多个相关含义的概念 同义关系(synonymy) 指具有相同意义的不同词位之间的关系 上下位关系(hyponymy) 指具有类别包含(class-inclusion)关系的词位之间的关系 我们知道，意义表示是以基本的谓词-论元结构为基础的，在组成这样的表示时，我们假定词位的某些类倾向于促成谓词和谓词-论元结构，而其他的倾向于促成论元。这里探讨的是，词位的各个意义表示之间具有可分析的内在结构，正是这个内在结构与语法相结合，才确定了良构句子中词位之间的关系。 Thematic Roles题元角色(Thematic Roles)是一组范畴，为刻画动词的某些 argument 的特征提供了浅层语义语言，比如下面两个句子 12Houston&apos;s Billy Hatcher broke a bat.He opened a rawer. 通过 FOPC 可以得到下面的部分表示12∃e,x,y ISA(e,Breaking) ∧ Breaker(e,BillyHatcher) ∧ BrokenThing(e,y) ∧ ISA(y,BaseballBat)∃e,x,y ISA(e,Opening) ∧ Opener(e,he) ∧ OpenedThing(e,y) ∧ ISA(y,Door) 可以发现，动词 break 和 open 的主语的角色分别为 Breaker 和 Opener，然而每种可能发生事的深层角色(deep role)都是特定的，比如 Breaking 事件中的 Breaker，Opening 事件中的 Opener，Eating 事件中的 Eater 等，但 Breaking 和 Opener 有一些共同点，它们都是有意志的行为人，常常是有生命的，并且对它们的事件负有直接因果责任，题元角色(Thematic Roles)就是表示这种共性的一种方式，比如说我们把这两个动词的主语称为 agent。 常用的 Thematic roles 及其定义 The Thematic Grid or Case Frame shows• How many arguments the verb has• What roles the arguments have• Where to find each argument For example, you can find the agent in the subject position Thematic roles 的另一个用途是，通过题元层级(thematic hierarchy)来决定主语和宾语，如上，如果一个动词的题元描述包括一个 AGENT，一个 INSTRUMENT，和一个 THEME，那么 AGENT 被实现为主语，如果题元描述值包括一个 INSTRUMENT 和一个 THEME，那么 INSTRUMENT 成为主语。 Verb Subcategorization动词可以有不同数量的 argument，以及不同的 VP 规则，应用 SUBCAT 特征，可以创建 allowed arguments 的集合。 Selectional Restriction选择限制(selectional restriction)是一种语义约束，通过容许词位对那些能够与它们在一个句子中出现的词位和短语设置某些语义限制，来增加语义角色。举个例子，看下面四个句子，前两个句子很正常，我们可以说 dog, child 是开心的，因为他们是动物，有情绪，所以可以把他们和 happy 联系起来，然而后两个句子就非常的诡异，事实上它们违反了选择限制(selectional restriction)。 12341. The dog was happy.2. The child was happy.3. The rock was happy.4. The napkin was happy. 我们可以通过面向事件的意义表示，来捕捉选择限制的语义，像 eat 这样的动词的语义贡献可以表示为1∃e,x,y Eating(e) ∧ Agent(e, x) ∧ Theme(e,y) 所有关于 y(theme 角色的填充者)的信息是：通过 THEME 关系，与 Eating 事件相关联，为加入 y 必须是可食用的东西这一选择限制，我们可以通过简单添加一个新的 term 来实现，如下1∃e,x,y Eating(e) ∧ Agent(e, x) ∧ Theme(e,y) ∧ ISA(y, EdibleThing) 当遇到像 ate a hamburger 这样的短语，语义分析器能够形成如下的表示1∃e,x,y Eating(e) ∧ Agent(e, x) ∧ Theme(e,y) ∧ ISA(y, EdibleThing) ∧ ISA(y, Hamburger) 这个表示是完全合理的，假如在知识库中有一个合理的事实集，y 在范畴 Hamburger 中的成员属性与它再范畴 EdibleThing 中的成员属性是一致的。相反，ate a takeoff 这样的短语是不合理的，因为 takeoff 中的成员属性与范畴 EdibleThing 中的成员属性不一致。然而这种方法预先假定存在一个大规模的关于组成选择限制的概念的事实逻辑库，遗憾的是，尽管这类知识库正在建设，但还没有普遍使用，而且几乎没有达到任务所需规模的知识库。 一个更实际的方法是利用 WordNet 信息库中的上下位关系，这种方法中，语义角色的选择限制是用 WordNet 的同义集而不是逻辑概念来表述的，如果填充语义角色的词位是由谓词给语义角色指定的同义集的上位词中的一个，那么这个给定的意义表示可以被判断为良构的。 如在 WordNet 的 60，000 个同义集中，有一个 {food, nutrient} 的同义集，我们可以将它指定为对动词 eat 的 THEME 角色的选择限制，也就是将这个橘色的填充者限定为再这个同义集或其下位词中，看下图，hamburger 的上位关系链显示它确实为 food","tags":"nlp semantic-analysis 语义分析"},{"title":"NLP笔记 - Relation Extraction","url":"/2017/04/10/NLP笔记 - Relation Extraction/","text":"Stanford NLP 关于关系抽取的笔记，仅探讨如何提取关系的三元组(triple)，即一个谓词(predicate)带 2 个形参(argument)，比如说 Founding-location(IBM,New York) 这类。 关系抽取的应用领域还是很广泛的，如 建立新的结构化的知识库(knowledge bases)几乎各个领域都会用到 扩大现有知识库将更多的单词添加到 WordNet 词典(thesaurus)将更多事实(facts) 添加到 FreeBase 或者 DBPedia中 支持 QA 系统The granddaughter of which actor starred in the movie “E.T.”? (acted-in ?x “E.T.”)(is-a ?y actor)(granddaughter-of ?x ?y) 先来看下关系抽取的数据集以及现有的关系定义。比较有名的ACE(Automated Content Extraction)有 6 大类关系 17 个子类，用于医疗的UMLS 有 134 中 entity type，54 种关系…… 还有的一些世界范围内知名的高质量大规模开放知识图谱，如包括 DBpedia、Yago、Wikidata、BabelNet、ConceptNet 以及 Microsoft Concept Graph等，中文的有开放知识图谱平台 OpenKG…… ACE 的 17 类关系 具体的应用实例 Wikipedia 的 info box info box 信息可以转换成 RDF 三元组 $(subject \\ predicate \\ object)$ 如 123Golden Gate Park location San Francisco =&gt;dbpedia:Golden_Gate_Park dbpedia-owl:location dbpedia:San_Francisco 常用的 Freebase relations 123456people/person/nationality,people/person/profession,biology/organism_higher_classification,location/location/containspeople/person/place-of-birthfilm/film/genre RDF 是一种本体语言，关于本体，貌似是本科时的东西了，就不多说了。 Relation extractors 手写规则(hand-written patterns) 监督学习(supervised machine learning) 半监督/无监督学习(semi-supervised and unsupervised) Bootstrapping(using seeds) Distant supervision Unsupervised learning from the web Hand-written patterns首先是基于字符串的 pattern，举一个 IS-A 的关系 Agar is a substance prepared from a mixture of red algae, such as Gelidium, for laboratory or industrial use 通过 such as 可以判断这是一种 IS-A 的关系，可以写的规则是： 123456“Y such as X ((, X)* (, and|or) X)”“such Y as X”“X or other Y”“X and other Y”“Y including X”“Y, especially X” 另一个直觉是，更多的关系是在特定是实体之间的，所以我们可以用 Named entity tag 来帮助关系抽取，比如说 123• located-in (ORGANIZATION, LOCATION)• founded (PERSON, ORGANIZATION)• cures (DRUG, DISEASE) 然后想到了我们可以把基于字符串的 pattern 和基于 ner 的 pattern 结合起来，就有了下面的例子。 对应的工具有 Stanford CoreNLP 的 tokensRegex。 手写规则的优点是： 人工规则有高准确率(high-precision) 可以为特定领域定制(tailor) 缺点是： 低召回率(low-recall) 要考虑周全所有可能的 pattern 很难，也很费时间精力 需要为每条关系来定义 pattern Supervised relation extraction研究综述漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025 Zhou[13] 在 Kambhatla 的基础上加入了基本词组块信息和 WordNet，使用 SVM 作为分类器，在实体关系识别的准确率达到了 55.5%，实验表明实体类别信息的特征有助于提高关系抽取性能； Zelenko[14] 等人使用浅层句法分析树上最小公共子树来表达关系实例，计算两颗子树之间的核函数，通过训练例如 SVM 模型的分类器来对实例进行分。但基于核函数的方法的问题是召回率普遍较低，这是由于相似度计算过程匹配约束比较严格，因此在后续研究对基于核函数改进中，大部分是围绕改进召回率。但随着时间的推移，语料的增多、深度学习在图像和语音领域获得成功，信息抽取逐渐转向了基于神经模型的研究，相关的语料被提出作为测试标准，如 SemEval-2010 task 8[15]。基于神经网络方法的研究有，Hashimoto[16] 等人利用 Word Embedding 方法从标注语料中学习特定的名词对的上下文特征，然后将该特征加入到神经网络分类器中，在 SemEval-2010 task 8 上取得了 F1 值 82.8% 的效果。基于神经网络模型显著的特点是不需要加入太多的特征，一般可用的特征有词向量、位置等，因此有人提出利用基于联合抽取模型，这种模型可以同时抽取实体和其之间的关系。联合抽取模型的优点是可以避免流水线模型存在的错误累积[17-22]。其中比较有代表性的工作是[20]，该方法通过提出全新的全局特征作为算法的软约束，进而同时提高关系抽取和实体抽取的准确率，该方法在 ACE 语料上比传统的流水线方法 F1 提高了 1.5%，；另一项工作是 [22]，利用双层的 LSTM-RNN 模型训练分类模型，第一层 LSTM 输入的是词向量、位置特征和词性来识别实体的类型。训练得到的 LSTM 中隐藏层的分布式表达和实体的分类标签信息作为第二层 RNN 模型的输入，第二层的输入实体之间的依存路径，第二层训练对关系的分类，通过神经网络同时优化 LSTM 和 RNN 的模型参数，实验与另一个采用神经网络的联合抽取模型[21]相比在关系分类上有一定的提升。但无论是流水线方法还是联合抽取方法，都属于有监督学习，因此需要大量的训练语料，尤其是对基于神经网络的方法，需要大量的语料进行模型训练，因此这些方法都不适用于构建大规模的 Knowledge Base。 [13] Guodong Z, Jian S, Jie Z, et al. ExploringVarious Knowledge in relation Extraction.[c]// acl2005, Meeting of the Association for ComputationalLinguistics, Proceedings of the Conference, 25-30 June, 2005, University of Michigan, USA. DBLP.2005:419-444. [14] Zelenko D, Aone C, Richardella A. KernelMethods for relation Extraction[J]. the Journal ofMachine Learning Research, 2003, 1083-1106. [15] Hendrickx I, Kim S N, Kozareva Z, et al.semEval-2010 task 8: Multi-way classification ofsemantic relations between Pairs of nominals[c]//the Workshop on semantic Evaluations: recentachievements and Future Directions. association forComputational Linguistics, 2009:94-99. [16] Hashimoto K, Stenetorp P, Miwa M, et al. Task-oriented learning of Word Embeddings for semanticRelation Classification[J], Computer Science,2015:268-278. [17] Singh S, Riedel S, Martin B, et al. JointInference of Entities, Relations, and Coreference[C]//the Workshop on automated Knowledge baseConstruction ,San Francisco, CA, USA, October27-november 1. 2013:1-6. [18] Miwa M, Sasaki Y. Modeling Joint Entity andrelation Extraction with table representation[c]//conference on Empirical Methods in naturalLanguage Processing. 2014:944-948. [19] Lu W, Dan R. Joint Mention Extraction andclassification with Mention Hypergraphs[c]//conference on Empirical Methods in naturallanguage Processing. 2015:857-867. [20] Li Q, Ji H. Incremental Joint Extraction of EntityMentions and relations[c]// annual Meeting of theAssociation for Computational Linguistics. 2014:402-412. [21] Kate R J, Mooney R J. Joint Entity andrelation Extraction using card-pyramid Parsing[c]//conference on computational natural languagelearning. 2010:203-212. [22] Miwa M, Bansal M. End-to-End Relation Extraction using lstMs on sequences and tree structures[c]// annual Meeting of the association for computational linguistics. 2016:1105-1116. 分类器非常传统的监督学习思路 12345678- 选择我们想提取的关系集合- 选择相关的命名实体集合- 寻找并标注数据 选择有代表性的语料库 标记命名实体 人工标注实体间的关系 分成训练、开发、测试集- 训练分类器 为了提高 efficiency，通常我们会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用 task-specific feature-set。 可以采用的分类器有 MaxEnt Naive Bayes SVM … 特征E.g., American Airlines, a unit of AMR, immediately matched the move, spokesman Tim Wagner saidMention 1: American AirlinesMention 2: Tim Wagner Word features Headwords of M1 and M2, and combination M1: Airlines, M2: Wagner, Combination: Airlines-Wagner Bag of words and bigrams in M1 and M2 {American, Airlines, Tim, Wagner, American Airlines, Tim Wagner} Words or bigrams in particular positions left and right of M1/M2 M2: -1 spokesman M2: +1 said Bag of words or bigrams between the two entities {a, AMR, of, immediately, matched, move, spokesman, the, unit} Named Entities Type and Mention Level Features Named-entities typesM1: ORGM2: PERSON Concatenation of the two named-entities typesORG-PERSON Entity Level of M1 and M2 (NAME, NOMINAL, PRONOUN)M1: NAME [it or he would be PRONOUN]M2: NAME [the company would be NOMINAL] Parse Features Base syntactic chunk sequence from one to the otherNP NP PP VP NP NP Constituent path through the tree from one to the otherNP ↑ NP ↑ S ↑ S ↓ NP Dependency pathAirlines matched Wagner said Gazetteer and trigger word features Trigger list for family: kinship termsparent, wife, husband, grandparent, etc. [from WordNet] Gazetteer:List of useful geo or geopolitical words Country name list Other sub-entities Evaluation最常用的 Precision, Recall, F1 小结如果测试集和训练集很相似，那么监督学习的准确率会很高，然而，它对不同 genre 的泛化能力有限，模型比较脆弱，另一方面，获取这么大的训练集代价也是昂贵的。 Semi-supervised realation extractionSeed-based or bootstrapping approaches半监督学习主要是利用少量的标注信息进行学习，这方面的工作主要是基于 Bootstrap 的方法。基于 Bootstrap 的方法主要是利用少量的实例作为初始种子(seed tuples)的集合，然后利用 pattern 学习方法进行学习，通过不断的迭代，从非结构化数据中抽取实例，然后从新学到的实例中学习新的 pattern 并扩充 pattern 集合。 漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025 Brin[23]等人通过少量的实例学习种子模板，从网络上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，其主要贡献是构建了 DIPRE 系统；Agichtein[24]在 Brin 的基础上对新抽取的实例进行可信度的评分和完善关系描述的模式，设计实现了 Snowball 抽取系统；此后的一些系统都沿着 Bootstrap 的方法，但会加入更合理的对 pattern 描述、更加合理的限制条件和评分策略，或者基于先前系统抽取结果上构建大规模 pattern；如 NELL（Never-EndingLanguage Learner）系统[25-26]，NELL 初始化一个本体和种子 pattern，从大规模的 Web 文本中学习，通过对学习到的内容进行打分来提高准确率，目前已经获得了 280 万个事实。 [23] brin s. Extracting Patterns and relations fromthe World Wide Web[J]. lecture notes in computerScience, 1998, 1590:172-183. [24] Agichtein E, Gravano L. Snowball : Extractingrelations from large Plain-text collections[c]// acMConference on Digital Libraries. ACM, 2000:85-94. [25] Carlson A, Betteridge J, Kisiel B, et al. Toward anarchitecture for never-Ending language learning.[c]// twenty-Fourth aaai conference on artificialIntelligence, AAAI 2010, Atlanta, Georgia, Usa, July.DBLP, 2010:529-573. [26] Mitchell T, Fredkin E. Never-ending Languagelearning[M]// never-Ending language learning.Alphascript Publishing, 2014. Relation Bootstrapping 12345• Gather a set of seed pairs that have relation R• Iterate:1. Find sentences with these pairs2. Look at the context between or around the pair and generalize the context to create patterns3. Use the patterns for grep for more pairs 看一个完整的例子 从 5 对种子开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 $(authoer, book)$ 抽取到了 relation pattern，x, by y, 和 x, one of y’s Snowball对 Dipre 算法的改进。Snowball 也是一种相似的迭代算法，Dipre 的 X,Y 可以是任何字符串，而 Snowball 要求 X,Y 必须是命名实体，并且 Snowball 对每个 pattern 计算了 confidence value 123456Group instances w/similar prefix, middle, suffix, extract patterns • But require that X and Y be named entites • And compute a confidence for each pattern.69 ORGANIZATION &#123;&apos;s, in, headquaters&#125; LOCATION.75 LOCATION &#123;in, based&#125; ORGANIZATION Distant SupervisionDistant Supervision 其实结合了 bootstrapping 和监督学习的长处，它使用一个大的数据库来得到海量的 seed example，然后从这些 example 中创建许多的 feature，最后与有监督的分类器相结合。 与监督学习相似的是这种方法用许多的 feature 训练了一个分类器，通过详细的人工创造的知识进行监督，不需要用迭代的方法来扩充 pattern。 与无监督学习相似的是这种方法采用了大量没有标注的数据，对训练语料库中的 genre 并不敏感，适合泛化。 ​ Unsupervised relation extraction Bollegala[27]从搜索引擎摘要中获取和聚合抽取模板，将模板聚类后发现由实体对代表的隐含语义关系; Bollegala[28]使用联合聚类(Co-clustering)算法，利用关系实例和关系模板的对偶性，提高了关系模板聚类效果，同时使用 L1 正则化 Logistics 回归模型，在关系模板聚类结果中筛选出代表性的抽取模板，使得关系抽取在准确率和召回率上都有所提高。 无监督学习一般利用语料中存在的大量冗余信息做聚类，在聚类结果的基础上给定关系，但由于聚类方法本身就存在难以描述关系和低频实例召回率低的问题，因此无监督学习一般难以得很好的抽取效果。 [27] Bollegala D T, Matsuo Y, Ishizuka M. Measuringthe similarity between implicit semantic relationsfrom the Web[J]. Www Madrid! track semantic/dataWeb, 2009:651-660. [28] Bollegala D T, Matsuo Y, Ishizuka M. RelationalDuality: Unsupervised Extraction of semantic relations between Entities on the Web[c]//International Conference on World Wide Web, WWW 2010, Raleigh, North Carolina, Usa, April. DBLP, 2010:151-160. ​Open Information Extraction 从网络中抽取关系，没有训练数据，没有关系列表。过程如下：12345671. Use parsed data to train a “trustworthy tuple” classifier2. Single-pass extract all relations between NPs, keep if trustworthy3. Assessor ranks relations based on text redundancyE.g.,(FCI, specializes in, sobware development)(Tesla, invented, coil transformer) Evaluation of Semi-supervised and Unsupervised Relation Extraction因为抽取的是新的关系，并不能准确的计算 precision 和 recall。然而我们可以估计，从结果集中随机抽取一个关系的 sample，然后人工来检验准确率 ​ $$\\hat P = {\\text {Number of correctly extracted relations in the sample} \\over \\text {Total number of extracted relations in the sample}}$$ 也可以计算不同 recall level 上的 precision，比如说分别计算在前 1000，10,000，100,000 个新的关系中的 precision，在各个情况下随机取样。 然而，并没有方法来计算 recall。","tags":"nlp relation-extraction information-extraction"},{"title":"NLP 笔记 - Knowledge Representation","url":"/2017/04/07/NLP 笔记 - Knowledge Representation/","text":"作为 NLP 笔记 - Meaning Representation Languages 这一篇的补充，简单介绍了事件(event)，时间(time)，信念(beliefs) 的意义表示。 Knowledge Representation OntologiesMammal includes Cat,Dog,WhaleCat includes PersianCat, ManxCat Categories and ObjectCategories: Cat; Object: Martin the catCategories is a set of object, object is part of categories Events Times Beliefs ​一些常见关系，ISA, AKO, HASA ISA relationis a ISA(Martin,Cat) AKO relationa kind of AKO(PersianCat,Cat) HASA relationhas a HASA(Cat, tail) Categories and Subsumption范畴(Category)表示的是一种所属关系(ISA)，一个范畴的所有成员共享一套相关的特征，表示范畴的最普通方法是为每个范畴造出一个一元的谓词，这样的谓词可以对每个有关范畴进行说明。如12Maharani is an Indian restaurant.IndianRestaurant(Maharani) 左边的项是 category，括号里是 domain element。 Subsumption 表示的是一种包含关系(AKO)，如12All Indian restaurants are restaurants.IndianRestaurant ⊑ Restaurant 注意的是，IndianRestaurant(Maharani) 这种方法里范畴表示的是关系，而不是实实在在的客体，只能对构成关系的各个成分有所说明，而很难对于范畴本身有所说明，比如我们想表达1MostPopular(Maharani, VegetarianRestaurant) 这就不是一个合格的 FOPC 公式，因为 predicate 必须是 term，而不能是其他的 predicate。解决这个问题的方法是“具体化”(reification)，把我们想表述的所有概念都表示为实实在在的客体，这样就可以把 VegetarianRestaurant 这个范畴表示为诸如 Maharani 这样的客体啦，如12ISA(Maharani, IndianRestaurant)AKO(IndianRestaurant, Restaurant) Representing Events事件(event) 表示包括一个单独的谓词(predicate)以及与给定的例子想联系的角色所需的多个论元(argument)。以下面四个句子为例，动词 eat 这样的 predicate 的 argument 个数是可变的，然而这些例子都表示同一类事件 1234- Martin ate- Martin ate in the morning- Martin ate fish- Martin ate fish in the morning 用 FOL 来表达，第一种方式是为动词所允许的每种 argument 格式建立一个次范畴化框架(subcategorization)，也就是为 eating 建立不同的谓词，来处理 eat 的各种可能的行为方式，这样就会比了 eating 究竟有多少个 argument 的问题，然而这种方法代价太高了1234- Eating1(Martin)- Eating2(Martin, Morning)- Eating3(Martin, Fish)- Eating4(Martin, Fish, Morning) 可以看到，事件之间在逻辑上存在着明显的关系，如如果 4 为真，3,2,1 也为真，然而这种方法并不能提供这些关系，一种解决方法是使用 意义假设(meaning postulate)，把谓词中的不同语义联系在一起123- ∀x,y,z Eating4(x,y,z) =&gt; Eating3(x,y)- ∀x,y,z Eating4(x,y,z) =&gt; Eating2(x,z)- ∀x,y,z Eating4(x,y,z) =&gt; Eating1(x) 很明显，这种方法负担太重，存在 scalability 的问题，也不适合处理个性化的事件。 第二种方式是只用一个框架来定义所有可能出现的 arguments，这种方法假定谓词的 argument 数目与该谓词在它的次范畴化框架中所表现出来的 argument 数目是相同的，然而在实际应用中，我们很难确定一个给定时间的正确角色数目12Eating4(x,y,z) with some arguments unspecified 造成的问题是 Too many commitments Hard to combine Eating4(Martin, Fish, z) with Eating4(Martin,y,Morning) 第三种方式 Reification(具体化)，使事件成为能够量词化的客体，并且能够通过定义好的关系与其它客体联系起来，如1∃ e: ISA(e, Eating) ∧ Eater(e, Martin) ∧ Eaten(e,Fish) 表示存在一个吃饭的事件，Martin 是这个事件的行为者，Fish 是被吃的东西，这样的表示方法不需要说明量词的确定数目，无论出现多少角色和填充项都可以结合到谓词中，也不需要对角色进行意义假设。 Representing Time很多句子包含了时间的信息，上面的语义表达并没有讨论时间表示的问题，这里介绍下时间表达的基本概念12345678- Martin went from the kitchen to the yard- ISA(e,Going) ∧ Goer(e, Martin) ∧ Origin(e,kitchen) ∧ Target(e,yard)Issue- no tense information: past? present? future?Fluents- A predicate that is true at a given time: T(f,t) 我们可以增加时间变量事件的时间段(e.g., IntervalOf(w,i))、事件的终点(e.g., EndPoint(i,e))以及由动词时态(e.g., Precedes(e,Now))来说明关于这个终点到当前时间的时间谓词，然而简单动词的关系并不是直截了当的，现在时可以用于说明将来事件，将来时也可以用于说明一个过去事件，为了处理这种现象，Reichenbach(1947)提出了参照点(reference point)的概念，如下 E: event, R: reference, U: utterance 下面的例子中，departed 这个事件就是参照点(reference time)，吃饭事件在参照点之前1When Mary&apos;s flight departed, I had eaten lunch. Representing Beliefs有一些单词和词语的意义表示包含的逻辑公式并不一定在现实世界中真实存在，而是某个假设世界中的东西，这些单词具有“创造世界的能力”，如 believe, want, imagine, know 等。 12345Example- Milo believes that Martin ate fishOne possible representation- ∃ e,b: ISA(e,Eating) ∧ Eater(e,Martin) ∧ Eaten(e,Fish) ∧ ISA(b,Believing) ∧ Believer(b,Milo) ∧ Believed(b,e) 然而这种表示中，所有的连接部分都必须为真，这导致的结果是 “Martin ate fish”，漏掉了信念这个事件，然而，Speaker 的信念并不能使这个命题在现实世界中成为真命题。处理这种情况的标准方法是使用 operator 来增强 FOPC，我们可以引入一个称为 Believes 的 operator，取两个 FOPC 公式作为它的 argument，一个公式指派一个 believer，另一个公式指派所相信的命题，如1Believes(Milo, ∃ e: ISA(e,Eating) ∧ Eater(e,Martin) ∧ Eaten(e,Fish)) Believes 这样的 operator 又称为 模态算符(modal operator)，相应地，用 modal operator 来增强的逻辑，称为 模态逻辑(modal logic) Other conceptsTBox and ABoxTBox包含了应用领域关于类别或概念的知识，如12All bistros are restaurantsAll restaurants are businesses ABox包含了领域里关于个体的事实，如1India Garden is an Indian restaurant Negation and DisjuncitonNegation12IndianRestaurant ⊑ not ItalianRestaurantIndian restaurants can’t also be Italian restaurants. Disjunciton12Restaurant ⊑ (or ItalianRestaurant IndianRestaurant MexicanRestaurant)Restaurants are Italian restaurants, Indian restaurants, or Mexican restaurant.","tags":"nlp semantic-analysis 语义分析"},{"title":"NLP 笔记 - Meaning Representation Languages","url":"/2017/04/07/NLP 笔记 - Meaning Representation Languages/","text":"CMU 11611 的课程笔记。主要是关于意义表示的一些理论性知识，重点掌握一阶谓词演算(First Order Predicate Calculus) Semantics Road Map Lexical semantics Vector semantics Meaning representation languages and semantic roles Compositional semantics, semantic parsing Discourse and pragmatics 语义分析常用的知识源 词本身的意义• Word-sense identifier, like bass7• Morphological info• Grammatical info (POS, etc.)• Phonetic info, if speech system• Semantic info• Comments, etc. 语法结构所带的意义 话语的结构知识 发生话语的上下文知识以及与话题相关的常识 ​这一篇讲 meaning representation，它常见的应用场景有： 在考试中回答文章问题 具有背景知识，如关于问题主题的背景知识、关于学生知识水平的背景知识以及关于如何正常回答(answered normally)这些问题的背景知识 在饭店里阅读菜单点菜 阅读菜单、点什么菜、到哪里吃饭、根据菜谱做菜、编写新的菜谱等等这些都要求对食品有深入的知识，知道怎样做菜，知道人们喜欢吃什么以及喜欢到什么饭店等 通过阅读说明书学习使用新软件 要求对当前计算机、有关软件及使用有深入知识，对用户有一般知识 注意的是这一篇的重点是表示句子的字面意义(literal meaning)，关注的是与单词的常规意义紧密联系的表示，而不反映它们出现的上下文环境，这种表示在涉及到俗语(idioms)和比喻(metaphor)时会显得不足。 Desirable qualities探讨 Meaning representation 的最基本要求。 Verifiability我们需要确定 meaning representation 的真实性，最直接的办法就是把 representation 和知识库(knowledge base)的表示相比较或匹配。比如下面这个句子 1Does Hello Bistro serve vegetarian food? 假定这个问题包含了 Maharani serves vegetarian food 的意义，将其简单注释为 Serves(Maharani, VegetarianFood)，那么我们就要看这个输入的 representation 是否能和关于饭店(restaurant)的事实知识库(knowledge base of facts)相匹配，返回结果如下 If 在知识库中找到一个表示与之匹配 -&gt; 返回一个肯定回答 Elif 知识库是完全的 -&gt; 返回否定 Else -&gt; 返回不知道 这个概念就是 可能性验证(verifiability)，也就是系统把意义表示所描述的情况与在知识库中所模拟的某个世界的情况进行比较的一种能力。 Unambiguous Representation无歧义表示(Unambiguous Representation) 要求最终的 meaning representation 只能有一个无歧义的表示，如下面的例子，我们只能准确的捕捉其中一种意义，而不能同时表示两种。有一些方法可以来决定某种解释比另外的解释更优先(或者更不优先)，这一篇暂且不讨论这类技术。 Canonical Form规范形式(Canonical Form)要求的是表达相同事情的输入必须有相同的意义表示(input that mean the same thing should have the same meaning representation)。 比如下面四句话 1234• “Mad Mex has vegetarian dishes.”• “They have vegetarian food at Mad Mex.”• “Vegetarian dishes are served at Mad Mex.”• “Mad Mex serves vegetarian fare.” 系统必须把 vegetarian dishes, vegetarian food, vegetarian fare 归入在这种上下文环境中的同一个事物，同时，这里 have 和 serve 的用法也是等价的，我们希望 meaning representation 能做到这一点。有一种思路是，查下字典，会发现这些单词都具有许多不同词义(word sense)，同时也可以看出，至少有一个意义是这些单词都共享的(可能是同义词synonymous)，如果有能力从不同用法中筛选出这个共享的意义，就可以把同样的意义表示指派给不同的单词/短语。 Inference, Variables, and Expressiveness推论(Inference)说明了系统根据输入的意义表示以及存储的背景知识做出可靠结论的能力。 看下面两个例子，对第一个问句而言，基于规范形式的方法和简单的匹配不能使系统对这个问题做出合适回答，我们需要把这个问题的意义表示和在知识库中表示的事实联系起来。 12• “Can vegetarians eat at Mad Mex?”• “I’d like to find a restaurant where I can get vegetarian food.” 对于第二个句子而言，它并没有对任何特定的饭店进行推论，用户想要的是关于某个出售素食的饭店的信息，并没有提到特定的饭店，所以也不能进行简单匹配，需要引入 variable 来注释这句话，变成 $$Serves(x, VegetarianFood)$$ 只有当 x 能够被知识库中某个已知的课题来替换，使整个命题得到匹配时，我们才可以说这个命题被成功匹配了，匹配完成后才可以用来实现用户的提问。 最后，意义表示方法应该具有足够的表达能力(expressiveness)，最理想的情况当然是只用一个单独的意义表示语言(meaning representation language)就可以恰当表达任何自然语言的意义。当然这个期望可能太高了，下面会讲到一般的 一阶谓词演算(FOL)就具有足够的表达能力来处理多数问题。 Structure下图说明了 I have a car 这个句子使用的四种常见的意义表示语言，第一行是 一阶谓词演算(First Order Predicate Calculus)，中间部分是一个语义网络(Semantic Network)，第三行包含一个概念依存(Conceptual Dependency)的图示和一个基于框架的表示(Frame-Based) 尽管四种方式各有差别，但是都表达了下面三个特征： 实体(Objects) e.g., people, restaurants, cuisines 实体性质(Properties of objects) e.g., pickiness, noisiness, spiciness 实体之间的关系(Relations between objects) e.g., serves(Oishii Bento, Japanese) First Order Predicate CalculusFOL(First Order Logic)可以用来表示 Objects, Relations, Functions ObjectsMartin the cat RelationsMartin and Moses are brothers FunctionsMartin’s age 上图是一个用于说明 EOPC 表示句法的一个上下文无关语法。逐个来看一下。 Term先来看一下项(term)这个概念，项是 EOPC 表示客体的一种设置，包含三个信息块，常量(constant)、函数(function)和变量(variable)，常量引用所描述的世界中的特定客体，函数在英语中经常表示为所属格(genitive)的概念，如 location of Maharani 或 Maharani’s location，翻译成 EOPC 可以表示为 LocationOf(Maharani)，函数在局上上相当于一个单独的 argument predicate，但尽管外表上它很像 predicate，而实际上只涉及一个单独客体的“项”，这样的好处是，用函数来引用客体时，不用与命名它的常量相联系，当存在像饭店这样的很多命名客体时，如果使用函数，只需要像一个 location 这样的函数就可以与各种名字的饭店联系起来。变量之前提到过，就是方便我们对客体做出判断，进行推论，而不必参照任何特定命名客体。 Quantifier另外，引用特定的匿名客体，以及一般性的引用在一个集合中的全部客体，都可以通过 量词(quantifier)来实现，存在量词(existential quantifier, ∃)，读作 there exists，全称量词(universal quantifier, ∀)，读作 for all。看一下解释 Predicates再看一下 predicates，predicates 是一种符号，用于引用名称以及在给定领域内的一定数量的客体之间的关系，如 12Serves(UnionGrill, AmericanFood)Restaurant(UnionGrill) 第一个表示的意思是，serve 是具有两个位置的 predicate，由常量 Maharani 和 VegetarianFood 标出的客体之间的关系，第二个表示略有不同，原句是 Maharani is a restaurant，predicate 只有一个位置，不涉及多个客体，只是确认一个单独客体的某个性质，这种情况下，predicate 对 Maharani 的范畴所属关系进行编码。 ConnectivesAnyway，有了引用客体的能力(refer to objects)、确认关于客体事实的能力(assert facts about objects)、把一些客体与另外的客体相互联系的能力(relate objects to one another)，就能够构造出初步的组合表示。而更大的组合表示需要逻辑连词(logical connective)把不同的意义表示结合到一起。如下 123Have(Speaker, FiveDollars) ∧ ¬ Have(Speaker, LotOfTime)∀x Person(x) ⇒ Have(x, FiveDollars)∃x,y Person(x) ∧ Restaurant(y) ∧ ¬HasVisited(x,y) 常用的连接词和解释 常见的两个错误： =&gt; 是 ∀ 的主要连词，∧ 和 ∀ 搭配往往会出错，如我们要表达 All cats eat fish， 123456Wrong:∀x Cat(x) ∧ EatsFish(x)Everyone is a cat and everyone eats fish.Correct:∀x Cat(x) =&gt; EatsFish(x) 当然也有例外，如下面这句 ∧ 和 ∀ 搭配，就是对的​ ∀x Person(x) ∧ Know(I, x) =&gt; Smartness(x) &lt; Smartness(Max)​ Max is the smartest person I know. ∧ 是 ∃ 的主要连词，=&gt; 和 ∃ 搭配往往会出错，如我们要表达 There’s a cat that eats fish. 123456Wrong:∃x Cat(x) =&gt; EatsFish(x)is true if anyone who is not a cat (if leftside is False, then anything can go into right side)Correct:∃x Cat(x) ∧ EatsFish(x) ​ Example具体来个例子，下面这个句子 1Ay Caramba is near ICSI. 通过辨认与句子中的各种语法成分对应的 term 和 predicate，并构造逻辑公式，可以得到下面的结果 1Near(LocationOf(AyCaramba),LocationOf(ICSI)) 这个公式的意义是根据 LocationOf(AyCaramba) 和 LocationOf(ICSI) 两项之间的关系、谓词 near 以及它们所模拟的世界中相应的客体和关系等而获得。这个句子可以根据在显示世界中 Ay Caramba 是不是真的和 ICSI 相近而被指派 True 或者 False 值。 两道题 第 1 题答案 DJBAE，第 2 题答案 ECDAH Lambda Expressionlambda 符号(Church, 1940)提供了形式化参数的功能，对 FOPC 进行了扩充，它引入了下面的表达式： $$\\lambda x P(x)$$ $x$是变量，$P(x)$是使用这些变量的 FOPC 表达式。lambda表达式的意义在于可以生成新的 FOPC 表达式，在这些新的表达式中，形参变量由指定项来绑定，也就是 lambda 变量由指定的 FOPC 项来进行简单的字面替换，去掉 lambda，这个过程也就是 lambda 化简($\\lambda$ -reduction)，如下面将 lambda 表达式用于常量 A，对表达式进行化简 $$\\lambda x P(x)(A)$$ $$P(A)$$ lambda符号提供了动词语义中需要的两种能力：形参表使我们获得变量集，lambda化简实现用项来替换变量的处理。 最简单的例子来理解：if $inc(x) = \\lambda x \\ x+1$then $inc(4) = (\\lambda x \\ x+1)(4)=5$ if $add(x,y) = \\lambda x, \\lambda y(x+y)$then $add(3,4) = (\\lambda x,\\lambda y(x+y))(3)(4)=(\\lambda y 3+y)(4)=3+4=7$ Semantics of FOLFOL 句子可以被赋 true/false 值，如下1234Eg.Milo is younger than Martin&lt;(AgeOf(Milo),AgeOf(Martin))=true=(AgeOf(Milo),AgeOf(Martin))=false 一些补充见 NLP 笔记 - Knowledge Representation InferenceModus Ponens取式推理(Modus Ponens)相当于非形式化的 if-then 推理，比如说 $\\alpha$ 和 $\\beta$ 都是 EOPC 的公式，那么，可以把取式推理定义如下： 我们把 implication rule 的左边的项作为 前提(antecedent)，右边的项作为 结论(consequent)，如果前提在知识库中出现，那么就可以推论出结论。举个例子 公式 VegetarianRestaurant(Rudys) 与前提相匹配，就可以用取式推理，得出 Serves(Rudys, VegetarianFood) 这个结论。 取式推理有两种应用方式，向前链接(Forward Chaining)和向后链接(Backward Chaining)，向前链接就是刚才所描述的方法，优点是有关事实必须在知识库中表现出来，因为在向前链接中所有的推论都必须实现进行，这样可以充分减少回答下一个问题所需时间，因为这时只需要进行简单查询，而缺点是，所引用或存储的事实可能是以后永远都用不上的。产生式系统(production system)大量使用认知模型的研究成果，通过增加控制知识的方法来决定所要激发的规则，从而提升了向前链接系统。 Forward chaining as individual facts are added to the database, all derived inferences are generatedBackward chaining starts from queries, e.g., the Prolog programming language 关于向后链接(Backward Chaining)，第一步是根据提问是否存储在知识库来判定提问公式是否为真，如果提问不在知识库中，下一步就搜索在知识库中有没有可以应用的 implication rule，如果一条规则的结果部分与提问公式相匹配，那么这条规则就是可应用的规则。如果存在任意这样的规则，并且规则的前提为真，那么提问就被证明了。然后把前提作为一个新的提问，就可以递归向后链接。还是以上面的例子为例，我们首先看 Serves(Rudys, VegetarianFood)在不在知识库中，发现它不在，就开始搜索一个可应用的规则可以让我们得到横线上面给定的规则。也就是用常量替换 x 后，证明 VegetarianRestaurant(Rudys)。Prolog就是一个向后链接的语言。如下面的例子，知识库中存在前 5 条知识，我们要证明最后一条 ?- father(M, bill) 是否为真，首先找到第一条，知道我们需要 parent(M, bill), male(M)，才能证明 father(M, bill) 为真，然后发现，parent(john, bill) + male(john)，即 M=john 时，father(M, bill) 为真，得证。 123456father(X,Y): -parent(X, Y), male(X).parent(john, bill)parent(jane, bill)female(jane)male(john)?- father(M, bill) 这里要注意的一个概念是向后链接(Backward Chaining) vs. 向后推理(Backward Inference) 向后链接是从提问到已知事实的推理 可靠的推理方法 向后推理是从已知结果到未知前提的推理 不可靠的推理方法 如果一个规则的结果为真，就假定其前提也为真 如果知道 Serves(Rudys, VegetarianFood) 为真，那么VegetarianRestaurant(Rudys)也为真 一些原则Universal Instantiation Existential Instantiation Unification Description Logics除了 FOPC 外，常用的意义表示方法还有语义网络(Semantic network)、框架(frame)方法。其中框架方法又叫做槽填充(slot-filter)表示法，特征称为槽(slot)，而这些槽的值用填充者(filter)来表示。这种表示方法比FOL的限制性更强。 ​","tags":"nlp semantic-analysis 语义分析 fol fopc"},{"title":"QA system - Question Generation","url":"/2017/04/06/QA system - Question Generation/","text":"关于如何从给定文本中产生合适的问句。–持续更新中– 做了一段时间的 Asking System，尝试了各种包，也踩了很多的坑，从全无头绪到现在小有心得，中间经历了很多，这里做一些记录。 总的思路是找出简单的陈述句，然后对其进行变形(如下)。 12X is Y =&gt; Is X Y? / What is Y? (what/why/who/when)The X verbs Y =&gt; Does X verb Y / What does the X verb? 第一大问题是怎么找候选陈述句，过于复杂的句子我们需要进行简化，我们要找的句型是 S &lt; (NP $.. VP)，然而就是这样的 NP VP 下接的诸多介词短语或从句也够我们烦恼的了，定义更加限制性的规则还是很有必要的。另外非常适合用来产生问题的句子结构还有 同位语结构，动词修饰名词结构等等，下文会提到。 找出的这些候选陈述句应当提前做好 指代消解，方便进一步处理。 无论是对一般疑问句还是特殊疑问句，关键的都是找 谓词(predicate)。 对于一般疑问句而言，如果 predicate 是 auxiliary verb 或者 modal，比如 is, was, are, did, have, etc.，那么直接将 predicate 提前，其余部分按原顺序拼接，而 predicate 不是 auxiliary verb 也不是 modal，那么可能需要将动词还原成 do+动词原形的形式，然后将助动词提前，其余照抄(此时句子中的动词已经还原)。 而对特殊疑问句而言，需要利用 NER 来确定对哪个词进行提问以及用哪种疑问词，NER 的质量在这种场景下显得尤其重要。在实践过程中发现部分的 NER 对时间和地点的识别能力不是很强，这时候可能需要人工规则来进行补充，比如给介词短语添加限制来确定地点等。特殊疑问句另一个问题是一些不可能作为 answer phrase 的词，在下文的 Marking Unmovable Phrases 中也会提到，最为简单粗暴的方法是在 what/who 的问句中只对直接宾语来进行提问。 最后，关于问句的泛化，可以利用 WordNet 来替换一些关键词。 顺便提一下句子类型，在论文里经常会出现 declarative sentence 这类专有名词，这里稍稍解释翻译下。 Declarative Sentences 陈述句，陈述一个事实，以句号结尾，是最常见的类型 e.g. There are five million people at risk. Imperative Sentence 祈使句，以感叹号或者句号结尾 e.g. Fetch my umbrella!/Please bring my umbrella. Interrogative Sentence 疑问句，以问号结尾 e.g. Can you find my umbrella? Exclamatory Sentence 感叹句，表达兴奋或者其他情感，感叹号结尾 e.g. You’ve broken my umbrella! 在 QG 系统中，我们需要的是 Declarative Sentences QG Framework问句如何产生？一般是从文章中提取出合适的可以产生问句的 candidate，然后对其进行变形来得到。很多有用的问题可以被看做是把一个陈述句通过 词汇(lexical)、句法(syntactic)、语义(semantic) 层面的转化得到的。因此，在产生问句的阶段，我们需要把原有的句子转化为陈述句。 看一下 question generation 的框架。 Stage 1，通过改变词汇来将原有语句转化为陈述句。有些句子很复杂，有些句子我们只需要某些成分，所以可以通过一些方法将原有的句子化简，形成能够产生问句的陈述句。在这个阶段，很多 NLP transformation 的方法都会被用到，包括 extractive summarization, sentence compression, sentence splitting, sentence fusion, paraphrase, textual entailment, lexical semantics for word substitution 等。 Stage 2，通过进行一些句法层面的转化(如 WH-movement, subject-auxiliary inversion 等)将陈述句转换为问句，这个模块又叫 question transducer。 Stage 3，对上一阶段产生的问题进行排序，特征可以是 source sentence, input sentences, question, transformation 各部分的特征集合。 明确一些概念： source sentence 输入文档中的原始句子 input sentence question transducer 的输入，可能是原始句子也可能是经过转化的陈述句 answer phrase 陈述句里可能被作为问句成分的目标词(targets for WH-movement) question phrase 替代 answer phrase 的疑问词 Stage 1Introduction输入： 原始文本输出： 陈述句 过于复杂的句子往往会导致不自然或者没有意义的问句，因此我们首先需要进行预处理以便简化 transformation。可以做的比如移除一些短语类型，像是句子开始的连词，句子层次的修饰语等，在论文 headline generation (Dorr and Zajic, 2003) and summarization (Toutanova et al., 2007) 中有具体介绍。一些规则如下 Practice实际项目中为了得到更快的速度，我们大大简化了这一流程，首先，忽略所有过长的句子(&gt;=50个单词)，其次，只选择 同位语(APPOSITION)、动词修饰短语(VERB_MODIFIER)、名词动词结构的短语(NP_VP) 三种类型的句子成分作为产生问句的 candidate。 规则123NP_VP = &quot;S &lt; (NP=np ?$PP=pp1 $.. (VP=vp &lt; (/VB.?/=tensed ?$.. SBAR=reason)))&quot;APPOSITION = &quot;NP !&lt; CC !&lt; CONJP &lt; (NP=np1 $.. (/,/ $.. (NP=app $.. /,/)))&quot;VERB_MODIFIER = &quot;NP=noun &gt; NP $.. VP=modifier&quot; 操作这些规则还是用 tregex，由于是 python，选择 Stanford coreNLP，具体见 ParseTree操作若干-Tregex and Stanford CoreNLP。 对标注好的部分进行重组，形成规范化的简单句子。以 NP_VP 规则为例，就是形成 NP + VP + PP1的句子。 Stage 2输入： 上一步产生的陈述句输出： 一个问句集合 先来看一下流程图，下图描述了如何从给定文本产生一个问句，带*的表示特殊疑问句必须的步骤，一般疑问句不需要。 answer type 可以是名词短语或者是介词短语，能够产生 who, what, where, when, how much 这类的问句。系统可以进行扩展来产生其他的类似 how, why, what kind of 这类的问句。 一个句子可能存在多个可能的 answer phrase，而一个 answer phrase 可能产生多个 question phrase，举个例子 12345678Declarative sentence:Francium was discovered by Marguerite Perey in France in 1939Possible questions:• Where was francium discovered by Marguerite Perey in 1939?• When was francium discovered by Marguerite Perey in France?• Was francium discovered by Marguerite Perey in France in 1939?• By what was francium discovered in France in 1939? 当然，最后一个句子是一个错误，Marguerite Perey 应该是个人。Question transducer 会 overgenerate 很多不相关、不重要的问句。这一阶段会用到的技术： mark phrases that cannot be answer phrases, due, for example, to island constraints; remove each answer phrase and generate possible question phrases for it; decompose the main verb; invert the subject and auxiliary verb; insert one of the question phrases 一个完整的例子 Marking Unmovable Phrasesinput tree 中有些短语由于 WH-movement 的限制，是不可能作为 answer phrases 的，所以我们可以预先把这些成分用 UNMV- 标记给替换掉，这部分的操作可以是并行的，因为它们的顺序不重要。当然这里有两条规则是例外的，它们用在限制 input tree 的下一步传播，适用于所有其他规则，第一条规则把 UNMV- 节点下的所有节点都标记为 UNMV-。第二条规则把 movable 节点下的所有节点标记为 UNMV-，因为名词短语是可以移动的 islands，名词短语是可以移动的这一事实限制很有用，比如说，在关系从句中的短语是不能移动的，如下面产生的问句是不合理的。 12345Input sentence:I bought the book that inspired Bob.Question:Who did I buy the book that inspired? 具体规则如下： Generating Possible Question Phrasestransducer 查看所有可能的 answer phrase，对每一个可能，复制 input tree，移除 answer phrase，产生可能的 question phrase(这个过程在 yes-no 问句中省略)。 给定一个 answer phrase，question phrase 包含一个 question word(e.g., who,what,where,when)，也可能是个介词短语如 whose car，跟着 answer phrase 的 head。 对一个给定的 answer phrase，系统使用这个短语的 entity label 和句法结构来产生一系列可能的 question phrase，每一个都用来产生最后的问句。下图描述了产生 question phrase 的一些限制。 Practice实践中我们用 spacy 来检测 named entity，主要是因为 spacy 的速度很快， 先对所有 word 进行遍历，找到 PRP 或者 NUM，判断是否能形成 whose 以及 how many/how much 的问题，同时记录是否有 named entity，如果有，再来看 named entity 1234if word.tag_.startswith(&apos;PRP&apos;) and is_possessive(word): question_phrase = &apos;whose&apos;if word.pos_.startswith(&apos;NUM&apos;) and word.ent_type_ != &apos;DATE&apos;:: question_phrase = &apos;how many_how much&apos; 之所以要分两步，是因为上面的 whose 和 how many/how much 其实是对单词提问的，而剩下的 who/where/when/how/why 是对短语进行提问的。对于 who/where/when，可以用 named entity 来进行识别。 123456if ne.label_ == &apos;PERSON&apos;: question_phrase = &apos;who&apos;if ne.label_ in [&apos;LOC&apos;,&apos;GPE&apos;]: question_phrase = &apos;where&apos;if ne.label_ in [&apos;DATE&apos;,&apos;TIME&apos;]: question_phrase = &apos;when&apos; 对于 why 和 how，基本是基于规则，如果在 reason 部分有 because, since, as 等表示原因的单词，那么就可以产生 why 的问句，如果在 pp2 部分有 using, by, through, with, via 等表示方式的单词，就可以产生 how 的问句。 值得注意的是，有些数字后面跟的是速度的单位，比如说 km/s, mph 等，这时候问 how many(much) km/s 就有点诡异了，所以可以加个判断，如果量词后面跟这些单词，就产生 how fast 的问句；另外有些数字后面如果跟的是 %，那么就变成 how many percent 这种问句。至于用 how many 还是 how much，就看下一个名词是单数还是复数了(注意如果量词是 one，下一个名词是单数，然而提问方式得变成 how many noun_plural)。 Decomposition of the Main VerbIntroduction为了实现 subject-auxiliary inversion，如果一个 auxiliary verb 或者 modal 没有出现，question transducer 将会把主要的动词还原成 do(合适形态) + 动词原形，然后修改动词短语的树的结构。 如 John saw Mary 会变成 John did see Mary。 如果 auxiliary verb 已经存在了，那么并不需要 decomposition，如 John has seen Mary 会变成 Who has John seen。 下图识别了需要 decompose 的动词 另外，可以通过 WordNet 来 lemmatize each verb first by checking morphological variants，每次从动词的最右边去掉一个字母直到在 WordNet 里找到匹配的单词，这种方法非常适合英文因为大多数动词都可以从 lemma 添加几个字母(如 ed)派生得到，或者从 WordNet 里的 lemma 匹配得到。 Practice这里用到了 patterns.en 的包123456789101112from patterns.en import lemma# check if contains auxiliarydef has_auxiliary(head_verb_tag, verb): if head_verb_tag==&apos;MD&apos; or lemma(verb[0]) in [&apos;be&apos;,&apos;do&apos;,&apos;have&apos;] and len(verb)&gt;1: return True return False# decomposition of verbdef decompose_verb(verb, verb_tag): tense = verb_tense_dict[verb_tag] return conjugate(&apos;do&apos;, tense), lemma(verb) Subject-Auxiliary Inversion这一部分仍然是对句子的操作，目的是把陈述句变成问句。 首先，parse tree 的 “S” 需要被重新标记为“SQ”，表示它是问题的一部分。然后移动 auxiliary 或 copula 移动，使它成为 SQ 节点的第一个 child。然后使用 “SQ” 节点为该句子形成一个新树。在 yes-no questions 的情况下，问题树的根节点将具有 “SQ” 节点作为该树唯一的 child。在 WH-questions 的情况下，根节点具有 “SBARQ” 子节点。然后，该 “SBARQ” 节点具有一个问题短语节点(例如“WHNP”) 以及一个 “SQ” 作为子节点。 在转换成问句后，在这个节点和逗号之前的所有修饰语都会被移动到句子的前面，以便产生更自然的问题，如产生 Following Thomas Jefferson, who was elected the 4th president? 而不是 Who, following Thomas Jefferson, was elected the 4th president? Inserting Question Phrases将每个可能的 question phrase 插入作为 SBARQ 的子节点，如果是一般疑问句，就不用进行这一步了。 Post-processing为了保证正确的 formatting and punctuation。句号要改为问号，输出要 detokenized，移除多余的空格。另外，所有包含了代词(pronouns)的问句都太模糊了(e.g., What does it have as a head of state)，所以可以过滤掉所有有人称代词(personal pronouns)，所属代词(possessive pronouns)，以及只包含了限定词(determiners)的名词短语。 当然，改进的版本是进行指代消解。 Stage 3Discriminative reranker 上图描述了 bad question 出现的一些原因。在产生一大堆可能的问题后，我们要对问句进行排序。论文提到的是用 logistic regression 来定义一个 acceptable probability p(a|q,t) 和 unacceptable probability p(u|q,t) = 1-p(a|q,t)。先训练一个 boolean model ，只要出现上面的任何一种问题，就认为这个问句是 unacceptable 的。接着训练一个 aggregate model，模型如下 $$p(a|q,t)=\\prod^K_{i=1}p_i(a_i|q,t)$$ 其中 i 是影响 acceptable 的各个因素(grammaticality, making sense, vagueness, etc.), K 在这里是 8。 用到的特征如下图，目标函数是 regularized log-likelihood，regularizaiton constant 由 cross-validation 选择产生。用到的训练集有 WIKI-ENG，WIKI-SIMP 和 theWall Street Journal data in the Penn Treebank (Marcus et al., 1993)。实验结果表明，aggregate ranking 在 P@10 上提升了 43.3%，在 P@25 上提升了40%。 Practice实际中我们并没有来训练模型，主要是因为找不到合适的有标注的训练集。我们用了非常简单的几个标准来进行排序。 Complexity看 question 包含了多少个单词划分4 个 bucket [0, 5], [5, 20], [20, 30], [30,…]，如果在 [5,20] 之间，给最高分，在 [0, 5] 或者 [30,…] 间，就给 penalty Difficulty基本假设是一个好的问题应该有一个确定的答案与之相配。理想情况下是看这个问句能不能被回答，以及容不容易被回答。然而这里的答案抽取、问题产生大部分依赖规则，所以也用规则来定义问题难度了，认为 what, why, how 比较难回答， question word 在中间的句子比较难回答，这些规则通过观察部分有标签的数据集得到 Diversity给每种类型的问句设置权重，在结果集里各类问句都按比例出现，保证多样性 Fluency用 ginger server 来检查语法 Yes/No Question举个例子说明 binary question例句1 (包含 auxiliary verb 或者 modal)：1The cat had/MD slept/VBD on the mat. 我们需要做的是将 MD 前置，拼接句子，将句尾符号变为问号，成为答案是 YES 的问句。123=&gt; Had the cat slept on the mat?Yes! 例句2 (不包含 auxiliary verb 或者 modal)：1The cat slept/VBD on the mat. 我们需要做的是 decompose verb，把 slept 变成 did sleep，然后将 did 前置，拼接句子，将句尾符号变为问号，成为答案是 YES 的问句。123=&gt; Did the cat slept on the mat?Yes! 怎么产生答案是 NO 的句子？ 将句子中的 head word 随机替换成同等词性的词。123=&gt; Had the dog slept on the mat?No! WH Question Detect Candidate Sentences and Mark Movable Phrases 1234- Input:In 2008, because Olympics is coming, 5 valuable pandas including Jingjing were born in Beijing, China.- Rule:S &lt; (NP=np ?$PP=pp1 $.. (VP=vp &lt; (/VB.?/=tensed ?$.. SBAR=reason))) Yes-no Questions 1234- Yes Question:Were 5 valuable pandas including Jingjing born in Beijing , China in 2008?- No Question:Were the swallows born in Beijing , China in 2008? Choose Answer Phrases and Generate Question Phrases Decompose Verb 1234Eg.1. In 2008, because Olympics is coming, 5 valuable pandas including Jingjing were born in Beijing, China.were =&gt; wereEg.2. All four allies retained shared responsibility for Berlin.retained =&gt; did retain Invert Subject and Auxiliary and Insert Question Phrase 123456789- Input:5 valuable pandas including Jingjing were born in Beijing, China.- Output:were 5 valuable pandas including jingjing born in Beijing , China in 2008were 5 valuable pandas including jingjing born in Beijing , China in 2008where were 5 valuable pandas including Jingjing born in 2008when were 5 valuable pandas including Jingjing born in Beijing , Chinahow many valuable pandas including Jingjing were born in Beijing , China in 2008what were born in Beijing , China in 2008 Post Processing 123456789- Input:5 valuable pandas including Jingjing were born in Beijing, China.- Output:Where were 5 valuable pandas including Jingjing born in 2008?Were 5 valuable pandas including jingjing born in Beijing , China in 2008?When were 5 valuable pandas including Jingjing born in Beijing , China?How many valuable pandas including Jingjing were born in Beijing , China in 2008?What were born in Beijing , China in 2008?Were 5 valuable pandas including Jingjing born in Beijing , China in 2008? Tools/Packages python==2.7 spaCy==1.7.5 pattern==2.6 textblob==0.12.0 nltk==3.2.2 requests==2.13.0 scipy==0.18.1 sklearn==0.18.1 numpy==1.11.3 stanford-corenlp-full-2016-10-31 历程第一阶段 只寻找 NP VP 结构，用的 pattern 为 S &lt; (NP=np $.. (VP=vp &lt; /VB.?/=tensed)) 主语为代词(PROP)跳过，不做指代消解(速度慢) NER 考虑了 PERSON, LOC, GPE 对每个句子产生 yes/no 问句，包含 NER 的产生对应的 WHAT/WHO/WHERE 问句 原文(PART) Ant Ants are social insects of the family Formicidae ( ), and along with the related wasps and bees, they belong to the order Hymenoptera. Ants evolved from wasp-like ancestors in the mid-Cretaceous period between 110 and 130 million years ago and diversified after the rise of flowering plants. Today, more than 12,500 species are classified with upper estimates of about 22,000 species. They are easily identified by their elbowed antennae and a distinctive node-like structure that forms a slender waist. Ants form colonies that range in size from a few dozen predatory individuals living in small natural cavities to highly organised colonies which may occupy large territories and consist of millions of individuals. These larger colonies consist mostly of sterile wingless females forming castes of “workers”, “soldiers”, or other specialised groups. Nearly all ant colonies also have some fertile males called “drones” and one or more fertile females called “queens”. The colonies are sometimes described as superorganisms because the ants appear to operate as a unified entity, collectively working together to support the colony. 产生问句 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950NP VP(aux) Are ants social insects of the family Formicidae -LRB- -RRB-WHO NP VP Who are antsWHAT NP VP What are antsNP VP(aux) Are more than 12,500 species classified with upper estimates of about 22,000 speciesWHAT NP VP(aux) What are more than 12,500 speciesNP VP(no-aux) Do ants form colonies that range in size from a few dozen predatory individuals living in small natural cavities to highly organised colonies which may occupy large territories and consist of millions of individualsWHAT NP VP(aux) What do ants formNP VP(no-aux) Do these larger colonies consist mostly of sterile wingless females forming castes of `` workers &apos;&apos; , `` soldiers &apos;&apos; , or other specialised groupsWHAT NP VP(aux) What do these larger colonies consistNP VP(no-aux) Did males call `` drones &apos;&apos; and oneWHAT NP VP(aux) What did males callNP VP(aux) Have nearly all ant colonies some fertile males called `` drones &apos;&apos; and one or more fertile females called `` queens &apos;&apos;WHAT NP VP(aux) What did nearly all ant colonies someNP VP(no-aux) Do the ants appear to operate as a unified entity , collectively working together to support the colonyWHAT NP VP(aux) What do the ants appearNP VP(aux) Are the colonies sometimes described as superorganisms because the ants appear to operate as a unified entity , collectively working together to support the colonyWHAT NP VP(aux) What are the coloniesNP VP(aux) Have ants colonised almost every landmass on EarthWHERE NP VP(aux) Where did ants colonise colonisedNP VP(aux) Are the only places lacking indigenous ants Antarctica and certain remote or inhospitable islandsWHERE NP VP(aux) Where are the only places lacking indigenous ants areNP VP(aux) Has their long co-evolution with other species led to mimetic , commensal , parasitic , and mutualistic relationshipsWHAT NP VP(aux) What did their long co-evolution with other species leadNP VP(aux) Have hlldobler &amp; Wilson -LRB- 1990 -RRB- , p. 471 Ant societies division of labour , communication between individuals , and an ability to solve complex problemsWHAT NP VP(aux) What did hlldobler &amp; Wilson -LRB- 1990 -RRB- , p. 471 Ant societies divisionNP VP(aux) Have these parallels with human societies long been an inspiration and subject of studyWHAT NP VP(aux) What did these parallels with human societies longNP VP(no-aux) Do many human cultures make use of ants in cuisine , medication and ritualsWHAT NP VP(aux) What do many human cultures makeNP VP(aux) Are some species valued in their role as biological pest control agentsWHAT NP VP(aux) What are some speciesNP VP(aux) Is the word ant derived from ante of Middle English which is derived from mette of Old English and is related to the Old High German meiza , hence the modern German AmeiseWHERE NP VP(aux) Where is the word ant derived is derived is relatedWHO NP VP Who is the word antWHAT NP VP What is the word antNP VP(aux) Was the original meaning of the word `` the biter &apos;&apos; -LRB- from Proto-Germanic * ai - , `` off , away &apos;&apos; + * mait - `` cut &apos;&apos; -RRB-WHAT NP VP(aux) What was the original meaning of the wordNP VP(no-aux) Do all of these words come from West Germanic * amaitjoWHERE NP VP(aux) Where do all of these words comeNP VP(aux) Are the words in other Romance languages such as the Portuguese formiga , Italian formica , Spanish hormiga , Romanian furnic and French fourmi derivedWHAT NP VP(aux) What are the words in other Romance languages such as the Portuguese formiga , Italian formica , Spanish hormiga , Romanian furnic and French fourmiNP VP(aux) Is the family name Formicidae derived from the Latin formca -LRB- `` ant &apos;&apos; -RRB- from which the words in other Romance languages such as the Portuguese formiga , Italian formica , Spanish hormiga , Romanian furnic and French fourmi are derivedWHAT NP VP(aux) What is the family name FormicidaeNP VP(no-aux) Does formicidae belong to the order Hymenoptera , which also includes sawflies , bees and waspsWHAT NP VP(aux) What does formicidae belongNP VP(no-aux) Did ants fossilise in Baltic amber The family Formicidae belongs to the order Hymenoptera , which also includes sawflies , bees and waspsWHO NP VP Who did ants fossiliseWHAT NP VP What did ants fossiliseNP VP(no-aux) Did ants evolve from a lineage within the vespoid waspsWHAT NP VP(aux) What did ants evolve 第一个问题是指代消解，如下面这个句子 123456Ants are social insects of the family Formicidae ( ), and along with the related wasps and bees, they belong to the order Hymenoptera.Is supposed to generate=&gt;NP VP(no-aux)Do ants belong to the order HymenopteraWH NP VP(no-aux)What do ants belong to 应该同时能产生这两个问题，然而现在的代码遇到代词直接跳过，并没有进行匹配，所以不能产生。可以用 standford parser 做一次指代消解，然而再请求一次，加上标注、parse，时间上耗费太久。所以现在想着把上一步的 np 存到一个 list 里，如果下一个 np 匹配找到的是 PRP，就用 np 里的替换。这个解决方案也可以为产生 yes-no question 的 no question 做准备。 第二个问题是介词造成的不完整句子，需要对介词进行进一步处理 1What does ants consist =&gt; What does ants consist of 第三个问题是关于 have，have 可以作为完成时的 auxiliary，也可以作为行为动词 ‘have’ 表示拥有，而这里我默认了 have 作为 auxiliary 出现，其实是不对的，需要分情况讨论 12345Have nearly all ant colonies some fertile males called `` drones &apos;&apos; and one or more fertile females called `` queens &apos;&apos;is supposed to be=&gt;Do nearly all ant colonies have some fertile males called `` drones &apos;&apos; and one or more fertile females called `` queens &apos;&apos; 类似的问题是 be，比如 ‘A is B’ 和 ‘A is described as B’ 应该区分对待。 1234567NP VP(aux) Are the colonies sometimes described as superorganisms because the ants appear to operate as a unified entity , collectively working together to support the colony ?=&gt;WHAT NP VP What are the colonies ?is supposed to be=&gt;What are the colonies described as ? 然而这里有一个难点是 ‘A is described as B’ 和 ‘A is valued ‘ 第四个问题是疑问词，因为只 handle 了 WHO, WHAT, WHERE 的问题，而实际上，一些问句应该是 WHEN 的问题，如下。现在想到的是对于包含介词短语的句子，同时产生 WHERE 和 WHEN 两种问句类型，同样的，对于之前产生 WHO 的句子，也产生一个 WHAT 版本，然后由 QUESTION RANKING 来排序筛选。 关于 WHEN，尽量用命名实体 TIME 以及正则规则匹配，准确率会更高一些。 1234Ants evolved from wasp-like ancestors in the mid-Cretaceous period between 110 and 130 million years ago and diversified after the rise of flowering plants.=&gt; What did ants diversifySupposed to be=&gt; When did ants diversify 最后还有一些特殊符号的匹配，可以通过 post-processing 做处理 12-LRB- -RRB- =&gt; ()`` =&gt; &quot; 第二阶段基本解决了第一阶段的问题，并加了 ranking。 123456789101112131415161718192021222324252627282930313233Do ants form colonies that range in size from a few dozen predatory individuals living in small natural cavities to highly organised colonies which may occupy large territories and consist of millions of individuals ?More than 12,500 species are classified with upper estimates of about how many species ?What do ants form that range in size from a few dozen predatory individuals living in small natural cavities to highly organised colonies which may occupy large territories and consist of millions of individuals ?What have some fertile males called drones and one or more fertile females called queens ?Do males appear to operate as a unified entity , collectively working together to support the colony ?How many species are more than 12,500 species classified with ?What are classified with upper estimates of about 22,000 species ?Are ants social insects of the family Formicidae ?What do these larger colonies consist forming castes of workers , soldiers , or other specialised groups ?Are more than 12,500 species classified with upper estimates of about 22,000 species ?Do more than 12,500 species consist mostly of sterile wingless females forming castes of workers , soldiers , or other specialised groups ?Do these larger colonies consist mostly of sterile wingless females forming castes of workers , soldiers , or other specialised groups ?What did males call and one ?What form colonies that range in size from a few dozen predatory individuals living in small natural cavities to highly organised colonies which may occupy large territories and consist of millions of individuals ?Are people classified with upper estimates of about 22,000 species ?Do people have some fertile males called drones and one or more fertile females called queens ?What do the ants appear , collectively working together to support the colony ?Do the ants appear to operate as a unified entity , collectively working together to support the colony ?What do nearly all ant colonies have called drones and one or more fertile females called queens ?Do nearly all ant colonies have some fertile males called drones and one or more fertile females called queens ?Are nearly all ant colonies sometimes described as superorganisms because the ants appear to operate as a unified entity , collectively working together to support the colony ?How many species are classified with upper estimates of about 22,000 species ?Did males call drones and one ?What are ants of the family Formicidae ?Are people social insects of the family Formicidae ?What are more than 12,500 species classified with of about 22,000 species ?What are the colonies because the ants appear to operate as a unified entity , collectively working together to support the colony ?What appear to operate as a unified entity , collectively working together to support the colony ?What called drones and one ?What are social insects of the family Formicidae ?What are sometimes described as superorganisms because the ants appear to operate as a unified entity , collectively working together to support the colony ?What consist mostly of sterile wingless females forming castes of workers , soldiers , or other specialised groups ?Are the colonies sometimes described as superorganisms because the ants appear to operate as a unified entity , collectively working together to support the colony ? 参考链接：Question Generation via Overgenerating Transformations and Ranking","tags":"nlp"},{"title":"EMR 大文件操作及 Mapreduce 按 Value 排序若干","url":"/2017/04/03/EMR 大文件操作及 Mapreduce 按 Value 排序若干/","text":"关于 EC2 出现的 No space left on device 问题以及 Mapreduce postprocessing 怎么按 Value 排序 No space 问题EMR 开的 m3.xlarge 的机器，但是发现不能下载 8G 的压缩包，更别说是 30G 的文件了，显示的是 No space left on device 的错误。来看一下当前磁盘的情况。 1234567891011121314151617[hadoop@ip-172-31-24-108 ~]$ df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 7.4G 28K 7.4G 1% /devtmpfs 7.4G 0 7.4G 0% /dev/shm/dev/xvda1 9.8G 8.2G 1.5G 85% //dev/xvdb1 5.0G 34M 5.0G 1% /emr/dev/xvdb2 33G 334M 33G 2% /mnt/dev/xvdc 38G 35M 38G 1% /mnt1[hadoop@ip-172-31-24-108 ~]$ sudo file -s /dev/xvdc/dev/xvdc: SGI XFS filesystem data (blksz 4096, inosz 256, v2 dirs)[hadoop@ip-172-31-24-108 ~]$ lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTxvdb 202:16 0 37.5G 0 disk├─xvdb1 202:17 0 5G 0 part /emr└─xvdb2 202:18 0 32.5G 0 part /mntxvdc 202:32 0 37.5G 0 disk /mnt1xvda1 202:1 0 10G 0 disk / 发现硬盘 /dev/xvdc 的大小为 37.5G，足够容纳我们的文件，并且它有 MOUNTPOINT，建立好了文件系统，说明已经可以投入使用啦。 新建文件夹并 MOUNT123[hadoop@ip-172-31-24-108 ~]$ sudo mkdir /localinput[hadoop@ip-172-31-24-108 ~]$ sudo mount /dev/xvdc /localinput[hadoop@ip-172-31-24-108 ~]$ cd /localinput/ COPY 文件12[hadoop@ip-172-31-24-108 localinput]$ aws s3 cp s3://95869/com-friendster.ungraph.txt .download: s3://95869le/com-friendster.ungraph.txt to ./com-friendster.ungraph.txt Mapreduce 按 Value 排序Input 是 (key, frequency)，主要思路是 Mapper 里将 key,value 反转变成 (frequency, key)，然后定义 sort 的方法为 numerical descending order，reducer 再按正常顺序 (key, frequency) 输出。 Hadoop batch + Java用 JAVA 做其实是件很简单的事，在 main 函数里设置 Configuration，然后写个 ComparatorComparator12345678910111213public static class IntComparator extends WritableComparator &#123; public IntComparator() &#123; super(IntWritable.class); &#125; @Override public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) &#123; Integer v1 = ByteBuffer.wrap(b1, s1, l1).getInt(); Integer v2 = ByteBuffer.wrap(b2, s2, l2).getInt(); return v2.compareTo(v1); &#125;&#125; Configuration1234567891011121314151617public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); Job job = Job.getInstance(conf, &quot;word count&quot;); job.setJarByClass(WordCount.class); job.setMapperClass(TokenizerMapper.class); job.setNumReduceTasks(1);//number of reducers for the job job.setReducerClass(MyReducer.class); job.setOutputKeyClass(IntWritable.class);//change this job.setOutputValueClass(Text.class);//change this FileInputFormat.addInputPath(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1])); System.exit(job.waitForCompletion(true) ? 0 : 1);&#125; Hadoop streaming + python用 EMR Streaming + python 也很简单。在 Add Steps 时加上 argument 配置123-D mapreduce.job.reduces=1-D mapred.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator-D mapred.text.key.comparator.options=-nr SparkSpark 就更是超级无敌简单了，假设 calRdd 计算了 (key, frequency)，那么就只要做如下操作1234# Sorts the nodes in decreasing order of their degreessortRdd=calRdd.map(lambda x:(x[1],x[0])).sortByKey(ascending=False).map(lambda x:(x[1],x[0]))# Prints the top-100 nodes which have the highest degreessortRdd.take(100)","tags":"emr"},{"title":"AWS EC2 部署 django 项目","url":"/2017/03/30/AWS EC2 部署 django 项目/","text":"关于 EC2 部署 django 项目以及 pip DistributionNotFound Error。 EC2 部署 django 项目其实不只是 django，大多数的 server 部署到 EC2 上要修改的地方其实都差不多。三个注意点： 确保 EC2 的端口开了 修改 django project 的 settings.py，把 EC2 的 public dns 加入 ALLOWED_HOSTSALLOWED_HOSTS = [&apos;ec2-52-14-223-164.us-east-2.compute.amazonaws.com&apos;] 开启 Server，注意监听地址python manage.py runserver 0.0.0.0:8000 EC2 pip DistributionNotFound Error顺便提一下 pip，好好的在安装依赖的过程中，突然出现了错误，pip 完全用不了了…1234567891011121314151617$ sudo pip --versionTraceback (most recent call last): File &quot;/usr/bin/pip&quot;, line 5, in &lt;module&gt; from pkg_resources import load_entry_point File &quot;/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py&quot;, line 3138, in &lt;module&gt; @_call_aside File &quot;/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py&quot;, line 3124, in _call_aside f(*args, **kwargs) File &quot;/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py&quot;, line 3151, in _initialize_master_working_set working_set = WorkingSet._build_master() File &quot;/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py&quot;, line 663, in _build_master return cls._build_from_requirements(__requires__) File &quot;/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py&quot;, line 676, in _build_from_requirements dists = ws.resolve(reqs, Environment()) File &quot;/usr/local/lib/python2.7/site-packages/pkg_resources/__init__.py&quot;, line 849, in resolve raise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The &apos;pip==6.1.1&apos; distribution was not found and is required by the application 起因是某小哥突然更新了 pip… 太忧伤……小哥 Google 了若干帖子，然而事实证明，bug 这种事，有时就算试过了所有网上的解决方案也不一定能 de 出来，哪怕是卸载了重来。。 当然收获还是有的，Stack overflow 上有个解释不错 On upgrading pip on the system, as the root user, you actually overwrite your system PIP program, and are subject to severe problem when further installing Python packages for your Linux system (with yum/dnf). The correct way to work with this is to create a virtualenv as a user, and on that virtualenv you upgrade PIP. Isolated from the system Python installation. Anything remotely serious you will want to do with Python on this machine should be running at least Python 2.7 anyway - or 3.6 if it is Python 3 compatible. (Your system Python is 2.6 and you have a Python2. on /usr/local which might conflict, exactly depending on the order of PATH as you found out). Anyway，应该是版本冲突 + 配置的问题，于是先看一下 pip 文件123$ which pip/usr/local/bin/pip$ vim /usr/local/bin/pip 123456789101112#!/usr/bin/python2.7# EASY-INSTALL-ENTRY-SCRIPT: &apos;pip==6.1.1&apos;,&apos;console_scripts&apos;,&apos;pip&apos;__requires__ = &apos;pip==6.1.1&apos;import reimport sysfrom pkg_resources import load_entry_pointif __name__ == &apos;__main__&apos;: sys.argv[0] = re.sub(r&apos;(-script\\.pyw?|\\.exe)?$&apos;, &apos;&apos;, sys.argv[0]) sys.exit( load_entry_point(&apos;pip==6.1.1&apos;, &apos;console_scripts&apos;, &apos;pip2.7&apos;)() ) 要知道 pip9.0.1 其实已经有了，所以手动把所有 pip==6.1.1 改成 pip==9.0.1，然而并没有起作用。 那就直接追踪下问题出现的目录吧 123456789101112$ cd /usr/local/lib/python2.7/site-packages/pkg_resources/$ ls__init__.py __init__.pyc$ cd ..$ lsappdirs-1.4.3.dist-info djangorestframework-3.6.2.dist-info olefile-0.44.egg-info pip-9.0.1-py2.7.egg setuptoolsappdirs.py easy-install.pth OleFileIO_PL.py pkg_resources setuptools-34.3.3.dist-infoappdirs.pyc easy_install.py OleFileIO_PL.pyc pyparsing-2.2.0.dist-info six-1.10.0.dist-infodjango easy_install.pyc packaging pyparsing.py six.pyDjango-1.10.6.dist-info markdown packaging-16.8.dist-info pyparsing.pyc six.pycdjango_filter-1.0.2.dist-info Markdown-2.6.8.egg-info pip READMEdjango_filters olefile pip-9.0.1.dist-info rest_framework 然后注意了，我们确实有 pip-9.0.1，然而我们并木有 pip2.7 这个东西，有的只是 pip！所以 =&gt;123456789101112#!/usr/bin/python2.7# EASY-INSTALL-ENTRY-SCRIPT: &apos;pip==9.0.1&apos;,&apos;console_scripts&apos;,&apos;pip&apos;__requires__ = &apos;pip==9.0.1&apos;import reimport sysfrom pkg_resources import load_entry_pointif __name__ == &apos;__main__&apos;: sys.argv[0] = re.sub(r&apos;(-script\\.pyw?|\\.exe)?$&apos;, &apos;&apos;, sys.argv[0]) sys.exit( load_entry_point(&apos;pip==9.0.1&apos;, &apos;console_scripts&apos;, &apos;pip&apos;)() ) 然后，问题解决～～","tags":"django ec2"},{"title":"ParseTree操作若干-Tregex and Stanford CoreNLP","url":"/2017/03/24/ParseTree操作若干-Tregex and Stanford CoreNLP/","text":"网上教程太少，只能自己摸索了。关于怎么用 python 来调用 Stanford Parser。–持续更新中– Tregex 用来做句子层面的识别及操作，简单理解就是关于 tree 的 regex。一些语法知识见The Wonderful World of Tregex。用 java 来调用 API 更简单一点，然而项目需要，所以这一篇讲怎么用 python 来调用。 Stanford CoreNLPStanford NLP 的工具还可以有 Server 端！简直是 python 使用者一大福利。下载安装CoreNLP Server 先测试一下1java -cp &quot;*&quot; -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file input.txt ok，可以运行，然后开启 server 12# Run the server using all jars in the current directory (e.g., the CoreNLP home directory)java -mx4g -cp &quot;*&quot; edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000 之后就可以通过 python 发送 http 请求来调用接口啦~ Python 代码1234567import requestsurl = &quot;http://localhost:9000/tregex&quot;request_params = &#123;&quot;pattern&quot;: &quot;(NP[$VP]&gt;S)|(NP[$VP]&gt;S\\\\n)|(NP\\\\n[$VP]&gt;S)|(NP\\\\n[$VP]&gt;S\\\\n)&quot;&#125;text = &quot;Pusheen and Smitha walked along the beach.&quot;r = requests.post(url, data=text, params=request_params)print r.json() 结果1&#123;u&apos;sentences&apos;: [&#123;u&apos;0&apos;: &#123;u&apos;namedNodes&apos;: [], u&apos;match&apos;: u&apos;(NP (NNP Pusheen)\\n (CC and)\\n (NNP Smitha))\\n&apos;&#125;&#125;]&#125; Tregex 的基本语法之后再慢慢补充吧。 示例假定已经安装好了 nltk, stanford nlp 各类包，并设置好了路径。 Parse Tree from NLTK1234567891011121314151617181920from __future__ import division, unicode_literalsimport nltkfrom nltk.parse.stanford import StanfordParserparser = StanfordParser(model_path=&quot;edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz&quot;)def getParserTree(line): &apos;&apos;&apos; return parse tree of the string :param line: string :return: list of tree nodes &apos;&apos;&apos; return list(parser.raw_parse(line))# get parse treetext = &apos;Harry Potter, a young boy, is very famous in US&apos;testTree = getParserTree(text)print testTree 输出1[Tree(&apos;ROOT&apos;, [Tree(&apos;S&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;NNP&apos;, [&apos;Harry&apos;]), Tree(&apos;NNP&apos;, [&apos;Potter&apos;])]), Tree(&apos;,&apos;, [&apos;,&apos;]), Tree(&apos;NP&apos;, [Tree(&apos;DT&apos;, [&apos;a&apos;]), Tree(&apos;JJ&apos;, [&apos;young&apos;]), Tree(&apos;NN&apos;, [&apos;boy&apos;])]), Tree(&apos;,&apos;, [&apos;,&apos;])]), Tree(&apos;VP&apos;, [Tree(&apos;VBZ&apos;, [&apos;is&apos;]), Tree(&apos;ADJP&apos;, [Tree(&apos;RB&apos;, [&apos;very&apos;]), Tree(&apos;JJ&apos;, [&apos;famous&apos;]), Tree(&apos;PP&apos;, [Tree(&apos;IN&apos;, [&apos;in&apos;]), Tree(&apos;NP&apos;, [Tree(&apos;NNP&apos;, [&apos;US&apos;])])])])])])])] Parse Tree from CoreNLP Server1234567import requests#&quot;annotators&quot;, &quot;tokenize, ssplit, pos, lemma, ner, parse, dcoref&quot;url = &apos;http://localhost:9000/?properties=&#123;&quot;annotators&quot;: &quot;parse&quot;, &quot;outputFormat&quot;: &quot;text&quot;&#125;&apos;text=&apos;Harry Potter, a young boy, is very famous in US&apos;r = requests.post(url, data=text)print r.content 输出1234567891011121314151617181920212223242526272829303132333435363738Sentence #1 (12 tokens):Harry Potter, a young boy, is very famous in US[Text=Harry CharacterOffsetBegin=0 CharacterOffsetEnd=5 PartOfSpeech=NNP][Text=Potter CharacterOffsetBegin=6 CharacterOffsetEnd=12 PartOfSpeech=NNP][Text=, CharacterOffsetBegin=12 CharacterOffsetEnd=13 PartOfSpeech=,][Text=a CharacterOffsetBegin=14 CharacterOffsetEnd=15 PartOfSpeech=DT][Text=young CharacterOffsetBegin=16 CharacterOffsetEnd=21 PartOfSpeech=JJ][Text=boy CharacterOffsetBegin=22 CharacterOffsetEnd=25 PartOfSpeech=NN][Text=, CharacterOffsetBegin=25 CharacterOffsetEnd=26 PartOfSpeech=,][Text=is CharacterOffsetBegin=27 CharacterOffsetEnd=29 PartOfSpeech=VBZ][Text=very CharacterOffsetBegin=30 CharacterOffsetEnd=34 PartOfSpeech=RB][Text=famous CharacterOffsetBegin=35 CharacterOffsetEnd=41 PartOfSpeech=JJ][Text=in CharacterOffsetBegin=42 CharacterOffsetEnd=44 PartOfSpeech=IN][Text=US CharacterOffsetBegin=45 CharacterOffsetEnd=47 PartOfSpeech=NNP](ROOT (S (NP (NP (NNP Harry) (NNP Potter)) (, ,) (NP (DT a) (JJ young) (NN boy)) (, ,)) (VP (VBZ is) (ADJP (RB very) (JJ famous) (PP (IN in) (NP (NNP US)))))))root(ROOT-0, famous-10)compound(Potter-2, Harry-1)nsubj(famous-10, Potter-2)punct(Potter-2, ,-3)det(boy-6, a-4)amod(boy-6, young-5)appos(Potter-2, boy-6)punct(Potter-2, ,-7)cop(famous-10, is-8)advmod(famous-10, very-9)case(US-12, in-11)nmod:in(famous-10, US-12) annotators 可以加其他 parameter，得到更多的 ner, lemma 等信息，输出也可以设定为 json 或 html 等格式。 同位语得到 parse tree 的同位语部分，规则如下，第一个 NP 是 parent，后面两个 NP 是 sisters，中间由逗号隔开，这是同位语的基本形式。1NP=n1 &lt; (NP=n2 $.. (/,/ $.. NP=n3)) 代码：12345678910111213141516from __future__ import division, unicode_literalsimport nltkfrom nltk.parse.stanford import StanfordParserimport requestsAPPOSITION = &quot;NP=n1 &lt; (NP=n2 $.. (/,/ $.. NP=n3))&quot;def getAppositions(tree): url = &quot;http://localhost:9000/tregex&quot; request_params = &#123;&quot;pattern&quot;: APPOSITION&#125; r = requests.post(url, data=text, params=request_params) return r.json()text = &apos;Harry Potter, a young boy, is very famous in US&apos;print getAppositions(text) 输出1&#123;u&apos;sentences&apos;: [&#123;u&apos;0&apos;: &#123;u&apos;namedNodes&apos;: [&#123;u&apos;n1&apos;: u&apos;(NP\\n (NP (NNP Harry) (NNP Potter))\\n (, ,)\\n (NP (DT a) (JJ young) (NN boy))\\n (, ,))\\n&apos;&#125;, &#123;u&apos;n2&apos;: u&apos;(NP (NNP Harry) (NNP Potter))\\n&apos;&#125;, &#123;u&apos;n3&apos;: u&apos;(NP (DT a) (JJ young) (NN boy))\\n&apos;&#125;], u&apos;match&apos;: u&apos;(NP\\n (NP (NNP Harry) (NNP Potter))\\n (, ,)\\n (NP (DT a) (JJ young) (NN boy))\\n (, ,))\\n&apos;&#125;&#125;]&#125; 再进一步处理1234567891011121314151617def getAppositions(tree): url = &quot;http://localhost:9000/tregex&quot; request_params = &#123;&quot;pattern&quot;: APPOSITION&#125; r = requests.post(url, data=text, params=request_params) js = r.json() if js[&apos;sentences&apos;][0] and &apos;0&apos; in js[&apos;sentences&apos;][0] and &apos;namedNodes&apos; in js[&apos;sentences&apos;][0][&apos;0&apos;]: return js[&apos;sentences&apos;][0][&apos;0&apos;][&apos;namedNodes&apos;] return Nonetext = &apos;Harry Potter, a young boy, is very famous in US&apos;testTree = getParserTree(text)res = getAppositions(testTree)if res: for c in res: print c 输出：123&#123;u&apos;n1&apos;: u&apos;(NP\\n (NP (NNP Harry) (NNP Potter))\\n (, ,)\\n (NP (DT a) (JJ young) (NN boy))\\n (, ,))\\n&apos;&#125;&#123;u&apos;n2&apos;: u&apos;(NP (NNP Harry) (NNP Potter))\\n&apos;&#125;&#123;u&apos;n3&apos;: u&apos;(NP (DT a) (JJ young) (NN boy))\\n&apos;&#125;","tags":"nlp parsetree"},{"title":"NLP 笔记 - 平滑方法(Smoothing)小结","url":"/2017/03/24/NLP 笔记 - 平滑方法(Smoothing)小结/","text":"系统总结下之前零零散散提到过的 smoothing 方法。 引入我们来看一个概率模型，也就是 p(e)在 event space E 下的概率分布，模型很可能会用最大似然估计(MLE)，如下$$P_{MLE}={c(x) \\over \\sum_ec(e)}$$ 然而，由于并没有足够的数据，很多事件 x 并没有在训练数据中出现，也就是 c(x)=0，$P_{MLE}=0$，这是有问题的，没有在训练数据中出现的数据，并不代表不会在测试数据中出现，如果没有考虑到数据稀疏性，你的模型就太简单了！ Data sparsity 是 smoothing 的最大原因。Chen &amp; Goodman 在1998 年提到过，几乎所有数据稀疏的场景下，smoothing 都可以帮助提高 performance，而数据稀疏性几乎是所有统计模型(statistical modeling)都会遇到的问题。而如果你有足够多的训练数据，所有的 parameters 都可以在没有 smoothing 的情况下被准确的估计，那么你总是可以扩展模型，如原来是 bigram，没有数据稀疏，完全可以扩展到 trigram 来提高 performance，如果还没有出现稀疏，就再往高层推，当 parameters 越来越多的时候，数据稀疏再次成为了问题，这时候，用合适的平滑方法可以得到更准确的模型。实际上，无论有多少的数据，平滑几乎总是可以以很小的代价来提高 performance。 平滑方法 Additive smoothing Good-Turing estimate Jelinek-Mercer smoothing (interpolation) Katz smoothing (backoff) Witten-Bell smoothing Absolute discounting Kneser-Ney smoothing 差值(Interpolation) vs. 回退(backoff)先来理解下平滑方法的两种思想，一个是差值，简单来讲，就是把不同阶的模型结合起来，另一种是回退，直观的理解，就是说如果没有 3gram，就用 bigram，如果没有 bigram，就用 unigram，两者的区别： 插值（Jelinek-Mercer）和回退（Katz）都涉及到来自较高和较低阶模型的信息 主要区别：在决定非零计数的 n-gram 的概率时，差值模型使用低阶模型的信息，而回退模型则不使用 相同点：在决定没有出现过的(零计数) n-gram 时，两者都用了低阶模型的信息 事实证明，做差值模型的回退版本和做回退模型的差值版本都不难~(Kneser-Ney最开始是回退模型，而 Chen&amp;Goodman 也做了差值版本) 另外还有一点，与差值平滑算法相比，回退算法所需参数较少，而且可以直接确定，无需通过某种迭代重估算法反复训练，因此实现更加方便。 Additive smoothingAdd-one smoothing也叫 Laplace smoothing，假设 we saw each word one more time than we did，下面以 bigram model 为例给出加 1 平滑的模型MLE estimate:$$P_{MLE}(w_i|w_{i-1})={c(w_{i-1}w_i) \\over c(w_{i-1})}$$Add-1 estimate:$$P_{Add-1}(w_i|w_{i-1})={c(w_{i-1}w_i)+1 \\over c(w_{i-1})+V}$$ 通常情况下，V={w:c(w)$\\gt$0}$\\cup${UNK} 举个例子，假设语料库为下面三个句子123JOHN READ MOBY DICKMARY READ A DIFFERENT BOOKSHE READ A BOOK BY CHER 那么 JOHN READ A BOOK 这个句子的概率是： 而 CHEN READ A BOOK 这个句子出现的概率是： 如果使用加1平滑，那么概率就变成了： 加 1 平滑通常情况下是一种很糟糕的算法，与其他平滑方法相比显得非常差，然而我们可以把加 1 平滑用在其他任务中，如文本分类，或者非零计数没那么多的情况下。 Additive smoothing对加 1 平滑的改进就是把 1 改成 $\\delta$，且 $0 \\lt \\delta \\le 1$，也就是 pretend we’ve seen each n-gram $\\delta$ times more than we have，当然，Gale &amp; Church(1994) 吐槽了这种方法，说表现很差。 $$P_{Add-1}(w_i|w_{i-1})={c(w_{i-1}w_i)+\\delta \\over c(w_{i-1})+\\delta V}$$ Good-Turing smoothing基本思想: 用观察计数较高的 N-gram 数量来重新估计概率量大小，并把它指派给那些具有零计数或较低计数的 N-gram Idea: reallocate the probability mass of n-grams that occur r+1 times in the training data to the n-grams that occur r times. 一般情况下，我们选出现过一次的概率，也就是 Things seen once 这一概念：Things seen once: 使用刚才已经看过一次的事物的数量来帮助估计从来没有见过的事物的数量。举个例子，假设你在钓鱼，然后抓到了 18 条鱼，种类如下：10 carp, 3 perch, 2 whitefish, 1 trout, 1 salmon, 1 eel，那么下一条鱼是 trout 的概率是多少？很简单，我们认为是 1/18 那么，下一条鱼是新品种的概率是多少？不考虑其他，那么概率是 0，然而根据 Things seen once 来估计新事物，概率是 3/18 在此基础上，下一条鱼是 trout 的概率是多少？肯定就小于 1/18，那么怎么估计呢？在 Good Turing 下，对每一个计数 r，我们做一个调整，变为 r*，公式如下，其中 $n_r$ 表示出现过 r 次的 n-gram。$$r^* = (r+1){n_{r+1} \\over n_r}$$ 然后，我们就有$$P_{GT}(x:c(x)=r) = {r^* \\over N}$$ 所以，c=1时，$C^* (trout)= 2*1/3 = 2/3$$P^* (trout)={2/3 \\over 18}={1 \\over 27}$ 问题然后，问题来了，如果 $n_{r+1}=0$ 怎么办？这在 r 很高的情况下很常见，因为在对计数进行计数时(counts of counts)，会出现 “holes”。即使没有这个 hole，对很高的 r 来说，$n^r$ 也是有噪音的(noisy)。 所以，我们应该这样来看 $r^*$:$$r^* = (r+1){E(n_{r+1}) \\over E(n_r)}$$ 但是，问题是怎么估计这种期望呢？这需要更多的解释。 Jelinek-Mercer smoothing(Interpolation, 差值)同样，以语言模型为例，我们看这样一种情况，如果 c(BURNISH THE) 和 c(BURNISH THOU) 都是 0，那么在前面的平滑方法 additive smoothing 和 Good-Turing 里，p(THE|BURNISH)=p(THOU|BURNISH)，而这个概率我们直观上来看是错误的，因为 THE 要比 THOU 常见的多，$p(THE|BURNISH)\\gt p(THOU|BURNISH)$ 应该是大概率事件。要实现这个，我们就希望把 bigram 和 unigram 结合起来，interpolate 就是这样一种方法。 用线性差值把不同阶的 N-gram 结合起来，这里结合了 trigram，bigram 和 unigram。用 lambda 进行加权$$ \\begin{aligned} p(w_n|w_{n-1}w_{n-2}) &amp; = \\lambda_1 p(w_n|w_{n-1}w_{n-2}) \\\\ &amp; + \\lambda_2 p(w_n|w_{n-1}) \\\\ &amp; + \\lambda_3 p(w_n) \\end{aligned}$$ $$\\sum_i \\lambda_i=1$$ 怎样设置 lambdas?把语料库分为 training data, held-out data, test data 三部分，然后 Fix the N-gram probabilities(on the training data) Search for lambdas that give the largest probabilities to held-out set:$logP(w_1…w_n|M(\\lambda_1…\\lambda_k))=\\sum_ilogP_M(\\lambda_1…\\lambda_k)(w_i|w_{i-1})$ 这种差值其实是一个递归的形式，我们可以把每个 lambda 看成上下文的函数，如果对于一个特定的 bigram 有特定的计数，假定 trigram 的计数是基于 bigram 的，那么这样的办法将更可靠，因此，可以使 trigram 的 lambda 值更高，给 trigram 更高权重。 $$ \\begin{aligned} p(w_n|w_{n-1}w_{n-2}) &amp; = \\lambda_1 (w^{n-1}_{n-2})p(w_n|w_{n-1}w_{n-2}) \\\\ &amp; + \\lambda_2 (w^{n-1}_{n-2})p(w_n|w_{n-1}) \\\\ &amp; + \\lambda_3 (w^{n-1}_{n-2})p(w_n) \\end{aligned}$$ 通常 $\\lambda w^{n-1}_{n-2}$ 是用 EM 算法，在 held-out data 上训练得到(held-out interpolation) 或者在 cross-validation 下训练得到(deleted interpolation)。$\\lambda w^{n-1}_{n-2}$ 的值依赖于上下文，高频的上下文通常会有高的 lambdas。 Katz smoothing回退式算法。和 Good-Turing 一样，对计数进行调整，以 bigram 为例，非 0 计数的 bigram 都根据打折比率 $d_r$ 进行打折，比率约为 ${r^* \\over r}$，这个比率是由 Good-Turing 计算得到的，然后根据下一个低阶分布(如 unigram)，对没有出现过的 bigram 重新分配从非零计数中减去的值。 以 bigram 为例看看它是怎么做的： 对于 $d_r$ 的一些探讨，当一个 n-gram 出现次数足够大时，MLE 其实是一个可靠的概率估计，而当计数不是足够大时，就可以采用 Good-Turing 对其进行平滑，让计数为 0 时，退回低阶模型。 Witten-Bell smoothing一个 JM smoothing 的实例，当 n-gram $w^i_{i-n+1}$ 在训练数据中出现的时候，我们应该用高阶模型，否则，用低阶模型。所以 $1-w^i_{i-n+1}$ 应该是一个单词在训练数据中没有出现在 $w^i_{i-n+1}$ 后面的概率，可以用跟在 $w^i_{i-n+1}$ 后的 unique words 的数量来估计，公式为： 举个例子来理解一下，考虑 spite 和 constant 的 bigram，在 Europarl corpus 中，两个 bigram 都出现了 993 次，以 spite 开始的 bigram 只有 9 种，大多数情况下 spite 后面跟着 of(979次)，因为 in spite of 是常见的表达，而跟在 constant 后的单词有 415 种，所以，我们更有可能见到一个跟在 constant 后面的 bigram，Witten-Bell 平滑就考虑了这种单词预测的多样性，所以： $1-\\lambda_{spite}={9 \\over 9+993}=0.00898$$1-\\lambda_{constant}={415 \\over 415+993}=0.29474$ Absolute discounting和 Jelinek-Mercer 相似，Absolute discounting 包括了对高阶和低阶模型的差值，然而它并不是用高阶模型的 $P_{ML}$ 乘以一个 lambda，而是从每个非零计数里减掉一个固定的 discount $\\delta \\in [0,1]$ 先简单的来看下 bigram model，加上 Absolute discounting 就是： 完整的公式 一般来说，$\\delta$ 就直接取 0.75 好啦~ Kneser-Ney smoothing是 Absolute discounting 的一个扩展，对回退部分做了一个修正。 Idea: 只有在高阶模型的计数很小或者为 0 时，低阶模型才显得重要，(换种说法，只有在 bigram 没有出现过时，unigram 才有用)，因此应针对该目的进行优化 举个例子1Shannon game: I can&apos;t see without my reading (Francisco/glasses)? reading 后面跟 Francisco 还是 glasses 呢？因为 “San Francisco” 是个很常见的地名，所以 Francisco 有一个很高的 unigram 概率，比 glasses 高，而 Francisco 偏偏只在 San 后面出现，这就非常不合理。而更合理的方式是，给 Francisco 一个较低的 unigram 概率，这样，bigram 模型表现会更好。 改进的方案是，我们不看 how likely is w，而去看 how likely is w to appear as a novel continuation，也就是，对每个单词，我们看它对应的 bigram type 的数量，然后，每个 bigram type 在第一次出现的时候都是 novel continuation 所以最后的公式为: 小结 影响最大的因素是使用 modified backoff distribution，如 Kneser-Ney smoothing Jelinek-Mercer 平滑在小型训练数据集上表现更好，而 Katz 在大型训练集上表现更好 Katz 在计数大的 n-grams 上效果很好，而 Kneser-Ney 适合小的计数 Absolute discounting 要优于 linear discounting 在非零计数较低的情况下，Interpolated models 优于 backoff 添加 free parameters 到算法中，通过 held-out data 上优化这些参数可以提高性能 参考链接Stanford Language ModelingNLP Lunch Tutorial: SmoothingLanguage models","tags":"nlp 平滑 smoothing"},{"title":"NLP 笔记 - 再谈词向量","url":"/2017/03/21/NLP 笔记 - 再谈词向量/","text":"CMU 11611 的课程笔记。再次探讨词向量。 之前有过一篇总结，词向量总结笔记（简洁版），这一次，从 intuition 角度来谈词向量的发展，对上一篇是一个补充。 大纲：Distributional (vector) models of meaning Sparse: PPMI-weighted word-word co-occurrence matrices Dense: Word-word SVD 50-2000 dimensions Skip-grams and CBOW Brown clusters 5-20 binary dimensions Thesaurus-based meaning之前谈到单词的相似度，可能会用到词典(thesaurus)。然而并不是每一种语言都有词典，我们也很难每年去更新词典，再者，基于词典的方法的召回率(recall)很低，很多单词和短语被漏掉了，而且词典在动词、形容词上的表现并不是很好。 Joint distributions model of meaning用 joint distribution 来表示一个词？几乎不可能。英语大概有 1 百万的词，如果我们只考虑 unigram model，那么我们也得有 1 百万个参数，如果考虑 bigram，那么，至少有 10^12 的参数，想要稳定的估计，还必须要非常大的样本量，不管是获取还是处理这样的大的样本，都不容易。 Distributional models of meaning所以有了新的方法，distributional models of meaning，它的 intuition 是词类的分布特征，如果两个单词能够出现在相似的环境中，它们往往是相似的，换句话说，就是 一个词是由它周围的单词来定义的，所以我们要得到的是当前词和它的周围词共同出现的次数。当然，这种方法并不能区分近义词反义词，如 fast 和 slow 在这种情况下就可能是同义的。 Distributional models of meaning = vector-space models of meaning = vector semantics 有几种不同类型的向量模型(vecotr models) Sparse vector representations Mutual-information weighted word co-occurrence matrices Dense vector representations: Singular value decomposition (and Latent Semantic Analysis) Neural-network-inspired models (skip-grams, CBOW) Brown clusters Sparse vectorsWords and co-occurrence vectors先来看两个矩阵，词-文档矩阵(Term-document matrix) 和 词共现矩阵(Term-term matrix) Term-document matrix表示每个单词在文档中出现的次数(词频)，每一行是一个 term，每一列是一个 document 两篇文档的向量相似 =&gt; 两篇文档相似，如上图 doc3 和 doc4，我们就认为它们是相似的。两个单词的向量相似 =&gt; 两个单词相似，如上图的 fool 和 clown，就是相似的。 Term-term matrix然后我们可以考虑更小的粒度，更小的上下文，也就是不用整篇文档，而是用段落(paragraph)，或者小的窗口(window of $\\pm 4$ words)，所以这个时候，向量就是对上下文单词的计数，大小不再是文档长度 |D|，而是窗口长度 |V| 了，所以现在 word-word matrix 是 |V|*|V| 看一个上下文为 7 个单词的 word-word matrix，同样，每一行是一个 term，每一列是一个上下文(context) 关于窗口的大小，还有一个基本知识，如果窗口很小，比如说在 $\\pm$ 1-3 之间，那么这个向量是更加基于语法(syntactic)的向量，而如果窗口更长一些，比如说在 $\\pm$ 4-10 之间，那么向量是更加基于语义(semantic)的。 实际情况下，这个矩阵依然是非常稀疏的，大多数值都是 0，然而这并没有什么问题，我们还是可以用很多高效的算法来处理这种稀疏矩阵。 Positive Pointwise Mutual Information(PPMI)先来看看两种词共现(co-occurrence)的类型。 First-order co-occurrence(syntagmatic association) 通常是临近词，比如说，wrote 是 book 或者 poem 的 first-order associate Second-order co-occurrence(paradigmatic association) 通常有相似的临近词/上下文，比如说，wrote 是 said 或者 remarked 的 second-order associate 原始的词频对单词间的联系可能不是一个很好的估计，因为它非常的 skewed，一些停顿词如 the, of 非常的常见，也就没有区分度，而我们想要的是看 context word 能不能对 target word 提供有用的信息，于是就有了 PPMI。 先看下 PMI，看两个事件 x,y 同时出现的概率是不是比单独出现的概率高呢？$$PMI(X,Y)=log_2{P(x,y) \\over P(x)P(y))}$$ PMI 的范围是负无穷到正无穷，但是负值会带来各种各样的问题，所以我们通常会把负的 PMI 替换成 0，也就是有了 Positive PMI(PPMI) $$PPMI(word_1,word_2)=max(log_2{P(word1,word2) \\over P(word1)P(word2)},0)$$ P(w=information, c=data)=6/19=.32P(w=information)=11/19=.58P(c=data)=7/19=.37 所以$PMI(information,data)=log_2(.32 / (.37 * .58))=.57$ PMI 有 bias，rare words 会有很高的 PMI 值，有两个解决办法 Give rare words slightly higher probabilites Add-one smoothing Weighting PPMI这也就是第一种解决办法，加上一个 $\\alpha$，比如 $\\alpha=0.75$ $$PPMI\\alpha (w,c)=max(log_2{P(w,c) \\over P(w)P\\alpha (c)},0)$$ $$P\\alpha (c)={count(c)^\\alpha \\over \\sum_c count(c)^\\alpha}$$ 对罕见的 c 来说，$P\\alpha(c) &gt;&gt; P(c)$，来个例子，P(a)=.99, P(b)=.01，那么 $P\\alpha(a)={.99^.75 \\over .99^.75 + .01^.75}=.97$，同理，$P\\alpha(b)=.03$。 Add-k smoothing前面讲过很多次 Add-k smoothing 啦，就不多说了，直接上图 Measuring similarity: the cosinecosine 就没啥好多讲的了，+1 就是相同方向，-1 就是相反方向，0 就是正交，垂直方向，因为 PPMI 不会是负的，也就是 cosine 的范围是 0-1，很简单，就不举例了，看一下其他的相似性度量方法。 Adding syntax加入句法特征，如果两个单词有相似的句法结构上下文，那么这两个单词就是相似的，比如说 duty 和 responsibility，看一下句法分布 Modified by adjectives:additional, administrative, assumed, collective, congressional, constitutional… Objects of verbs:assert, assign, assume, attend to, avoid, become, breach..。 Co-occurrence vectors based on syntactic dependencies每个维度：在 R 个语法关系集合中的一个 context word，比如说 Subject-of-“absorb” 所以一个向量不是 |V| 个特征，而是 R|V| 个特征，举个例子，看一下 cell 这个单词的计数 注意这里的矩阵其实是 |V|*R|V| 大小的，也可以把它变成 |V|*|V| 大小的，举个例子$$M(“cell”,”absorb”) = count(subj(cell,absorb)) + count(obj(cell,absorb)) + count(pobj(cell,absorb))$$ PMI 在依存关系的应用，看下面的例子，drink it 比 drink wine 更常见，然而 wine 比 it 更加 drinkable tf-idftfidf 是另一种替代 PPMI 来衡量关联性(association)的方法，通常来说，并不是从来计算单词与单词之间的相似度，而是来考虑单词与文档之间的联系。 Dense VectorsPPMI 的向量很长(length |V|= 20,000 to 50,000)，而且很稀疏(大多数元素都是 0)，与之相对应的是稠密向量(dense vectors)，它更加短(length 200-1000)，更加稠密(大多数元素不是 0)，稠密向量的好处在于，它更容易作为机器学习中的特征，因为需要更少的 weights，而另一方面，它更容易泛化，也能更好的捕获同义词。 怎样用更少的维度来估计 N 维的数据集？有很多相关方法 PCA – principle components analysis Factor Analysis SVD SVD奇异值分解和特征值分解的目的都是提取一个矩阵最重要的特征，特征值分解要求变换的矩阵必须是方阵，而奇异值分解是一个能适用于任意矩阵的一种分解的方法。$A=U \\Sigma V^T$，$\\Sigma$ 除了对角线，其余元素都是 0，对角线元素就是奇异值，U 和 V 都是方阵，里面的向量分别是左奇异向量和右奇异向量，如下： 把奇异值和特征值对应起来，首先，我们将一个矩阵 A 的转置再乘以 A，将会得到一个方阵，我们用这个方阵求特征值可以得到 $(A^T A)v_i=\\lambda_iv_i$，得到的 v 就是右奇异向量，然后还可以得到 $$\\sigma_i = \\sqrt {\\lambda_i}$$$$u_i={1 \\over \\sigma_i}Av_i$$ 里面的 $\\sigma$ 就是奇异值，u 就是左奇异向量。奇异值 σ 跟特征值类似，在矩阵 Σ 中也是从大到小排列，而且σ 减少特别的快，在很多情况下，前 10% 甚至 1% 的奇异值的和就占了全部的奇异值之和的 99% 以上了。也就是说，我们也可以用前 r 大的奇异值来近似描述矩阵，这里定义一下部分奇异值分解：$$A_{m*n} \\approx U_{m*r} \\Sigma_{r*r}V^T_{r*n}$$ 右边的三个矩阵相乘的结果将会是一个接近于 A 的矩阵，在这儿，r 越接近于 n，则相乘的结果越接近于 A。而这三个矩阵的面积之和（在存储观点来说，矩阵面积越小，存储量就越小）要远远小于原始的矩阵 A，我们如果想要压缩空间来表示原矩阵 A，我们存下这里的三个矩阵：U、Σ、V就好了。 看一下奇异值分解在词向量中的应用， 没必要保留所有的维度，我们可以只留 top k 个奇异值，比如说 300，结果是对原始 X 的最小二乘近似。我们也不需要做乘法，直接用 W 表示就好了，W 的每一行，是一个 K 维的向量，来表示单词 W。 对于 LSA，我们一般会用 300 维，通常会给权重，local weight 就是取 log term frequency，global weight 就是取 idf 或者用 entropy 来衡量。 SVD 在词共现矩阵(term-term matrix)的应用 dense SVD embeddings 有时比 sparse PPMI 的效果好，尤其是在 word similarity 这类任务上。主要原因是 dense SVD embeddings 进行了去噪，丢掉了低维的，可能不重要的信息 截断有助于提高泛化能力 相对较小的维度有利于分类器来训练权重 更好的捕获 higher order 共现信息 Neural Language ModelWord2Vec 的算法，Skip-grams 和 CBOW，见 词向量总结笔记（简洁版） GloVe vs. Word2vec学习词向量的两种方式，一种是用 Global matrix factorization methods，对词共现矩阵进行 factorization，如 LSA，另一种是用 local context window methods，如 Skip-gram 之类。然而，两种方法各有利弊，LSA 利用了统计数据，但是在单词相似性的任务上表现相对很差，是一个次优的向量空间结构，而 Skip-gram 等方法在单词相似性的任务上表现很好，但没有利用整个语料库的统计数据，因为它只对局部的上下文进行训练，而不是基于全局的共现矩阵。 GloVe 和 Word2vec 是现在常用的两种 word vector 方法/工具，两者最为显著的不同，是 word2vec 认为所有 co-occurrences 的权重都应该是相同的，而 GloVe 认为权重不应该相同，所以 GloVe 提出了 weighted least squares regression model，用加权最小二乘法来最小化两个词的向量点积与它们共现次数的对数之间的差异。事实上，GloVe 的作者表明两个词共现概率的比值（而不是它们的共现概率本身），更适合作为向量差来编码信息。 这两者在大部分 NLP 任务中的表现其实差不多，然而 GloVe 比 Word2Vec 多了个优势，它更容易来做并行化，也就是，更加容易训练更多的数据。 关于 count-based model 和 predictive model，具体的区别见 Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors。两个模型都会学习单词的共现特征，不同的是，predictive model 训练一个神经网络，预测周围的词语/目标词，优化损失函数(the loss of predicting the target words from the context words given the vector representations)，而 count-based model 首先对整个语料库建立一个共现矩阵，然后对这个矩阵做 Factorization，以此产生低维向量，通常，是通过最小化 “reconstruction loss” 来实现的。 “reconstruction loss”: tries to find the lower-dimensional representations which can explain most of the variance in the high-dimensional data. In the specific case of GloVe, the counts matrix is preprocessed by normalizing the counts and log-smoothing them. This turns out to be A Good Thing in terms of the quality of the learned representations. 2014 年，Baroni 等人表明 predictive model 几乎在所有的任务中都优于 count-based model，然而，当 GloVe 被 Levy 等人认为是一个预测模型时，它显然是正在分解一个词语上下文共现矩阵，更接近于诸如主成分分析（PCA）和潜在语义分析（LSA）等传统的方法，不止如此，Levy 等人还表示 word2vec 隐晦地分解了词语上下文的 PMI 矩阵。 另外提几点，来自 Illinois 的 Jiaqi Mu 做的分享中提到的，关于两者的一些统计数据 从这些学习到的词向量来看，它们并不是 0 均值的，词向量聚集在均值周围，均值模长是词向量模长的 1/3 左右，我们知道向量之间的相似度是由夹角来描述的，如果有偏移，对相似度会有影响。另一方面，它们不是各向同性的，也就是说，向量并不是均匀分布在整个空间内，对空间的利用并不充分，有可能在某个空间上聚集了更多的能量，Jiaqi Mu 针对这两点做了 postprocessing，移除了非 0 偏置，并用主成分分析算出哪些维度的能量比较集中，进行了降维，然后实验发现，neural network 本身就能学习去掉均值、去掉某些方向这类的操作(automatically learn the postprocessing operation)。 Brown clustering在NLP 笔记 - Part of speech tags中提到过，就不多说啦。","tags":"nlp word2vec deep-learning 词向量"},{"title":"NLP笔记 - Information Extraction","url":"/2017/03/18/NLP 笔记 -Information Extraction/","text":"Stanford NLP 关于信息抽取的笔记，只是一个比较笼统的介绍，两块内容，命名实体识别(Named Entity Recognition)和序列模型(Sequence Model)。提到的具体算法，之后整理后再贴出~ 信息抽取(IE) 系统抽取的往往是清楚的、事实性的信息，如：Who did what to whom when? 这种比较结构化的信息。有很多方面的应用，最简单的比如说从公司报告中抽取盈利数据、总部信息、董事会成员等等信息，或者 Apple，Google mail 抽取日期时间，给出加入日历的建议这种(如下图)，非常 low-level 的信息抽取。 Named Entity Recognition(NER)命名实体识别(NER)在信息抽取中扮演着重要角色，它有两个关键词：find &amp; classify，找到命名实体，并进行分类。 应用： 命名实体作为索引和超链接 情感分析的准备步骤，在情感分析的文本中需要识别公司和产品，才能进一步为情感词归类 关系抽取(Relation Extraction) QA 系统，大多数答案都是命名实体 Machine learning approach非常标准的机器学习方法Training: 收集代表性的训练文档 为每个 token 标记命名实体(不属于任何实体就标 Others O) 设计适合该文本和类别的特征提取方法 训练一个 sequence classifier 来预测数据的 label Testing: 收集测试文档 运行 sequence classifier 给每个 token 做标记 输出命名实体 编码方式看一下下面两种给 sequence labeling 的编码方式，IO encoding 简单的为每个 token 标注，如果不是 NE 就标为 O(other)，所以一共需要 C+1 个类别(label)。而 IOB encoding 需要 2C+1 个类别(label)，因为它标了 NE boundary，B 代表 begining，NE 开始的位置，I 代表 continue，承接上一个 NE，如果连续出现两个 B，自然就表示上一个 B 已经结束了。 在 Stanford NER 里，用的其实是 IO encoding，有两个原因，一是 IO encoding 运行速度更快，而是在实践中，两种编码方式的效果差不多。IO encoding 确定 boundary 的依据是，如果有连续的 token 类别不为 O，那么类别相同，同属一个 NE；类别不相同，就分割，相同的 sequence 属同一个 NE。而实际上，两个 NE 是相同类别这样的现象出现的很少，如上面的例子，Sue，Mengqiu Huang 两个同是 PER 类别，并不多见，更重要的是，在实践中，虽然 IOB encoding 能规定 boundary，而实际上它也很少能做对，它也会把 Sue Mengqiu Huang 分为同一个 PER，这主要是因为更多的类别会带来数据的稀疏。 特征选择Features for sequence labeling:1234567• Words Current word (essentially like a learned dictionary) Previous/next word (context)• Other kinds of inferred linguistic classification Part of speech tags• Label context Previous (and perhaps next) label 再来看两个 featureWord substringsWord substrings 的作用是很大的，以下面的例子为例，NE 中间有 ‘oxa’ 的十有八九是 drug，NE 中间有 ‘:’ 的则大多都是 movie，而以 field 结尾的 NE 往往是 place。 Word shapes可以做一个 mapping，把单词长度(length)、大写(capitalization)、数字(numerals)、希腊字母(Greek eltters)、单词内部标点(internal punctuation)都作为特征。如下面的表，把所有大写字母映射为 X，小写字母映射为 x，数字映射为 d… Evaluation评估 IR 系统或者文本分类的任务，我们通常会用到 precision，recall，F1 这种 set-based metrics，见信息检索评价的 Unranked Boolean Retrieval Model 部分，但是在这里对 NER 这种 sequence 类型任务的评估，如果用这些 metrics，可能会有一些问题，如 boundary error。因为 NER 的评估是按每个 entity 而不是每个 token 来计算的，我们需要看 entity 的 boundary。以下面一句话为例1First Bank of Chicago announced earnings... 正确的 NE 应该是 First Bank of Chicago，类别是 ORG，然而系统识别了 Bank of Chicago，类别 ORG，也就是说，右边界(right boundary)是对的，但是左边界(left boundary)是错误的，这其实是一个常见的错误。 12345正确的标注：ORG - (1,4)系统：ORG - (2,4) 而计算 precision，recall 的时候，我们会发现，对 ORG - (1,4) 而言，系统产生了一个 false negative，对 ORG - (2,4) 而言，系统产生了一个 false positive！所以系统有了 2 个错误。F1 measure 对 precision，recall 进行加权平均，结果会更好一些，所以经常用来作为 NER 任务的评估手段。另外，专家提出了别的建议，比如说给出 partial credit，如 MUC scorer metric，然而，对哪种 case 给多少的 credit，也需要精心设计。 Sequence models下一篇博客会具体讲 MEMM 和 CRF，这里大概整理下课程提到的内容，当做是一个预告好了。 MEMM inferenceNLP 的很多数据都是序列类型的，像 sequence of characters, words, phrases, lines, sentences，我们可以暂时把任务当做是给每一个 item 打标签，如下图所示。 对于 Maximum Entropy Markov Model (MEMM) 及 Conditional Markov Model (CMM) 这类模型，分类器在给定 observation 以及之前的决策下，每一次做一个决策，以当前观察和之前的决策为基础。 For a Conditional Markov Model (CMM) a.k.a. a Maximum Entropy Markov Model (MEMM), the classifier makes a single decision at a time, conditioned on evidence from observations and previous decisions 在每个 decision point，使用了右边表格里的所有特征。 流程如图所示，非常清楚。Inference in Systems： Greedy Inference讨论下各种 inference 像上面所说的，”decide one sequence at a time and move on”，实际上是一个 greedy inference。举个例子，在词性标注中，可能模型在位置 2 的时候挑了当前最好的 PoS tag，但是到了位置 4 的时候，其实发现位置 2 应该有更好的选择，然而，greedy inference 并不会 care 这些。因为它是贪婪的，只要当前最好就行了。 Greedy Inference:优点: 速度快，没有额外的内存要求 非常易于实现 有很丰富的特征，表现不错 缺点: 贪婪 Beam Inference 在每一个位置，都保留 top k 种可能(当前的完整序列) 在每个状态下，考虑上一步保存的序列来进行推进 优点: 速度快，没有额外的内存要求 易于实现(不用动态规划) 缺点: 不精确，不能保证找到全局最优 Viterbi Inference 动态规划 需要维护一个 fix small window 优点: 非常精确，能保证找到全局最优序列 缺点: 难以实现远距离的 state-state interaction CRFs另一种 sequence model 是条件随机场(Coditional Random Fields, CRFs)，是一个完整的序列模型(whole-sequence conditional model)而不是局部模型的连接。 训练会比较慢，但是可以防止 causal-competition biases。","tags":"nlp information-extraction"},{"title":"会议笔记 - Nuts and Bolts of Applying Deep Learning","url":"/2017/03/17/会议笔记 - Nuts and Bolts of Applying Deep Learning/","text":"对第 30 届神经信息处理系统大会（NIPS 2016）中百度首席科学家吴恩达教授的演讲Nuts and Bolts of Building Applications using Deep Learning，做的笔记。最重要内容是 偏差/方差(bias/variance)分析框架。 中文 PPT 深度学习的崛起 吴恩达在开场提到：深度学习为何这么火？答案很简单：因为数据规模正在推动深度学习的进步。 从图中得到的： 不同于传统机器学习模型，对 DL 来说，数据量和 performance 几乎是线性的关系 在小数据集部分(small data regime)，也就是 x轴最左边，不同方法的差别是非常小的，然而随着数据量的增大，变化就非常快了 吴恩达还提到了一点，你为了某个 task 去得到/使用一个数据集是一回事，你去维护这个数据集让它 scaleable 又是另一回事。所以对商业应用，一般需要两个团队，系统团队(systems team)和算法团队(algorithms team)。 主要的 DL 模型 普通神经网络(General DL) 全连接模型 顺序模型(Sequence Models) (1D 顺序) RNN, GRU, LSTM, CTC, 注意力模型 图像模型(Image Models) CNN 未来的 AI(Unsupervised and Reinforcement learning) 无监督学习（稀疏编码 ICA, SFA,）增强学习 端到端的学习AI 工程师并不用花很多时间在特征工程或者说中间层的特征表达上(intermediate representations)，而是可以直接从一端(原始输入)到另一端(输出)。另外，DL 能产生的不是一个简单的数字(i.e. a class prediction)，它还能产生特征向量。比如在图像标注(Image captioning)中，CNN 用来产生输入图像的特征向量，然后这个向量又会被作为 RNN 的主要输入，来为图像产生标注(caption)。另外的例子如翻译、语音识别，图像生成等。 这看起来很简单，貌似 DL 就可以完全取代之前的 ML 模型了？并！不！是！ 始终要记得一个前提，这种端对端的方法只有在数据量足够大的时候才能有好的表现，所以，如果大的数据集很难获得，那么就要用 DL 模型就要很谨慎了。在实践过程中，并不是所有的场合都有大的标注数据集，所以加入了人工设计的特征信息(hand-engineered information)和领域知识(feild expertise)的模型往往占了上风。 深度学习策略一个机器学习工程师在建模的时候会有很多问题： 什么时候去找更多的数据？ 要不要用更长的时间去训练? 什么时候要重新思考一下架构(architecture)？ 什么时候引入/丢掉正则项？… 为了系统解决这个问题，Ng 带来了一个 偏差/方差(bias/variance) 分析框架。 数据集划分 在大多数的 DL 问题中，训练集和测试集通常来自不同的分布，这种情况下，将数据分成 train/dev/test 可能会有点 tricky。有些人可能会从训练集中砍一部分来做开发集，如第一行。而实际上这样的效果是很差的，因为通常意义上来说，我们希望我们的开发集和测试集来自同一个分布，否则，很有可能工程师花费很多很多的时间在开发集上进行调参，然而测试集和开发集上的结果非常的不同，就浪费了很多精力。 因此，聪明的做法是像图中的第二行，将测试集分为 dev/test 两部分。Ng 建议说，在实践中，可以对两个分布的数据集都划分一部分作为开发集，如第三行的图，这样，不同错误之间的 gap 可以帮助我们更好的分析问题(如下图)。 错误分类先来了解一下三种错误 人类水平误差(human level error) 训练集误差(training set error) 开发集误差(validation set error) 高偏差(high bias)来看一下 高偏差(high bias)，对应的问题是 underfitting，训练集的错误率就很高，这种情况下，需要建立更大的模型 高方差(high variance)高方差(high variance)，对应的问题是 overfitting，在训练集上表现的非常完美，然而开发集和测试集却有很高的错误率。下一步是引入正则或者多加些数据来调优。 高偏差和高方差高偏差(high bias) 和 高方差(high variance) 都很高的话，就要多加入数据，或者重新设计一下架构(或者用新的模型)了 分析框架所以分析框架就来了 中文版 人类的表现水平当 DL 在处理某项任务上比人类表现还差时，你经常会看到最快的进步，而当它能达到甚至超越人类的精度后，模型就应该趋于稳定了(意思说我们就不要再去动它了)。为什么呢？因为数据集会有一个理论上的”极限”，之后对模型的种种优化很有可能只是无用功，另外，人类往往很擅长做这些任务，要超过人类的表现，从边际收益看太不划算了。 再次重申下，人类水平的误差和贝叶斯最优误差不是一回事，如果你不知道这一点，那么很可能在训练模型后的下一步做无用功。 举个例子，一个图像识别的任务，如果下图左下角的表现，也就是 train error: 8%，dev error: 10%，而人类水平的误差是 1%，那么你可以尝试增加模型大小，增加训练时间等方式来提升模型，然而如果人类水平的误差是 7.5%，那这更多的是一个方差的问题，你可能需要花更多时间来合成数据，或者找和测试集更相似的数据来训练模型。 顺便提一句，总是有优化空间的，即使已经达到了人类水平的精度，也总有一些数据子集效果不怎么好，可以在这上面努力。 最后，说一下怎么来定义人类水平的误差，以医疗领域的图像标签任务为例，有下面的集中误差，选哪一个作为人类水平误差？ 普通人类(typical human): 5% 普通医生(general doctor): 1% 专家医生(specialized doctor): 0.8% 专家会诊(group of specialized doctors): 0.5% 答案是选最后一个，因为和贝叶斯最优误差最接近。 学习建议最后，Ng 提出了两点建议，来帮助大家提高作为 DL 工程师的能力。 Practice, Practice, Practice: 参与 Kaggle 的竞赛，多读相关的博客，参与论坛讨论… Do the Dirty Work: 读大量的论文，做实验尝试去得到和论文一样的结果，很快，你就会有自己的想法，建自己的模型啦~ 参考链接：Nuts and Bolts of Applying Deep Learning (Andrew Ng)Nuts and Bolts of Applying Deep Learning — SummaryNuts and Bolts of Applying Deep Learning","tags":""},{"title":"论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks","url":"/2017/03/14/论文笔记 - LightRNN - Memory and Computation-Efficient Recurrent Neural Networks/","text":"关于如何用 2-Component 共享词向量来优化 RNN。 原文：LightRNN: Memory and Computation-Efficient Recurrent Neural Networks部分译文： 微软重磅论文提出LightRNN：高效利用内存和计算的循环神经网络 这里只是稍微总结一下。 研究问题LightRNN 解决的问题是在 perplexity 差不多的情况下 减少模型大小(model size) + 加快训练速度(computational complexity)。论文在多个基准数据集进行语言建模任务来评价 LightRNN，实验表明，在困惑度（perplexity）上面，LightRNN 实现了可与最先进的语言模型媲美或更好的准确度，同时还减少了模型大小高达百倍，加快了训练过程两倍。这带来的意义无疑是深远的，它使得先前昂贵的 RNN 算法变得非常经济且规模化了，RNN 模型运用到 GPU 甚至是移动设备成为了可能，另外，如果训练数据很大，需要分布式平行训练时，聚合本地工作器（worker）的模型所需要的交流成本也会大大降低。 主要思路单词表示(Word Representation)主要思路是使用 二分量（2-Component） 来共享 embeddings。 将词汇表中的每一个词都分配(或者说填入)到一个二维表格中，然后每一行关联一个向量，每一列关联另一个向量。根据一个词在表中的位置，该词可由行向量和列向量两个维度联合表示。表格中每一行的单词共享一个行向量，每一列的单词共享一个列向量，所以我们仅需要 $2 \\sqrt |V|$ 个向量来表示带有|V|个词的词汇表，远少于现有的方法所需要的向量数|V|。 $x^r_i$: 第 i 行$x^c_j$: 第 j 列 引入 RNN知道了怎么用两个向量来表示一个词语，下一步就是如何将这种表示方法引入到 RNN 中。论文的做法非常简单，将一个词的行向量和列向量按顺序分别送入 RNN 中，以语言模型(Language Model, LM)为例，要计算下一个词是 $w_t$ 的概率，先根据前文计算下一个词的行向量是 $w_t$ 的概率，在根据前文和 $w_t$ 的行向量来计算下一个词的列向量是 $w_t$ 的概率，行向量和列向量的概率乘积就是下一个词是 $w_t$ 的概率。 单词分配怎么来分配单词形成这个表格呢？ 对冷启动(cold start)来说，随机初始化分配单词 对给定的 allocation 训练 embedding vectors 直到收敛(convergence) 停止条件(stopping criterion)可以是训练时间或者是 perplexity(for LM model) 固定上一步中学习到的 embedding vectors，重新分配单词(refine allocation)，标准当然是最小化损失函数了 损失函数/优化问题损失函数：交叉熵(corss-entropy)给定 T 个单词，损失函数 NNL(negative log-likelihood) 为：$$NNL = \\sum^T_{t=1}-logP(w_t)=\\sum^T_{t=1}-logP_r{w_t}-logP_c(w_t)$$ 扩展一下，$NNL=\\sum^{|V|}_{w=1}NLL_w$，而单词 w 的损失函数 $NNL_w$ 为：$$ \\begin{aligned} NNL_w &amp; = \\sum_{t \\in S_w} -logP(w_t) = l(w,r(w),c(w))\\\\ &amp; = \\sum_{t \\in S_w} -logP_r(w_t)+ \\sum_{t \\in S_w} -logP_c(w_t) = l_r(w,r(w)) + l_c(w,c(w)) \\\\ \\end{aligned}$$ $S_w$: 单词 w 的所有可能出现的位置的集合 $(r(w),c(w))$: 单词 w 在 allocation table 的位置 $l_r(w,r(w))$: 单词 w 的行损失(row loss) $l_c(w,c(w))$: 单词 w 的列损失(column loss) 假定 $l(w,i,j)=l(w,i)+l(w,j)$ 的情况下，计算 $l(w,i,j)$ 的复杂度是 $O(|V|^2)$，而事实上，所有的 $l_r(w,i)$ 和 $l_c(w,j)$ 都在 LightRNN 训练的前向传播中计算过了。对所有的 $w,i,j$ 计算 $l(w,i,j)$ 后，我们可以把 reallocation 的问题看做下面的优化问题： 这个优化问题又可以等价为一个标准的 最小权完美匹配(minimum weight perfect matching problem)，可以用 minimum cost maximum flow(MCMF) 算法来实现，复杂度为 $O(|V|^3)$，主要思路大概如下图，论文的实验中用的是一个最小权完美匹配的近似算法 1/2-approximation algorithm，复杂度为 $O(|V|^2)$，这和整个 LightRNN 的训练复杂度(约为 $O(|V|KT)$，K 是训练过程的 epoch 数，T 是训练集中的 token 总数)比起来不算什么。 相关工作 [1] Ravindra K Ahuja, Thomas L Magnanti, and James B Orlin. Network flows. Technical report, DTIC Document, 1988.[2] Jeremy Appleyard, Tomas Kocisky, and Phil Blunsom. Optimizing performance of recurrent neural networks on gpus. arXiv preprint arXiv:1604.01946, 2016.[3] Yoshua Bengio, Jean-Sébastien Senécal, et al. Quick training of probabilistic neural nets by importance sampling. In AISTATS, 2003.[4] Jan A Botha and Phil Blunsom. Compositional morphology for word representations and language modelling. arXiv preprint arXiv:1405.4273, 2014.[5] Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robinson. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint arXiv:1312.3005, 2013.[6] Welin Chen, David Grangier, and Michael Auli. Strategies for training large vocabulary neural language models. arXiv preprint arXiv:1512.04906, 2015.[7] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.[8] Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. Learning to forget: Continual prediction with lstm. Neural computation, 12(10):2451–2471, 2000.[9] Joshua Goodman. Classes for fast maximum entropy training. In Acoustics, Speech, and Signal Processing, 2001. Proceedings.(ICASSP’01). 2001 IEEE International Conference on, volume 1, pages 561–564. IEEE, 2001.[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.[11] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.[12] Shihao Ji, SVN Vishwanathan, Nadathur Satish, Michael J Anderson, and Pradeep Dubey. Blackout: Speeding up recurrent neural network language models with very large vocabularies. arXiv preprint arXiv:1511.06909, 2015.[13] Yoon Kim, Yacine Jernite, David Sontag, and Alexander M Rush. Character-aware neural language models. arXiv preprint arXiv:1508.06615, 2015.[14] Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. Recurrent neural network based language model. In INTERSPEECH, volume 2, page 3, 2010. [15] TomášMikolov, Stefan Kombrink, Lukáš Burget, Jan Honza Cˇ ernocky, and Sanjeev Khudanpur. Extensions of recurrent neural network language model. In Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on, pages 5528–5531. IEEE, 2011.[16] Andriy Mnih and Geoffrey E Hinton. A scalable hierarchical distributed language model. In Advances in neural information processing systems, pages 1081–1088, 2009.[17] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In Aistats, volume 5, pages 246–252. Citeseer, 2005.[18] Christos H Papadimitriou and Kenneth Steiglitz. Combinatorial optimization: algorithms and complexity. Courier Corporation, 1982.[19] Jan Pomikálek, Milos Jakubícek, and Pavel Rychl`y. Building a 70 billion word corpus of english from clueweb. In LREC, pages 502–506, 2012.[20] Robert Preis. Linear time 1/2-approximation algorithm for maximum weighted matching in general graphs. In STACS 99, pages 259–269. Springer, 1999.[21] Ha¸sim Sak, Andrew Senior, and Françoise Beaufays. Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition. arXiv preprint arXiv:1402.1128, 2014.[22] Martin Sundermeyer, Ralf Schlüter, and Hermann Ney. Lstm neural networks for language modeling. In INTERSPEECH, pages 194–197, 2012.[23] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104–3112, 2014.[24] Duyu Tang, Bing Qin, and Ting Liu. Document modeling with gated recurrent neural network for sentiment classification. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1422–1432, 2015.[25] Paul J Werbos. Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, 78(10):1550–1560, 1990.[26] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. arXiv preprint arXiv:1410.3916, 2014.[27] Dong Yu, Adam Eversole, Mike Seltzer, Kaisheng Yao, Zhiheng Huang, Brian Guenter, Oleksii Kuchaiev, Yu Zhang, Frank Seide, Huaming Wang, et al. An introduction to computational networks and the computational network toolkit. Technical report, Technical report, Tech. Rep. MSR, Microsoft Research, 2014, 2014. research. microsoft. com/apps/pubs, 2014.[28] Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. Recurrent neural network regularization. arXiv preprint arXiv:1409.2329, 2014.","tags":"deep-learning rnn"},{"title":"论文笔记 - Wide and Deep Learning for Recommender Systems","url":"/2017/03/13/论文笔记 - Wide and Deep Learning for Recommender Systems/","text":"Google Play 用的深度神经网络推荐系统，主要思路是将 Memorization(Wide Model) 和 Generalization(Deep Model) 取长补短相结合。论文见 Wide &amp; Deep Learning for Recommender Systems Overview of System 先来看一下推荐系统的整体架构，由两个部分组成，检索系统(或者说候选生成系统） 和 排序系统(排序网络)。首先，用 检索(retrieval) 的方法对大数据集进行初步筛选，返回最匹配 query 的一部分物品列表，这里的检索通常会结合采用 机器学习模型(machine-learned models) 和 人工定义规则(human-defined rules) 两种方法。从大规模样本中召回最佳候选集之后，再使用 排序系统 对每个物品进行算分、排序，分数 P(y|x)，y 是用户采取的行动(比如说下载行为)，x 是特征，包括 User features e.g., country, language, demographics Contextual features e.g., device, hour of the day, day of the week Impression features e.g., app age, historical statistics of an app WDL 就是用在排序系统中。 Wide and Deep Learning简单来说，人脑就是一个不断记忆（memorization）并且归纳（generalization）的过程，而这篇论文的思想，就是将宽线性模型（Wide Model，用于记忆，下图左侧）和深度神经网络模型（Deep Model，用于归纳，下图右侧）结合，汲取各自优势形成了 Wide &amp; Deep 模型用于推荐排序（下图中间）。 Wide Model Memorization can be loosely defined as learning the frequent co-occurrence of items or features and exploiting the correlation available in the historical data. 要理解的概念是 Memorization，主要是学习特征的共性或者说相关性，产生的推荐是和已经有用户行为的物品直接相关的物品。 用的模型是 逻辑回归(logistic regression, LR)，LR 的优点就是简单(simple)、容易规模化(scalable)、可解释性强(interpretable)。LR 的特征往往是二值且稀疏的(binary and sparse)，这里同样采用 one-hot 编码，如 “user_installed_app=netflix”，如果用户安装了 Netflix，这个特征的值为 1，否则为 0。 为了达到 Memorization，我们对稀疏的特征采取 cross-product transformation，比如说 AND(user_installed_app=netflix, impression_app=pandora”) 这个特征，只有 Netflix 和 Pandora 两个条件都达到了，值才为 1，这类 feature 解释了 co-occurrence 和 target label 之间的关系。一个 cross-product transformation 的局限在于，对于在训练集里没有出现过的 query-item pair，它不能进行泛化(Generalization) 到此，总结一下，宽度模型的输入是用户安装应用(installation)和为用户展示（impression）的应用间的向量积（叉乘），模型通常训练 one-hot 编码后的二值特征，这种操作不会归纳出训练集中未出现的特征对。 Linear model 大家都很熟悉了$$y = w^Tx+b$$ $x = [x_1, x_2, …, x_d]$ 是包含了 d 个特征的向量，$w = [w_1, w_2, …, w_d]$ 是模型参数，b 是偏置。特征包括了原始的输入特征以及 cross-product transformation 特征，cross-product transformation 的式子如下：$$\\varnothing_k(x)=\\prod^d_{i=1}x_i^{c_{ki}}$$ $c_{kj}$是一个布尔变量，如果第 i 个特征是第 k 个 transformation φk 的一部分，那么值就为 1，否则为 0，作用： This captures the interactions between the binary features, and adds nonlinearity to the generalized linear model. Deep Model Generalization is based on transitivity of correlation and explores new feature combinations that have never or rarely occurred in the past. 要理解的概念是 Generalization，可以理解为相关性的传递(transitivity)，会学习新的特征组合，来提高推荐物品的多样性，或者说提供泛化能力(Generalization) 泛化往往是通过学习 low-dimensional dense embeddings 来探索过去从未或很少出现的新的特征组合来实现的，通常的 embedding-based model 有 Factorization Machines(FM) 和 Deep Neural Networks(DNN)。特殊兴趣或者小众爱好的用户，query-item matrix 非常稀疏，很难学习，然而 dense embedding 的方法还是可以得到对所有 query-item pair 非零的预测，这就会导致 over-generalize，推荐不怎么相关的物品。这点和 LR 正好互补，因为 LR 只能记住很少的特征组合。 为了达到 Generalization，我们会引入新的小颗粒特征，如类别特征（安装了视频类应用，展示的是音乐类应用，等等）AND(user_installed_category=video, impression_category=music)，这些高维稀疏的类别特征（如人口学特征和设备类别）映射为低纬稠密的向量后，与其他连续特征（用户年龄、应用安装数等）拼接在一起，输入 MLP 中，最后输入逻辑输出单元。 一开始嵌入向量(embedding vectors)被随机初始化，然后训练过程中通过最小化损失函数来优化模型。每一个隐层(hidden-layer)做这样的计算：$$a^{(l+1)}=f(W^{(l)}a^{(l)}+b^{(l)})$$ f 是激活函数(通常用 ReLU)，l 是层数。 总结一下，基于 embedding 的深度模型的输入是 类别特征(产生embedding)+连续特征。 Joint Training对两个模型的输出算 log odds ratio 然后加权求和，作为预测。 Joint Training vs Ensemble Joint Training 同时训练 wide &amp; deep 模型，优化的参数包括两个模型各自的参数以及 weights of sum Ensemble 中的模型是分别独立训练的，互不干扰，只有在预测时才会联系在一起 用 mini-batch stochastic optimization 来进行训练，可以看下这篇论文Efficient Mini-batch Training for Stochastic Optimization。 在论文提到的实验中，训练时 Wide Model 部分用了 Follow-the-regularized-learder(FTRL)+ L1 正则，Deep Model 用了 AdaGrad，对于逻辑回归，模型预测如下： System Implementationpipeline 如下图 Data GenerationLabel: 标准是 app acquisition，用户下载为 1，否则为 0Vocabularies: 将类别特征(categorical features)映射为整型的 id，连续的实值先用累计分布函数CDF归一化到[0,1]，再划档离散化。 Continuous real-valued features are normalized to [0, 1] by mapping a feature value x to its cumulative distribution function P(X ≤ x), divided into $n_q$ quantiles. The normalized value is $i-1 \\over n_q-1$for values in the i-th quantiles. Model Training训练数据有 500 billion examples， Input layer 会同时产生稀疏(sparse)的和稠密(dense)的特征，具体的 Model 上面已经讨论过了。需要注意的是，当新的训练数据来临的时候，我们用的是热启动(warm-starting)方式，也就是从之前的模型中读取 embeddings 以及 linear model weights 来初始化一个新模型，而不是全部推倒重新训练。 Model Serving当模型训练并且优化好之后，我们将它载入服务器，对每一个 request，排序系统从检索系统接收候选列表以及用户特征，来为每一个 app 算分排序，分数就是前向传播的值(forward inference)啦，可以并行训练提高 performance。 参考链接《Wide &amp; Deep Learning for Recommender Systems 》笔记深度学习第二课：个性化推荐","tags":"recommender-systems"},{"title":"深度学习知识框架","url":"/2017/03/10/深度学习知识框架/","text":"之前也写过 DNN/CNN…，然而都是哪里需要学哪里，对深度学习并没有一个知识框架，现在来补一补~ 图片来自小象学院公开课，下面直接解释几条线 神经网络线性回归 (+ 非线性激励) → 神经网络 有线性映射关系的数据，找到映射关系，非常简单，只能描述简单的映射关系 大部分关系是非线性的，所以改进方法就是加一个非线性激励，某种程度是一个 NORMALIZE，但是是非线性的，对参数有更强的描述能力 +非线性激励，描述稍微复杂的映射关系，形成神经网络 神经网络输入是 1 维信息，普通网络之间进行的是代数运算，然后经过非线性激励，形成新的神经网络 RNN神经网络 (+时域递归) → RNN 神经网络处理一维信息，然而一维信息很可能是有前后的时间联系的，如人的语音，前面说的话与后面是有联系的，RNN 学习前后关系 相当于某一刻的输出同时也作为下一刻的输入，所以这一刻的输入不仅是这一刻的输入+上一刻输出的信息 LSTMRNN (+记忆GATE) → LSTM RNN 只考虑前一刻信息，Tn 时刻只考虑 Tn-1 的，那么 Tn-2，就是 Tn-2 → Tn-1 → Tn 逐层衰减，信息也会越来越弱 如果很久之前的记忆很重要，要把它记下来，就相当于有一个记忆方程，那么就可以用 LSTM，实现长记忆短记忆 Gate 来分析哪一部分存储，哪一部分进行传递 应用： 语句生成 → 自动翻译智能对话 CNN神经网络 (+卷积核) → CNN 基本的代数运算用卷积核来代替。一维到二维甚至是三维的转化，相当于一个空间上的扩展 应用： 图片分类 → 目标分类(人脸识别/物品识别/场景识别/文字识别)、目标检测(安防/自动驾驶) 更先进的CNN 深度，宽度，递归的变化 增加深度(网络层数)，E.g.OverFeat-accurate，VGG 增加宽度(filter数)，E.g.zf-big，OverFeat-accurate 递归的变化，可以跳过下一层，传到后面几层 结构与性能 特定问题的具体结构 比如说人脸识别，我们知道人脸有大体结构，用 CNN 来做识别时，可以让不同位置的像素不共享参数，眼睛有处理眼睛部分的卷积核，鼻子有处理鼻子部分的卷积核，它们之间不共享参数，这样的话参数会很多，但这样训练的结果可能会更好一些，专门对眼睛/鼻子进行训练 LSTM + CNNLSTM 卷积化(LSTM + CNN) 应用： 产生理解图片的语言 → 图片描述/标注 → 看图说话，时域的图片 → 视频分类 → 视频搜索 NLP 方向比较成熟的只有语音识别，语义挖掘方面还是目前的热点 增强学习外部反馈 → 增强学习 模仿人类学习的模型 CNN 能理解，把它放在游戏中，做决策，给出反馈，让它学会决策的能力 应用： 围棋，德州扑克，自动游戏，路径规划 GAN生成网络 + 判别网络 → 对抗网络 生成网络学会怎么生成数据，如输入有表情图片，学习怎么输出没有表情的图片，实际生成质量不是很好 判别网络判断生成网络生成的图片是不是真的 两者结合生成网络生成的图片越来越逼真，判别网络鉴别图片的能力也越来越强 作用： 生成数据，相当于无监督学习","tags":"deep-learning"},{"title":"Python os.environ.get() return None","url":"/2017/03/10/Python os.environ.get() return None/","text":"为这个问题痛苦了很久！所以就决定把本该放在 Wiki 上的东西放这了！起因是明明设置了环境变量，却不能在 python 文件中获取。 问题描述非常诡异的一件事Jupter 和 python shell 都能运行的代码：1234&gt;&gt;&gt; from nltk.parse.stanford import StanfordParser&gt;&gt;&gt; parser=StanfordParser(model_path=&quot;edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz&quot;)&gt;&gt;&gt; print list(parser.raw_parse(&quot;the quick brown fox jumps over the lazy dog&quot;))[Tree(&apos;ROOT&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;DT&apos;, [&apos;the&apos;]), Tree(&apos;JJ&apos;, [&apos;quick&apos;]), Tree(&apos;JJ&apos;, [&apos;brown&apos;]), Tree(&apos;NN&apos;, [&apos;fox&apos;])]), Tree(&apos;NP&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;NNS&apos;, [&apos;jumps&apos;])]), Tree(&apos;PP&apos;, [Tree(&apos;IN&apos;, [&apos;over&apos;]), Tree(&apos;NP&apos;, [Tree(&apos;DT&apos;, [&apos;the&apos;]), Tree(&apos;JJ&apos;, [&apos;lazy&apos;]), Tree(&apos;NN&apos;, [&apos;dog&apos;])])])])])])] 运行 py 文件就不行123456from nltk.parse.stanford import StanfordParserdef getParserTree(line): parser=StanfordParser(model_path=&quot;edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz&quot;) print list(parser.raw_parse(line))getParserTree(&quot;the quick brown fox jumps over the lazy dog&quot;) Error:123456789101112131415161718Traceback (most recent call last): File &quot;Helper.py&quot;, line 70, in &lt;module&gt; getParserTree(doc1) File &quot;Helper.py&quot;, line 55, in getParserTree parser=StanfordParser(model_path=&quot;edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz&quot;) File &quot;/Library/Python/2.7/site-packages/nltk/parse/stanford.py&quot;, line 51, in __init__ key=lambda model_name: re.match(self._JAR, model_name) File &quot;/Library/Python/2.7/site-packages/nltk/internals.py&quot;, line 714, in find_jar_iter raise LookupError(&apos;\\n\\n%s\\n%s\\n%s&apos; % (div, msg, div))LookupError:=========================================================================== NLTK was unable to find stanford-parser\\.jar! Set the CLASSPATH environment variable. For more information, on stanford-parser\\.jar, see: &lt;http://nlp.stanford.edu/software/lex-parser.shtml&gt;=========================================================================== 问题探索来看一下环境变量，同样诡异的事就发生了，用 jupter 或 python shell 运行下面的代码，可以得到环境变量路径123&gt;&gt;&gt; import os&gt;&gt;&gt; os.environ.get(&apos;CLASSPATH&apos;)/Users/sure/stanford-tools//stanford-postagger-full-2015-04-20/stanford-postagger.jar:/Users/sure/stanford-tools//stanford-ner-2015-04-20/stanford-ner.jar:/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser.jar:/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar 然而放到 py 文件里，就只能 output 出一个 None 为啥！明明设置好了环境变量！看 ~/.bash_profile1234export STANFORDTOOLSDIR=/Users/sure/stanford-tools/export CLASSPATH=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/stanford-postagger.jar:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/stanford-ner.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jarexport STANFORD_MODELS=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/models:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/classifiers 索性一个简单粗暴的方法是直接在 py 文件里，StanfordParser 传进绝对地址参数，第一个参数是 path/to/jar，第二个参数是 path/to/module，然后就 可以运行文件了。123parser = StanfordParser(&apos;/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser.jar&apos;, &apos;/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar&apos;,model_path=&quot;edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz&quot;)print list(parser.raw_parse(&quot;the quick brown fox jumps over the lazy dog&quot;)) 然而想一想，我们要用 Stanford PoS tagging，要用 NER，要用 parser，还要用 dependency parser，那得多麻烦！而且作为一个 team，share code，每个人的路径都不一样。。。 有两个解决方案，一是把对应的 jar 包，model 之类的所有东西放进当前目录下，然后在 py 文件里 get 当前目录，再进行拼接，传入参数；二是单独设置一个配置文件，每个人都配好各自的环境，在 py 文件里调用配置文件，这两种方法都可以解决个人路径不一样的问题。 然而，为什么还是这么麻烦。为什么 get 不到环境变量！ 问题解决来看一下 os.environ 这个函数，才发现 os.environ 保存的是 python 运行的当前 shell 中的环境变量。于是就想到了：我们根本没有在当前 shell 中 mark &amp; export varible 好不好！所以： 12345678$ STANFORDTOOLSDIR=/Users/sure/stanford-tools/$ CLASSPATH=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/stanford-postagger.jar:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/stanford-ner.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser.jar:$STANFORDTOOLSDIR/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar$ STANFORD_MODELS=$STANFORDTOOLSDIR/stanford-postagger-full-2015-04-20/models:$STANFORDTOOLSDIR/stanford-ner-2015-04-20/classifiers$ export STANFORDTOOLSDIR$ export CLASSPATH$ export STANFORD_MODELS$ python2.7 -c &apos;import os;print os.environ.get(&quot;CLASSPATH&quot;)&apos;/Users/sure/stanford-tools//stanford-postagger-full-2015-04-20/stanford-postagger.jar:/Users/sure/stanford-tools//stanford-ner-2015-04-20/stanford-ner.jar:/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser.jar:/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar Done!123$ python2.7 Helper.py/Users/sure/stanford-tools//stanford-postagger-full-2015-04-20/stanford-postagger.jar:/Users/sure/stanford-tools//stanford-ner-2015-04-20/stanford-ner.jar:/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser.jar:/Users/sure/stanford-tools//stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar[Tree(&apos;ROOT&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;DT&apos;, [&apos;the&apos;]), Tree(&apos;JJ&apos;, [&apos;quick&apos;]), Tree(&apos;JJ&apos;, [&apos;brown&apos;]), Tree(&apos;NN&apos;, [&apos;fox&apos;])]), Tree(&apos;NP&apos;, [Tree(&apos;NP&apos;, [Tree(&apos;NNS&apos;, [&apos;jumps&apos;])]), Tree(&apos;PP&apos;, [Tree(&apos;IN&apos;, [&apos;over&apos;]), Tree(&apos;NP&apos;, [Tree(&apos;DT&apos;, [&apos;the&apos;]), Tree(&apos;JJ&apos;, [&apos;lazy&apos;]), Tree(&apos;NN&apos;, [&apos;dog&apos;])])])])])])]","tags":"python shell stanfordparser"},{"title":"NLP 笔记 - Dependency Parsing and Treebank","url":"/2017/03/09/NLP 笔记 - Dependency Parsing and Treebank/","text":"CMU 11611 的课程笔记。关于 Treebank，parsing algorithm，advanced grammar，这一章介绍的非常简略，以后会补充。 Treebank来考虑一下 production rules 是怎么产生的，过去很长一段时间用的都是 hand-written grammars，需要专家编写，很难 scale，覆盖率也非常有限，所以人们手工建立了 treebank，也就是对某些语料集做的标注(annotated data)，之后 production rules 就可以通过算法直接从 treebank 抽取。E.g. 利用 Head rules，我们可以将 Penn Treebank tree 自动转化为一个 dependency tree，一些规则如下：1234567NPIf there is an NN daughter, the rightmost NN daughter is the head.If there is an NP daughter, the leftmost NP daughter is the head.If there is an NNP daughter , the rightmost NNP daughter is the head.SIf there is a VP daughter, the leftmost VP daughter is the head.ETC. 优势 Reusability of the labor Many parsers, POS taggers, etc. 一个 treebank 包含了很多种信息，可以用于多种 parser Valuable resource for linguistics Broad coverage Penn Treebank 包含了多个语料库(Brown Corpus/Wall Street Journal/ATIS/Switchboard)，每个语料库有大约一百万的单词，覆盖很广 Frequencies and distributional information 包含了 frequency 信息 Use Machine Learning algorithms to train parsers 把 treebank 数据分为 training set/dev set/test set，来训练 parser 吧~ A way to evaluate systems 可以用来评估 parser 效果 问题最大的一个问题是 too big to fail。因为建立这些 treebank 很费时费力费钱，所以它们不能轻易的被替代；另外，尽管大多数的决定是由专家来做的，然而大多数的 coding 确是由非专家来完成的，而这些人也处于高压以及有限预算下，treebank 并不是尽善尽美的。 Treebank DatasetThe Prague Dependency Treebanks: Extremely high quality The Google Universal Dependency Treebanks123456789• There were many different dependency treebanks in different formats, using different tagsets.• A consortium of researchers (spurred by Google) created universal tagsets. – around 12 parts of speech – around 12 dependencylabels • e.g., nsubj, dobj, aux, etc.• The tagsets were optimized for cross-lingual transfer of models.• It is important to note that many good linguists were involved. – The trees are not universal. – Just the tag sets and the guidelines for how to correctly apply the tagsets. ToolsTregexT-Regex operatorsT-surgeon Dependency Parsing Dynamic programming (CFG with heads + CKY) 和 lexicalized PCFG parsing 类似 时间复杂度：O(n^5) Eisner (1996) 提出一种 O(n^3) 的算法, 在结束的时候再产生 items with heads 而不是在中间产生 Graph algorithms McDonald et al.’s (2005) MSTParser(Maximum Spanning Tree), 单独用 ML 分类器来给 dependencies 算分 Constraint Satisfaction Karlsson (1990), etc. 建立所有 links, 然后删掉不符合 hard constraints 的 link “Deterministic parsing” Nivre et al. (2008): MaltParser, Greedy choice of aKachments guided by ML classifiers 实现 Dependency Parsing 主要要解决 linking 和 shifting 的问题，通常可以用机器学习分类器来解决 Source of information/Features: Bilexical affinities issues→the is plausible Dependency distance mostly short links Intervening material Dependencies rarely span intervening verbs or punctuation Valency of heads How many dependents on which side are usual for a head? Some lexical word links are more common MaltParser有时间再回来填坑Dependency Parsing Advanced Grammars Standard CFG Lexicalized Grammars Other formalisms Tree Adjoining Grammars Unification Grammars Categorial Grammars Tree Adjoining Grammars(TAG)TAG 是一个改写树的系统(formal tree rewriting system) Basics of TAG Formalism Primitive elements: elementary trees Initial trees Auxiliary trees Operations Substitution Adjoining Derivations Derived trees Derivation trees TAG 是 CFG 的一个局部域，一级树(One level tree)对应一条规则，不是每条规则都要词汇化(lexicalized)。 Is a grammar capable of Lexicalization of each elementary domain Encapsulation of the arguments of the lexical anchor Elementary trees至少包括了一个边界节点(frontier node)是 terminal 符号，或者我们说是 lexical anchor。 Initial tree &amp; Substitution 所有内部节点(interior nodes)是 non-terminal 符号 边界节点(frontier node)是 terminal/non-terminal 符号，用来替换，标记为↓ E.g. Auxiliary Trees &amp; Adjoining 有一个边界节点(frontier node)必须被标记为 foot node(*) 这个 foot node 必须是 non-terminal 符号，并且和根节点(root node)相同 E.g. An Introduction toTree Adjoining Grammars Unification GrammarsUnification Grammars 主要用于解决 一致性(agreement)问题，希望不用重复执行 NP-single 和 NP-plural 的 NP 规则 123456• S → NP VP[NP NUMBER] = [VP NUMBER]• Det → these[Det NUMBER] = plural• MD → does[MD NUMBER] = singular [MD PERSON] = third 貌似要研究一下 feature structure，参考Unification Grammars Categorial Grammars(CCG)大多数的 CCG 是从成分角度来分析句子结构的，所以它们是 phrase structure grammars基本的 5 条规则： A/B + B = A B + A\\B = A A/B + B/C = A/C A CONJ A’ = A A = X/(X\\A) Forward: X/Y Y =&gt; X X 后面如果接 Y，那么这个 phrase 就变成 XBackward: Y X\\Y =&gt; X X 前面如果是 Y，那么这个 phrase 就变成 X E.g. Dependency vs Constituent可以通过 head rules 来从 CFG 中得到 dependency parse CT → DT 要比 DT → CT 简单多了。 Tree ExampleTreebank Tree Parent-Annotated Tree Headed Tree Lexicalized Tree","tags":"nlp"},{"title":"NLP 笔记 - Question Answering System","url":"/2017/03/02/NLP 笔记 - Question Answering System/","text":"关于如何建立一个 QA 系统。整理自 Stanford NLP 公开课及 Jurafsky &amp; Chris Manning 的 NLP book draft。 Single Document QA基于某个 document 的 QA 系统，一般来说假定问题答案出现在了文档中。这是我们要做的项目，之后再具体介绍。 Question Types Simple (factoid) questions (most commercial systems) 简单的问题，可以用简单的事实回答，答案简短通常是一个 named entity Who wrote the Declaration of Independence? What is the average age of the onset of autism? Where is Apple Computer based? Complex (narrative) questions 稍微复杂的叙述问题，答案略长 What do scholars think about Jefferson’s position on dealing with pirates? What is a Hajj? In children with an acute febrile illness, what is the efficacy of single medication therapy with acetaminophen or ibuprofen in reducing fever? Complex (opinion) questions 复杂的问题，通常是关于观点／意见 Was the Gore/Bush election fair? IR-Based(Corpus-based) Approaches简言之，就是用信息检索的方法来找最佳 answer，下面是 IR-based factoid AQ 的流程图，包括三个阶段，问题处理(question processing)，篇章检索(passage retrieval)和答案处理(answering processing) Question Processing Answer Type Detection: 分析 question，决定 answer type Query Formulation: 形成合适的查询语句进行检索 Passagge Retrieval 通过检索得到 top N documents 把 documents 拆分称合适的单位(unit/passage) Answer Processing 得到候选的 answer 进行排序，选出最佳 answer Question Processing两个任务，确定 answer type，形成 query。有些系统还会从 question 里提取出 focus。 Answer type: the kind of entity the answer consists of (person, location, time, etc.)Query: the keywords that should be used for the IR system to use in searching for documentsFocus: the string of words in the question that are likely to be replaced by the answer in any answer string found 这一阶段需要做的事： E.g.Question: Which US state capital has the largest population?Answer type: cityQuery: US state capital, largest, populationFocus: state capital Answer Type Detection通常而言，我们把它当作一个机器学习的分类问题 定义类别 注释训练数据，给数据打上分类标签 训练分类器，所用特征可以包括 hand‐written rules Define answer types前人已经提供了一些 answer type 的层次型分类结构，如 Answer Type Taxonomy(from Li &amp; Roth) Two‐layered taxonomy 6 coarse classes ABBEVIATION, ENTITY, DESCRIPTION, HUMAN, LOCATION, NUMERIC_VALUE 50 fine classes HUMAN: group, individual, title, description ENTITY: animal, body, color, currency… LOCATION: city, country, mountain… FeaturesFeatures:123456- words in the questions- part-of-speech of each word- named entities in the questions- question headword- semantic information about the words in the questions WordNet synset ID of the word Classification一些分类方法: Hand-written rules Machine Learning Hybrid Regular expression‐based rules can get some cases: Who {is|was|are|were} PERSON PERSON (YEAR – YEAR) Other rules use the question headword = headword of first noun phrase after wh‐word: Which city in China has the largest number of foreign financial companies? What is the state flower of California? 当然也可以把上述某些分类方法当作特征一起进行训练。就分类效果而言，PERSON, LOCATION, TIME 这类的问题类型有更高的准确率，REASON，DESCRIPTION 这类的问题更难识别。 Query Formulation根据 question 产生一个 keyword list，作为 IR 系统的输入 query。可能的流程是去除 stopwords，丢掉 question word(where, when, etc.)，找 noun phrases，根据 tfidf 判断 keywords 的去留等等。如果 keywords 太少，还可以通过 query expansion 来增加 query terms。 Keyword selection algorithm： Results: 21 - 2 - Answer Types and Query Formulation-NLP-Dan Jurafsky &amp; Chris Manning Passage Retrieval有了 query，我们进行检索，会得到 top N 的文档，然而文档并不是得到 answer 的最好的单位，下一步我们需要从文档抽取 potential answer passages，来方便后面的 answer processing。passage 可以是 sections, paragraphs, sentence，具体情况具体分析。 两个步骤： 过滤掉那些不可能包含 answer 信息的 passage 可以运行 named entity 或者 answer type 的分类器 对剩下的 passage 进行排序 监督机器学习方法 特征:• The number of named entities of the right type in the passage • The number of question keywords in the passage • The longest exact sequence of question keywords that occurs in the passage • The rank of the document from which the passage was extracted • The proximity of the keywords from the original query to each other For each passage identify the shortest span that covers the keywords contained in that passage. Prefer smaller spans that include more keywords (Pasca 2003, Monz 2004). • The N-gram overlap between the passage and the question Count the N-grams in the question and the N-grams in the answer passages. Prefer the passages with higher N-gram overlap with the question (Brill et al., 2002). 对于基于 web 的 QA 系统，我们可以依靠网页搜索来做 passage extraction，简单来说，可以把网页搜索产生的 snippets 作为 passages。 Answer Processing现在，我们已经有了 question type，也给文本打了 Named Entities 的标签，就可以进一步缩小 candidate answer 的范围。 Answer IdentificationAnswer Identification 模块复杂找到问题的最佳 answer，对于具有 named entity 的问题，这个模块必须确定有正确 answer 的句子，对于没有 named entity 类型的问题，这个模块基本上得从头开始。 经常使用的方法是 word overlap Basic Word Overlap: 对每个候选答案计算分数，依据是答案中/附近的 question words 的数量 Stop Words: 有时 closed class words（通常称为IR中的停止词）不包括在 word overlap 中。 Stemming: 有时要用到 morphological analysis，仅仅比较词根(e.g. “walk” and “walked” would match). Weights: 一些 word 可能比其他 word 的权重更重（例如，动词可能被赋予比名词更多的权重） Answer ExtractionPattern‐extraction methods在 passage 上运行 answer‐type tagger，返回包含了正确的 answer-type 的文本。 E.g.12345Who is the prime minister of India” (PERSON) Manmohan Singh, Prime Minister of India, had told left leaders that the deal would not be renegotiated.“How tall is Mt. Everest? (LENGTH) The official height of Mount Everest is 29035 feet 有时候光用 pattern-extraction 方法是不够的，一方面我们不能创造规则，另一方面 passage 里也可能有多个 potential answer。另外，对于没有特定定命名实体类型的答案，我们可以使用正则表达式(人工编写或自动学习)。 N-gram tiling methodsN-gram tiling 又被称为 redundancy-based approach(Brill et al. 2002, Lin 2007)，基于网页搜索产生的 snippet，进行 ngram 的挖掘，具体步骤如下： N-gram mining 提取每个片段中出现的 unigram, bigram, and trigram，并赋予权重 N-gram filtering 根据 ngram 和预测的 answer type 间的匹配程度给 ngram 计算分数 可以通过为每个 answer type 人工编写的过滤规则来计算具体分数 N-gram tiling 将重叠的 ngram 连接称更长的答案 standard greedy method:1. start with the highest-scoring candidate and try to tile each other candidate with this candidate 2. add the best-scoring concatenation to the set of candidates 3. remove the lower-scoring candidate 4. continue until a single answer is built Rank Candidate Answers 可能用到的 feature1234567• Answer type match: True if the candidate answer contains a phrase with the cor- rect answer type.• Pattern match: The identity of a pattern that matches the candidate answer. Number of matched question keywords: How many question keywords are contained in the candidate answer.• Keyword distance: The distance between the candidate answer and query key- words (measured in average number of words or as the number of keywords that occur in the same syntactic phrase as the candidate answer).• Novelty factor: True if at least one word in the candidate answer is novel, that is, not in the query.• Apposition features: True if the candidate answer is an appositive to a phrase con- taining many question terms. Can be approximated by the number of question terms separated from the candidate answer through at most three words and one comma (Pasca, 2003).• Punctuation location: True if the candidate answer is immediately followed by a comma, period, quotation marks, semicolon, or exclamation mark.• Sequences of question terms: The length of the longest sequence of question terms that occurs in the candidate answer. Knowledge-based Approaches(Siri)对 query 建立语义模型，然后做一个 mapping 来找 answer。 semantic parsers: map from a text string to any logical form Build a semantic representation of the query Times, dates, locations, entities, numeric quantities Map from this semantics to query structured data or resources Geospatial databases Ontologies (Wikipedia infoboxes, dbPedia, WordNet, Yago) Restaurant review sources and reservation services Scientific databases 流行的本体库(ontologies)有 Freebase (Bollacker et al., 2008) 和 DBpedia (Bizer et al., 2009)，它们从 Wikipedia 的 infoboxes 提取了大量的三元组，可以用来回答问题。如下面这个三元组就可以回答 factoid questions，像是 ‘When was Ada Lovelace born?’ 或者 ‘Who was born in 1815?’的问题。12subject predicate objectAdaLovelace birth-year 1815 Mapping12“When was Ada Lovelace born?” → birth-year (Ada Lovelace, ?x)“What is the capital of England?” → capital-city(?x, England) Rule-based Methods对于一些非常常见的问题，我们可以用人工编写规则来从 question 里抽取关系，比如说 birth-year 的关系，我们可以用 question word When，动词 born，来抽取 named entity。 Supervised Methods一般来说，系统会有一个初始的 lexicon(每个命名实体对应着一些实例)，也会有一些默认的匹配规则，这些规则能够把 question parse tree 的某些部分映射为特定关系。 下面是一个二元组例子，用于训练分类器1“When was Ada Lovelace born?” → birth-year (Ada Lovelace, ?x) 有很多这样的 pair，更多的规则将被引入，然后我们就可以预测 unseen data。 Semi-Supervised Methods有监督的学习当然很棒，可是我们很难得到庞大的训练数据，所以一个办法就是利用textual redundancy。最常见的 redundancy 的例子当然就是 web 了，网络中存在着大量的能够表达关系的 textual variants，所以很多方法都利用了网络文本，如半监督学习算法 distant supervision，或者是无监督学习算法 open information extraction。把网络数据与规范的知识来源(canonical knowledge source)如 wikipedia 对齐，我们能创建/学习新的映射规则。 另一个 redundancy 的来源是 paraphrase databases，如 wikianswers.com 这些 question paraphrases 的 pair 可以通过 MT alignment 方法建立 MT-style phrase table 来将原始问题翻译成同义的问题，这种方法在现代的 QA 系统中经常用到。 Hybrid/DeepQA System(IBM Watson) 构建问题的浅层语义表达(shallow semantic representation) 用信息检索方法来产生候选答案 利用本体和半结构化数据 用更多的 knowledge source 来为候选答案计算分数 Geospatial databases Temporal reasoning Taxonomical classification 一些基本事实： “The operative goal for primary search eventually stabilized at about 85 percent binary recall for the top 250 candidates; that is, the system generates the correct answer as a candidate answer for 85 percent of the questions somewhere within the top 250 ranked candidates.” “If the correct answer(s) are not generated at this stage as a candidate, the system has no hope of answering the question. This step therefore significantly favors recall over precision, with the expectation that the rest of the processing pipeline will tease out the correct answer, even if the set of candidates is quite large.” IBM 的 Watson 系统架构： 后面补充。 Evaluation如果只返回一个 answer，就用 Accuracy，如果有多个，就用 MRR，MRR 对所有的 RR 值求平均，RR(Reciprocal rank) 指的是 1/rank of first right answer。 参考链接：Chapter 28: Question AnsweringChapter23.2: Question Answering","tags":"nlp"},{"title":"NLP 笔记 - Constituency Parsing","url":"/2017/02/28/NLP 笔记 - Syntax and Parsing/","text":"CMU 11611 的课程笔记。讲句法的相关概念及各种 parsing 算法包括 CFG / PCFG / CKY / Earley 等。 Context-Free Grammars我们怎么知道哪些单词可以组合在一起(形成一个成分)呢？一个明显的依据是它们都可以出现在相同的句法环境中。Context-Free Grammar，简称 CFG，又称短语结构语法(Phrase-Structure Grammar)，形式化方法等价于Backus-Naur范式(Backus-Naur Form，简称BNF)。 CFG 对形式语言(formal language)进行了限制，production rule 箭头(→)左边只能是一个 non-terminal symbol，表示某种聚类或概括性，右边的项是一个或多个 terminal 和 non-terminal 符号构成的有序表，可以把 CFGs 想象成句子的 generator，那么可以把“→”读为“用右边的符号串来重写左边的符号”。定义如下： N: a set of non-terminal symbols $\\Sigma$: a set of terminal symbols R: a set of production rules of the form $X \\ → \\ Y_1Y_2Y_n$ for n&gt;=0, $X \\in N$, $Y_i \\in (N \\cup \\Sigma)$ $S \\in N$: a distinguished/special start symbol 来个例子 我们可以把 CFGs 想象成 declarative programs，像是 Prolog, SQL, XQuery，Re，只声明最后想要做什么(ultimate goal)，而不是怎么做(intermediary steps)，也就是说相同程序可以被用在各种不同的 context 下面，而命令式编程(imperative programs)则是基于上下文的。 CFGs specify what is to be computed in terms of rules and let generalized computation mechanisms solve for the particular cases 判断一些语言是不是 Context-Free Grammar1234567891011Example 1: L1 = &#123; anbn | n is a positive integer &#125; is a context-free language. For the following context-free grammar G1 = &lt; V1 , , S , P1 &gt; generates L1 :V1 = &#123; S &#125; , = &#123; a , b &#125; and P1 = &#123; S -&gt; aSb , S -&gt; ab &#125;.Example 2: L2 = &#123; wwr| w &#123;a, b &#125;+ &#125; is a context-free language , where w is a non-empty string and wr denotes the reversal of string w, that is, w is spelled backward to obtain wr . For the following context-free grammar G2 = &lt; V2 , , S , P2 &gt; generates L2 :V2 = &#123; S &#125; , = &#123; a , b &#125; and P2 = &#123; S -&gt; aSa , S -&gt; bSb , S -&gt; aa , S -&gt; bb &#125;.Example 3: Let L3 be the set of algebraic expressions involving identifiers x and y, operations + and * and left and right parentheses. Then L3 is a context-free language. For the following context-free grammar G3 = &lt; V3 , 3, S , P3 &gt; generates L3 :V3 = &#123; S &#125; , 3 = &#123; x , y , ( , ) , + , * &#125; and P3 = &#123; S -&gt; ( S + S ) , S -&gt; S*S , S -&gt; x , S -&gt; y &#125;.Example 4: Portions of the syntaxes of programming languages can be described by context-free grammars. For example&#123; &lt; statement &gt; -&gt; &lt; if-statement &gt; , &lt; statement &gt; -&gt; &lt; for-statement &gt; , &lt; statement &gt; -&gt; &lt; assignment &gt; , . . . , &lt; if-statement &gt; -&gt; if ( &lt; expression &gt; ) &lt; statement &gt; , &lt; for-statement &gt; -&gt; for ( &lt; expression &gt; ; &lt; expression &gt; ; &lt; expression &gt; ) &lt; statement &gt; , . . . , &lt; expression &gt; -&gt; &lt; algebraic-expression &gt; , &lt; expression &gt; -&gt; &lt; logical-expression &gt; , . . . &#125; . CFG 有两个相关任务，一个是 Recognition(识别)，一个是 Parsing(剖析)，输入与输出如下： Input: sentence w=(w1,…,wn) and CFG G Output(recognition): true iff $w \\in Language(G)$ Output(parsing): one or more derivations for w, under G 可以用 Earley 算法在 O(n^3) 的时间复杂度内识别 CFG，下面会具体介绍。 Context-Free Grammar Chomsky Normal Form(CNF)FSA and CFG当一个 non-terminal 符号的展开式中也包含了这个 non-terminal 符号时，就会产生语法的递归(recursion)问题，如 Norminal → Norminal PP中，就有递归问题。 Chomsky(1959)证明了一个上下文无关语言(L)能够被有限自动机(FSA)生成，当且仅当存在一个生成语言 L 的、没有任何中心-自嵌入(center-embedded)递归的上下文语法($A→\\alpha A \\beta$) 之后会讨论 FSA 的一个扩充版本，递归转移网络(recursive transition network，简称 RTN)，它给 FSA 增加了很强的地柜能力。由 RTN 形成的自动机恰好与上下文无关语法同构(isomorphic)，在一定场合下，可以作为研究 CFG 的一个有用的比喻。 L(G) 是一种 push-down automata，可以被 normalized(Chomsky normal form) Chomsky normal form Only one or two symbols on RHS CNF让各个语法都拥有一个标准的形式非常有用(语法的规则部分都采用一种特殊的形式)。CNF 就是这样一种标准形式。如果一个 CFG 是 ε-free （ ε 表示空串），而且它的 rules 只有如下两种形式之一，且 $X, Y, Z \\in N, \\ w \\in T$，那个这个 CFG 就是采用 CNF 形式的。CNF 语法都是二分叉的。 X → Y Z X → w Transformation任何语法都可以转化成一个弱等价的 CNF 形式，只改变树的结构，且能识别相同的语言。基本思路如下： Empties and unaries are removed recursively n-ary rules are divided by introducing new nonterminals(n&gt;2) CFGs 到 CNF 的转化过程： For each rule X → A B C Rewrite as X → A X2 X2 → B C相当于引入了一个新的 non-terminal 一个上下文无关语法 $G=(N, \\Sigma, R, S)$ 在 Chomsky Normal Form 下的表达如下： N: a set of non-terminal symbols $\\Sigma $: a set of terminal symbols R: a set of rules which take one of two forms: X → $Y_1Y_2$ for X $\\in$ N, and $Y_1Y_2 \\in N$ X → Y for X $\\in$ N, and Y $\\in \\Sigma$ $S \\in N$: distinguished start symbol E.g. Binarization Binarization is crucial for cubic time CFG parsing. 这是我们必须知道的一条法则，在高效的 CFG parsing 中，Binarization 几乎总是必不可少的，可能是在 parsing 算法之前(如 CKY)，也可能是隐藏在了 parsing 算法中，但它总会被用到。 看一下 binarization 之前的 parse tree，VP → V NP PP 这一条是不符合 CNF 规则的 添加新的 non-terminal @VP_V，进行 binarization 之后的 parse tree Unaries/Empties进一步讨论下 unaries/empties，处理过程如下： 对 CNF 来说，重建 n-aries 是非常容易的，然而重建 unaries/empties 就非常的 tricky 了，一个 neat and clean 的 CNF 往往需要删除 empties and unaries，但另一方面，我们也可以简单的保留它们(通常只删除 emptie，保留 unaries，如上图的 non-empties 的树)，以便能够重建原来的 tree。 Recognition把识别当作一个搜索来做，算法如下非常简单：12345678Agenda = &#123; state0 &#125;while(Agenda not empty) s = pop a state from Agenda if s is a success-state return s // valid parse tree else if s is not a failure-state: generate new states from s push new states onto Agendareturn nil // no parse! Parsing上下文无关语法最后能产生剖析树(parse tree)，这里看一下输入输出以及产生的信息，下面具体介绍 parse 过程。INPUT: The burglar robbed the apartment.OUTPUT: Parse Trees 可以传达的信息 Part of speech for each word N = noun, V = verb, DT = determiner Phrases Noun Phrases (NP): “the burglar”, “the apartment” VerbPhrases(VP): “robbedtheapartment” Sentences (S): “the burglar robbed the apartment” Useful Relationships “the burglar” is the subject of “robbed”, see picture below Application: Machine Translation E.g. English word order: subject-verb-object, Japanese word order: subject-object-verb 12345 S / \\ NP VP | |Subject Verb Parsing 的算法有两类，一个是 top-down，一个是 bottom-up。 Top-down Parser Start state: (S, 0) Scan: From (wj+1 β, j), you can get to (β, j + 1). Predict: If Z → γ, then from (Z β, j), you can get to (γβ, j). Final state: (ε, n) 假定剖析要并行地构造出所有可能的树。算法开始时假定，给初始符号指派 S，输入就可以从 S 开始被推导出来。下一步搜索所有能够以 S 为顶点的树，寻找在语法的所有规则中左手边为 S 的规则。如下图，原始句子为 Book that flight，有三条规则可以展开 S，所以在图中的搜索空间第二层中，创造了三个局部树。 在第三层中，只有第五个 parse tree(由规则 VP → Verb NP 展开的树)最后与输入句子 Book that flight 相匹配。这里用的是 Left-Most Derivations 方法，每次都从最左边的 non-terminal X 开始，把 X 替换成 $\\beta$($X→\\beta$ 是 R 里的一条规则)，再举一个例子：E.g.[S], [NP VP], [D N VP], [the N VP], [the man VP], [the man Vi], [the man sleeps] Bottom-up Parser Start state: (ε, 0) Shift: From (α, j), you can get to (α wj+1, j + 1). Reduce: If Z → γ, then from (αγ, j) you can get to (α Z, j). Final state: (S, n) 从输入的单词开始，每次都是用语法中的规则，试图从底部的单词向上构造剖析树。如果剖析器成功地构造了以初始符号 S 为根的树，而且这个树覆盖了整个输入，那么剖析就获得了成功。同样，以 Book that flight 为例，book 有歧义，可能是动词也可能是名词，所以就有了刚开始的分叉。 对于 bottom-up 的剖析，从一层到下一层时，要寻找被剖析的成分是否与某个规则的右手边相匹配，这与 top-down 的剖析正好相反。最后第二层，把 book 解释为名词的树枝在搜索空间中被剪除，因为语法中没有以 Nominal NP 为右边的规则，因而无法继续剖析。 Top-down vs Bottom-up两种方法各有优缺点。Top-down 策略绝不会浪费时间搜索一个不可能以 S 为根的树，或者说，它不可能去搜索那些在以 S 为根的树中找不到位置的子树；与此相反，bottom-up 策略中，那些不可能导致 S 的树大量存在着，如上面的例子，刚开始就把 book 错误的解释为名词，而在给定语法中，这样的树根本不可能推导出 S。另一方面，top-down 会花费大量努力去产生与输入不一致的根为 S 的树，在 top-down 的图中，第三层六个树里，前四个树的左分支都不能与 book 匹配，因而这些树都不能形成最后的 parse tree。top-down 的这个弱点是由于这种方法在没有检查输入符号之前就开始生成树了，反之，bottom-up 绝不会去搜索那些不是以实际的输入为基础的树。 由此可见，这两种方法都不能有效利用语法和输入单词中的约束条件。 总而言之，Parsing 要解决的两个问题，一个是怎么 avoid repeated work，另一个是怎么解决 ambiguity。 Ambiguity由 CFG 产生的字符串可能有多个 derivation，这就会产生 ambiguity。E.g.VP → Verb NP prefer a morning flightVP → Verb NP PP leave Boston in the morningVP → Verb PP leaving on Tuesday如上，一个 VP 可能有多个规则，因此一个句子也可能有多个 parse tree。 Ambiguity 的来源： Part-of-Speech ambiguity NNS → walks Vi → walks Prepositional Phrase Attachment the fast car mechanic under the pigeon in the box 关于 attachment 带来的 ambiguity，再多讲几句，放在不同的地方修饰不同的词差别是很大的，一个 Prepositional Phrase(PP) 可以跟在前面的名词/动词前面，这就会产生各种歧义。 怎么选择正确的 parse 呢？有一种方法是基于统计数据，在语料库中，看某个 PP 跟在特定名词/动词后面的概率，取概率大的那种 parse。 Grammaticality从语法而言，也有很多种表达，虽然下面的句子有些在我们看来语法上是错误的，然而表达上却是没有问题的123456• I&apos;ll write the company• I&apos;ll write to the company• It needs to be washed• It needs washed• They met Friday to discuss it• They met on Friday to discuss it Summary CFG 提供了一个用于创建语法的工具集 Grammars that work well (for a given application) Grammars that work poorly (for a given application) 关于CFG理论，没有一个先验 prior 来告诉你给定应用的“正确”语法看起来应该是怎样的 一个好的语法通常是： Doesn’t over-generate very much (high precision) Doesn’t under-generate very much (high recall) 在实践中具体情况具体分析 CFG可能不足以完全捕获自然语言的语法 but almost adequate computationally well-behaved not very convenient as a means for hand- crafting a grammar not probabalistic 有些信息抽取问题可以不使用完全剖析，而使用层叠式 FSA(cascade)来解决 Improved AlgorithmsProbabilistic Context-Free Grammar(PCFGs)对 CFG 的最简单的提升就是概率上下文无关语法(PCFG)，又称随机上下文无关语法(Stochastic Context-Free Grammar，简称 SCFG)，其最大贡献是它进行了歧义消解(disambiguation)，来自 Stanford 讲义 上下文无关语法 G 是由四个参数 (N,$\\Sigma$, R, S)来定义的 N: a set of non-terminal symbols $\\Sigma$: a set of terminal symbols R: a set of production rules of the form $A \\ → \\ \\beta$, $A \\in N$, $\\beta \\in (N \\cup \\Sigma)$ $S \\in N$: a distinguished/special start symbol PCFG 的产生式 R 中的每个规则都加上来一个条件概率，从而增强了这些规则：$$A → \\beta [p]$$ 所以 PCFG 是一个五元组 (N,$\\Sigma$, P, S, D)，D 的功能是给 R 中的每个规则指派一个概率，或者说是把给定的 non-terminal 符号 p 展开为符号序列 $\\beta$ 时的概率，这个概率通常表示为 $P(A → \\beta)$，或者 $P(A → \\beta|A)$，一个 non-terminal 符号的所有展开，概率之和为1. PCFG 可以用来估计关于一个句子及其 parse tree 的有用概率的数量。PCFG 可以对于一个句子 S 的每个 parse tree T(也就是每个推导结果)都指派一个概率，这在歧义消解(disambiguation) 中是非常有用的。一个特定 parse tree T 的概率定义为在该 parse tree 中用来展开每个节点 n 的所有规则 r 的概率的乘积：$$P(T,S)=\\prod_{n \\in T} p(r(n))$$所以作为结果的概率 P(T,S)既是剖析和句子的联合概率，又是剖析 P(T)的概率。这是 make sense 的，因为剖析包含了句子中的所有单词，所以 P(S|T)=1,所以有$$P(T,S)=P(T)*P(S|T)=P(T)$$ 歧义消解(disambiguation)例子： 算出 $P(T_l)=1.5*10^{-6}$，$P(T_r)=1.7*10^{-6}$，右侧的 parse tree 具有比较高的概率，所以如果歧义消解算法选择具有最大 PCFG 概率的剖析，那么这个剖析便可以通过这样的歧义消解算法选择正确的结果。 形式化一下，得到给定句子 S 的最佳 parse tree T$$ \\begin{aligned} \\hat T(S) &amp;= argmax_{T \\in \\tau(S)} P(T|S) \\\\ &amp; = argmax_{T \\in \\tau(S)} {P(T|S) \\over P(S)} \\\\ &amp; = argmax_{T \\in \\tau(S)} P(T, S) \\\\ &amp; = argmax_{T \\in \\tau(S)} P(T) \\\\ \\end{aligned}$$ $$P(S) = \\sum_{T \\in \\tau(S)} P(T,S) = \\sum_{T \\in \\tau(S)} P(T)$$ 在 PCFG 中，如果一种语言的所有句子的概率之和为 1，就可以说这个 PCFG 是坚固的(consistent)，有些递归规则会使语法变得不坚固，如概率为 1 的规则 S→S 就会导致概率量的丧失，因为推导永远不会终止。 PCFG 是 robust 的，它考虑了所有的可能，虽然通常带来了很低的概率；它部分解决了 grammar ambiguity 的问题，但并没有那么完美，因为它的独立性假设太强了；同时，PCFG 给出了一个基于概率的语言模型(probabilistic language model)，然而它往往比 trigram model 的表现差的多，因为它缺少 lexicalization 另外，PCFG 假设任何一个 non-terminal 符号的展开与任何其他 non-terminal 符号的展开是独立的，然而这个假设太强了，可以通过 state-splitting 的方式来放宽假设，如下面的 Parent Annotation Tree 和 Marking possessive NPs Tree。同时要注意的是，如果分割太多了，可能会导致稀疏性问题。 Cocke-Kasami-Younger主要是一种 bottom-up 的剖析算法，使用动态规划表来存储结果。输入必须是具有 Chomsky 范式(CNF)的。以 People fish tanks 这个句子，形象化的理解 PCFG 下的 CKY 算法。首先为一个句子建立一个三角形的表格，然后 bottom-up 一层一层向上填充 chart 以前两个单词为例，假定单词的 PoS 已经填充完毕，现在我们要填充最上面的 cell。根据右边的规则找出所有可能的组合，计算概率。注意，如果规则的等式左边是 S，我们只保留最大概率的那个组合。在这个例子里，我们看到有两个可能性能够组成 sentence，S → NP VP 和 S → VP，这种情况下，我们只S → NP VP。 核心算法 完整算法(stanford slides) score, back 两个数组的作用是用空间换时间 worked example 时间复杂度： Worst case: O(n^3*g) Best in worst case Others better in average case Summary: Fills in table bottom-up, using dynamic programming • Only builds constituents that have evidence in the input • Never builds a constituent instance more than once • But it builds things that cannot be used Chomsky Normal Form is annoying 15 - 3 - CKY Parsing -Stanford NLP-Professor Dan Jurafsky &amp; Chris Manning15 - 4 - CKY Example-Stanford NLP-Professor Dan Jurafsky &amp; Chris Manning Earley主要是一种 top-down 的剖析算法，使用动态规划表来有效存储中间结果。与 CKY 算法相比，Earley 的优势在于： Never build things that are useless (goes top-down)，大多数情况下时间复杂度小于 $O(n^3)$ 不用把 grammar 转化成 CNF 范式 如果输入有 N 个单词，Earley 算法会创建一个 N+1 大小的 chart，对于句子中每一个单词的位置，chart 包含一个状态表来表示已经生成的部分剖析树，在句子结尾，chart 把对于给定输入的所有可能的剖析结果进行编码，每个可能的子树只表示一次，并且这个子树表示可以被需要它的所有的剖析共享。 我们用点规则(dotted rules)来表示状态，来分隔走过的进程以及未完成的进程，每个 chart entry 可能含有三种信息： Completed constituents and their locations: S → · VP [0,0] 点在成分左侧，表示这个特定的开始节点 S，第一个 0 表示预测的成分开始于 input string 的开头，第二个 0 表示点也在开头的位置 In-progress constituents: NP → Det · Nominal [1,2] NP 开始于位置 1，Det 已经被成功剖析，期待下一步处理 Nominal Predicted constituents: VP → V NP · [0,3] 点处于两个成分右侧，表示已经成功找到了与 VP 相对应的树，而且这个 VP 横跨在整个 input string 上 从左到右走过 chart 的由 N+1 个状态组成的集合，按顺序处理每个集合中的各个状态，每一步根据具体情况将下面描述的三个操作中的一个应用于每个状态，向前移动后，不会再回溯，直到最后一个状态 S → $\\alpha$ · [0,N]，表示剖析成功。 简单版的步骤 Predict all the states you can upfront Read a word Extend states based on matches Generate new predictions Go to step 2 When you’re out of words, look at the chart to see if you have a winner 假设设有CFG如下：1234567S → NP VPNP → DT NNVP → VBD NPDT → theNN → ratNN → cheeseVBD → ate 下面以 the rat ate the cheese 为输入来演示一下 Earley 算法。12345678910111213141516171819202122S → ● NP VP [0,0] （Predictor）:初始状态 -(0)NP → ● DT NN [0,0] （Predictor）:由初始状态 (0) 得到 -(1)DT → the ● [0,1] (Scanner) :由 (1) 得到 -(2)NP → DT ● NN [0,1] (Completer):由 (1) 和 (2) 归并得到 -(3)NN → rat ● [1,2] (Scanner) :由 (3) 得到 -(4)NP → DT NN ● [0,2] (Completer):由 (3) 和 (4) 归并得到 -(5)S → NP ● VP [0,2] (Completer):由 (0) 和 (5) 归并得到 -(6)VP → ● VBD NP [2,2] (Predictor）:由 (6) 得到 -(7)VBD → ate ● [2,3] (Scanner) :由 (7) 得到 -(8)VP → VBD ● NP [2,3] (Completer):由 (7) 和 (8) 归并得到 -(9)NP → ● DT NN [3,3] （Predictor）:由 (9) 得到 -(10)DT → the ● [3,4] (Scanner) :由 (10) 得到 -(11)NP → DT ● NN [3,4] (Completer):由 (10) 和 (1) 归并得到 -(12)NN → cheese ● [4,5] (Scanner) :由 (12) 得到 -(13)NP → DT NN ● [3,5] (Completer):由 (12) 和 (13) 归并得到 -(14)VP → VBD NP ● [2,5] (Completer):由 (9) 和 (14) 归并得到 -(15) S → NP VP ● [0,5] (Completer):由 (6) 和 (15) 归并得到 -(16) 具体算法 E.g. 具体来看三个操作预测(Predictor)、完成(Completer)、扫描(Scanner)。 Predictor: for non-terminals 用于 dotted-rule 中 dot 右侧为 non-terminal 符号但又不是词类范畴(part-of-speech category)的任何状态 对语法提供的 non-terminal 符号的不同展开，都创造一个新的状态，放到同样一个 chart 中，开始和结束位置与之前相同 S → · VP [0,0]，用 Predictor，就是在第一个 chart entry 中增加状态 VP → · Verb, [0,0] 和 VP → · Verb NP, [0,0] Scanner: for words 用于 dotted-rule 中 dot 右侧为词类范畴(part-of-speech category)的状态 检查 input string，把对应于所预测的词类范畴(part-of-speech category)的状态加入到 chart 中，scanner 操作后，从输入状态中造出一个新的状态 VP → · Verb NP [0,0]，dot 后面是词类，所以 scanner 要在输入中寻找当前的单词，而 book 是一个 verb，与当前状态中的预测匹配，所以创造出一个新的状态 VP → Verb · NP [0,1]，然后把这个新的状态加到 chart 中，跟随在当前处理过的状态之后 Completer: otherwise 状态中的 dot 到达规则右端时，剖析算法成功找到了在输入的某个跨度上的一个特定的语法范畴，completer 的目标就是寻找输入中在这个位置的语法范畴，发现并且推进前面造出的所有状态 NP → Det Nominal · [1,3]，completer 要寻找以 1 为结尾并预测 NP 的状态，找到由 Scanner 造出的状态 VP → Verb · NP [0,1]，结果是加入一个新的完成状态 VP → Verb NP · [0,3] CKY and EarleyCKY 和 Earley 都是 chart parsing 的方法，Earley 是 top-down 的，CKY 是 bottom-up 的。也有两个算法都不能解决的问题，如一致性(agreement)问题：12345678910• Number Chen is/people are• Person I am/Chen is• Tense Chen was reading/Chen is reading/Chen will be reading• Case not in English but in many other languages such as German, Russian, Greek• Gender not in English but in many other languages such as German, French, Spanish 可以用 Combinatorial Explosion 方法来解决，如下，分开表示第一人称NP、第二人称NP、第三人称NP的规则，然而这样的组合太多了。123456– S → NP VP– S → 1sgNP 1sgVP– S → 2sgNP 2sgVP– S → 3sgNP 3sgVP...– 1sgNP → 1sgN 另外一个问题是次范畴化的问题(Subcategorization Frames)，这需要依存算法来解决。12345678910111213141516• Direct object The dog ate a sausage• Prepositional phrase Mary left the car in the garage• Predicative adjective The receptionist looked worried• Bare infinitive She helped me buy this place• To-infinitive The girl wanted to be alone• Participial phrase He stayed crying after the movie ended• That-clause Ravi doesn’t believe that it will rain tomorrow• Question-form clauses She wondered where to go 最后，来回顾一下 CFG 的假设，CFG 假设任何一个 non-terminal 符号的展开与任何其他 non-terminal 符号的展开是独立的，然而这个假设是不成立的，可以看一下下面的例子，这个问题的解决需要引入 Lexicalized grammars。12345678Non-independence– All NPs 11% NP PP, 9% DT NN, 6% PRP– NPs under S 9% NP PP, 9% DT NN, 21% PRP– NPs under VP 23% NP PP, 7% DT NN, 4% PRP– (example from Dan Klein) Constituency Parser Evaluation需要有 label 数据，评价方法如下，上面的 parse tree 是标准的，下面的 parse tree 是算法产生的，我们标注每一个成分的起始和终止位置，然后比较两个 tree，看两个 tree 对应成分的起始和终止位置是否相同，计算 precision，recall，F1，和 tagging accuracy。 Labeled-Precision: 3/7=42.9%Labeled-Recall: 3/8=37.5%LP/LR-F1: 40.0%Tagging-Accuracy: 11/11=100.0% 这种评估方式有其弱点，上层的错误会被下层持续继承，如上面的例子，只有最后一个单词 yesterday 的识别出现了错误，然而一层层传承下来，准确率就变得很低。 参考链接：自然语言处理中的Earley算法","tags":"nlp"},{"title":"NLP 笔记 - Syntax Introduction","url":"/2017/02/27/NLP 笔记 - Syntax Introduction/","text":"CMU 11611 的课程笔记。讲句法的相关概念，sentence parsing 的两大结构(Constituency structure and Dependency structure)，以及Chomsky Hierarchy。 Syntax句法(syntax) 具体来说就是把单词安排在一起的方法，前面我们其实已经涉猎了一些句法知识，如 POS, ngram 等，这一章将介绍相对更复杂的概念。 Syntax is NOT Morphology: 形态学以单词为单位，处理的是单词内部的结构；而句法处理多个单词的各种组合，单位是词组和句子 形态学通常是不规则的；而句法通常是规则的，不规则占小比例，大多数情况下句法由全局的一般规则组成。 Syntax is NOT Semantics: 语义是关于句子的含义；句法是关于句子的结构本身 一个句子在句法结构上可以是 well-formed，然而语义上非常糟糕 E.g. Colorless green ideas sleep furiously 一些比较有名的语言学理论尝试从句法表达中“读取”语义表达 Constituency(组成性)基本思想： 单词的组合可以具有像一个单独的单位或短语那样的功能，这样的单词组合称为成分(constituent)，我们可以通过成分的集合来观察句子结构。 constituent: a group of words that “go together” (or relate more closely to one another than to other words in the sentence). We can view the structure of a sentence as a collection of nested constituents 可以从几个角度来识别成分： Distribution: 一个成分可以是一个能放在句子不同位置的单位(unit)E.g. John talked [to the children] [about drugs]. John talked [about drugs] [to the children]. Substituion/expansion/pro-forms: 可以被替换/扩充的一些 unit，比如说一些状语E.g. I sat [on the box/right on top of the box/there] Coordination/regular internal sturcture/no intrusion/fragments/semantics… 最简单粗暴的方法就是理解为 词组(phrase)，多个单词组成的成分就是词组(phrase)，一个词组可以内嵌多个词组 12345678E.g.Noun Phrases• **The elephant** arrived.• **The big ugly elephant** arrived.Prepositional Phrases(also contains a noun phrase)• I arrived **on ***Tuesday*** **.• I arrived **under the ***leaking roof*** **. Grammatical relation(语法关系)语法关系(grammatical relation) 是传统语法关于主语(SUBJECTS)和宾语(OBJECTS)的思想的形式化，在之后讨论一致关系(agreement)中再具体介绍语法关系，这里先有个印象。 关于主语，我们有下面三种认定事实： 主语是句子中的第一个名词短语 主语是句子中的动作发出者(actor) 主语是 what the sentence is about 所有这些都是对的，但没有一个 always right。 123456789101112131415161718192021222324252627282930313233E.g.– Oswald shot Kennedy– Kennedy was shot by Oswald – Oswald was shot by Ruby– Who shot Oswald?• Active/Passive– Oswald shot Kennedy– Kennedy was shot by Oswald• Relative clauses– Oswald who shot Kennedy was shot by Ruby– Kennedy who Oswald shot didn&apos;t shoot anybody• Syntactic (not semantic)– The batter hit the ball. [subject is semantic agent]– The ball was hit by the batter. [subject is semantic patient]– The ball was given a whack by the batter. [subject is semantic recipient]– &#123;George, the key, the wind&#125; opened the door.• Subject ≠ topic– I just married the most beautiful woman in the world.– Now beans, I like.– As for democracy, I think it’s the best form of government.• English subjects– agree with the verb– when pronouns, in nominative case (I/she/he vs. me/her/him)– omitted from infinitive clauses (I tried __ to read the book, I hoped __ to be chosen)• English objects– when pronouns, in accusative case– become subjects in passive sentences Subcategorization and dependency(次范畴化和依存关系)次范畴化和依存关系(subcategorization and dependency) 涉及到单词和短语之间的某些类别的关系，如动词 want 后可以接不定式(I want to fly to Detroit) 或名词短语(I want a flight to Detroit)，这种事实称为动词的次范畴(subcategorization)，也是之后再讨论。 Two views of linguistic structure Constituency (phrase structure) Phrase structure organizes words into nested constituents. It’s represented by trees generated by a context-free grammar. An important construct is the constituent (complete sub-tree). 通常由上下文无关语法 产生，重要的组成是 成分。一种 bottom-up 的理解是，对一个句子的所有单词进行词性标注，然后根据一定的规则，一步步将其合并为“更大”的成分(产生子树)，直到组成一个句子。 Dependency structure Dependency structure shows which words depend on (modify or are arguments of) which other words. The basic unit is a binary relation between words called a dependency 依存结构(Dependency structure) 两个主要构成部分是 head 和 dependents head: 提供了主要含义(main meaning)的单词 “this smart student of linguistics with long hair” 这个例子中的 head 是 student，而不是 hair 之类的东西 提供了最重要的屈折特征(inflectional features)的单词 Inflection includes things like tense, number, and gender 来看一些 Dependency structure 的作用，一个从句子产生的角度来看，可以通过 head 确定名词词组(noun phrase)的单复数，以此来决定后面动词的单复数。看下面的例子，只有 “teacher/teachers” 这个 head 决定了 noun phrase 是单数还是复数，“class/classes”，“child/children” 并没有什么用。123456789101112131415Singular Plural• The teacher blinks• The short teacher blinks• The teacher of the class blinks• The teacher of the classes blinks• The children’s teacher blinks• The child’s teacher blinks• The teachers blink• The short teachers blink• The teachers of the class blink• The teachers of the classes blink• The children’s teachers blink• The child’s teachers blink 另一个应用是 QA 系统，如下，要回答 Who won an award? 这个问题，可能会有两个答案，student 或者 Alan，然而看 dependency parse tree 可以发现，student 和 won 之间有直接的联系(direct link)，所以结果当然是 student won an award Chomsky HierarchyFormal Grammar一个形式语法(formal grammar) G 定义了一个 formal language，用 L(G)来表示，包括以下部分： N: a set of non-terminal symbols $\\Sigma$: a set of terminal symbols R: a set of production rules of the form $(\\Sigma \\cup N)^* N(\\Sigma \\cup N)^* \\rightarrow (\\Sigma \\cup N)^* $ $S \\in N$: a distinguished/special start symbol 一些术语 Grammatical: a sentence in the language Ungrammatical: a sentence not in the language Derivation: sequence of top-down production steps Parse tree: graphical representation of the derivation A string is grammatical iff there exists a derivation for it. Chomsky Hierarchy Chomsky 根据 production rule 的形式，把形式语法分为4类： 0型语法(type 0 grammar)：重写规则为 φ → ψ，并且要求 φ 不是 empty string。 上下文有关语法(context-sensitive grammar)：重写规则为 φ1Aφ2 → φ1ωφ2，在上下文 φ1-φ2 中，单个的 non-terminal 符号 A 被重写为符号串 ω，所以，这种语法对上下文敏感，是上下文有关的。上下文有关语法又叫做 1型语法。 上下文无关语法(context-free grammar)：重写规则为A → ω，左边是一个 non-terminal 符号，右边是一个或多个 terminal 和 non-terminal 符号。当 A 重写为 ω 时，没有上下文的限制，所以，这种语法对上下文自由，是上下文无关的。上下文无关语法又叫做 2型语法。把上下文无关语法应用于自然语言的形式分析中，就形成了“短语结构语法”(phrase structure grammar) 有限状态语法/正则语法(finite state grammar/regular grammar)：重写规则为 A→aQ 或 A→a。左边必须是一个 non-terminal 符号，右边可以是一个 empty string，或者是一个 terminal 符号，又或者是一个 terminal 符号跟一个 non-terminal 符号，只有这三种情况。如果把 A 和 Q 看成不同的状态，那么，由重写规则可知，由状态 A 转入状态 Q 时，可生成一个终极符号 a，因此，这种语法叫做有限状态语法。有限状态语法又叫做 3型语法。 每一个有限状态语法的都是上下文无关的，每一个上下文无关语法都是上下文有关的，而每一个上下文有关语法都是0型的，Chomsky把由0型语法生成的语言叫0型语言，把由上下文有关语法、上下文无关语法、有限状态语法生成的语言分别叫做上下文有关语言、上下文无关语言、有限状态语言。有限状态语言包含于上下文无关语言之中，上下文无关语言包含于上下文有关语言之中，上下文有关语言包含于0型语言之中。这样就形成了语法的“Chomsky层级”（Chomsky hierarchy）。在自然语言处理中,我们最感兴趣的是上下文无关语法和上下文无关语言,它们是短语结构语法理论的主要研究对象。 Pumping Lemma for Regular Languages An intuition (from Jurafsky &amp; MarEn, p. 533): “…if a regular language has any long strings (longer than the number of states in the automaton), there must be some sort of loop in the automaton for the language. We can use this fact by showing that if a language doesn’t have such a loop, then it can’t be regular.” 如果一个 RL 有任何长字符串（比自动机中的状态数更长），在该语言的自动机中必定有某种循环。我们可以使用这个事实表明，如果一种语言没有这样的循环，那么它不能是 regular 的。 由此可见英语是 regular language123L1 = (the cat|dog|mouse|...)* (chased|bit|ate|...)* likes tuna fishL2 = EnglishL1 ∩ L2 = (the cat|dog|mouse|...)^n (chased|bit|ate|...)^(n-1) likes tuna fish 语法的Chomsky层级","tags":"nlp"},{"title":"NLP 笔记 - Part of speech tags","url":"/2017/02/24/NLP 笔记 - Part of speech tags/","text":"CMU 11611 的课程笔记。介绍 POS 的一些概念和基本算法。 句法(syntax)是 NLP 的骨架，研究单词之间的形式关系 单词怎样聚类称为词类(part-of-speech) 怎样与相邻的单词组合成短语 一个句子的单词与单词之间彼此依赖的方式 这一篇介绍 POS，单词怎样聚类称为词类。 定义词类 又称为 POS(Part Of Speech)、词的分类、形态类或词汇标记，根据形态和句法功能来定义，有以下特点： 分布特征(Distributional) 单词能够出现在相似的环境中 单词有相似的功能 形态特征(Morphological) 单词有相同的前缀后缀(词缀具有相似的功能) 在句法结构中有相似的上下文环境 无关于含义(meaning)，也无关于语法(可以是主语/宾语，等等) 分类分为两大类：封闭类(closed class) 和 开放类(open class)。 封闭类 包含的单词成员相对固定的词类 介词(prepositions)/限定词(determiners)/代词(pronouns)/连接词(conjunctions)/助动词(auxiliary verbs)/小品词(particles)/数词(numerals) 开放类 不断有新的词被创造出来 名词 专有名词(proper noun) 普通名词(common noun) 可数名词(count noun)，物质名词(mass noun) 动词 形容词 副词 应用做自然语言处理的相关任务时，往往我们有太多的单词，需要很多的数据来训练规则，而训练的这些规则会非常的 specific。POS 有助于模型的泛化，并帮助 reduce model size，另外，POS 还有以下的应用： 提供关于单词及其邻近成分的大量有用信息 如区分名词、动词等 知道一个词是主有代词还是人称代词，就能知道什么词会出现在它的近邻(主有代词＋名词，人称代词＋动词) 提供单词发音的信息 有些词既可以做名词也可以做形容词，发音是不同的 -&gt; 更自然的发音 -&gt; 语音合成系统 分割词干(stemming) 单词词类 -&gt; 形态词缀 用于信息检索/信息抽取 自动词义排歧算法/局部剖析(parital parsing) 词类标注及算法POS tagging，给语料库中的每个单词指派一个词类或者词汇类别标记的过程。 输入 单词的符号串和标记集 输出 让每个单词都标上一个单独的而且是最佳的标记 主要有三种标注算法： 基于规则的标注(rule-based tagging) 一个手工制定的歧义消解规则的数据库，规则说明歧义消解的条件 E.g. 当一个歧义单词的前面是限定词时，就可以判断它是名词，而不是动词 随机标注(stochastic tagging) 使用一个训练语料库来计算在给定的上下文中某一给定单词具有某一给定标记的概率 E.g. HMM 基于转换的标注(transformation-based tagging) 规则+机器学习，规则可以由前面已标注好的训练语料库自动推导出来 HMMHMM 又称为隐马尔可夫模型，用概率方法进行 POS 标注。假定标注问题可以通过观察周围的单词和标记来解决。对于一个给定的句子或单词序列，HMM 标注算法选择使得下面的公式为最大值的标记序列：$$P(word|tag)*P(tag|previous \\ n \\ tags)$$ HMM 通常是针对一个句子来选择最好的标记序列，而不是基于一个单词，二元语法 HMM 标注算法对于单词 $w_i$ 选择标记 $t_i$，使得对于给定的前面的标记 $t_{i-1}$ 和当前单词 $w_i$，其概率最大：$$t_i=argmax_jP(t_j|t_{i-1},w_i)$$ Prior p(Y) language model, likelihood of a tag sequence Posterior p(x|y) likelihood of word given ta find the max for both Bayes Rule: P(Y|X)=P(Y)P(X|Y)/P(X) 这个模型也可以进行平滑(用NLP 笔记 - Language models and smoothing提到的回退或者线性差值，来避免零概率 用 Viterbi 算法找出概率最大的标记序列，见Hidden-Markov-Models 举个例子：… Prior: Likelihood of tag sequence… Posterior: MLE of word… 注： P(PropN|Bill) = P(Bill|PropN) * P(PropN|Start) / P(Bill)，这里没有给出 P(Bill)。 Unsupervised PoS Tagging如果单词有相同的上下文(前驱词和后继词分布)，那么它们也会有相同的标记，所以 找到所有的上下文：w1 X w2 找到频率最高的 Xs，然后给 Xs 标记 重复以上过程，直到终止条件(自定义) 对英语来说，可以重复 20 次 E.g. BE/HAVE MR/MRS AND/BUT/AT/AS TO/FOR/OF/IN VERY/SO SHE/HE/IT/I/YOU 然而没有 Nonuns/Verb/Adj 这些识别标记 Brown Clustering是一种自底向上的层次聚类算法(hierarchical agglomeretive)，基于 n-gram 模型和马尔科夫链模型。是一种硬聚类(hard clustering)，每一个词都在且只在唯一的一个类中。 输入：语料库 输出：二叉树 树的叶子节点是一个个词，每个词用类似霍夫曼编码的方式进行编码 树的中间节点是我们想要的类（中间结点作为根节点的子树上的所有叶子为类中的词） 容易 scale 基本思想： 初始的时候，将每一个词独立的分成一类，然后，将两个类合并，使得合并之后 quality 函数最大，然后不断重复上述过程，达到想要的类的数量的时候停止合并。quality 函数，是对于 n 个连续的词（w）序列能否组成一句话的概率的对数的归一化结果。跟踪 cluster 合并的过程，可以从下往上建一个二叉树，每一个单词都被表示为一个 binary string(从根到叶子节点的路径)，每一个中间的节点都是一个类。 Quality = merges two words that have similar probabilities of preceding and following words(More technically quality = smallest decrease in the likelihood of the corpus according to a class-based language model) 关于 class-based language model，可以看Class-Based n-gram Models of Natural Language 形成的二叉树： 算法：1234- Begin with every word in its own cluster- Until we have one cluster: - Merge two clusters based on some measure of quality- Assign each word a bit-string based on the clusters it was in and when they were merged. Ex: Each isolated cluster will have no bit-string. Every time we merge two clusters, set the bit-strings in one cluster to &quot;0&quot; + c1_old_bit_string and the other to &quot;1&quot; + c2_old_bit_string 补充算法 Feature-based tagger——————————————–我是分界线——————————————–之所以叫补充算法，是因为上面所述的算法来自书/PPT，而下面的算法来自 stanford 讲义 Sequence Labeling as Classification123456789101112• Word the: the → DT• Lowercased word Importantly: importantly → RB• Prefixes unfathomable: un- → JJ• Suffixes Importantly: -ly → RB• Capitalization Meridian: CAP → NNP• Word shapes 35-year: d-x → JJ 然后训练一个分类器来预测 tag，当然特征也可以引入上下文(sliding window)，这种方法称为 Sequence Labeling as Classification 更好的特征往往是当前 token 前后 token 的类别，但是我们不知道这些类别，所以要往前/往后看，使用之前的 outputForward Classification Backward Classification Maximum Entropy Markov Model(MEMM)A sequence version of the logistic regression(also called maximum entropy) classifier找到最佳的标记序列，基础算法:$$ \\begin{aligned} \\hat T &amp; = argmax_T P(T|W) \\\\ &amp; = argmax_T \\prod_i P(t_i|w_i,t_{i-1}) \\\\ \\end{aligned}$$ 每个 tag 的特征 更多 feature 用 Viterbi 算法来实现 未知词如何来估计未知词的标记？大概有下面几种办法 假定每个未知词在所有可能的标记中都是有歧义的，也就是说都具有相同的概率 根据上下文相关的 POS trigram 给未知词恰当的标签 在未知词上的标记的概率分布与在训练集中只出现一次的单词的标记的概率分布非常相似 与NLP 笔记 - Language models and smoothing提到的 Good-Turing smoothing 思想类似 使用关于单词拼写的信息 4 类特殊的正词法特征，包括 3 个屈折词尾(-ed,-s,-ing)，32个派生后缀(-ion,-al,-ive,-ly)，4个大写(captial)值(首字母大写，非首字母大写等)以及连字符(hyph)规则 $P(w_i)=P(unknown-word|t_i)P(captial|t_i)P(endings|hyph/t_i)$ 小结各种方法的准确率 词类标注是歧义消解(disambiguation) 的一个重要方面。英语中大多数单词是没有歧义的，然而最常用的单词很多都是有歧义的，如 can 可以是助动词，也可以是名词，还可以是动词，POS 标注的问题就是消解这样的歧义，在一定的上下文中选择恰如其分的标记。 E.g. 参考链接Brown Clustering算法和代码学习Brown Clustering &amp;&amp; Global Linear Models","tags":"nlp part-of-speech 词性标注"},{"title":"NLP 笔记 - Language models and smoothing","url":"/2017/02/24/NLP 笔记 - Language models and smoothing/","text":"CMU 11611 的课程笔记。Language model 在别的课中不管是单机还是分布式都实现过好几次，然而却没有深入系统的研究过。 应用场景Language model 通常有两类目标，一个是 计算句子或一系列单词出现的概率，另一个是 单词预测(word prediction)，通常的应用场景有： Machine Translation P(high winds tonite)&gt;P(large winds tonite) Spell Correction The office is about fifteen minuets from my house P(about fifteen minutes from)&gt;P(about fifteen minuets from) Speech Recognition P(I saw a van) &gt;&gt; P(eyes awe of an) +Summarization,question,answering,etc. 文本预处理问题标点是否把标点算为单词，取决于不同的任务。对于诸如 语法检查、拼写错误检查、作者辨认 这样的任务，标点符号的位置是很重要的。因此这些应用中经常把标点符号看做单词。 大小写大多数统计应用来说，是忽略大小写的，尽管有时候也把大写作为个别的单独特征来处理(在拼写错误更正或词类标注中) 屈折形式 词形(wordform): 在语料库中以屈折形式出现的单词形式 词目(lemma): 具有同一词干、同一主要词类、同一词义的词汇形式的集合 型(type): 语料库中不同单词的数目 例(token): 使用中的单词数目 当前大多数基于 N-gram 的系统都是以词形(wordform)为基础的。所以，cat 和 cats 要分别处理为两个单词。然而在很多领域中，我们想把 cat 和 cats 看成同一个抽象单词的实例，可以用词典，词典中不包含有屈折变化的形式。用词典来计算词目比计算词形更方便。 口语语料库 话段(fragment): 相当于句子 片段(fragment): 一个单词在中间被拦腰切开而形成的，如 main-mainly 有声停顿(filled pause): 如 um, uh 取决于应用的具体情况，如果在自动语音识别的基础上建立一个自动听写系统，我们可能需要把片段剔除。而有声停顿，更倾向于被当成单词来处理，um 和 uh 的意思稍有不同，一般当说话人胸有成竹要说某个话段时，他就 um，而当说话人想说但还没找到恰当的单词来表达时，就用 uh，另外，uh 经常可以用来作为预测下一个单词的线索，所以很多系统都把它当做一个单词来处理。 简单的(非平滑的) N 元语法数学基础Chain Rule$$P(x_1,x_2,x_3,…,x_n) = P(x_1)P(x_2|x_1)P(x_3|x_1,x_2)…P(x_n|x_1,…,x_n,1)$$ Markov AssumptionN-gram 的基本假设是 一个单词的概率只依赖于它前面单词的概率，这也就是 马尔可夫假设。举个例子：P(the | its water is so transparent that) $\\approx$ P(the | that)P(the | its water is so transparent that) $\\approx$ P(the | transparent that) 事实上，马尔可夫链就是一种加权有限状态自动机，加权 FSA 的下一个状态总是依赖于他前面有限的历史(有限自动机的状态数目总是有限的)，bigram 可以看成是每个单词只有一个状态的马尔可夫链，也称为一阶马尔可夫模型，N-gram 称为 N-1 阶马尔可夫模型。 $$P(w_1w_2…w_n) \\approx \\sum_iP(w_i|w_{i-k}…w_{i-1})$$ 再转换下$$P(w_1|w_1w_2…w_n) \\approx \\sum_iP(w_i|w_{i-k}…w_{i-1})$$ Maximum Likelihood Estimate很简单啦，以 Bigram 为例，就是 $P(w_i|w_{i-1})={count(w_{i-1},w_i) \\over count(w_{i-1})}$ Models注意，在下面的模型中，我们用到了 padding，所有 N-gram 模型都用了一个特殊符号来标记句子的结束(STOP_SYMBOL)，N&gt;1 时，另外用一个特殊符号来标记句子的开始(START_SYMBOL)，来方便计算。 Uniform Model假定语言中的任何一个单词后面可以跟随该语言中的任何一个单词，且概率是相等的。如果英语中有 100,000个单词，那么任何一个单词后面跟随其他任何单词的概率将是 1/100,000，即 0.00001 Unigram Model任何一个单词后面可以跟随着其他任何单词，但后面一个单词按照它正常的频度来出现，所以可以根据相对频度对下面将要出现的单词指派一个概率分布的估值。 $$ \\begin{aligned} p(W=w) &amp; = p(W_1=w_1, W_2=w_2,…,W_{L+1}=stop) \\\\ &amp; = (\\prod^L_{l=1}p(W_l=w_l))p(W_{L+1}=stop) \\\\ &amp; = (\\prod^L_{l=1}p(w_l))p(stop) \\end{aligned}$$ Full History Model如果不是简单地看单词相对频度，而是要看单词对于给定历史的条件概率，那么就有了 full history model。 Every word is assigned some probability, conditioned on every history. $$\\begin{aligned} p(W=w) &amp; = p(W_1=w_1, W_2=w_2,…,W_{L+1}=stop) \\\\ &amp; = (\\prod^L_{l=1}p(W_l=w_l|W_{1:l-1}=w_{1:l-1}))p(W_{L+1}=stop|W_{1:L}=w_{1:L}) \\\\ &amp; = (\\prod^L_{l=1}p(w_l|history_l))p(stop|history_L) \\end{aligned}$$ N-Gram Model Every word is assigned some probability, conditioned on a fixed-length history(n-1) $$ \\begin{aligned} p(W=w) &amp; = p(W1=w1, W2=w2,…,W_{L+1}=stop) \\\\ &amp; = (\\prod^L_{l=1}p(W_l=w_l|W_{l-n+1:l-1}=w_{l-n+1:l-1}))p(W_{L+1}=stop|W_{L-n+1:L}=w_{L-n+1:L}) \\\\ &amp; = (\\prod^L_{l=1}p(w_l|history_l))p(stop|history_{L+1}) \\end{aligned}$$ 以 Bigram 为例，假设 &lt;s&gt; 为 START_SYMBOL，&lt;/s&gt; 为 STOP_SYMBOL$$p(w^1_L)=\\prod^L_{l=1}P(w_l|w_{l-1})p(stop|w_{L+1})$$ 文本：123&lt;s&gt; I am Sam &lt;/s&gt;&lt;s&gt; Sam I am &lt;/s&gt;&lt;s&gt; I do not like green eggs and ham &lt;/s&gt; 那么有123456P(I|&lt;s&gt;)=2/3P(Sam|&lt;s&gt;=1/3P(am|I)=2/3P(&lt;/s&gt;|Sam)=1/2P(Sam|am)=1/2P(do|I)=1/3 第一句话的概率就是1P(I|&lt;s&gt;)*P(am|I)*P(Sam|am)*P(&lt;/s&gt;|Sam) 对数(Logprob)由于概率都小于 1，相乘的概率越多，所有概率的乘积就越小，这样就会有数值下溢(underflow)的危险，所以习惯上会采用对数空间来进行计算(加法比乘法快)，给每个概率取对数再相加，最后再取结果的反对数。 归一化(Normalizing)归一化，就是用某个总数来除，使最后得到的概率的值处于 0 和 1 之间，以保持概率的合法性，也就是：$$p(w_n|w_{n-1})={C(w_{n-1}w_n) \\over \\sum_wC(w_{n-1}w)}$$ 要注意的一个优化是，给定单词 $w_{n-1}$ 开头的所有二元语法的计数必定等于该单词 $w_{n-1}$ 的一元语法的计数，也就是说，对一般的 N-gram，参数估计为： $$p(w_n|w^{n-1}_{n-N+1})={C(w^{n-1}_{n-N+1}w_n) \\over C(w^{n-1}_{n-N+1})}$$ Unknown word对 unknown word 的处理，一般我们建一个固定大小的 lexicon(比如说语料库里 frequency&gt;5 的单词)，再新建一个 token &lt;UNK&gt;，不在 lexicon 里的 token (也就是 frequency&lt;5 的单词)都编译成 &lt;UNK&gt;，然后把 &lt;UNK&gt; 当做普通单词处理。 N-gram 对语料库的敏感性直观上的两个重要事实： N 越大 N-gram 的精度也应相应增加 训练模型的上下文越长，句子连贯性也就越好 N-gram 性能强烈依赖于它们的语料库(特别是语料库的种类和单词的容量) 为了很好的在统计上逼近英语，需要一个规模很大、包含不同种类、覆盖不同领域的语料库 平滑(Smoothing)每个特定的语料库都是有限的，从任何训练语料库得到的 bigram 矩阵都是稀疏的(sparse)，存在着大量的零概率 bigram 的场合，当非零计数很小时，MLE 会产生很糟糕的估计值。平滑就是给某些零概率和低概率的 N-gram 重新赋值并给它们指派非零值。 加 1 平滑(add-one smoothing)也叫 Laplace smoothing，假设 we saw each word one more time than we didMLE estimate:$$P_{MLE}(w_i|w_{i-1})={c(w_{i-1}w_i) \\over c(w_{i-1})}$$Add-1 estimate:$$P_{Add-1}(w_i|w_{i-1})={c(w_{i-1}w_i)+1 \\over c(w_{i-1})+V}$$ 加 1 平滑是一种很糟糕的算法，与其他平滑方法相比显得非常差，然而我们可以把加 1 平滑用在其他任务中，如文本分类，或者非零计数没那么多的情况下。 Good-Turing smoothing基本思想: 用观察计数较高的 N-gram 数量来重新估计概率量大小，并把它指派给那些具有零计数或较低计数的 N-gram 首先理解一个概念Things seen once: 使用刚才已经看过一次的事物的数量来帮助估计从来没有见过的事物的数量。举个例子，假设你在钓鱼，然后抓到了 18 条鱼，种类如下：10 carp, 3 perch, 2 whitefish, 1 trout, 1 salmon, 1 eel，那么下一条鱼是 trout 的概率是多少？很简单，我们认为是 1/18 那么，下一条鱼是新品种的概率是多少？不考虑其他，那么概率是 0，然而根据 Things seen once 来估计新事物，概率是 3/18 在此基础上，下一条鱼是 trout 的概率是多少？肯定就小于 1/18，那么怎么估计呢？在 Good Turing 下，$$P^*_{GT} (things \\ with \\ zero \\ frequency)={N_1 \\over N_2}$$$$c^* = {(c+1)N_{c+1} \\over N_c}$$Nc = the count of things we’ve seen c times 所以，c=1时，$C^* (trout)=2*{N2 \\over N1} = 2*1/3 = 2/3$$P^* (trout)={2/3 \\over 18}={1 \\over 27}$ Backoff(回退)直观的理解，如果没有 3gram，就用 bigram，如果没有 bigram，就用 unigram。 Linear Interpolation(线性差值)我们看这样一种情况，如果 c(BURNISH THE) 和 c(BURNISH THOU) 都是 0，那么在前面的平滑方法 additive smoothing 和 Good-Turing 里，p(THE|BURNISH)=p(THOU|BURNISH)，而这个概率我们直观上来看是错误的，因为 THE 要比 THOU 常见的多，$p(THE|BURNISH) \\ ge p(THOU|BURNISH)$ 应该是大概率事件。要实现这个，我们就希望把 bigram 和 unigram 结合起来，interpolate 就是这样一种方法。 用线性差值把不同阶的 N-gram 结合起来，这里结合了 trigram，bigram 和 unigram。用 lambda 进行加权$$ \\begin{aligned} p(w_n|w_{n-1}w_{n-2}) &amp; = \\lambda_1 p(w_n|w_{n-1}w_{n-2}) \\\\ &amp; + \\lambda_2 p(w_n|w_{n-1}) \\\\ &amp; + \\lambda_3 p(w_n) \\end{aligned}$$ $$\\sum_i \\lambda_i=1$$ 怎样设置 lambdas?把语料库分为 training data, held-out data, test data 三部分，然后 Fix the N-gram probabilities(on the training data) Search for lambdas that give the largest probabilities to held-out set:$logP(w_1…w_n|M(\\lambda_1…\\lambda_k))=\\sum_ilogP_M(\\lambda_1…\\lambda_k)(w_i|w_{i-1})$ 这其实是一个递归的形式，我们可以把每个 lambda 看成上下文的函数，如果对于一个特定的 bigram 有特定的计数，假定 trigram 的计数是基于 bigram 的，那么这样的办法将更可靠，因此，可以使 trigram 的 lambda 值更高，给 trigram 更高权重。 $$ \\begin{aligned} p(w_n|w_{n-1}w_{n-2}) &amp; = \\lambda_1 (w^{n-1}_{n-2})p(w_n|w_{n-1}w_{n-2}) \\\\ &amp; + \\lambda_2 (w^{n-1}_{n-2})p(w_n|w_{n-1}) \\\\ &amp; + \\lambda_3 (w^{n-1}_{n-2})p(w_n) \\end{aligned}$$ 通常 $\\lambda w^{n-1}_{n-2}$ 是用 EM 算法，在 held-out data 上训练得到(held-out interpolation) 或者在 cross-validation 下训练得到(deleted interpolation)。$\\lambda w^{n-1}_{n-2}$ 的值依赖于上下文，高频的上下文通常会有高的 lambdas。 更多平滑见 Stanford Language Modeling Evaluation在训练集上训练参数，在测试集上测试 performance，那么之后怎么来评估模型呢？最好的办法当然是 外部评价方法 是把两个模型放到具体的任务环境中(spelling corrector/speech recognizer/MT system)，然后测试模型，比较两个模型的准确率。然而这种方法比较麻烦，所以一般还是用 内部评价方法，perplexity 来评估模型，尽管它不是一个很好的估计(除非真实情况就是 test data 和 training data 是非常相似的)，但好歹也是有用的，一般用于 pilot experiments 中。 Perplexity Perplexity is the inverse probability of test set normalized by the number of words 第二个式子用了 chain rule，第三个式子是 bigram 的情况。举个例子来理解 perplexity，如果一个句子由 0-9 位数字随机生成，那么这个句子的 perplexity 是多少？假定每个 digit 出现的概率都是 1/10。=&gt; PP(W)=(1/10)^-1=10 我们的目标是最小化 perplexity，lower perplexity=better model。 理论基础是 熵(entropy)，熵在 NLP 中是非常有价值的，可以用来度量一个特定语法中的信息量是多少，度量给定语法和给定语言的匹配程度有多高，预测一个给定的 N-gram 中的下一个单词是什么，如果给定两个语法和一个语料库，我们还可以使用熵来估计哪个语法和语料库匹配的更好… 小结 Relative frequencies (count &amp; normalize) Transform the counts: Laplace/“add one”/“add λ” Good-Turing discounting Interpolate or “backoff”: With Good-Turing discounting: Katz backoff – “Stupid” backoff Absolute discounting: Kneser-Ney 更复杂的一些 N-gram 方法 cache LM(Kuhn and de Mori 1990) 用 long-distance trigger 来替代局部 N-gram(Rosenfeld, 1996; Niesler and Woodland, 1999; Zhou and Lua, 1998) 可变长 N-gram(variable-length N-gram)(Ney et al., 1994; Kneser, 1996; Niesler and Woodland, 1996) 用语义信息来丰富 N-gram 基于潜在语义索引(latent semantic indexing)的语义词联想方法(Coccaro and Jurafsk, 1988; Bellegarda, 1999) 从联机词典和类属词典中提取语义信息的方法(Demetriou et al., 1997) 基于类的 N-gram 基于更结构化的语言知识的语言模型(如概率剖析) 使用当前话题的知识来提升 N-gram(Chen et al., 1998; Seymore and Rosenfeld 1997; Seymore et al., 1998; Florian and Yarowsky 1999; Khudanpur and Wu, 1999） 使用言语行为和对话知识来提升 N-gram 参考链接：Stanford Language Modeling","tags":"nlp"},{"title":"django + bootstrap 使用网页模板","url":"/2017/02/23/django + bootstrap 使用网页模板/","text":"项目需要，快速上手 Django 的笔记。 初识 DjangoDjango 使用了类似 MVC 的架构，只是在定义和解释上略为不同，称为 MTV ( Model–Template–View )。 Django 处理 request 的流程: 浏览器送出 HTTP request Django 依据 URL configuration 分配至对应的 View View 进行资料库的操作或其他运算，并回传 HttpResponse 浏览器依据 HTTP response 显示网页画面 另外 Django 无需数据库就可以使用，它提供了对象关系映射器（ORM），可以使用 Python 代码来描述数据库结构。 Install1$ pip install django 查看版本12$ python -m django --version1.10.5 Simple ExampleStart project1$ django-admin startproject mysite 目录结构:1234567mysite/├── manage.py└── mysite ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 各个文件的作用：123456789101112The outer mysite/ root directory is just a container for your project. Its name doesn’t matter to Django; you can rename it to anything you like.manage.py: A command-line utility that lets you interact with this Django project in various ways. You can read all the details about manage.py in django-admin and manage.py.The inner mysite/ directory is the actual Python package for your project. Its name is the Python package name you’ll need to use to import anything inside it (e.g. mysite.urls).mysite/__init__.py: An empty file that tells Python that this directory should be considered a Python package. If you’re a Python beginner, read more about packages in the official Python docs.mysite/settings.py: Settings/configuration for this Django project. Django settings will tell you all about how settings work.mysite/urls.py: The URL declarations for this Django project; a “table of contents” of your Django-powered site. You can read more about URLs in URL dispatcher.mysite/wsgi.py: An entry-point for WSGI-compatible web servers to serve your project. See How to deploy with WSGI for more details. 现在就可以在 mysite 目录下运行了1$ python manage.py runserver 浏览器打开 ‘http://127.0.0.1:8000/‘ 能看到 “Welcome to Django” 的页面。 如果有别的程序占用端口，可以修改 django 运行的端口 1$ python manage.py runserver 8080 修改 server 的 IP1$ python manage.py runserver 0.0.0.0:8000 修改 python 代码并保存时会自动加载 server，不用重新启动。然而，如果有添加文件等操作，就要重新启动了。 Create app1$ python manage.py startapp mysample 目录结构:12345678910111213141516171819mysite/├── manage.py├── mysample│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py└── mysite ├── __init__.py ├── __pycache__ │ ├── __init__.cpython-36.pyc │ └── settings.cpython-36.pyc ├── settings.py ├── urls.py └── wsgi.py Projects vs apps所谓 app 是指完成一些功能的 web 应用，比如博客系统（weblog system），公共记录的数据库（a database of public records）或者是一个简单的投票系统（a simple poll app）。project 是指一个特定网站的一系列配置文件和应用的集合。一个项目（project）可以包含多个应用（app）,一个应用（app）可以被多个项目（project）使用。 ViewsDjango view 其实是一个 function，处理 HttpRequest，并回传 HttpResponse 收到 HttpRequest 参数Django 从网页接收到 request 后，会将 request 中的信息封装产生一个 HttpRequest，并当成第一个参数，传入对应的 view function 需要回传 HttpResponseHttpResponse.contentHttpResponse.status_code …等 编辑 mysample/views.py:1234567from django.shortcuts import renderfrom django.http import HttpResponsefrom django.template import loader# Create your views here.def index(request): return HttpResponse(&quot;Hello, world.&quot;) 这段代码做的是： 从 django.http 中引用 HttpResponse 类别 宣告 hello_world 这个 view 当 hello_world 被呼叫时，回传包含字串 Hello World! 的 HttpResponse URLDjango 需要知道 URL 与 view 的对应关系，这个对应关系就是 URL conf (URL configuration)，通常定义在 urls.py，包含了一连串的规则 (URL patterns)，Django 收到 request 时，会一一比对 URL conf 中的规则，决定要执行哪个 view function 在 mysample 里新建一个 urls.py 文件来 map url，现在的目录结构:1234567891011121314151617181920mysite/├── manage.py├── mysample│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ ├── urls.py│ └── views.py└── mysite ├── __init__.py ├── __pycache__ │ ├── __init__.cpython-36.pyc │ └── settings.cpython-36.pyc ├── settings.py ├── urls.py └── wsgi.py 编辑 mysample/urls.py:123456789from django.conf.urls import urlfrom . import viewsapp_name = &apos;mysample&apos;urlpatterns = [ # ex: /mysample/ url(r&apos;^$&apos;, views.index, name=&apos;index&apos;),] 现在要把这个 urls.py 连到 mysite 上，编辑 mysite/urls.py:12345678from django.conf.urls import include, urlfrom django.contrib import adminurlpatterns = [ # point the root URLconf at the mysample.urls module url(r&apos;^mysample/&apos;, include(&apos;mysample.urls&apos;)), url(r&apos;^admin/&apos;, admin.site.urls),] url() 函数接收四个参数，两个是必需的： regex 和 view，还有两个是可选的：kwargs 和 name。 regex – 定义的 URL 规则－ 规则以 regular expression（正规表示式）来表达 － r&apos;^mysample/&apos; 代表的是 mysample/ 这种 URL － Django 从第一个开始，按顺序依次使用列表里的正则表达式来尝试匹配请求的 URL，直到遇到一个可以匹配的表达式 － 不尝试匹配 GET 或 POST 的参数，也不匹配域名部分 view – 对应的 view function－ 当 Django 找到匹配的正则表达式时，就会调用这个视图函数 － 调用时传递的第一个参数是一个 HttpRequest 对象，后续的参数是所有被正则表达数捕捉的部分 － 如果正则式使用简单捕获，捕获结果会作为位置参数传递；如果使用名字捕获，捕获结果会作为关键字参数传递 url() 参数之 kwargs－ 任意个关键字参数可以作为一个字典传递给目标视图函数 url() 参数之 name－ 给 URL 起个名字，以便在 Django 的模板里无二义性的引用到它 － 这个非常有用的特性允许你只用更改一个文件就能全局性的改变某个 URL 我们使用的 include() 函数只是简单的引用其他的 URLconf 文件，让 URLconf 也能轻松的「即插即用」。请注意 include() 函数的正则表达式不包含 $ 符号（匹配字符串结尾）但是结尾有斜线。当 Django 遇到一个 include()，它砍掉被正则表达式匹配上的部分，并把剩余的字符串发送个作为参数的 URLconf 做进一步处理。 然后运行：1$ python manage.py runserver 打开 ‘http://localhost:8000/mysample/&#39;，就可以看到 “Hello, world.” 主页。 Bootstrap这里使用的模板是SB Admin static 和 templates 文件在 mysite 下新建文件夹 static，把 bootstrap 下载的模板复制到里面，然后在 mysite/mysite 下新建一个 templates 文件夹，把 html 文件复制到里面 目录结构:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102└── mysite ├── manage.py ├── mysample │ ├── __init__.py │ ├── __pycache__ │ │ ├── __init__.cpython-36.pyc │ │ ├── urls.cpython-36.pyc │ │ └── views.cpython-36.pyc │ ├── admin.py │ ├── apps.py │ ├── migrations │ │ └── __init__.py │ ├── models.py │ ├── tests.py │ ├── urls.py │ └── views.py ├── mysite │ ├── __init__.py │ ├── __pycache__ │ │ ├── __init__.cpython-36.pyc │ │ ├── settings.cpython-36.pyc │ │ ├── urls.cpython-36.pyc │ │ └── wsgi.cpython-36.pyc │ ├── settings.py │ ├── templates │ │ └── mysample │ │ └── dashboard.html │ ├── urls.py │ └── wsgi.py └── static ├── css │ ├── bootstrap-rtl.css │ ├── bootstrap-rtl.min.css │ ├── bootstrap.css │ ├── bootstrap.min.css │ ├── plugins │ │ └── morris.css │ ├── sb-admin-rtl.css │ └── sb-admin.css ├── font-awesome │ ├── css │ │ ├── font-awesome.css │ │ └── font-awesome.min.css │ ├── fonts │ │ ├── FontAwesome.otf │ │ ├── fontawesome-webfont.eot │ │ ├── fontawesome-webfont.svg │ │ ├── fontawesome-webfont.ttf │ │ └── fontawesome-webfont.woff │ ├── less │ │ ├── bordered-pulled.less │ │ ├── core.less │ │ ├── fixed-width.less │ │ ├── font-awesome.less │ │ ├── icons.less │ │ ├── larger.less │ │ ├── list.less │ │ ├── mixins.less │ │ ├── path.less │ │ ├── rotated-flipped.less │ │ ├── spinning.less │ │ ├── stacked.less │ │ └── variables.less │ └── scss │ ├── _bordered-pulled.scss │ ├── _core.scss │ ├── _fixed-width.scss │ ├── _icons.scss │ ├── _larger.scss │ ├── _list.scss │ ├── _mixins.scss │ ├── _path.scss │ ├── _rotated-flipped.scss │ ├── _spinning.scss │ ├── _stacked.scss │ ├── _variables.scss │ └── font-awesome.scss ├── fonts │ ├── glyphicons-halflings-regular.eot │ ├── glyphicons-halflings-regular.svg │ ├── glyphicons-halflings-regular.ttf │ ├── glyphicons-halflings-regular.woff │ └── glyphicons-halflings-regular.woff2 └── js ├── bootstrap.js ├── bootstrap.min.js ├── jquery.js └── plugins ├── flot │ ├── excanvas.min.js │ ├── flot-data.js │ ├── jquery.flot.js │ ├── jqu ery.flot.pie.js │ ├── jquery.flot.resize.js │ └── jquery.flot.tooltip.min.js └── morris ├── morris-data.js ├── morris.js ├── morris.min.js └── raphael.min.js 注意要修改 html 里引用 css 和 js 的路径，如：1&lt;link href=&quot;/static/css/bootstrap.min.css&quot; rel=&quot;stylesheet&quot;&gt; 配置修改 mysite 下的 settings.py，添加 templates 的目录路径以及 static files 的目录路径123456789101112131415161718192021222324TEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [&apos;your directory/mysite/mysite/templates&apos;], &apos;APP_DIRS&apos;: True, &apos;OPTIONS&apos;: &#123; &apos;context_processors&apos;: [ &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.request&apos;, &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, ], &#125;, &#125;,]# Static files (CSS, JavaScript, Images)# https://docs.djangoproject.com/en/1.10/howto/static-files/STATIC_URL = &apos;/static/&apos;STATICFILES_DIRS = ( &apos;your directory/mysite/static/&apos;,) 渲染修改 mysample/views.py，渲染 html 文件而不是仅仅输出一段文字1234567from django.shortcuts import renderfrom django.http import HttpResponsefrom django.template import loader# Create your views here.def index(request): return render_to_response(&apos;index.html&apos;) 效果图 参考链接Django简易教程之一（models）Django documentDjango-intro 中文版","tags":"django 前端 bootstrap"},{"title":"推荐系统--隐语义模型LFM","url":"/2017/02/17/推荐系统--隐语义模型LFM/","text":"主要介绍 隐语义模型 LFM(latent factor model)。 隐语义模型最早在文本挖掘领域被提出，用于找到文本的隐含语义，相关名词有 LSI、pLSA、LDA 等。在推荐领域，隐语义模型也有着举足轻重的地位。下述的实验设计见 推荐系统–用户行为和实验设计 算法基本思想核心思想: 通过隐含特征(latent factor)联系用户兴趣和物品。具体来说，就是对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。基于兴趣分类的方法需要解决3个问题： 如何对物品进行分类？ 如何确定物品对哪些类的物品感兴趣，以及感兴趣的程度？ 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？ 如何对物品进行分类？物品分类往往是通过人工编辑进行，然而人工编辑存在很多缺陷 编辑的分类大部分是从书的内容出发，而不是从书的读者群出发。 比如说《具体数学》这本书，人工编辑可能认为属于数学，而这本书的读者可能更多是计算机出身的，会认为它属于计算机 编辑很难控制分类的粒度 有些推荐我们做粗粒度就可以了(比如说初学者)，而有些推荐我们需要深入到细分领域(比如资深研究人员) 编辑很难给一个物品多个分类 编辑很难给出多个维度的分类 编辑很难决定一个物品在某一个分类中的权重 隐含语义分析技术(latent variable analysis)采取基于用户行为统计的自动聚类，可以较好解决上面提出的问题。 代表用户意见 分类来自对用户行为的统计，和 ItemCF 在物品分类方面的思想类似，如果两个物品同时被多个用户喜好，那么这两个物品可能属于同一个类 控制分类粒度 自定义分类个数 一个物品多分类 计算出物品属于某个类的权重，因此每个物品都不是硬性地被分到某一个类中 多维度分类 基于用户的共同兴趣计算出来的，如果用户的共同兴趣是某一个维度，那么 LFM 给出的类也是相同维度 物品在分类下的权重 统计用户行为决定物品在某一个分类中的权重，如果某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重可能比较高 算法隐含语义分析技术有很多著名的模型和方法，相关的名词有 pLSA、LDA、隐含类别模型(latent class model)、隐含主题模型(latent topic model)、矩阵分解(matrix factorization)，这些技术和方法本质上是相通的，很多方法都可以用于个性化推荐系统。本篇只介绍 LFM。 用户对物品的兴趣计算用户 u 对物品 i 的兴趣$$Preference(u,i)=r_{ui}=P^T_uq_i=\\sum^F_{f=1}p_{u,k}q_{i,k}$$ $p_{u,k}$: 模型参数，用户 u 的兴趣和第 k 个隐类的关系 $q_{i,k}$: 模型参数，第 k 个隐类和物品 i 之间的关系 产生负样本我们这里用的是隐反馈数据集，只有正样本(用户喜欢什么物品)，而没有负样本(用户对什么物品不感兴趣)，因此第一个问题是如何对每个用户产生负样本。 Rong Ran 提出了以下方法。 对于一个用户，用他所有没有过行为的物品作为负样本 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证没给用户的正负样本数目相当 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品 Rong Ran 表示第一种负样本太多，计算复杂度高，精度也差，而第三种优于第二种，第二种优于第四种。 另外需要遵循的原则是： 对每个用户，要保证正负样本的平衡(数目相似) 对每个用户采样负样本时，要选取哪些很热门，但用户却没有行为的物品 对于冷门物品，可能用户压根没发现，所以谈不上是否感兴趣 负样本采样过程123456789101112131415161718&apos;&apos;&apos;items: dictionary of items where user takes actionitems_pool: list of candidate items; the more popular item i is, the more often item i appear&apos;&apos;&apos;def RandomSelectNegativeSample(self, items): ret = dict() for i in items.keys(): ret[i] = 1 n=0 for i in range(0, len(items) * 3): # make the number of negative samples close to that of positvie item = items_pool[random.randint(0, len(items_pool) - 1)] if item in ret: continue ret[item] = 0 n+=1 if n &gt; len(items): break return ret 损失函数及学习过程得到一个用户-物品集 K={(u,i)}，如果(u,i)是正样本，则有 $r_{ui}=1$，否则$r_{ui}=0$，然后通过随机梯度下降来优化损失函数找到最合适的参数 p 和 q： $\\lambda ||p_u||^2 + \\lambda ||q_i||^2$ 是防止过拟合的正则化项，$\\lambda$ 通过实验获得。 12345678910111213141516171819def LatentFactorModel(user_items, F, N, alpha, lambda): [P, Q] = InitModel(user_items, F) for step in range(0,N): for user, items in user_items.items(): samples = RandSelectNegativeSamples(items) for item, rui in samples.items(): eui = rui - Predict(user, item) for f in range(0, F): P[user][f] += alpha * (eui * Q[item][f] - lambda * P[user][f]) Q[item][f] += alpha * (eui * P[user][f] - lambda * Q[item][f]) alpha *= 0.9def Recommend(user, P, Q): rank = dict() for f, puf in P[user].items(): for i, qfi in Q[f].items(): if i not in rank: rank[i] += puf * qfi return rank 实验4 个隐类中排名最高的一些电影 参数： 隐特征个数 F 学习速率 alpha 正则化参数 lambda 负样本/正样本比例 ratio 实验发现，ratio 对 LFM 性能影响最大，随着负样本数目的增加，LFM 的准确率和召回率有明显提高，当 ratio &gt; 10后趋于稳定，同时，随着负样本数目增加，覆盖率不断降低，流行度不断增加，说明 ratio 参数控制了推荐算法发掘长尾的能力。另外，与之前实验比较，在所有指标上都优于 UserCF 和 ItemCF。然而当数据集非常稀疏时，LFM 的性能会明显下降。 固定 F=100, alpha=0.02, lambda=0.01,研究 ratio 对推荐性能的影响。 实际应用LFM 模型在实际使用中有一个困难，就是很难实现实时推荐。经典的 LFM 模型每次训练都需要扫描所有的用户行为记录，并且需要在用户行为记录上反复迭代来优化参数，所以每次训练都很耗时，实际应用中只能每天训练一次。在新闻推荐中，冷启动问题非常明显，每天都会有大量的新闻，这些新闻往往如昙花一现，在很短的时间获得很多人的关注，然后在很短时间内失去关注，实时性就非常重要。雅虎对此提出了一个解决方案。 首先，利用新闻链接的内容属性(关键词、类别等)得到链接 i 的内容特征向量 yi，其次，实时收集用户对链接的行为，并且用这些数据得到链接 i 的隐特征向量 qi，然后，利用下面的公式预测用户 u 是否会单击链接 i: $$r_{ui}=x^T_uy_i+p^T_uq_i$$ $y_i$: 根据物品的内容属性直接生成$x_{uk}$: 用户 u 对内容特征 k 的兴趣程度，用户向量 $x_u$ 可以根据历史行为记录获得，每天计算一次$p_u$,$q_i$: 实时拿到的用户最近几小时的行为训练 LFM 模型获得 对于一个新加入的物品 i，可以通过 $x^T_uy_i$估计用户 u 对物品 i 的兴趣，然后经过几个小时后，通过 $p^T_uq_i$得到更准确的预测值。 小结与基于邻域的方法相比的优缺点：","tags":""},{"title":"推荐系统--基于邻域(neighborhood-based)的协同过滤算法","url":"/2017/02/10/推荐系统--基于邻域的协同过滤算法/","text":"主要介绍 基于用户的协同过滤算法(UserCF) 和 基于物品的协同过滤算法(ItemCF)。 基于邻域的算法是推荐系统中最基本的算法，主要分两大类，一类是基于用户的协同过滤算法，另一类是基于物品的协同过滤算法。协同过滤的本质其实是 KNN，我们要定义的是 什么是“最匹配”。下述的实验设计见 推荐系统–用户行为和实验设计 基于用户的协同过滤算法(User CF)当一个用户 A 需要个性化推荐时，先找到和他有相似兴趣的其它用户，然后把那些用户喜欢的、而用户 A 没有听说过的物品推荐给 A。强调 把和你有相似爱好的其他的用户的物品推荐给你 过程： 将一个用户对所有物品的偏好作为一个向量来计算用户之间的相似度，找到和目标用户兴趣相似的用户集合； 找到这个集合中的用户喜欢的，且目标用户没有访问过的物品，计算得到一个排序的物品列表作为推荐。 算法与实验用户-用户计算用户之间的相似度。 Jaccard 公式$$W_{uv}={|N(u) \\cap N(v)| \\over |N(u) \\cup N(v)|}$$ N(u): 用户 u 喜欢的物品集合 N(v): 用户 v 喜欢的物品集合 余弦相似度$$W_{uv}={|N(u) \\cap N(v)| \\over \\sqrt{|N(u) || N(v)|}}$$ 123456789def UserSimilarity(train): W = dict() for u in train.keys(): for v in train.keys(): if u == v: continue W[u][v] = len(train[u] &amp; train[v]) W[u][v] /= math.sqrt(len(train[u]) * len(train[v]) * 1.0) return W 算法优化:对两两用户都计算余弦相似度，时间复杂度是 O(|U|*|U|)，在用户数很大的时候非常耗时。而很多用户相互之间并没有对同样的物品产生过行为，很多时候 $|N(u) \\cap N(v)|=0$，有计算的浪费。所以可以换个思路，首先计算 $|N(u) \\cap N(v)| \\neq 0$ 的用户对 (u,v)，然后再对这种情况除以分母 $\\sqrt{|N(u) || N(v)|}$ 具体做法： 建立物品到用户的倒排表对于每个物品都保存对该物品产生过行为的用户列表令稀疏矩阵 $C[u][v]=|N(u) \\cap N(v)|$E.g. 用户 u 和 v 同时属于倒排表中 K 个物品对应的用户列表，就有 $C[u][v]=K$ 建立用户相似度矩阵扫描倒排表中每个物品对应的用户列表将用户列表中的两两用户对应的 $C[u][v]$ 加 1，得到所有用户之间不为 0 的 $C[u][v]$ 代码：123456789101112131415161718192021222324def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i in items.keys(): if i not in item_users: item_users[i] = set() item_users[i].add(u) #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u in users: N[u] += 1 for v in users: if u == v: continue C[u][v] += 1 #calculate finial similarity matrix W W = dict() for u, related_users in C.items(): for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 用户-物品用户 u 对物品 i 的感兴趣程度 S(u,K): 和用户 u 兴趣最接近的 K 个用户 N(i): 对物品 i 有过行为的用户集合 $w_{uv}$: 用户 u 和用户 v 的兴趣相似度 $r_{uv}$: 用户 v 对物品 i 的兴趣，单一行为的隐反馈数据下，所有的 $r_{uv}=1$ 代码12345678910def Recommend(user, train, W): rank = dict() interacted_items = train[user] for v, wuv in sorted(W[u].items, key=itemgetter(1), reverse=True)[0:K]: for i, rvi in train[v].items: if i in interacted_items: #we should filter items user interacted before continue rank[i] += wuv * rvi return rank UserCF 实验UserCF 只有一个重要的参数 K，即每个用户选出 K 个和他兴趣最相似的用户。不同 K 值下 UserCF 算法的性能指标 对比实验： Random 算法每次随机挑选 10 个用户没有产生过行为的物品推荐给用户准确率和召回率远高于 Random 算法，但覆盖率非常低，结果都非常热门 MostPopular 算法按照物品的流行度给用户推荐他没产生过行为的物品中最热门的 10 个物品准确率和召回率很低，但覆盖率很高，结果平均流行度很低。 参数 K 的影响： 准确率和召回率没有线性关系，在一定区域内都可以获得不错的精度 流行度K 越大 UserCF 推荐结果越热门K 越大参考的人越多，推荐结果就越趋近于全局热门的物品 覆盖率K 越大，覆盖率越低越趋近于推荐全局热门的物品，长尾物品的推荐越来越少 用户相似度优化考虑 idf 类似影响，如果绝大多数人都买过《新华字典》，并不能说明他们兴趣相似，所以需要惩罚用户 u 和用户 v 共同兴趣列表中热门物品对他们相似度的影响，通过 ${1 \\over log1+|N(i)|}$ 代码12345678910111213141516171819202122232425def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i in items.keys(): if i not in item_users: item_users[i] = set() item_users[i].add(u) #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u in users: N[u] += 1 for v in users: if u == v: continue C[u][v] += 1 / math.log(1 + len(users)) #calculate finial similarity matrix W W = dict() for u, related_users in C.items(): for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W UserCF-IIF 实验 发现 UserCF-IIF 在各项性能上略优于 UserCF。 小结相比于 ItemCF，UserCF 在目前的实际应用中使用并不多。 优点和适用场景： 可以发现用户感兴趣的热门物品 用户有新行为，不一定造成推荐结果的立即变化 适用于用户较少的场合，否则用户相似度矩阵计算代价很大 适合时效性较强，用户个性化兴趣不太明显的领域 缺点： 数据稀疏性。一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到相似用户。 算法扩展性。随着用户数量越来越大，计算用户相似度矩阵越来越困难，时空复杂度的增长和用户数的增长近似于平方关系。 对新用户不友好，对新物品友好，因为用户相似度矩阵不能实时计算 很难提供令用户信服的推荐解释 基于物品的协同过滤算法(Item CF)假设：物品 A 和物品 B 具有很大的相似度是因为喜欢物品 A 的用户大多也喜欢物品 B通过分析用户的行为记录计算物品之间的相似度。强调 把和你喜欢的物品相似的物品推荐给你。在京东、天猫上看到「购买了该商品的用户也经常购买的其他商品」，就是主要基于 ItemCF。 过程： 基于用户对物品的偏好计算相似度，找到相似的物品； 根据物品的相似度和用户的历史行为预测当前用户还没有表示偏好的物品，计算得到一个排序的物品列表作为推荐。 过程： 计算物品之间的相似度 根据物品的相似度和用户的历史行为给用户生成推荐列表 算法与实验物品-物品Jaccard 公式:$$W_{ij}={|N(i) \\cap N(j)| \\over |N(i)|}$$ N(i): 喜欢物品 i 的用户数 $|N(i) \\cap N(j)|$: 喜欢物品 i 和物品 j 的用户数 同样的，考虑 idf 影响：如果物品 j 很热门，很多人都喜欢，那么 $W_{ij}$ 就会很大，接近 1，也就是说，任何物品会和热门的物品有很大相似度，所以惩罚物品 j 的权重，减轻热门物品和许多物品相似的可能性。 $$W_{ij}={|N(i) \\cap N(j)| \\over \\sqrt{|N(i) || N(j)|}}$$ 和 UserCF 类似，ItemCF 也可以首先建立用户-物品倒排表(每个用户建立一个包含他喜欢的物品的列表)，然后对于每个用户，将他物品列表中的物品两两在共现矩阵 C 中加 1。 代码123456789101112131415161718def ItemSimilarity(train): # calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i in users: N[i] += 1 for j in users: if i == j: continue C[i][j] += 1 # calculate final similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 左边是输入的用户记录，每一行代表一个用户感兴趣的物品集合，然后对每个物品集合，将里面对物品两两加一，得到一个矩阵。最终将这个矩阵相加得到 C 矩阵，其中 $C[i][j]$ 记录了同时喜欢物品 i 和物品 j 的用户数，最后，将 C 矩阵归一化可以得到物品之间的余弦相似度矩阵 W。 用户-物品得到物品的相似度后，计算用户 u 对一个物品的兴趣： 和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。 N(u): 用户喜欢的物品集合 S(j,K): 和物品 j 最相似的 K 个物品的集合 $w_{ji}$: 物品 j 和 i 的相似度 $r_{ui}$: 用户 u 对物品 i 的兴趣隐反馈数据集，如果用户 u 对物品 i 有过行为，即可令 $r_{ui}=1$ 123456789def Recommendation(train, user_id, W, K): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), key=itemgetter(1), reverse=True)[0:K]: if j in ru: continue rank[j] += pi * wj return rank ItemCF 实验不同 K 值下的性能 参数 K 的影响： 准确率和召回率没有线性关系，在一定区域内都可以获得不错的精度 流行度随着 K 的增加，流行度逐渐提高当 K 增加到一定程度，流行度不再有明显变化 覆盖率K 越大，覆盖率越低 用户活跃度对物品相似度的影响举个例子吧，一个用户，是开书店的，买了亚马逊上 80% 的书准备用来自己卖，所以购物车里包含了亚马逊上 80% 的书，假设亚马逊一共有 100 万本书，那么这意味着 80 万本书两两之间产生了相似度，内存里将诞生一个 80w * 80w 的矩阵。然而，虽然用户很活跃，但这些书并非基于兴趣，而且这些书覆盖了亚马逊图书的很多领域，所以这个用户对他所购买书对两两相似度的贡献应该远远小于一个只买了十几本自己喜欢的书的文学青年。所以我们需要一个 IUF(Inverse User Frequency)，来修正物品相似度的计算公式 为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中。1234567891011121314151617def ItemSimilarity(train): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i in users: N[i] += 1 for j in users: if i == j: continue C[i][j] += 1 / math.log(1 + len(items) * 1.0) #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 可以看到，ItemCF-IUF 明显提高了覆盖率 物品相似度的归一化将相似度矩阵按最大值归一化，可以提高推荐的准确率、覆盖率和多样性。对相似度矩阵 w 进行 $$w’_{ij}={w_{ij} \\over max_j w_{ij}}$$ 举个例子，假设有 A、B 两类物品，A 类物品之间的相似度是 0.5，B 类物品之间的相似度是 0.6，A 类物品和 B 类物品之间的相似度是 0.2，如果一个用户喜欢了 5 个 A 类物品和 5 个 B 类物品，ItemCF 推荐的是 B 类物品，而如果归一化之后，A 类物品的相似度和 B 类物品的相似度都是 1，那么推荐列表中 A 类物品和 B 类物品的数目也应该是大致相等的，这就保障了多样性。 归一化后的性能 小结因为物品直接的相似性相对比较固定，所以可以预先在线下计算好不同物品之间的相似度，把结果存在表中，当推荐时进行查表，计算用户可能的打分值。 优点和适用场景： 可以发现用户潜在的但自己尚未发现的兴趣爱好 有效的进行长尾挖掘 利用用户的历史行为给用户做推荐解释，使用户比较信服 适用于物品数明显小于用户数的场合，否则物品相似度矩阵计算代价很大 适合长尾物品丰富，用户个性化需求强的领域 缺点： 对新用户友好，对新物品不友好，因为物品相似度矩阵不需要很强的实时性 UserCF vs ItemCF总的而言，UserCF 的推荐更社会化，着重于反应和用户兴趣相似的小群体的热点，ItemCF 的推荐更个性化，着重于维系用户的历史兴趣。大家都觉得 Item CF 从性能和复杂度上比 User CF 更优，其中的一个主要原因就是对于一个在线网站，用户的数量往往大大超过物品的数量，同时物品的数据相对稳定，因此计算物品的相似度不但计算量较小，但这种情况只适应于提供商品的电子商务网站，对于新闻，博客或者微内容的推荐系统，情况往往是相反的，物品的数量是海量的，同时也是更新频繁的。一般来说，这两种算法经过优化后，最终得到的离线性能是近似的。具体选择还是要看具体情境。 社交网络/新闻领域适用 UserCF： 用户兴趣不是特别细化绝大多数都喜欢看热门的新闻，即使是个性化，也是比较粗粒度的，如体育/新闻这种大类。 个性化新闻推荐更加强调抓住新闻热点热门程度和时效性是个性化推荐的重点，UserCF 可以给用户推荐和他有相似爱好的一群其他用户今天都在看的新闻，这样在抓住热点和时效性的同时，保证了一定程度的个性化。 物品的更新速度远远快于新用户的加入速度在新闻网站中，物品的更新速度远远快于新用户的加入速度，而且对于新用户，完全可以给他推荐最热门的新闻。ItemCF 需要维护一张物品相关度的表，如果物品更新很快，那么这种表也需要很快更新，这在技术上很难实现。 非社交网络如图书/电商/电影网站，适用 ItemCF 用户的兴趣比较持久 用户不太需要流行度来辅助他们判断一个物品的好坏，而是可以通过自己熟悉领域的只是自己判断物品的质量 个性化推荐的任务是帮助用户发现和他研究领域相关的物品。 物品数目较少，物品相似度相对于用户的兴趣一般比较稳定。 提供推荐解释 对比 哈利波特问题主要指某个物品太热门导致很多物品都与之相关。 解决方案： 分母上加大对热门物品的惩罚$$W_{ij}={|N(i) \\cap N(j)| \\over |N(i)|^{1- \\alpha} |N(j)|^{\\alpha}}$$ $\\alpha \\in [0.5,1]$，通过提高 $\\alpha$，就可以惩罚热门的 j。$\\alpha$ 越大，覆盖率越高，结果的平均热门程度就越低，因此通过这种方法可以在适当牺牲准确率和召回率的情况下显著提升结果的覆盖率和新颖性(降低流行度即提高了新颖性)。 然而，这并不能彻底解决哈利波特问题。每个用户一般都会在不同的领域喜欢一种物品。两个不同领域的最热门物品之间往往具有比较高的相似度，这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等，这些就不是协同过滤讨论的范畴了。","tags":"nlp recommender-systems 推荐系统"},{"title":"推荐系统--用户行为和实验设计","url":"/2017/02/08/推荐系统--用户行为和实验设计/","text":"主要介绍推荐系统用户行为数据、实验设计，是接下来算法实验的基础。 用户行为用户行为数据用户行为分为 显性 和 隐性 两种。 显性反馈行为(explicit feedback)用户评分、喜欢/不喜欢 隐性反馈行为(implicit feedback)页面浏览行为、消费行为 两者比较 如何表示用户： user id产生行为的用户 item id产生行为的对象 behavior type行为的种类(如购买还是浏览) context产生行为的上下文，包括时间和地点 behavior weight行为的权重(用户评分、观看时长等) behavior content行为的内容(评论文本、标签等) 数据集的一般分类： 无上下文信息的隐性反馈数据集包含 user id, item id如 Book-Crossing 无上下文信息的显性反馈数据集包含 user id, item id, 物品评分 有上下文信息的隐性反馈数据集包含 user id, item id, 用户对物品产生行为的 timestamp如 Lastfm 有上下文信息的显性反馈数据集包含 user id, item id, 物品评分, 用户对物品产生行为的 timestamp如 Netflix Prize 用户行为分析物品流行度 和 用户活跃度 都近似于 长尾分布。下图表示用户活跃度和物品流行度的关系(MovieLens 数据集)。 一般认为，新用户倾向于浏览热门物品，因为对网站不熟悉，只能点击首页的热门物品，而老用户会逐渐开始浏览冷门物品。 仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法，有很多种方法，这里介绍 基于邻域的方法(neighborhood-based), 隐语义模型(latent factor model), 基于图的随机游走算法(random walk on graph)，这其中，最有名、在业界得到最广泛应用的算法是基于邻域的方法。接下来的博客会一一讨论这些算法。 实验设计数据集采用 GroupLens 提供的 MovieLens 数据集，选中等大小的数据集，包含 6000 多用户对 4000 多部电影的 100 万条评分。 实验目的研究隐反馈数据集中的 Top N 推荐问题，因此忽略数据集中的评分记录。预测的是用户会不会对某部电影评分，而不是预测用户在准备对某部电影评分对前提下会给电影评多少分。 注意这里隐反馈数据集只有正样本(用户喜欢什么物品)，而没有负样本(用户对什么物品不感兴趣)。 实验过程离线实验。 将用户行为数据集均匀的随机分成 M 份(这里取 8)挑一份作为测试集，剩下 M-1 份作为训练集 在训练集上建立用户兴趣模型，在测试集上评测，统计评测指标 M 次实验，每次使用不同的测试集M 次试验的评测指标取平均值防止过拟合如果数据集够大，模型够简单，为了快速通过离线实验初步选择算法，也可以只进行一次实验 12345678910def SplitData(data, M, k, seed): test = [] train = [] random.seed(seed) for user, item in data: if random.randint(0,M) == k: test.append([user,item]) else: train.append([user,item]) return train, test 评测指标 准确率 召回率 覆盖率 新颖度 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def Precision(train, test, N): hit = 0 all = 0 for user in train.keys(): tu = test[user] rank = GetRecommendation(user, N) for item, pui in rank: if item in tu: hit += 1 all += N return hit / (all * 1.0)def Recall(train, test, N): hit = 0 all = 0 for user in train.keys(): tu = test[user] rank = GetRecommendation(user, N) for item, pui in rank: if item in tu: hit += 1 all += len(tu) return hit / (all * 1.0)def Coverage(train, test, N): recommend_items = set() all_items = set() for user in train.keys(): for item in train[user].keys(): all_items.add(item) rank = GetRecommendation(user, N) for item, pui in rank: recommend_items.add(item) return len(recommend_items) / (len(all_items) * 1.0)def Popularity(train, test, N): item_popularity = dict() for user, items in train.items(): for item in items.keys(): if item not in item_popularity: item_popularity[item] = 0 item_popularity[item] += 1 ret = 0 n=0 for user in train.keys(): rank = GetRecommendation(user, N) for item, pui in rank: ret += math.log(1 + item_popularity[item]) n += 1 ret /= n * 1.0 return ret 该实验设计用于接下来 基于邻域的方法(neighborhood-based), 隐语义模型(latent factor model), 基于图的随机游走算法(random walk on graph) 的博客中。","tags":"nlp recommender-systems 推荐系统"},{"title":"CMU 11642 Search Engines - 大纲梳理","url":"/2017/02/06/CMU 11642 Search Engines - 大纲梳理/","text":"CMU 11642 的课程笔记大纲。涉及了很多算法，详细见具体的链接，代码就不贴了。欢迎讨论，欢迎指正～ Jamie 搜索引擎这门课，还是很有收获的，课上除了一些基本概念和算法外还有很多最新研究，涵盖内容非常广，绝对不止一本书。据 Jamie 讲，在 yahoo 等公司搜索部门的学生回来说现在做的工作感觉就是当年做的作业，是否有夸张不知道，然而大家可以感受下。已经过了选课阶段，就当给下一届想选的小盆友一点 workload 信息吧： reading notes。每周有大量的 reading，可能是教材也可能是论文。注意 reading notes 的成绩是 binary 的，1 or 0，不要以为在 blackboard 上看到自己是 80 分就以为有了0.8，80分＝0分！ homework。五次作业完成一个完善的 search engine，语言是 java，大概三四十个类，每次都是在上一次的基础上进一步改进，所以除了最后一次作业外，你做的每一次作业的 performance 都将深深的影响下一次。如果你发现你的运行时间比 Callen 给的时间要长很多，请务必进行优化。作业不难，通常是让你实现各种算法，常用的以及某些论文中的，然而评分很严，很多 corner case 要注意。每次作业完成都有一篇 report，需要做很多实验(四五十个至少吧，不写脚本的话感觉可以从天黑做到天亮)，并做“深刻”总结，之所以说“深刻”是因为有时候我绞尽脑汁写的东西得到的评语是 shallow。一把心酸泪。一般来说一天写算法再一天过全部的 test case，最后做实验写 report。 exam。期中期末两次考试，上过 text analytics 的人都知道，Callen 的一贯风格，考试广度优先，题量大，靠本能，你腾出时间来思考你就输了，给分低。 但是说了这么多不要怕！！就算考试成绩再低你的最后分数也会很好看！！ 关于能不能 hold 住，这么说吧我上学期还选了 Machine learning(11601A)，Distributed Systems(95702)，以及 Data Structures for Application Programmers(08722)，感觉 4 门课老实说大课只能 focus 一到两门，如果各位还要刷题找工作，还是建议 P/F 或者是 audit 一门。 然后回到正题，高度总结下，这门课就讲了两个问题，一个是如何准确匹配查询与文档，一个是如何快速返回检索结果，就是 效果 vs 效率 的一个权衡。下面的总结梳理了这门课的重点，其中会涉及很多具体算法，然而这只是简单的提纲，不能把公式/算法都列出来，具体的可以看下面的链接或者看书/讲义。透露一点：多数的算法项目里你都需要去实现，而不需要实现的算法，Jamie 也不会轻易放过你，所以你们觉得会在哪里出现呢？😁 文档表示源文档到索引的过程：Raw data –(Format Parser)–&gt; Canonical format –(Lexical Analyzer)–&gt; Index terms –(Index data structures)–&gt; Indexer 元描述(Meta-descriptions)- Fields (author, title, inlink, url) 关键词、受控词汇(controlled vocabulary)scheme 由识别文档主题的规则、指定词库、索引术语、分配索引的规则四部分组成 - 优点 § 召回率高 § 支持浏览和搜索 § 在医学、法律、专利方面比较流行 - 不足 § 人工标注创建和维护的成本很高 § 人工标注可能不一致 § 检索受限制 自动文档表示(Free-text or full-text index terms) 一般用词袋(Bag of Words)，文档由该文档中出现的词的集合所表示 ○ 优点 § 简单、有效 ○ 缺点 § 无法从词袋表示恢复原文档 § 忽略了词之间和句法关系以及篇章结构的信息 过程： 1. 符号化(Tokenization):识别词的边界 2. 停用词(Stop Words) 过滤不具有内容信息的词，停用词表依赖于具体文档集及具体应用 ○ 优点 § 停用词并不能提高检索效果 § 大幅减少索引大小 § 缩短检索时间 ○ 不足 § 难以满足某些特殊的 query(to be or not to be) 3. 词语形态规范化(Normalization) 规范化词语的形态信息: 时态，数量，如 company &amp; companies, sell &amp; sold 4. 词根(Stemming) 处理词缀信息 ○ 优点 § 更准确地表示文档 § 匹配更广泛的查询 ○ 不足 § Stemming 的结果可能不是词语 § 不相关的词可能具有相同的 stem 5. 词形还原(Lemmatization) 将词语变为其语法原型(syntactic stem)，使用一般规则与例外处理，处理过程要考虑词性的不同 ○ 优点 § 更准确地表示文档 § 匹配更广泛的查询 大部分互联网搜索引擎并不使用 stemming/lemmatization § 文档集很大 § 不太考虑召回率 § Stemming 结果并不完美 大部分互联网搜索引擎使用停用词表，Jammie Callen 课上好像说现在不怎么用？ Search Engines笔记 - Document RepresentationsNLP 笔记 - Words, morphology, and lexicons 文档索引 目的在于提高检索效率 索引词项的统计特性- Heaps定律：对词项数目的估计 - Zipf定律：对词项的分布建模 索引分类- Term dictionary - Inverted lists § 重点。常用的有 frequency inverted lists 和 positional inverted lists。 § 可看做连标数组，每个链表的表头包含关键词，其后序单元则包括所有包括这个关键词的文档标号，以及一些其他信息，如该词的频率和位置等 - Attributes - Fields masks - Forward Index - ... 索引对象通常采用 word 构建索引 词组怎么办？ - 事前处理 precoordinate(只有一个 inverted list)，合并可能的词组，interest rate -&gt; interest_rate - 事后处理 postcoordinate(有多个 inverted lists)，查询的时候加上 #NEAR/1。interest rate -&gt; #NEAR/1(interest rate) 索引算法- 单机版 - BSBI(Block sort-based indexing) - SPIMI(Single-pass in-memory indexing) - 分布式索引 - 技术：sharding, replication, MapReduce - 优化：分层索引 - 索引压缩 - Delta Gap - Variable Byte Encoding - 索引优化 - Skip lists，考虑 operators(如 #NEAR,#WINDOW,#SYN,Boolean AND，调整指针) 以及 Top-Docs(截取部分 top docs) - 一个 term 多个 inverted list，比如一份不存位置信息，一份存，对于不需要位置信息的 operator，就用前一个索引 - 动态索引 - 周期性索引重构 - 辅助索引 数据结构- 一般采用 B-Tree(B+ tree, B* tree)，易于扩展，用于完全匹配(exact-match lookup)，范围寻找(range lookup)，前缀寻找（prefix lookup） - 哈希表，不易于扩展，用于完全匹配(exact-match lookup) Search Engines笔记 - Index Construction 查询处理 TAAT(Term-at-a-time)每处理完一个 inverted list，部分更新文档分数，再处理下一个。 - 优点：高效，易于理解 - 缺点：可能爆内存，因此很少用在 large-scale systems DAAT(Document-at-a-time)每处理一篇文档，就算出 complete score，再处理下一篇文档。 - 优点：易于进行内存管理，可以进行 query evaluation 的优化，常用在大规模的系统 - 缺点：效率没有 TAAT 高 TAAT/DAAT hybrids平衡 Efficiency 和 memory control Eg. block-based TAAT(compute TAAT over blocks of document ids) Search Engines笔记 - Query Processing 信息检索模型 基本思想如果一篇文档与一个查询相似，那么该文档与查询相关 相似性- 字符串匹配 - 相似的词汇 - 相同的语义 检索模型 - 完全匹配模型／布尔模型(Boolean Model) - Unranked boolean model，只有匹配不匹配，没有分数。 - Ranked boolean model，为文档计算特定分数。 ○ 优点 § 简单，效率高 § 可预测，可解释，对查询严格掌控 ○ 缺点 § 一般用户难以构造布尔查询 § 严格匹配，导致过少或过多的检索结果 § 很难在 Precision 和 Recall 间得到平衡 尽管布尔模型不再用作主流文档检索模型，但其思想常用于实现高级(综合)检索功能 - 最佳匹配模型(Best-Match Model) 衡量一篇文档与 information need 的匹配程度，与完全匹配模型（匹配／不匹配）相比更注重用户体验，不管有没有匹配都会返回文档结果。有很多种方法，但说到底公式其实都和 tf-idf 的公式相似。 1. 向量空间 Vector space retrieval model(VSM) - 思想: 文档与查询都是高维空间中的一个向量 - 向量空间表示 - 文档是词语组成的向量 - 词语是文档组成的向量 - 查询是词语组成的向量 - 相似性 - 用内积衡量 ○ 缺点 § 长文档由于更可能包含匹配词语，因而更可能相关 § 然而，如果两篇文档具有同样的相似值，用户更倾向于短文档，短文档更聚焦在用户信息需求上 § 相似性计算中应该考虑文档长度(进行规范化) - 用夹角来衡量 - 考虑 tf, idf, doclen - tf: 词语出现的频率 - idf: 区别不同词语的重要性 - doclen: 对文档长度进行补偿 - 其他相似性度量 - Minkowski metric(dissimilarity) - Euclidian distance(dissimilarity) - Jacquard measure - Dice&apos;s coefficient ○ 优点 § 简单有效 ○ 缺点 § 过于灵活，自己设置 term weight，确定相似度度量方法，自己设置怎么支持 query-independent weights 2. 概率理论 Probabilistic retrieval model(BM25) - RSJ weight * tf weight * user weight ○ 优点 § 有很强的概率理论支持 § 在新的环境中参数可以被调整 § 在大量的 evaluation 中都非常有效 ○ 缺点 § 经验调整参数 3. 统计语言模型 Statistical language model(query likelihood) 生成两个模型，一个文档的语言模型，一个查询的语言模型，有两种方案来对文档进行排序， - query likelihood 加上 Jelinek-Mercer Smoothing 和 Bayesian Smoothing With Dirichlet Priors - KL divergence 4. 推理网络 Inference networks(Indri) - document + smoothing parameter(α,β) -&gt; language model(θ) -&gt; language model vocabulary(r) Document Priors与 query 无关的用来评估文档价值的 estimates(query independent)，主要有 spam score, PageRank, length of url 等，与上面的算法结合可以综合评估网页的分数。 Search Engines笔记 - Exact-match retrievalSearch Engines笔记 - Best-Match 个性化 基本逻辑：- Representation: 描述用户的兴趣/偏好 - Learning: 从数据中学习兴趣/偏好 - Ranking: 在检索算法中使用兴趣/偏好 主要方法：- 基于话题 - 根据用户的长期检索历史对用户建模，得到的用户模型是在类别标签上的一个概率分布 - 对排序列表进行 rerank，top n 的文档是两个分数的组合: - 原始文档分数 - 文档类别和用户兴趣类别的匹配分数 - 长期 vs 短期 将用户信息分为长期信息、短期信息、长期＋短期信息三组信息，每个特征都分别从这三组信息中分别提取出来，然后训练分类器 - 典型 vs 非典型信息需求 - 根据用户长期检索历史创建 user profile - 判断非典型信息需求 - 衡量 profile 和 session 的 divergence - 从用户历史记录里得到的每个 session feature 的 divergence - session 和 historical vocabularies 的 cosine 距离 - session 和 historical topic categories 的 cosine 距离 - 提取特征，训练分类器 Search Engines笔记 - Personalization 多样性一个 query 可能表达了不同的信息需求，相关性模型可能带来的结果是大多文档只能满足同一个信息需求，我们希望检索到的文档是多样性的，能够覆盖到大多数的需求，满足更多用户。 算法- Implicit Methods query intent 隐含在文档排名中，假设相似的文档涵盖了相似的 intent - Maximum Marginal Relevance (MMR) - 基于相似度，对文档重排序。 - 重排序的标准是选择与 query 相似度高的，但和之前已经选出来的文档的相似度低的文档 - Learning to Rank - 相当于 MMR 的有监督版本 - 和 ListMLE 相同，写下 likelihood function，计算 MLE.. - Explicit Methods 明确定义了 query intent，对文档重新排序，以便覆盖所有的 query intent - xQuAD 选择涵盖多个 intents 的文档，给需要覆盖的 intents 赋予较高的权重 - PM-2 然后选择一个覆盖这个 intent 的文档，如果这个文档能覆盖其它 intents，那么给它加分 评价指标- Precision-IA@k - α-NDCG Search Engines笔记 - Diversity 联合搜索对一个 query，我们可以放到合适的多个垂直数据库里检索，然后合并结果呈现给用户。 Resource representation(资源表达)- 获取每个数据库的信息 - 通常用 query-based sampling 方法 Resource selection(资源选择)对资源进行排序，对每个查询选择少量资源进行检索 - 无监督算法 看作资源排序的问题，估计 P(ri|q) - content-based methods - Bag-of-words method - 对各个资源下 query 和 resource 的相似度 S(q,c) 来对资源进行排序 - 将一个资源看作一个大的词袋 - E.g. CORI - query 和 resource 的相似度，这并不是我们的初衷 - Sample documents method - 对每个资源采样然后合并得到一个 centralized index，记录每个文档来自哪个 resource - E.g. ReDDE - 高的召回率和准确率，通常来说效果都大于等于 CORI，尤其是数据库大小分布是 skewed 时 - query-based methods 对 query，搜索各个资源下的 query log，找出 match 的 query，然后求当前 query 和历史 query 的相似度 S(q,qpast)，对资源进行排序 - 监督算法 给定一个查询，选择一个或更多的 verticals 将问题定义为一个 “one-vs-all” 的分类任务 - 对每个 vertical 都训练一个分类器 - 对 “no vertical” (web only) 也训练一个分类器 - 选择一个/多个具有最高置信度(confidence score)的分类器 Result-merging(结果合并)即对来自不同搜索引擎／数据库对结果进行 merge，产生最终展现给用户的 ranking list。 用所有的 sampled documents 创建一个 index，从选定的资源里检索文档，对每个文档计算 sim (q, d)，同时根据数据库情况计算每个文档的 authority score，最后分数就是 score(d) = f ( sim (q, d), authority (d) ) - Semi-Supervised method - 对每个文档我们有两个分数，Sample index (resource neutral) score，Resource i (resource-specific) score - 学习 f (resource-specific) = resource-neutral 思路可以用于大规模分布式搜索引擎 Search Engines笔记 - Federated SearchSearch Engines笔记 - ReDDE Algorithm for Resource Selection Web 检索 Web 检索 = 文档检索 + 针对 Web 检索的新技术 Web 页面采集 爬虫：快速有效地收集尽可能多的有用 Web 页面，包括页面之间的链接结构- Web 爬虫需要具备的特性 - 健壮 robustness, 避免 spider traps - 友好 politeness, 遵守 web server 的采集协议 - 分布式 distributed, 多台机器分布式采集 - 可扩展 scalable, 爬虫架构方便扩展 - 性能与效率，有效利用系统资源 - 质量 quality, 倾向于采集有用的页面 - 新颖 freshness, 获取网页的最新版本 - 可扩充 Extensible, 能够处理新数据类型、新的采集协议等 - Web 页面爬取策略 - 深度优先 - 广度优先 - 实际应用中以广度优先为主，深度优先为辅 - 难点 - 暗网的采集，只有向数据库提交查询才形成的 Web 页面 - Web 2.0 内容，脚本语言等生成的动态内容 - 多媒体内容 Web 页面排序 页面排序值 = 页面内容相关度 +/* 页面重要性 Web 链接分析- 理论基础：Web 页面之间的超链关系非常重要，一条从页面 A 指向页面 B 的链接表明 - A 与 B 相关 - A 推荐/引用/投票/赞成 B - 经典算法 - PageRank - Topic-Sensitive PageRank(TSPR) - T-Fresh - HITS - Hypertext Induced Topic Selection 基于学习的网页排序Learning to Rank 主要包括三个类别 - Pointwise - 训练数据是一个文档类别或分数 - Accurate score ≠ accurate ranking - 忽略文档的位置信息 - Pairwise - 训练数据是文档对的一个偏好(一对文档选哪个) - Accurate preference ≠ accurate ranking - 忽略文档的位置信息 - Listwise - 训练数据是文档的排名 - 难以直接优化 ranking metrics 主流算法有 - RankSVM - RankNet - ListNet Learning to Rank 工具包 - RankLib - people.cs.umass.edu/~vdang/ranklib.html 评价指标 - WTA(Winners take all) - MRR(Mean Reciprocal Rank) - MAP(Mean Average Precision) - NDCG(Normalized Discounted Cumulative Gain) - RC(Rank Correlation) Search Engines笔记 - Authority Metrics聚类-小土刀爬虫总结(一)– 爬虫基础 &amp; python实现爬虫总结(二)– scrapy爬虫总结(三)– cloud scrapy爬虫总结(四)– 分布式爬虫爬虫总结(五)– 其他技巧爬虫总结–汇总贴 伪相关反馈Pseudo Relevance Feedback 自动产生更好的 query。基本逻辑 是把原始查询当做分类器，用它来给部分数据打标签，得到 top-ranked documents，然后用 labeled data 来产生更优的 classifier。基本过程： 用原始 query 检索文档 取结果的前 N 篇文档作为训练集，这些文档相关度可能不高，然而我们的目的是学习 vocabulary pattern。 应用 relevance feedback algorithm 选取 term 和 term weight 组成新的 query 来检索文档 Query expansion 平均能使 MAP 提高 20% 但同时也有可能让 1/3 的用户感到 annoy 所以通常来说，query expansion 会用在召回率很重要的场景，或者 average performance 很重要的场景，比如 legal retrieval, TREC, research paper 等。 Search Engines笔记 - Pseudo Relevance Feedback 信息检索评价 评价检索模型或搜索引擎的性能 主要考虑搜索质量 vs 搜索效率，这里主要谈搜索质量 评测数据集一般人工构建 构成 - 文档集合(documents) - 信息需求(information needs)及查询集(queries) - 相关性判断(relevance judgements) 已有评测集 - TREC § trec.nist.gov § 最具影响力 § 多种信息检索任务，侧重于英文 - NTCIR § research.nii.ac.jp/ntcir/ - CLEF § www.clef-campaign.org 评价指标衡量检索结果与标准答案的一致性 - 对 Unranked Retrieval(非排序检索)的评价 - Precision and Recall - P@n - F-Measure - Average Results(Micro, Macro) - 对 Ranked Retrieval(排序结果)的评价 考虑相关文档在检索结果中的排序位置，考虑在不同 recall levels 的 precision 值 - AP and MAP - MRR (Mean Reciprocal Rank) - NDCG (Normalized Discounted Cumulative Gain) - RBP (Rank-Biased Precision) 评价方法 - Cranfield Methodology 1. 获得文档(documents)集合 2. 获得信息需求(information needs)集合 3. 获得相关性判断(relevance judgments) 4. 计算(Measure)各种方法找到相关文档的效果 5. 比较(Compare)各个方法的有效性 - 动态环境下的评价(Interleaved) 主要用 Interleaved testing 方法。通常输入是两个排序列表，分别由不同方法产生，输出是一个排序列表，由输入的所有文档重新排序产生。 - Balanced interleaving 第一次决定从哪个方法开始，然后交替把文档加入 interleaved ranking，如果遇到了已经评估过的文档，就直接 counter++，但是不把文档加进 interleaved ranking 里。 - Team-draft interleaving 每一轮都随机产生先取哪种方法，如果有重复，跳过，取下一个。 一般来说，我们更多的会使用 Cranfield，因为 § Cranfield 更成熟，已经使用了很多年而且易于理解 § Cranfield 支持大量的 metrics，能提供更多关于 ranking behavior 的信息 § Cranfield 几乎在所有场景下都使用，而 Interleaving 需要有 query traffic § 尽管如此，interleaving 仍然是一个很有用的工具，在 Inexpensive, adaptive, sensitive to small differences 的情景下效果较好 Search Engines笔记 - Evaluating Search Effectiveness 搜索日志最重要的是两个问题 How to represent users1. 从日志中得到 (user,query) pairs 2. 为用户创建 pseudo documents - 标题: user id - 内容: 每条 query 的前 10 篇文档对应的 Yahoo! 分类目录 3. 计算相似度 e.g. JS divergence, cosine Segmenting search logs into sessions- 把 search log 划分为一个个基于信息需求的 dialogue，实际就是用户发出初始查询，搜索引擎给出结果，用户不满意，重新修改查询语句再次搜索，然后得到新的结果，不断循环知道解决问题/放弃检索，这期间的行为就构成了 dialogue - 划分可以考虑的因素：时间、相同的 term、编辑距离、相同点击、文档类别、分类器等等 Search Engines笔记 - Search logs 搜索引擎优化(SEO)提高网站或网页在搜索引擎中可见度(排名)的过程 基本思想- 基于各类搜索引擎的工作原理(采集、索引、排序等)，对网站进行相关的优化的调整，提高网站在搜索引擎中的排名 - 白帽：合理优化，不牺牲用户体验 - 黑帽：不正当优化，牺牲用户体验 § 重复、隐藏文字、链接工厂、桥页、跳页 影响排名的因素- 内部因素 § URL 中出现关键词 § 网页 Title 中出现关键词 § 常规内容中出现关键词 § 在页面的最后一段中出现关键词 § &lt;Head&gt; 标签 比如 h1, h2 中出现关键词 § 站内的链接中出现关键词 § 导向相关内容的导出链接 § 导出链接中出现关键词 § 图片文件名中出现关键词 § Alt 标签中出现关键词 § comment 中出现关键词 § 合理的频率更新内容 § 内容对搜索引擎的展示位置 § 网站结构循环 PR, 而非散发 PR § 关键词进行适当的修饰(加粗、斜体等) - 外部因素 § 大量的导入链接 § 从高 PR 值的网页获得导入链接 § 从相关内容网站获得导入链接 § 导入链接指向的网页有具体内容 § 锚文字中有关键词 § 锚文字周围有相关词 § 锚文字存在于文章或句子中 § 导入链接的时间长度，一般导入链接的存在时间有3-6个月 § 单向链接的价值高于交换链接 § 导入链接的页面的导出链接小于 100 个，流出链接越少越好 § 链接来自不同 IP § 合理的导入链接增长频率 SEO 操作- 站外 SEO § 网站外部链接优化、网站的链接见识、网站的外部数据分析等 § 交换、购买链接，提交网址到分类目录等 - 站内 SEO § 网站结构的设计、网站代码优化和内部链接优化、网站内容的优化、网站用户体验优化等 建议：丰富网站关键词、主题集中、友好的网页结构、避免重复、有规律的更新等 聚类-小土刀 所有课程笔记:Search Engines笔记 - Exact-match retrievalSearch Engines笔记 - Query ProcessingSearch Engines笔记 - Evaluating Search EffectivenessSearch Engines笔记 - Document RepresentationsSearch Engines笔记 - Best-MatchSearch Engines笔记 - Information NeedsSearch Engines笔记 - Pseudo Relevance FeedbackSearch Engines笔记 - Index ConstructionSearch Engines笔记 - CacheSearch Engines笔记 - Learning to RankSearch Engines笔记 - Search logsSearch Engines笔记 - Document StructureSearch Engines笔记 - Authority MetricsSearch Engines笔记 - PersonalizationSearch Engines笔记 - ReDDE Algorithm for Resource SelectionSearch Engines笔记 - Federated SearchSearch Engines笔记 - Diversity","tags":"nlp search-engines"},{"title":"OSX OpenCV for Python2.7/Python3.5 环境配置","url":"/2017/02/03/OSX OpenCV for Python2.7:Python3.5 环境配置/","text":"OpenCV 的环境配置。讲怎样用 conda 为 python 2.7 和 python 3.5 安装 opencv。 Setup python3安装Anaconda Python 3，因为它自动配置了很多 dependencies，方便我们之后使用。按要求安装好后记得重新开一个 terminal 然后输入 python 验证版本。12345MacBook-Pro-2:~ Shuang$ pythonPython 3.6.0 |Anaconda 4.3.0 (x86_64)| (default, Dec 23 2016, 13:19:00)[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; Install OpenCV12345678910111213$ pip install pillow...Successfully installed olefile-0.44$ conda install -c menpo opencv3=3.1.0Fetching package metadata ...........Solving package specifications: .UnsatisfiableError: The following specifications were found to be in conflict: - opencv3 3.1.0* -&gt; python 2.7* -&gt; openssl 1.0.1* - python 3.6*Use &quot;conda info &lt;package&gt;&quot; to see the dependencies for each package. 遇到版本不兼容的问题，尝试了各种各样的方法都不行，最后猜着可能是 python 3.6 版本太高了？于是决定尝试一下 python 3.5，结果居然成功了。。。123$ conda create -n python3.5 python=3.5$ source activate python3.5$ conda install -c menpo opencv3=3.1.0 记得每次都要 source 一下。 测试一下：123456$ python3.5Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul 2 2016, 17:52:12)[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; exit() 如法炮制，python 2.7 也成功安装了。12345678910$ conda create -n python2.7 python=2.7$ source activate python2.7$ python2.7Python 2.7.13 |Anaconda 4.3.0 (x86_64)| (default, Dec 20 2016, 23:05:08)[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.Anaconda is brought to you by Continuum Analytics.Please check out: http://continuum.io/thanks and https://anaconda.org&gt;&gt;&gt; import cv2&gt;&gt;&gt; exit() Install moviepy安装 moviepy 来处理 video，以后要用。1$ pip install moviepy Jupyter Notebook在 python3 的环境下可以通过 jupyter notebook 来进行交互，运行部分代码并查看结果。1$ jupyter notebook 如何让 jupyter notebook 也能运行 python 2 呢？尝试了网上的方法12python2 -m pip install --upgrade ipykernel # install the kernel package for Python 2python2 -m ipykernel install # register the Python 2 kernelspec 然而总是报错12345678910111213141516171819202122232425262728293031Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/Python/2.7/site-packages/pip/commands/install.py&quot;, line 317, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip/req/req_set.py&quot;, line 742, in install **kwargs File &quot;/Library/Python/2.7/site-packages/pip/req/req_install.py&quot;, line 831, in install self.move_wheel_files(self.source_dir, root=root, prefix=prefix) File &quot;/Library/Python/2.7/site-packages/pip/req/req_install.py&quot;, line 1032, in move_wheel_files isolated=self.isolated, File &quot;/Library/Python/2.7/site-packages/pip/wheel.py&quot;, line 247, in move_wheel_files prefix=prefix, File &quot;/Library/Python/2.7/site-packages/pip/locations.py&quot;, line 153, in distutils_scheme i.finalize_options() File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/command/install.py&quot;, line 346, in finalize_options self.create_home_path() File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/command/install.py&quot;, line 565, in create_home_path os.makedirs(path, 0700) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py&quot;, line 150, in makedirs makedirs(head, mode) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py&quot;, line 150, in makedirs makedirs(head, mode) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py&quot;, line 150, in makedirs makedirs(head, mode) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py&quot;, line 157, in makedirs mkdir(name, mode)OSError: [Errno 13] Permission denied: &apos;/Users/sure/Library/Python/2.7&apos;You are using pip version 7.1.2, however version 9.0.1 is available.You should consider upgrading via the &apos;pip install --upgrade pip&apos; command. 发现下面这种方法可以成功123conda create -n py2 python=2 anacondasource activate py2ipython kernel install","tags":"driverless-car"},{"title":"NLP 笔记 - Spelling, Edit Distance, and Noisy Channels","url":"/2017/02/02/NLP 笔记 - Spelling, Edit Distance, and Noisy Channels/","text":"CMU 11611 的课程笔记。这一篇介绍拼写的检查和更正，主要研究打字者键入的文本，同时这样的算法也可以应用于 OCR 和手写体识别。 这篇博客要解决的三个问题： Detecting isolated non-words(非词错误检查)如 giraffe 拼写成 graffe Fixing isolated non-words(孤立词错误改正)把 graffe 更正为 giraffe，但只在孤立的环境中寻找这个词 Fixing errors in context(依赖于上下文的错误检查和更正)真词错误，用上下文来检查和更正拼写错误。如把 I ate desert 改为 I ate dessert 拼写错误模式Kukich(1992) 把人的打字错误分为两大类：打字操作错误(typographic error) 和 认知错误(cognitive error)。 打字操作错误(typographic error)一般与键盘有关，如 spell 拼成了 speel包括 插入(insertion)，脱落(deletion)，替代(substitution)，换位(transposition)占所有错误类型的大多数 认知错误(cognitive error)由于写文章的人不知道如何拼写某个单词造成的 语音错误: 用语音上等价的字母序列来替代，如 separate 拼成了 seperate 同音词错误: 如用 piece 来替代 peace 所以单词的拼写错误其实有两类，Non-word Errors 和 Real-word Errors。前者指那些拼写错误后的词本身就不合法，如错误的将“giraffe”写成“graffe”；后者指那些拼写错误后的词仍然是合法的情况，如将“there”错误拼写为“three”（形近），将“peace”错误拼写为“piece”（同音），这一篇主要讲 Non-word Errors。 补充： OCR 错误分为五类：替代、多重替代、空白脱落、空白插入和识别失败 非词错误的检查与更正非词错误的检查一般有两种方法，一是 使用词典，二是 检查序列 使用词典看键入词是否出现在了词典中。用来做拼写错误检查的词典一般还要包括形态分析模式，来表示能产性的屈折变换和派生词。词典通常是哈希表，用 integer 代替 string，来提高 performance。 检查序列这个方法是自己概括的。类似于 “letter combination” 的思想。截取单词的部分字母，来检查这个字母序列在词典中出现的频率如何，是不是根本不会出现这种排列组合，如 “xy” 这个序列就基本不会出现在单词中，所以判断这个词是错误的。然而截取的长度很难定义，而且也需要使用词典。 非词错误改正查找词典中与 error 最近似的词，常见的方法有 Shortest weighted edit distance 和 Highest noisy channel probability。 编辑距离(edit distance)编辑距离，顾名思义，把一个符号串转换为另一个符号串所需的最小编辑操作的次数(how many letter changes to map A to B)。Leetcode 上有相应的题目。 编辑距离的 4 种转换方式 插入(insertion) 脱落(deletion) 替代(substitution) 换位(transposition) 示例123456789• Substitutions– E X A M P E L– E X A M P L E 2 substitutions• Insertions– E X A P L E– E X A M P L E 1 insertion• Deletions– E X A M M P L E– E X A _ M P L E 1 deletion 下图表示如何从 intention 变换到 execution。 由上图可知 intention 变换到 execution 的 Levenshtein 距离是 5。 算法最小编辑距离的算法。用动态规划(dynamic programming)来解决。只有插入(insertion)/脱落(deletion)/替代(substitution)三种操作的 Levenshtein 距离： 加上 transposition 的 Levenshtein 距离： Levenshtein Distance1234567891011121314151617181920212223242526272829function LevenshteinDistance(char s[1..m], char t[1..n]): // for all i and j, d[i,j] will hold the Levenshtein distance between // the first i characters of s and the first j characters of t // note that d has (m+1)*(n+1) values declare int d[0..m, 0..n] set each element in d to zero // source prefixes can be transformed into empty string by // dropping all characters for i from 1 to m: d[i, 0] := i // target prefixes can be reached from empty source prefix // by inserting every character for j from 1 to n: d[0, j] := j for j from 1 to n: for i from 1 to m: if s[i] = t[j]: substitutionCost := 0 else: substitutionCost := 1 d[i, j] := minimum(d[i-1, j] + 1, // deletion d[i, j-1] + 1, // insertion d[i-1, j-1] + substitutionCost) // substitution return d[m, n] intention 变换到 execution 的最小编辑距离。 Damerau-Levenshtein(DL) distance123456789101112131415161718192021222324252627282930313233343536algorithm DL-distance is input: strings a[1..length(a)], b[1..length(b)] output: distance, integer da := new array of |Σ| integers for i := 1 to |Σ| inclusive do da[i] := 0 let d[−1..length(a), −1..length(b)] be a 2-d array of integers, dimensions length(a)+2, length(b)+2 // note that d has indices starting at −1, while a, b and da are one-indexed. maxdist := length(a) + length(b) d[−1, −1] := maxdist for i := 0 to length(a) inclusive do d[i, −1] := maxdist d[i, 0] := i for j := 0 to length(b) inclusive do d[−1, j] := maxdist d[0, j] := j for i := 1 to length(a) inclusive do db := 0 for j := 1 to length(b) inclusive do k := da[b[j]] ℓ := db if a[i] = b[j] then cost := 0 db := j else cost := 1 d[i, j] := minimum(d[i−1, j−1] + cost, //substitution d[i, j−1] + 1, //insertion d[i−1, j ] + 1, //deletion d[k−1, ℓ−1] + (i−k−1) + 1 + (j-ℓ−1)) //transposition da[a[i]] := i return d[length(a), length(b)] Optimal String Alignment(OSA) distance12345678910111213141516171819202122232425algorithm OSA-distance is input: strings a[1..length(a)], b[1..length(b)] output: distance, integer let d[0..length(a), 0..length(b)] be a 2-d array of integers, dimensions length(a)+1, length(b)+1 // note that d is zero-indexed, while a and b are one-indexed. for i := 0 to length(a) inclusive do d[i, 0] := i for j := 0 to length(b) inclusive do d[0, j] := j for i := 1 to length(a) inclusive do for j := 1 to length(b) inclusive do if a[i] = b[j] then cost := 0 else cost := 1 d[i, j] := minimum(d[i-1, j ] + 1, // deletion d[i, j-1] + 1, // insertion d[i-1, j-1] + cost) // substitution if i &gt; 1 and j &gt; 1 and a[i] = b[j-1] and a[i-1] = b[j] then d[i, j] := minimum(d[i, j], d[i-2, j-2] + cost) // transposition return d[length(a), length(b)] 与 唯一的差别就是多了下面几行：123if i &gt; 1 and j &gt; 1 and a[i] = b[j-1] and a[i-1] = b[j] then d[i, j] := minimum(d[i, j], d[i-2, j-2] + cost) // transposition 噪声信道模型(Noisy Channel Model)Noisy Channel Model 即噪声信道模型，或称信源信道模型，这是一个普适性的模型，被用于 语音识别、拼写纠错、机器翻译、中文分词、词性标注、音字转换 等众多应用领域。噪声信道模型本身是一个贝叶斯推理的特殊情况。 其形式很简单，如下图所示： 应用于拼写纠错任务的流程如下： noisy word（即 spelling error）被看作 original word 通过 noisy channel 转换得到。由于在信道中有噪声，我们很难辨认词汇形式的真实单词的面目。我们的目的就是建立一个信道模型，使得能够计算出这个真实单词是如何被噪声改变面目的，从而恢复它的本来面目。噪声就是给正确的拼写戴上假面具的拼写错误，它有很多来源：发音变异、音子实现时的变异以及来自信道的声学方面的变异（扩音器、电话网络等）。 无论单词 separate 是怎样错误拼写了，我们只想把它识别为 separate。也就是，给定 observation，我们的任务是确定这个 observation 属于哪个类别的集合。所以，我们考虑一切可能的类，也就是一切可能的单词，在这些单词中，我们只想选择那些最有可能给出已有的 observation 的单词。也就是，在词汇 V 的所有单词中，我们只想使得 P(Word|Observation)最大的那个单词，也就是我们对单词 W 的正确估计就是 argmaxP(W|O) 现在已知 noisy word（用 O 表示）如何求得最大可能的 original word（用 W 表示），公式如下： $$ \\begin{aligned} argmax_{w \\in V} P(W|O) &amp; = argmax {P(W)P(O|W) \\over P(O)} \\ \\ \\ (Bayes \\ Rule) \\\\ &amp; = argmax P(W) * P(O|W) \\ \\ \\ (denom \\ is \\ constant) \\\\ \\end{aligned}$$ 看一下留下的两个 factor： P(W): prior, language modelhow likely the word is going to be a word P(O|W): likelihood, channel model/error modelif it was that word, how likely is that generates this exact error, models the correct word into a misspelled word Bayes 方法应用于拼写的算法分两个步骤： 提出候选更正表(proposing candidate correction)怎么产生候选更正表？可以采用编辑距离产生下面两种 words set 相似拼写(words with similar spelling) 相似发音(words with similar pronunciation)事实上，80%的错误单词与正确单词的编辑距离是 1，而几乎所有的情况下编辑距离都小于 2 对候选进行打分(scoring the candidate)用上面的 bayes 公式 Generate candidate words举个例子，给定拼写错误“acress”，首先通过词典匹配容易确定为 “Non-word spelling error”；然后通过计算最小编辑距离获取最相似的 candidate correction。下面是通过 insertion, deletion, substitution, transposition 四种操作转化产生且编辑距离为 1 的 candidate words。 此时，我们希望选择概率最大的 W 作为最终的拼写建议，基于噪声信道模型思想，需要进一步计算 P(W) 和 P(O|W)。 Language model probability通过对语料库计数、平滑等处理可以很容易建立语言模型，即可得到 P(w)，如下表所示，计算 Unigram Prior Probability（word 总数：404,253,213） Channel model probability$P(O|W)=probability \\ of \\ the \\ edit$ P(O|W)的精确计算至今还是一个没有解决的课题，我们可以进行简单的估算，用 confusion matrix，confusion matrix 是一个 26*26 的矩阵，表示一个字母被另一个字母错误替代的次数，有 4 种 confusion matrix(因为有四种错误)。 基于大量pair 计算 del、ins、sub 和 trans 四种转移矩阵，然后求得转移概率 P(O|W)，这里用 P(x|w) 表示: Calculation计算P(“acress”|w)如下： 计算P(w)P(“acress”|w)如下： “across”相比其他 candidate 可能性更大。 Evaluation一些测试集：• Wikipedia’s list of common English misspelling• Aspell filtered version of that list• Birkbeck spelling error corpus• Peter Norvig’s list of errors (includes Wikipedia and Birkbeck, for trainingor tes/ng) Other application噪声信道模型：Y $\\rightarrow$ Channel $\\rightarrow$ X看一下其他应用：在 POS tag 里，Y 就是 POS tag 序列，X 就是单词序列。在机器翻译里，如 L1 翻译成 L2，那么 Y 就是 L2， X 就是 L1，P(Y)就是 language model，P(X|Y) 就是 channel model。 真词错误的检查和更正25%-40% 的错误是真词(Real-word)，比如说 Can they lave him my messages? / The study was conducted mainly be John Black. 这类错误。真词错误的检查和更正往往依赖于上下文。 真词(Real-word)的检查和纠正:Detection： 每个 word 都作为 spelling error candidate。Correction： 从发音和拼写等角度，查找与每个 word 最近似的 words 集合作为拼写建议，常见的方法有 Highest noisy channel probability 和 classifier 对一个句子中的每个单词，都选出与之编辑距离为 1 的所有单词作为候选单词(包括原单词本身)，也就是说一个句子 N 个单词，就有 N 个 candidate set，然后从每个单词 set 里各取出一个单词组成一个句子，求 P(W) 最大的单词序列 简化版，就是在所有 candidate words 里，每次只选出一个单词，与其它原词组成句子，然后同样求 P(W) 最大的单词序列。 真词纠正和非词纠正的逻辑相同，都有 language model 概率和 channel model 概率，不同的是对真词纠正，channel model 的概率包含了 p(w|w) 也就是完全没有错误的概率。 拼写错误更正系统为了使人机交互(HCI)的体验更加友好，我们可以根据拼写检查的 confidence 来决定对其进行哪种操作 Very confident直接改正(autocorrect) Less confident给出最佳的更正单词(best correction) Less confident给出更正列表(correction list) Unconfident给出错误提示(flag)，就像 MS word 里错误单词下面的红线提示 Phone’c error model 噪声信道模型的改进可以改进/思考的方向： language model: 上文用的是 unigram，实际应用中当然是 bigram/trigram 效果会更好 channel model: 是否要考虑编辑距离大于 1 的情况 unseen words: 关于未登录词，尤其是层出不穷的新动词/名词，我们怎么处理。一般还是检查单词序列/组合的概率分布 classifier: 考虑分类器，综合各种特征 在实际应用中，我们并不会直接把 prior 和 error model probability 相乘，因为我们不能作出独立性假设，所以，我们会用权重来计算：$$\\hat w = argmax_{w \\in V} P(o|w)P(w)^{\\lambda}$$ 通常从训练集里学习 $\\lambda$ 参数。 有其他的方法对噪声信道模型进行改进，如允许更多的编辑(ph → f, le → al, etc.)，把发音特征加入信道等。另外，也可以把 channel model 和 language model 当做特征，并加入其他特征，来训练分类器来进行拼写错误的改正。 根据可能影响 p(misspelling|word) 的因素来提取特征：12345678• The source letter• The target letter• Surrounding letters• The position in the word• Nearby keys on the keyboard• Homology on the keyboard• Pronunciations• Likely morpheme transformations 参考链接斯坦福大学自然语言处理第五课“拼写纠错（Spelling Correction）”","tags":"nlp"},{"title":"NLP 笔记 - Words, morphology, and lexicons","url":"/2017/02/01/NLP 笔记 - Words, morphology, and lexicons/","text":"CMU 11611 的课程笔记。 Morphology(形态学)关键概念： words are not atoms单词不是原子，它是由 morphemes(语素) 构成的。如 misunderstandings，我们可以将其分解为 mis-understand-ing-s。 morphemes(语素)语素的种类: Roots(词根)一个单词最核心的语素，代表着这个单词最主要的含义。或者把它称为 stem(词干)？ Affixes(词缀) Prefixes(前缀)• pre-nuptual, ir-regular Suffixes(后缀)• determin-ize, iterat-or Infixes(中缀)• Pennsyl-f**kin-vanian Circumfixes(位缀)• ge-sammel-t concatenative morphology(毗邻性语素) 主要指前缀和后缀这一类语素，词是由一定数目的语素毗邻在一起而组成的。nonconcatenative morphology(非毗邻性语素) Umlaut foot : feet :: tooth : teeth Ablaut sing, sang, sung Root-and-pattern(词根与模式语素) or templatic morphology(模板语素)通常在阿拉伯语和其它闪美特语系中(Eg. Arabic, Hebrew, Afroasiatic languages)。如在希伯来语中，动词通常由词根和模板组成，词根又通常由3个辅音组成。 Infixation words(词)从语素构成单词的方法主要有两大类(可能部分交叉)：inflection(屈折)和 derivation(派生)。 Inflectional morphology(屈折形态学) 屈折把词干(stem)和一个语法语素(grammatical morpheme)结合起来，形成的单词一般和原来的词干术语同一个词类(word class)，还会产生诸如“一致关系”之类的句法功能。 Examples• Number (singular versus plural) automaton → automata• Case (nomina:ve versus accusa:ve versus…) he, him, his, … Derivational morphology(派生形态学) 派生把词干(stem)和一个词缀(suffixes/affixes/infixes)结合起来，但是形成的单词一般属于不同的词类(word class)，具有不同的含义(meaning)。 Examples• parse → parser• repulse → repulsive 补充：英语的名词通常只有两种屈折变化：一个词缀表示复数(plural)，一个词缀表示领属(possessive)。动词的屈折变化稍为复杂。英文动词有三种：主要动词(如 eat, sleep)，情态动词(如 can, will, should) 和基础动词(如 be, have, do)。主要动词还分规则动词和不规则动词，不同种类的变换各有不同。详见《自然语言处理综论》by Daniel, James P39。英语的屈折比其它语言相对简单，但英语的派生却相当复杂。名词可以由动词或形容词变换得到，形容词也可以从名词和动词派生。 Final-State Automaton(有限状态自动机)关键概念: 形式语言(formal language) 是一个模型，这个模型能够而且只能够生成或识别满足形式语言定义所要求的某一形式语言的符号串。而 自然语言(Natural language) 是现实中人们所说的语言，两者可能完全不同，然而我们通常使用形式语言来模拟自然语言的某些部分。 有限状态自动机(FSA) 是解决形态学(Morphology)问题的主要方法。可以用 FSA 识别的语言我们称为 regular language。 正则表达式 vs 有限状态自动机: 正则表达式是描述有限状态自动机的一种方法 任何正则表达式都可以用有限状态自动机来实现 任何有限状态自动机都可以用正则表达式来描述 两者彼此对称 FSA 模型： 一个经典例子是用 FSA 来识别羊的语言。我们把羊的语言定义为由下面的(无限)集合构成的任何字符串:1234baa!baaa!baaaa!... 描述这种羊的语言的正则表达式是/baa+!/，下图就是模拟这种正则表达式的一个自动机(automaton)。这是一个有向图，包括点(或结点)的有限集合和两个点之间的有向连接的弧的集合。圆圈表示点，箭头表示弧，这样一个自动机有 5 个状态，状态 0 是初始状态(start state)，用进入的箭头表示；状态 4 是最后状态(final state) 或接收状态(accepting state)，用双圈来表示，另外还有 4 个转移(transition)，用弧来表示。 自动机从 q0 开始，反复进行如下过程： 寻找输入的下一个字母，如果与自动机中离开当前状态的弧相匹配，那么就穿过这个弧，移动到下一个状态 如果输入的字母已经读完，那么进入接收状态(q4)，自动机就成功识别了输入。如果自动机总不能进入最后状态，或者输入已经读完，又或者某些输入与自动机的弧不匹配，或是自动机在某个非最后状态停住了，我们就说，自动机拒绝(reject)输入。 算法： 其它例子：FSA for English Nouns: FSA for English Adjective: FSA for English Deriva:onal Morphology: Morphological Parsing(形态剖析)主要有三种方法 Table Trie Final-state transducer 这里主要介绍第三种:有限状态转录机 Final State Transducers(FST)FST 模型: FSA vs FST:FSA 主要是来表达正则语言，主要作用是 识别(recognize) 语言；而 FST 既能够 识别(recognize) 语言，也能够 产生(generates) 语言，它可以剖析(parse)输入，或者把输入转化(transform)成另一种表达方式。 举个例子：12Input: a wordOutput: the word’s stem(s) and features expressed by other morphemes. 第二列输出包含了词干和有关的形态特征(feature)，这些特征说明了附加在词干上的有关信息。如 +N 这个特征表示这个词是名词，+SG 表示单数，+PL 表示复数。 输入 cats，经过形态剖析后可以得到输出 cat+N+PL，这样我们就知道 cat 是一个复数名词。我们使用的是 双层形态学(two-level morphology) 的方法来进行的形态剖析。把一个词表示为 词汇层(lexical level) 和 表层(surface level) 之间的对应，词汇层 表示组成该词的语素之间的简单毗邻关系，表层 表示该层实际拼写的最终情况。形态剖析要建立 映射规则，把在表层上的字幕序列(如 cats) 映射为词汇层上的语素和特征的序列(cat+N+PL)，两个层之间的映射的自动机就是 有限状态转录机(Final State Transducers)。有限状态转录机通过有限自动机来实现这种转录，因此我们通常把 FST 看成具有两层的 FSA，FST 具有比 FSA 更多的功能；FSA 通过确定符号集合来定义/识别形式语言，而 FST 则定义符号串之间的关系，这样就可以从另一个角度把 FST 看成是读一个符号串并生成另一个符号串的机器。 可以通过 4 个角度来看 FST: 作为识别器(recognizer)符号串的偶对作为输入和输出，如果该符号串偶对也在语言的符号串偶对(pair)中就接收，否则拒绝 作为生成器(generator)输出 yes 或 no 以及输出符号串的偶对 作为翻译器(translator)读一个符号串，输出另一个符号串 作为关联器(relater)计算两个集合之间的关系 其它例子： 补充:为了建立一个形态剖析器，至少需要： 词表(lexicon)：词干和词缀表及其基本信息(如一个词干是名词词干还是动词词干等) 形态顺序规则(morphotactics)：关于形态顺序的模型，解释在一个词内什么样的语素跟在什么样的语素后面。如英语表示复数的语素要跟在名词后面而不是前面 正词法规则(orthographic rule)：当两个语素结合时在拼写上发生什么变换。如 y-&gt;ie。 有很多 FST 的工具包，可以 compile &amp; rewrite FST 的规则，也可以将不同规则进行合并。 Stemming讲了无数遍的概念，就不展开了。12Input: a wordOutput: the word’s stem (approximately) Tokenization讲了无数遍的概念，就不展开了。12Input: raw textOutput: sequence of tokens normalized for easier processing.","tags":"nlp"},{"title":"推荐系统--开坑","url":"/2017/01/23/推荐系统--开坑/","text":"主要介绍推荐系统分析框架、应用场景以及评测方法等。之前做了个项目 App Recommender System，以为对推荐系统也了解了不少，结果在面试的时候第一次被问到时才发现之前做的并没能没有考虑到商业场景，委实太过于小打小闹。所谓知耻而后勇，就开了这个坑，打算系统学习下 Recommender System 这门课。 以一本通俗入门的书《推荐系统实践》by 项亮开始，以 University of Minnesota 的专项系列课程 Master Recommender Systems 为辅，来学习这个 topic。这一系列笔记仅供学习使用，文字/理念/图片均有可能来自以上两个来源。 概念需要区分的是 信息检索(Information Retrieval) 和 信息过滤(Information Filtering) 两个概念。 信息检索 针对的是 static content base + dynamic information need，通常使用的方法是 tfidf。信息过滤 则相反，针对的是 static information need + dynamic content base，主要的方法是对用户需求建模。推荐系统其实就是信息过滤的应用。搜索引擎需要用户主动提供准确的关键词来寻找信息，而推荐系统不需要这种明确需求，直接通过用户的历史行为给用户的兴趣建模，从而主动给用户推荐能满足用户兴趣和需求的信息，提高网站的点击率和转化率。 另外，推荐系统可以帮助发现物品的“长尾”。事实上，主流商品代表大多数用户的需求，而长尾商品则代表着小部分用户的个性化需求，后者才是更为重要的。以电商为例，如果只推荐主流产品，那么会产生大量长尾商品的库存积压，用户也不会感到惊喜或者满意。 推荐系统的三个主要组成部分： 前台展示页面 后台日志系统 推荐算法 推荐系统的三个参与方： 用户 物品提供者 提供推荐系统的网站 推荐系统分析框架 Analytical Framework of Recommend System看一下推荐系统分析框架的 8 要素。 domain(推荐领域）如已经购买过的东西 purpose（推荐目的）如让用户再次购买；add-on sales context（推荐背景）推荐活动发生的一些情况和限制。如随意浏览或者是为了购买某件商品而浏览 whose opinions（推荐者）如用户的购买记录；其它购物者 personalization level（个性化或定制化层次） Non-personalized recommend，像微博里列出的最热门的新闻、事件。它并不关注你是否对此感兴趣。 基于统计的有目标群体的推荐 Demographic，就好像买尿布的外国奶爸们顺手买的酒。 只针对你当前活动而作出的推荐 Ephemeral，标准格式“喜欢这个X的人们也喜欢……”。 分析长期记录得到的推荐 Consistent，如根据你的以往的消费记录，给你推荐一些物品。 privacy and trustworthiness（隐私性和可信度） 隐私性。这是不是我们希望网站拥有的数据 可信度。考虑会不会有内在的偏见，会不会有恶意的、非真实的操作等。 interface（接口）考虑输入输出。 输入分为 Explicit（Rating， Review， Vote， etc.）和 Implicit (Click， Purchase， Follow， etc.) 输出分为预测和推荐两种，预测是得到一个特定的评分结果，推荐是得到一堆推荐的事物。 algorithms（推荐算法）如 profitable products；product association 推荐系统的应用电子商务代表： 亚马逊。Amazon 被 RWW 称为“推荐系统之王”，主要的应用有个性化商品推荐列表和相关商品的推荐列表。 个性化推荐列表： 主要采用基于物品的推荐算法(item-based method)，给用户推荐和他们之前喜欢的物品相似的物品。另外还有一种是基于好友的个性化推荐，按照用户在 Facebook 的好友关系，给用户推荐他们的好友在亚马逊上喜欢的物品。感觉后者可能会带来更为严重的隐私争议，不过当然你可以选择禁用。 相关推荐列表： 亚马逊有两种相关商品列表，一种是包含购买了这个商品的用户也经常购买的其它商品，另一种是包含浏览过这个商品的用户经常购买的其它商品。相关推荐列表最重要的应用是打包销售，可能商品之间是互补的，当你下订单的时候，亚马逊会问你是否要同时购买这些商品，同时，会给出打包的折扣。 亚马逊有 20%-30% 的销售来自于推荐系统。 电影和视频网站代表： Netflix，YouTube，也都是基于物品的推荐算法。YouTube曾经做个一个实验，比较了个性化推荐的点击率和热门视频列表的点击率，实验结果表明个性化推荐的点击率是热门视频点击率的两倍。 个性化音乐网络电台代表： Pandora，Last.fm，豆瓣。Pandora 的算法主要基于内容，其音乐家和研究人员亲自听了上万首来自不同歌手的歌，然后对歌曲的不同特性(比如旋律、节 奏、编曲和歌词等)进行标注，这些标注被称为音乐的基因。然后，Pandora会根据专家标注的基因计算歌曲的相似度，并给用户推荐和他之前喜欢的音乐在基因上相似的其他音乐。Last.fm 并没有使用专家标注，而是利用用户行为计算歌曲的相似度。给用户推荐和他有相似听歌爱好的其他用户喜欢的歌曲。 音乐作为推荐物品的特点： 物品空间大 消费每首歌的代价很小 物品种类丰富音乐种类丰富，有很多的流派。 听一首歌耗时很少 物品重用率很高 用户充满激情用户很有激情，一个用户会听很多首歌。 上下文相关用户的口味很受当时上下文的影响，这里的上下文主要包括用户当时的心情(比如沮丧的时候喜欢听励志的歌曲)和所处情境(比如睡觉前喜欢听轻音乐)。 次序很重要用户听音乐一般是按照一定的次序一首一首地听。 很多播放列表资源很多用户都会创建很多个人播放列表。 不需要用户全神贯注 高度社会化用户听音乐的行为具有很强的社会化特性，比如我们会和好友分享自己喜欢的音乐。 上面这些特点决定了音乐是一种非常适合用来推荐的物品。因此，尽管现在很多推荐系统都是作为一个应用存在于网站中，比如亚马逊的商品推荐和Netflix的电影推荐，唯有音乐推荐可以支持独立的个性化推荐网站，比如Pandora、Last.fm和豆瓣网络电台。 社交网络代表： Facebook，Twitter主要应用在： 利用用户的社交网络信息对用户进行个性化的物品推荐 信息流的会话推荐 给用户推荐好友 Facebook 有个推荐 API，Instant Personalization，根据用户好友喜欢的信息，给用户推荐他们的好友最喜欢的物品。很多网站都用了这个 API 来实现网站的个性化，如 Yelp。 个性化阅读代表： Google Reader，鲜果网，Zite，Flipboard。 基于位置的服务代表： Foursquare往往和社交网络结合在一起。基于位置给用户推荐他近的且感兴趣的服务，用户就更有可能去消费。 个性化邮件代表： Tapestry， Google 谷歌于2010年推出了优先级收件箱功能。通过分析用户对邮件的历史行为，找到用户感兴趣的邮件，展示在一个专门的收件箱里。用户每天可以先浏览这个邮箱里的邮件，再浏览其他邮件。Google 的研究表明，该产品可以帮助用户节约 6% 的时间。 个性化广告代表： Facebook 广告定向投放目前已经成为了一门独立学科 – 计算广告学。个性化广告投放技术主要分为 3 种： 上下文广告 通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。 搜索广告 通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。 个性化展示广告 我们经常在很多网站看到大量展示广告(就是那些大的横幅图片)，它们是根据用户的兴趣，对不同用户投放不同的展示广告。雅虎是这方面研究的代表。 推荐系统评测一个完整的推荐系统一般存在 3 个参与方：用户、物品提供者和提供推荐系统的网站。 因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。以图书推荐为例，好的推荐系统需要： 需要满足用户的需求，给用户推荐那些令他们感兴趣的图书。 要让各出版社的书都能够被推荐给对其感兴趣的用户，而不是只推荐几个大型出版社的书。 能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。 推荐系统实验方法离线实验（offline experiment）步骤：(1) 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集;(2) 将数据集按照一定的规则分成训练集和测试集;(3) 在训练集上训练用户兴趣模型，在测试集上进行预测;(4) 通过事先定义的离线指标评测算法在测试集上的预测结果。 优点： 不需要对实际系统的控制权 不需要真是用户参与 速度快，能快速测试大量不同的算法 缺点： 无法获得更多商业上关注的指标，如点击率、转化率等。 离线实验的指标和商业指标存在差距。高预测率不等于高用户满意度。 用户调查（user study）像是一个过渡，离线实验的指标和实际的商业指标存在差距，算法直接上线测试又具有较高的风险，所以在上线测试前一般需要做一次用户调查。 用户调查需要有一些真实用户，让他们在需要测试的推荐系统上完成一些任务。在他们完成任务时，我们需要观察和记录他们的行为，并让他们回答一些问题。最后，我们需要通过分析他们的行为和答案了解测试系统的性能。 优点： 获得很多体现用户主观感受的指标 相对在线实验风险低，出错后容易弥补 缺点： 招募测试用户代价较大 很难组织大规模的测试用户，因此会使测试结果的统计意义不足 设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同 在线实验（online experiment）也就是传说中的 AB 测试。AB 测试是一种常用的在线评测算法的实验方法，通过一定的规则将用户随机分成几组，并对不同组的用户采取不同的算法，然后通过统计不同组用户的各种不同评测指标比较不同算法，比如统计不同组用户的点击率，通过点击率比较不同算法的性能。详见 AB test 优点： 可以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标 缺点： 周期长，必须进行长期的实验才能得到可靠的结果 简单的AB测试系统。 用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。 用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。 在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。 一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。 最后，通过在线的 AB 测试确定它在我们关心的指标上优于现有的算法。 评测指标用户满意度只能通过用户调查或者在线实验获得。 用户调查GroupLens 曾经做过一个论文推荐系统的调查问卷，该问卷的调查问题是请问下面哪句话最能描述你看到推荐结果后的感受 推荐的论文都是我非常想看的。 推荐的论文很多我都看过了，确实是符合我兴趣的不错论文。 推荐的论文和我的研究兴趣是相关的，但我并不喜欢。 不知道为什么会推荐这些论文，它们和我的兴趣丝毫没有关系。 在线实验主要通过一些对用户行为的统计得到。如利用购买率、点击率、用户停留时间和转化率等指标度量用户的满意度。 预测准确度最重要的离线评测指标。在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分成训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。 评分预测很多提供推荐服务的网站都有一个让用户给物品打分的功能(如知道了用户对物品的历史评分，就可以从中习得用户的兴趣模型，并预测该用户在将来看到一个所示)。那么，如果他没有评过分的物品时，会给这个物品评多少分。预测用户对物品评分的行为称为评分预测。 评分预测的预测准确度一般通过均方根误差(RMSE)和平均绝对误差(MAE)计算。对于测试集中的一个用户 u 和物品 i，令 $r_{ui}$ 是用户 u 对 u 物品 i 的实际评分，而 $\\hat r_{ui}$ 是推荐算法给出的预测评分，那么 RMSE 为 MAE 采用绝对值计算预测误差： 代码也非常简单123456def RMSE(records): return math.sqrt(sum[(rui=pui)**2 for u, i, rui, pui in records]) / float(len(records))def MAE(records): return sum([abs(rui - pui) for u, i, rui, pui in records]) / float(len(records)) Netflix认为RMSE加大了对预测不准的用户物品评分的惩罚(平方项的惩罚)，因而对系统的评测更加苛刻。研究表明，如果评分系统是基于整数建立的(即用户给的评分都是整数)，那么对预测结果取整会降低MAE的误差。 TopN 推荐TopN 推荐其实更符合实际需求。以电影为例，评分预测预测的其实是用户看了电影后会给什么样的评分，而电影推荐的目的是找到用户最可能感兴趣的电影，这两者当然不是一个概念。也许有一部历史片／文艺片非常好，用户看了会给非常高的分数，但是用户看的可能性非常小，可能用户就喜欢爱情片／脑残片呢。 覆盖率覆盖率(coverage)描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为 U， 推荐系统给每个用户推荐一个长度为 N 的物品列表 R(u)，那么推荐系统的覆盖率就是 覆盖率是一个内容提供商会关心的指标。以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。 考虑研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力，可以用信息熵或者基尼系数。信息熵: $H=-\\sum_{i=1}^np(i) \\ logp(i)$ (p(i) 是物品 i 的流行度除以所有物品流行度之和。) 是基尼系数（Gini Index）: $G={1 \\over n-1}\\sum_{j=1}^n(2j-n-1)p(i_j)$ ($i_j$ 是按照物品流行度p()从小到大排序的物品列表中第j个物品。) 下面的代码可以用来计算给定物品流行度分布后的基尼系数。12345678def GiniIndex(p): j = 1 n = len(p) G = 0 for item, weight in sorted(p.items(), key=itemgetter(1)): G += (2 * j - n - 1) * weight return G / float(n - 1) 如果这个分布比较平，那么说明推荐系统的覆盖率较高，推荐系统发掘长尾的能力就很好。而如果这个分布较陡峭，说明推荐系统的覆盖率较低。 推荐系统是否有马太效应呢?推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法(比如协同过 滤算法)是具有马太效应的。评测推荐系统是否具有马太效应的简单办法就是使用基尼系数。如果 G1 是从初始用户行为中计算出的物品流行度的基尼系数，G2 是从推荐列表中计算出的物品流行度的基尼系数，那么如果G2 &gt; G1，就说明推荐算法具有马太效应。 多样性用户的兴趣是广泛的，为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性描述的是推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的。假设 s(i， j)定义了物品 i 和 j 之间的相似度，那么用户 u 的推荐列表 R(u) 的多样性定义如下: 新颖性新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。在一个网站中实现新颖性的最简单办法是，把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。比如在一个视频网站中，新颖的推荐不应该给用户推荐那些他们已经看过、打过分或者浏览过的视频。 评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性。但是，用推荐结果的平均流行度度量新颖性比较粗略，因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查。 惊喜度惊喜度(serendipity)是最近这几年推荐系统领域最热门的话题。如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。 目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。 信任度如果你有两个朋友，一个人你很信任，一个人经常满嘴跑火车，那么如果你信任的朋友推荐 你去某个地方旅游，你很有可能听从他的推荐，但如果是那位满嘴跑火车的朋友推荐你去同样的 地方旅游，你很有可能不去。这两个人可以看做两个推荐系统，尽管他们的推荐结果相同，但用户却可能产生不同的反应，这就是因为用户对他们有不同的信任度。 度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。 提高推荐系统的信任度主要有两种方法。 增加推荐系统的透明度(transparency)增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。 考虑用户的社交网络信息利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。因为用户对他们的好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。 实时性在很多网站中，因为物品(新闻、微博等)具有很强的时效性，所以需要在物品还具有时效性时就将它们推荐给用户。 推荐系统的实时性包括两个方面。 推荐系统需要实时地更新推荐列表来满足用户新的行为变化。比如，当一个用户购买了iPhone，如果推荐系统能够立即给他推荐相关配件，那么肯定比第二天再给用户推荐相关配件更有价值。很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行 为相应的实时性，可以通过推荐列表的变化速率来评测。如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高。 推荐系统需要能够将新加入系统的物品推荐给用户。这主要考验了推荐系统处理物品冷启动的能力。对于新物品推荐能力，我们可以利用用户推荐列表中有多大比例的物品是当天新加 的来评测。 健壮性健壮性(即robust，鲁棒性)指标衡量了一个推荐系统抗击作弊的能力。 算法健壮性的评测主要利用模拟攻击。 给定一个数据集和一个算法，用这个算法给这个数据集中的用户生成推荐列表。 用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。 通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。 在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。 设计推荐系统时尽量使用代价比较高的用户行为。比如，如果有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代价远远大于攻击浏览行为。 在使用数据前，进行攻击检测，从而对数据进行清理。 小结离线实验的优化 目标 是:最大化预测准确度 使得 覆盖率 &gt; A，多样性 &gt; B， 新颖性 &gt; C，其中，A、B、C的取值应该视不同的应用而定。 这些指标本身就是相互矛盾的，还有一种统一的方法可能是 AUC(area under curve): 评测维度一般来说，评测维度分为如下3种。 用户维度主要包括用户的人口统计学信息、活跃度以及是不是新用户等。 物品维度包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。 时间维度包括季节，是工作日还是周末，是白天还是晚上等。","tags":"nlp recommender-systems 推荐系统"},{"title":"深度学习-从线性到非线性","url":"/2017/01/21/神经网络-从线性到非线性/","text":"这一篇讨论常用的非线性激励函数。 全连接神经网络一个浅层的神经网络，如下图其实就可以看作一个 logistic regression 模型加上非线性激励函数。 一个神经元的组成： 输入：n 维向量 线性加权：$z=\\sum^n_{i=1}w_ix_i+b$ 激活函数：a=h(z)，要求非线性，容易求导 输出值：a(标量) 当然我们可以加 z2, z3, a2, a3… 输入是 x1,x2…xn，输出是 a1,a2…am，如果给一个神经元，就是或 0 或 1 的输出，如果给多个，就从 logistic 回归变成了 softmax 回归。 一个输入，若干个中间层(可能是全连接／非全连接网络)，最后输出层，如果要做分类，就可以给一个或多个全连接网络（可以看作是 softmax）。 激活函数如果不用激活函数，或者说激活函数是f(x) = x，那么在这种情况下你每一层输出都是上层输入的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，来个例子，假设X1=W0*X0X2=W1*X1Y=W2*X2那么，线性矩阵相乘，可以直接简化为一层：Y=W2*W1*W0*X0=W3*X0，为什么还要用网络？ 所以，有线性回归网络吗？没有！ 正因为上面的原因，我们才要引入非线性函数作为激励函数，这样深层神经网络就有意义了（不再是输入的线性组合，可以逼近任意函数）。最早的想法是 sigmoid 函数或者 tanh 函数，输出有界，很容易充当下一层输入。 性质激活函数通常有如下一些性质： 非线性： 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。可微性： 当优化方法是基于梯度的时候，这个性质是必须的。单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数。f(x)≈x： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。输出值的范围： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate. 这些性质，也正是我们使用激活函数的原因。 分类Sigmoid 公式：$$f(x)=sigmoid(x)={1 \\over 1+e^{-x}}$$ 对其求导$$ \\begin{aligned} {df \\over dx} &amp; = -{1 \\over (1+e^{-x})^2}(-e^{-x}) \\\\ &amp; = {1 \\over 1+e^{-x}} {e^{-x} \\over 1+e^{-x}} \\\\ &amp; = {1 \\over 1+e^{-x}} {1+e^{-x}-1 \\over 1+e^{-x}} \\\\ &amp; = f(x)(1-f(x)) \\end{aligned}$$ Sigmoid 将数据映射到 [0,1] 缺点： Sigmoids saturate and kill gradients. 梯度下降非常明显，且两头过于平坦，容易出现梯度消失的情况当输入非常大或者非常小的时候(saturation)，神经元的梯度是接近于0的，从图中可以看出梯度的趋势。所以，你需要尤其注意参数的初始值来避免 saturation 的情况。如果初始值很大的话，大部分神经元可能都会处在 saturation 的状态而把 gradient kill 掉，这会导致网络变的很难学习。 输出值域不对称（非0均值）后一层的神经元将得到上一层输出的非 0 均值的信号作为输入，产生的一个结果就是：如果数据进入神经元的时候是正的(e.g. x&gt;0 elementwise in f=wTx+b)，那么 w 计算出的梯度也会始终都是正的。 tanh 公式：$$f(x)=tanh(x)={2 \\over 1+e^{-2x}}-1$$ 对其求导我们知道 $tanh(x)={sinh(x) \\over cosh(x)}$，所以对 f(x) 求导也就是对 ${sinh(x) \\over cosh(x)}$ 求导。$$ \\begin{aligned} {df \\over dx} &amp; = {cosh^2(x)-sinh^2(x) \\over cosh^2(x)} \\\\ &amp; = 1-tanh^2(x) \\\\ &amp; = 1-f(x)^2 \\end{aligned}$$ tanh 将数据映射到 [-1,1]，解决了 sigmoid 输出值域不对称问题，然而两头依旧过于平坦，梯度损失仍然明显。 ReLU(Rectified linear unit) $$f(x)=max(0,x)$$ 也就是 x&lt;0 取0，否则取本身。 优点： 收敛速度比 sigmoid/tanh 更快 可能是因为它是linear，而且 non-saturating 计算高效简单 相比于 sigmoid/tanh，ReLU 只需要一个阈值就可以得到激活值，ReLU具有所希望的特性，不需要输入归一化来防止它们达到饱和，也不用去算一大堆复杂的运算。 反向梯度没有损失 缺点： 正向截断负值，损失大量特征 训练时很“脆弱”，有 dead area 如，太高的 learning rate 配合上非常大的梯度流过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了。如果这个情况发生了，那么这个神经元的梯度就永远都会是 0. 实际操作中，如果 learning rate 很大，那么很有可能网络中的 40% 的神经元都”dead”了。 当然，如果你设置了一个合适的较小的 learning rate，这个问题发生的情况其实也不会太频繁。另外可以配合 Xavier 权重初始化方法，使用 adagrad 等方法自动调节 learning rate 来防止这种问题。 (-) Unfortunately, ReLU units can be fragile during training and can “die”. For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold. For example, you may find that as much as 40% of your network can be “dead” (i.e. neurons that never activate across the entire training dataset) if the learning rate is set too high. With a proper setting of the learning rate this is less frequently an issue. 有实验说，大概 80%-90%的特征都会被截断，然而 ReLU 仍然是非常常用的激励函数，因为特征足够多。 Leaky ReLU 对 ReLU 的改进，解决 dying ReLU 的问题。x&lt;0 时乘上一个 a 取较小的值，一般 a=0.01，可以保留更多的参数，反向梯度有部分损失。 为什么不变成 y=x？那不就回到了线性回归了嘛。 小结一般现在都直接取 ReLU，然而如果使用 ReLU，一定要小心设置 learning rate，要注意不要让你的网络出现很多 “dead” 神经元，如果这个问题不好解决，那么可以试试 Leaky ReLU、PReLU、random ReLU 或者 Maxout。另外，现在主流的做法，会多做一步batch normalization，尽可能保证每一层网络的输入具有相同的分布，见Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift。 sigmoid 缺点： 两头过于平坦 输出值域不对称（非0均值） tanh 缺点: 两头依旧过于平坦 ReLU: 收敛速度比 sigmoid/tanh 更快 计算高效简单 Dead Area 中权重不更新(leaky ReLU 不存在 dead area) 参考链接RELU 激活函数及其他相关的函数","tags":"deep-learning 激活函数"},{"title":"卷积神经网络 CNN 笔记","url":"/2017/01/20/卷积神经网络 CNN 笔记/","text":"CNN 对模式分类非常适合，其最初是为识别二维形状而特殊设计的，这种二维形状对平移、比例缩放、倾斜或其他形式对变形有高度不变性。 图像识别/分类图片识别／分类的一般过程：detect -&gt; align -&gt; represent -&gt; classify。具体到 CNN 就是检测到图片的位置，剪出来对齐，表达特征，对若干层进行不同的卷积、pooling，最后全连接网络做分类。 传统模型: Fixed features + unsupervised mid-level features + simple classifier 神经网络： Low-level features －> Mid-level features -> High-level features -> trainable classifier 李飞飞的 ImageNet 比赛，在 2012 年之前，经典做法是人工选一些原始特征出来(SIFT, Hog, Harr, etc.)，再稍加变换，可能用到一些聚类的算法，做一些中等级别的特征，然后给某个分类器做识别，一般就是 SVM。这种方法每一步都会损失数据，到最后可能就达不到很好的分类效果。 注： 把图像像素看成 words of bags，不同的原始图像可能分别是 M1*N, M2*N, M3*N 等等的 vectors，通过 K-means 的聚类聚比如说 1000 个类，就能把原来的 vectors 转化成长度为 1000 的直方图，也就形成中等级别的特征，维度就一样了，然后再选一个分类器。 2012 年第一次用了 CNN，正确率提高了 10%，人们意识到深度学习可能是图像识别非常有效的方式。与传统模型不同的是特征是自动选择的。 深度学习现在看来还可能是过冗余的，可以很多改进空间，如果能把 100M -&gt; 100K 的参数，就可以不用离线训练，也可以放到 App 中了。 卷积神经网络传统的神经网络都是采用全连接的方式，即输入层到隐藏层的神经元都是全部连接的，这样做将导致参数量巨大，使得网络训练耗时甚至难以训练，而 CNN 则通过局部连接、权值共享等方法避免了这一困难。 特点通过局部连接和权值共享减少了神经网络需要训练的参数的个数。 局部连接 权值共享(每个 feature map 共享参数) 池化 一般架构 可能有多个卷积层或多个输出层，某些卷积层不跟着 pooling 也是可以的。 卷积层(Convolutional Layer)卷积层是卷积神经网络基本结构，它由多个卷积核组合形成，每个卷积核同输入数据做卷积运算，形成新的特征图(feature map)，也就是，有几个卷积核，就有几个特征图。 比如说一张 32*32 的 RGB 图片，做卷积，一张图片就能理解。 Input volume: 32*32*3 Receptive fields: 5*5, stride 3 Number of neurons: 5 Output volume: (32-5)/3+1=10, -> 10*10*5 Weights for each of 10*10*5 neurons: 5*5*3=75 这其中，卷积核的 大小(size) 是由用户定义的，而 深度(或者说厚度)，是由输入数据定义的，一维数据就用一维卷积核，RGB 图片就是三维卷积核。 卷积核的 数目(kernel number)，常见参数有 64，128，256，为了使 GPU 并行更加高效。 每一个神经元从上一层的局部接受域得到输入，提取局部特征，每个局部特征相对于其他特征的位置被近似保留下来，原本的精确位置就没那么重要了。每一个计算层都由多个 feature map 组成，每个 feature map 都是平面形式的，平面中单独的神经元在约束下共享相同的权值集。这种结构约束具有平移不变性（强迫 feature map 的执行使用具有小尺度核的卷积，再接着使用一个 sigmoid 函数），另外，权值共享也可以实现自由参数数量的缩减。 卷积核的“矩阵”值，就是卷积神经网络的参数，卷积核的初值，通常随机生成，然后通过反向传播更新。随机生成可以通过高斯分布生成。一个问题： 卷积核初值完全一样好不好？不好！如果初值完全一样，那么反向梯度改变的量也差不多，整体就没有变化性，没有多样性。 padding &amp; stride padding 也就是边界扩充，在卷积计算过程中，为了允许边界上的数据也能作为中心参与卷积计算，将边界假装延伸，目的是为了确保卷积后特征图尺度一致。卷积核的宽度为 2i+1，添加 pad 的宽度就为 i。如上图，5*5 的图，卷积核 3*3，取 padding=1，对原始数据上下左右各补 1，可能会有偏移量，就相乘相加再加上偏移值。 步长(stride)是对输入特征图的扫描间隔，因为相邻的卷积窗口传达的信息可能会差不多，所以跳着取，提高效率。 权值设置：可以对所有权值做先验处理，按高斯分布做随机处理，然后梯度下降调整权值。 功能层卷积神经网络还需要一些额外功能： 非线性激励： 卷积是线性运算，需要增加非线性描述能力 降维： 特征图稀疏，需要减少数据运算量，保持精度，如做一个 pooling 归一化： 特征的 scale 保持一致，比如说映射到 [0,1] 之间 区域分割： 不同区域进行独立学习 区域融合： 对分开的区域合并，方便信息融合 增维： 增加图片生成或探测任务中的空间信息 非线性激励层(None-linear activation layer)如 ReLU 函数 更多见 神经网络-从线性到非线性 池化层(Pooling layer)每个卷积层跟着一个实现局部平均和子抽样的计算层，能达到降维的目的，由此 feature map 的分辨率降低。这种操作可以使 feature map 的输出对平移和其他形式的变形的敏感度下降。一张图解释下 2*2 的 max-pooling。 这样 M*M 的图像就成了 M/2 * M/2 的图像。当然还有 min-pooling 和 avg-pooling。作用: 降低输出规模 增加可解释性 避免丢失过多信息 归一化层(Normalization layer)如 批量归一化(Batch Normalization, BN)，原因是特征数的 scale 不一致，好处是可以加速训练，提高精度。 还有 近邻归一化(Local Response Normalization)，与 BN 不同的是，BN 依据 mini batch 的数据，而 LRN 仅需要自身，BN 训练中有学习参数，而 LRN 并没有。 $$x_i={x_i \\over (k+(\\alpha \\sum_jx^2_j))^\\beta}$$ 切分层(Slice layer)在某些应用中，希望独立对某些区域单独学习，比如说人脸识别，可以眼睛一套参数，耳朵一套参数。。好处是可以学习多套参数，得到更强的特征描述能力。 融合层(Merge layer)对独立进行特征学习的分支进行融合，来构建高效而精简的特征组合。 可以用 级连(concatenation) 的方法，其实也就是不同输入网络特征的简单叠加，比如说首尾相接。 也可以是合并，或者说运算的融合，对形状一致的特征曾，通过 +, -, x, max, conv 等原酸，形成形状相同的输出，如微软的残差网络。 全连接层及全卷积网络最后的输出一般是连一层全连接层(fully connected layer)，相当于 softmax 回归。当然其实也可以不连，像 FCN(全卷积网络)。 卷积层 的操作可以把 kernel 作用于输入的不同区域然后产生对应的特征图，也因此给定一个卷积层，并不要求输入是固定大小的。而 全连接层 的操作实际上是把输入拉成一个一维的向量，然后对这个一维向量进行点乘，这要求输入是固定大小的。这有的时候是很不合理的，如下图，如果要把红框的塔输入网络，就会产生图片变形。 如何网络接受任意的输入？把全连接层变成卷积层，这就是所谓的卷积化。这里需要证明卷积化的等价性。直观上理解，卷积跟全连接都是一个点乘的操作，区别在于卷积是作用在一个局部的区域，而全连接是对于整个输入而言，那么只要把卷积作用的区域扩大为整个输入，那就变成全连接了。所以我们只需要把卷积核变成跟输入的一个map的大小一样就可以了，这样的话就相当于使得卷积跟全连接层的参数一样多。举个例子，比如 AlexNet，fc6 的输入是 256x6x6，那么这时候只需要把 fc6 变成是卷积核为6x6的卷积层就好了。 与传统神经网络相比，CNN 参数和计算量更多还是更少了？参数变少了，因为都使用一套参数，而计算量却是变大了，因为卷积窗口要滑到不同的地方，进行计算、合并等操作。 优化提高泛化能力（减少 overfit） 增加神经网络层数。使用卷积层极大地减小了全连接层中的参数的数目，使学习的问题更容易 使用更多强有力的规范化技术（尤其是 dropout 和 regularization）来减小过度拟合 使用修正线性单元而不是 S 型神经元，来加速训练-依据经验，通常是3-5倍 使用 GPU 来计算 利用充分大的数据集，避免过拟合 使用正确的代价函数，避免学习减速 使用好的权重初始化，避免因为神经元饱和引起的学习减速 TensorFlow 实战TensorFlow 实战 MINST CNN 用于 NLP实习总结之 sentence embedding 参考链接Concepts and Tricks In CNN(长期更新)","tags":"deep-learning cnn"},{"title":"数据结构和算法 -- 堆","url":"/2016/12/27/数据结构和算法 -- 堆/","text":"最快找到一堆数里的最小值–最小堆。 Python heapqpython heapq 是 binary heap 的变种，见 binary heapHow to customize the heap order?Have each element on the heap to be a tuple, with the first tuple element being one that accepts normal Python comparisons. Eg.12345678&gt;&gt;&gt; def heapsort(iterable):... h = []... for value in iterable:... heappush(h, value)... return [heappop(h) for i in range(len(h))]...&gt;&gt;&gt; heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 基本用法123456789101112131415161718192021222324252627282930313233343536373839404142434445This module provides an implementation of the heap queue algorithm, also known as the priority queue algorithm.Heaps are binary trees for which every parent node has a value less than or equal to any of its children. This implementation uses arrays for which heap[k] &lt;= heap[2*k+1] and heap[k] &lt;= heap[2*k+2] for all k, counting elements from zero. For the sake of comparison, non-existing elements are considered to be infinite. The interesting property of a heap is that its smallest element is always the root, heap[0].The API below differs from textbook heap algorithms in two aspects: (a) We use zero-based indexing. This makes the relationship between the index for a node and the indexes for its children slightly less obvious, but is more suitable since Python uses zero-based indexing. (b) Our pop method returns the smallest item, not the largest (called a “min heap” in textbooks; a “max heap” is more common in texts because of its suitability for in-place sorting).These two make it possible to view the heap as a regular Python list without surprises: heap[0] is the smallest item, and heap.sort() maintains the heap invariant!To create a heap, use a list initialized to [], or you can transform a populated list into a heap via function heapify().The following functions are provided:heapq.heappush(heap, item)Push the value item onto the heap, maintaining the heap invariant.heapq.heappop(heap)Pop and return the smallest item from the heap, maintaining the heap invariant. If the heap is empty, IndexError is raised. To access the smallest item without popping it, use heap[0].heapq.heappushpop(heap, item)Push item on the heap, then pop and return the smallest item from the heap. The combined action runs more efficiently than heappush() followed by a separate call to heappop().New in version 2.6.heapq.heapify(x)Transform list x into a heap, in-place, in linear time.heapq.heapreplace(heap, item)Pop and return the smallest item from the heap, and also push the new item. The heap size doesn’t change. If the heap is empty, IndexError is raised.This one step operation is more efficient than a heappop() followed by heappush() and can be more appropriate when using a fixed-size heap. The pop/push combination always returns an element from the heap and replaces it with item.The value returned may be larger than the item added. If that isn’t desired, consider using heappushpop() instead. Its push/pop combination returns the smaller of the two values, leaving the larger value on the heap.The module also offers three general purpose functions based on heaps.heapq.merge(*iterables)Merge multiple sorted inputs into a single sorted output (for example, merge timestamped entries from multiple log files). Returns an iterator over the sorted values.Similar to sorted(itertools.chain(*iterables)) but returns an iterable, does not pull the data into memory all at once, and assumes that each of the input streams is already sorted (smallest to largest).heapq.nlargest(n, iterable[, key])Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in the iterable: key=str.lower Equivalent to: sorted(iterable, key=key, reverse=True)[:n]heapq.nsmallest(n, iterable[, key])Return a list with the n smallest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in the iterable: key=str.lower Equivalent to: sorted(iterable, key=key)[:n] Time complexityheapq.heapify(x): O(k)heapq.heappush(heap, item): O(logk)heapq.heappop(heap): O(logk) 对于 nsmallest 和 nlargest 的时间复杂度有点疑惑，找了些资料，就源代码而言，应该是 O(nlogt)，然而有一种说法是 O(t+n)，见 How does heapq.nlargest work?source code，2.7 和 3.4 这一部分是一样的。1234567891011121314151617def nsmallest(n, iterable): &quot;&quot;&quot;Find the n smallest elements in a dataset. Equivalent to: sorted(iterable)[:n] &quot;&quot;&quot; if n &lt; 0: return [] it = iter(iterable) result = list(islice(it, n)) if not result: return result _heapify_max(result) _heappushpop = _heappushpop_max for elem in it: _heappushpop(result, elem) result.sort() return result 例题23. Merge k Sorted ListsProblemMerge k sorted linked lists and return it as one sorted list. Analyze and describe its complexity. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&apos;&apos;&apos;Solution: Find out the minimum value in a bunch of elements, we use minheap. Time complexity for heap: heapify: O(k) push/poll an elem: O(logk) Space complexity: O(k) Time complexity: O(k+avg(n)klogk)&apos;&apos;&apos;# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def mergeKLists(self, lists): &quot;&quot;&quot; :type lists: List[ListNode] :rtype: ListNode &quot;&quot;&quot; root=ListNode(0) dummy=root h=[] for node in lists: if node: heapq.heappush(h,(node.val,node)) while h: val,node=heapq.heappop(h) dummy.next=ListNode(val) dummy=dummy.next if node.next: heapq.heappush(h,(node.next.val,node.next)) return root.next&apos;&apos;&apos;class Solution(object): def mergeKLists(self, lists): &quot;&quot;&quot; :type lists: List[ListNode] :rtype: ListNode &quot;&quot;&quot; largeList=[] for root in lists: while root: largeList.append(root.val) root=root.next largeList.sort() print largeList root=ListNode(0) dummy=root for n in largeList: print dummy.val dummy.next=ListNode(n) dummy=dummy.next return root.next &apos;&apos;&apos;","tags":"堆"},{"title":"kNN 小结","url":"/2016/12/26/kNN小结/","text":"回顾传统 kNN 算法以及优化方法。 kNN 的基本思路，给定一个训练数据集，对新的输入 instance，在训练数据集中找到与之最邻近的 k 个 instance，然后看这 k 个 instance 的大多数属于哪个类，那么这个类就是输入 instance 的最终类别。 特征归一化这算是常识性的知识啦，不过每次都会提醒一下。对于数值型的特征，我们一般都会进行归一化，如将数值范围处理到 0 到 1 之间，以此来保证每个特征是同等重要的。 来看看下面的例子，如果不归一化，那么，第一列(数字差值最大)的属性对计算结果的影响最大(代入相似度距离计算公式)，然而我们不希望这样。12345678940920 8.326976 0.953952 largeDoses14488 7.153469 1.673904 smallDoses26052 1.441871 0.805124 didntLike75136 13.147394 0.428964 didntLike38344 1.669788 0.134296 didntLike72993 10.141740 1.032955 didntLike35948 6.830792 1.213192 largeDoses42666 13.276369 0.543880 largeDoses...... 最简单的归一化做法 newValue=(oldValue-min)/(max-min) 代码123456789def autoNorm(dataSet): minVals = dataSet.min(0) # select min value from columns maxVals = dataSet.max(0) # select max value from columns ranges = maxVals - minVals # max-min m = dataSet.shape[0] normDataSet = zeros(shape(dataSet)) normDataSet = dataSet - tile(minVals, (m, 1)) # oldValue-min normDataSet = normDataSet / tile(ranges, (m, 1)) # division return normDataSet, ranges, minVals 当然，要记住在做分类的时候，也要先对特征进行归一化。 相似度距离计算怎么来判断邻近？如何来度量两个点之间的距离？距离选择很大程度上影响 kNN 的效果，因此它必须能足够的体现出样本间的相似和不同的程度，最常用的是欧式距离。 $$d(x,y):=\\sqrt {(x_1-y_1)^2+(x_2-y_2)^2+…+(x_n-y_n)^2}=\\sqrt {\\sum^n_{i=1}(x_i-y_i)^2}$$ 保存前 K 个点，可以用 最大堆(Max Heap) 实现。 根据具体的问题，距离也可以采用 余弦距离、海明距离、编辑距离 等等。 k 值选取 k 的选取是很重要的，看上面一个例子，蓝色和红色分别代表两个不同的类 B 和 R，绿色是输入 instance，我们要对其进行分类，可以发现，k 取 3 和 5 得到的分类结果是完全不同的。 k=3，新的 instance 属于 R 类别，因为离它最近的 3 个 instance 是有 2 个属于 R，1 个属于 B。 k=5，新的 instance 属于 R 类别，因为离它最近的 5 个 instance 是有 2 个属于 R，3 个属于 B。 所以，k 怎么选？ 事实上，通常来说，我们在一开始会选取一个较小的 k 值(k=1)，然后采取交叉验证(cross-validation)的方法，直到 k=n，取使交叉验证得到最好的结果的那个 k，经验上，k 小于数据集大小的平方根。 k 值太小 or k 值太大k 值太小容易产生过拟合，因为它很容易学到噪声，比如说 k=1，那么就只用看和输入 instance 最邻近的一个 instance，举个例子吧 而另一方面，k 值太大，那么意味着你的模型变得更加的简单，比如说 k=N(N为训练样本的个数)，那么无论输入的 instance 是什么类别，都会归到训练集中 instance 最多的那个类，也就是说，根本没有进行训练，只是简单的 count 而已，并没有利用训练集的其他大量的有用信息。 评价KNN 是一种 instance-based method，对于未知和非正态分布的数据可以取得较高的分类准确率，优缺点如下： 优点： 算法简单直观，易于实现 免训练，参数少 不需要产生额外的数据来描述规则，它的规则就是训练数据（样本）本身， 并不是要求数据的一致性问题，即可以存在噪音 虽然从原理上也依赖于极限定理，但在类别决策时，只与极少量的相邻样本有关。因此，采用这种方法可以较好地避免样本数量的不平衡问题，当然，在 k 值很大而样本又极度不平衡的情况下，结果就不妙了 最直接地利用了样本之间的关系，减少了类别特征选择不当对分类结果造成的不利影响，可以最大程度地减少分类过程中的误差项。对于一些类别特征不明显的类别而言，KNN法更能体现出其分类规则独立性的优势，使得分类自学习的实现成为可能 缺点： 时空复杂度高，分类速度慢 需要将所有训练样本首先存储起来，进行分类时实时进行计算处理，需要计算待分样本与训练样本库中每一个样本的相似度，才能求得与其最近的K个样本 对于高维样本或样本集规模较大的情况，其时间和空间复杂度较高，时间代价为O(mn)，其中 m 为向量空间模型空间特征维数，n 为训练样本集大小 样本库容量依赖性较强 有不少类别无法提供足够的训练样本，产生分类误差 特征作用相同 传统 KNN 认为每个属性的作用都是相同的(赋予相同权重)，而实际情况下，有些特征与分类是强相关的，有些特征与分类是弱相关的，还有一些特征(可能是大部分)与分类不相关。 K值的确定 KNN 算法必须指定 K 值，K 值选择不当则分类精度不能保证。 优化加快分类速度解决思路： 一是减少样本量，二是加快搜索 k 近邻。 减少样本量当训练样本集中样本数量太大时，可以从原始训练样本集中选择最优的子集进行 KNN 的寻找，这类方法主要包括 Condensing算法、WilSon 的 Editing 算法和 Devijver 的 MultiEdit 算法，Kuncheva 使用 遗传算法 在这方面也进行了一些研究。 加快搜索 k 近邻主要通过快速的搜索算法来实现，采用一定的方法加快搜索速度或减小搜索范围，如可以构造交叉索引表，利用匹配成功与否的历史来修改样本库的结构，使用样本和概念来构造层次或网络来组织训练样本。 常用的方法是先建立数据索引，然后再进行快速匹配。因为实际数据一般都会呈现出簇状的聚类形态，通过设计有效的索引结构可以大大加快检索的速度。索引树属于这一类，其基本思想就是对搜索空间进行层次划分。根据划分的空间是否有混叠可以分为 Clipping 和 Overlapping 两种。前者划分空间没有重叠，其代表就是 k-d 树；后者划分空间相互有交叠，其代表为 R 树。(这里只介绍k-d树) KD Tree构建 k-d tree1234567891011121.If Data-set为空，则返回空的k-d tree2.调用节点生成程序： - 确定split域 对于所有描述子数据（特征矢量），统计它们在每个维上的数据方差。以SURF特征为例，描述子为64维，可计算64个方差。挑选出最大值，对应的维就是split域的值。数据方差大表明沿该坐标轴方向上的数据分散得比较开，在这个方向上进行数据分割有较好的分辨率 - 确定Node-data域 数据点集Data-set按其第split域的值排序。位于正中间的那个数据点被选为Node-data。此时新的Data-set&apos; = Data-set\\Node-data（除去其中Node-data这一点）。3.dataleft = &#123;d属于Data-set&apos; &amp;&amp; d[split] ≤ Node-data[split]&#125; Left_Range = &#123;Range &amp;&amp; dataleft&#125; dataright = &#123;d属于Data-set&apos; &amp;&amp; d[split] &gt; Node-data[split]&#125; Right_Range = &#123;Range &amp;&amp; dataright&#125;4.left = 由（dataleft，Left_Range）建立的k-d tree，即递归调用 createKDTree（dataleft，Left_Range）并设置 left 的 parent 域为 Kd； right = 由（dataright，Right_Range）建立的k-d tree，即调用createKDTree（dataleft，Left_Range）并设置 right 的 parent 域为 Kd。 如上图的 2 维数据，构建 KD Tree 过程： 确定 split 域的首先该取的值。分别计算 x，y 方向上数据的方差得知x方向上的方差最大，所以 split 域值首先取0，也就是 x 轴方向； 确定 Node-data 的域值。根据 x 轴方向的值 2,4,5,7,8,9 排序选出中值为7，所以 Node-data = (7,2)。这样，该节点的分割超平面就是通过(7,2)并垂直于 split = 0(x轴)的直线x = 7； 确定左子空间和右子空间。分割超平面x = 7将整个空间分为两部分，如图2所示。x &lt; = 7的部分为左子空间，包含3个节点{(2,3)，(5,4)，(4,7)}；另一部分为右子空间，包含2个节点{(9,6)，(8,1)}。 最后生成的 k-d 树。 k-d tree 寻找星号表示要查询的点(2.1,3.1)。通过二叉搜索，顺着搜索路径很快就能找到最邻近的近似点，也就是叶子节点(2,3)。而找到的叶子节点并不一定就是最邻近的，最邻近肯定距离查询点更近，应该位于以查询点为圆心且通过叶子节点的圆域内。为了找到真正的最近邻，还需要进行’回溯’操作：算法沿搜索路径反向查找是否有距离查询点更近的数据点。此例中先从(7,2)点开始进行二叉查找，然后到达(5,4)，最后到达(2,3)，此时搜索路径中的节点为&lt;(7,2)，(5,4)，(2,3)&gt;，首先以(2,3)作为当前最近邻点，计算其到查询点(2.1,3.1)的距离为0.1414，然后回溯到其父节点(5,4)，并判断在该父节点的其他子节点空间中是否有距离查询点更近的数据点。以(2.1,3.1)为圆心，以0.1414为半径画圆，如图4所示。发现该圆并不和超平面y = 4交割，因此不用进入(5,4)节点右子空间中去搜索。 再回溯到(7,2)，以(2.1,3.1)为圆心，以0.1414为半径的圆更不会与x = 7超平面交割，因此不用进入(7,2)右子空间进行查找。至此，搜索路径中的节点已经全部回溯完，结束整个搜索，返回最近邻点(2,3)，最近距离为0.1414。 一个复杂点的例子如查找点为(2，4.5)。同样先进行二叉查找，先从(7,2)查找到(5,4)节点，在进行查找时是由y = 4为分割超平面的，由于查找点为y值为4.5，因此进入右子空间查找到(4,7)，形成搜索路径&lt;(7,2)，(5,4)，(4,7)&gt;，取(4,7)为当前最近邻点，计算其与目标查找点的距离为3.202。然后回溯到(5,4)，计算其与查找点之间的距离为3.041。以(2，4.5)为圆心，以3.041为半径作圆，如图5所示。可见该圆和y = 4超平面交割，所以需要进入(5,4)左子空间进行查找。此时需将(2,3)节点加入搜索路径中得&lt;(7,2)，(2,3)&gt;。回溯至(2,3)叶子节点，(2,3)距离(2,4.5)比(5,4)要近，所以最近邻点更新为(2，3)，最近距离更新为1.5。回溯至(7,2)，以(2,4.5)为圆心1.5为半径作圆，并不和x = 7分割超平面交割，如图6所示。至此，搜索路径回溯完。返回最近邻点(2,3)，最近距离1.5。k-d树查询算法的伪代码如表3所示。 上述两次实例表明，当查询点的邻域与分割超平面两侧空间交割时，需要查找另一侧子空间，导致检索过程复杂，效率下降。研究表明 N 个节点的 K 维 k-d 树搜索过程时间复杂度为：$O_{worst}=O(kN^{1-1/k})$。 关于 kd tree 的介绍来自于 k-d tree算法 训练样本的维护对训练样本库进行维护以满足 KNN 算法的需要，包括对训练样本库中的样本进行添加或删除。对样本库的维护并不是简单的增加删除样本，而是可采用适当的办法来保证空间的大小，如符合某种条件的样本可以加入数据库中，同时可以对数据库库中已有符合某种条件的样本进行删除。从而保证训练样本库中的样本提供 KNN 算法所需要的相对均匀的特征空间。 相似度距离公式优化为了改变传统 KNN 算法中特征作用相同的缺陷，可以对相似度的距离公式中给特征赋予不同权重，例如在欧氏距离公式中给不同特征赋予不同权重。特征的权重一般根据各个特征在分类中的作用设定，可根据特征在整个训练样本库中的所起的作用大小来确定权重，也可根据在训练样本的局部样本(靠近待测试样本的样本集合)中的分类作用确定权重。 K 值确定 K的选择往往通过大量独立的测试数据、多个模型来验证最佳的选择； K值一般事先确定，也可以使用动态的，例如采用固定的距离指标，只对小于该指标的样本进行分析 参考链接：KNN算法的优缺点和改进方法","tags":"machine-learning"},{"title":"新的开始","url":"/2016/12/20/新的开始/","text":"一直提醒着自己，不要活成别人的样子，然而一天天，一年年，还是偏离了初衷，走着别人认为正确认为光明的路。学金融、留学、做码农、刷题拼着进 google… 大抵是因为，不知道自己想要的究竟是啥样的，又觉着自己啥都无所谓，于是想着，那就跟着大流走吧，哪里最热就往哪里去，然后到了这里。 然而在这一学期终究是厌倦了。每天忙着做作业、刷题、找工作，唯独没有时间好好的学习。阅读列表里搁着一堆的待读文章也永远是待读的状态。 在这一刻回顾，只觉得茫茫然无所适从。太匆匆，太匆匆。做了很多题，写了很多算法，过的无比的“充实”，却不安心，好像学的是别人的，自己增长的不是知识，而只是经验。 更可怕的是，整夜整夜的失眠，觉着没什么记忆，如果有，也只是断层的，并不连贯。 并不满意自己现在的状态。也不想这样继续下去。 TVB 里说滥了的一句台词，做人呢，最重要就是开心，倒真是话糙理不糙。 可是，会笑，会闹，会折腾，并不意味着开心。 一直听着“既然来了美国，就争取留下来，再次也工作两年镀层金，回国起点就高了”“国外码农环境好，赚的多，又不累，还是多待几年”类似的话，听着听着就觉得，哎，好吧，既然你们都这么说，那我就试试。 然后就放了话，可是我只想进 google 怎么办，其它我都不喜欢。要不，进不了 google 我就回国去？ 这句话现在看来也只能骗鬼了。你问为啥要去 google？因为它名气最大。就像纽约之于金融，硅谷之于码农。可是你再问下去，为什么？我却说不上来，大抵是进 google 是不会错的，不会有风险的。 付出努力了吗？ 自然是有的，买了 leetcode 会员，刷了一些题，然而一直也并没有什么动力。潜意识里大概也觉着我是没那个水平进去的，进去了又如何呢？进不去又如何呢？好像也无所谓。进去了可能会有一瞬间的欢喜，然而又怎么样呢？进不去……大概会松一口气。 所以，你看，我也只不过想找个借口回国而已。 在这里终究是不安宁的，不是指走夜路总担心有个人突然拿着把枪出来的不安宁，而是觉着，被大家推着走。某个阶层，某个群体，好像总有着高度统一的价值观，什么是对，什么是错，什么时候该做什么事，界限分明像一本用了很多年的字典，真是令人沮丧。 之前和某个学心理学的朋友聊天，说到内心不平静，不安宁，怎么办。她说，一点点缩小自己的圈子。现在，我的圈子很小很小，才发现，缩小圈子或许只是一个表征，内在的核心是，专注于自身。自身的欢喜，自身的成长。不因外物而对自己施压，爱别人尊重别人的同时，也爱自己，尊重自己。相信自己的选择，喜欢自己的决定。 如果这个决定恰巧顺从了潮流，那么皆大欢喜，如果不是，那么，也要做好准备，因为逆行，意味着孤独。 索性人尽管不能离群索居，却只用对自己负责。 接下来的时间，我会花很长的时间来培养好的习惯，早起、读书、健身。 会花两三天看一篇论文，庖丁解牛式。 会花一周做一个项目，争取优化到方方面面。 会去读“无用之书”，去沉淀去感受形而上的东西。 不会再因为 due 或者 final 或者面试轻易放弃这些重要而不紧急的事。 会争取将我的一点点努力，呈现在博客里。 技术是一件很美好的东西，生活也是。 相对于自然，地理不过是细节。 相对于生活，知识也不过是细节。 能让我们丰盛的，是情感，是体验。 记得很多年前，同学说我应该是那种坐在欧洲某家咖啡店的窗边静静翻着英文书的人。 他说错了。我不喜欢喝咖啡。也不喜欢看英文书。 嗯其它或许是对的。 我向往这种慢悠悠的日子。 一张一弛，文武之道。","tags":""},{"title":"Distributed Systems笔记－NFS、AFS、GFS","url":"/2016/12/10/Distributed Systems笔记－NFS、AFS、GFS/","text":"CMU 95702 关于 NFS、AFS、GFS 的笔记。 NFS(Network File System)目的： Your files are available from any machine. Distribute the files and we will not have to implement new protocols. 特点： Defines a virtual C/S file system Stateless Uses RPC over TCP or UDP. NFS 的实质在于用户间计算机的共享。用户通过 NFS 客户端接入网络，可以访问同一网络中其它计算机系统的硬盘（该计算机为 NFS 服务端）。NFS 客户端可以 mount 远端文件系统的部分或全部到本地，访问这些文件系统就像访问在本地磁盘上的文件系统一样。 NFS 访问数据的速度以接近采用本地磁盘的速度为目标，NFS客户端的性能直接取决于服务端的性能和网络性能。如： 网络的最大吞吐量 服务端硬件性能：网卡，磁盘等 服务端缓存大小，TCP/IP的配置 服务端服务实例的运行个数 客户端请求的网络文件数 客户端的系统性能其它运行在客户或服务端上与NFS竞争资源的进程 NFS客户端将用户级别命令转化为RPC；NFS服务端将RPC转换为用户级别命令。NFS的主要缺点：文件服务器的定位对客户端非透明，即客户端需要知道服务端的确切地址（挂载点），这也导致了其可扩展性差，维护困难，优点是发展多年，Linux内核直接支持，使用简单方便。 NFS architecture NFS server operations -&gt; The directory and file operations are integrated into a single service. NFS client AFS(Andrew File System)目的： Scalability 特点： Modified from Coulouris CacheWhole files are cached in client nodes to reduce client server interactions -&gt; achieve scalability.A client cache would typically hold several hundreds of files most recently used on that computer.Permanent cache, surviving reboots. Consider UNIX commands and libraries copied to the client. Consider files only used by a single user.These last two cases represent the vast majority of cases. Gain: Your files are available from any workstation. Principle: Make the common case fast. Open file: When the client tries to open a fileclient cache is tried firstif not there, a server is located and the server is called for the file. The copy is stored on the client side and is opened. Subsequent reads and writes hit the copy on the client. Close file: When the client closes the file - if the files has changed it is sent back to the server. The client side copy is retained for possible more use. AFS(Andrew File System) 文件系统主要用于管理分部在不同网络节点上的文件。AFS 采用安全认证和灵活的访问控制提供一种分布式的文件和授权服务，该服务可以扩展到多个客户端。 AFS与NFS不同，AFS提供给用户的是一个完全透明，永远唯一的逻辑路径。因而其具有跨平台，分布式的特点。但是由于AFS使用本地文件系统来缓存最近被访问的文件块，访问一个在本地的AFS文件由于需要附加一些耗时的操作，比直接访问本地的其它文件要慢很多。AFS为读操作做了优化，写操作很复杂，是一个读快写慢的文件系统，不能提供很好的读写并发能力。 AFS architecture Implementation of file system calls in AFS File name space seen by clients of AFS System call interception in AFS The main components of the Vice service interface CMU’s Coda is an enhanced descendant of AFSVery briefly, two important features are:Disconnected operation for mobile computing.Continued operation during partial network failures in server network.During normal operation, a user reads and writes to the file system normally, while the client fetches, or “hoards”, all of the data the user haslisted as important in the event of network disconnection.If the network connection is lost, the Coda client’s local cache serves data from this cache and logs all updates.Upon network reconnection, the client moves to reintegration state; it sends logged updates to the servers. From Wikipedia GFS(Google File System)目的： Scalability 特点： Reliably with component failures. Massively large filesSolve problems that Google needs solved – not a massive number of files but massively large files are common. Write once, append, read many times. Streaming and no cacheAccess is dominated by long sequential streaming reads and sequential appends. No need for caching on the client. Throughput more important than latency. Each file is mapped to a set of fixed size chunks(64Mb/chunk). 3 replicasEach chunk is replicated on three different chunk servers. Master and chunk serversEach cluster has a single master and multiple (usually hundreds) of chunk servers.The master knows the locations of chunk replicas.The chunk servers know what replicas they have and are polled by the master on startup. Think of very large files each holding a very large number of HTML documents scanned from the web. These need read and analyzed.This is not your everyday use of a distributed file system (NFS and AFS). Not POSIX. Google physical infrastructure Structure OperationsReadSuppose a client wants to perform a sequential read, processing a very large file from a particular byte offset. The client can compute the chunk index from the byte offset. Client calls master with file name and chunk index. Master returns chunk identifier and the locations of replicas. Client makes call on a chunk server for the chunk and it is processed sequentially with no caching. It may ask for and receive several chunks. MutationSuppose a client wants to perform sequential writes to the end of a file. The client can compute the chunk index from the byte offset. This is the chunk holding End Of File. Client calls master with file name and chunk index. Master returns chunk identifier and the locations of replicas. One is designated as the primary. The client sends all data to all replicas.The primary coordinates with replicas to update filesconsistently across replicas.","tags":"分布式"},{"title":"Search Engines笔记 - Federated Search","url":"/2016/12/07/Search Engines笔记 - Federated Search/","text":"CMU 11642 的课程笔记。垂直数据库能获得更准确的搜索结果。那么对一个 query，我们可以放到合适的多个垂直数据库里检索，然后合并结果呈现给用户。简单解释就是结果来自多个数据库。用图片表示 当然，大多数数据库与我们的需求并不相关，所以可以略过。 Search portals 可以有不同的策略来处理不同类型的请求 搜索非结构化数据 将初始查询映射为对应的结构化查询 将查询定向到特定的搜索引擎» 汽车，音乐，图片，视频… 搜索结构化数据（数据库） - 例如，邮政编码，股票代码… 调用服务或进程 如，计算器，股票价格，航班跟踪… Constrains不合作环境 没有特别的 federated search 的支持 资源不受信任 合作环境 资源支持公共协议/ API 资源是受信任的，能够提供准确的信息 Components Resource representation(资源表达)。即获取每个数据库的信息 Resource selection(资源选择)。即对 resource/databases 进行排序，对每个查询选择少量资源进行检索。 Result-merging(结果合并)。即对来自不同搜索引擎／数据库对结果进行 merge，产生最终展现给用户的 ranking list。 其中 1 是在线下完成的(offline)，2、3 是在查询时完成的。 Resource representation如何表达资源的内容？ Bag of words: terms and frequencies Sample queries: Queries that this resource is good for Sample documents: Typical documents from this resource 一个例子解释 资源的内容信息如何获取 通过 protocol 向资源发出请求 对 query log 请求相关性评价 (relevance assessments) Query-based sampling: 提交查询，查看返回的内容 下面主要介绍第三种 query-based sampling Query-based sampling过程 选择一个初始查询 重复 N 次（例如，N = 100） 向搜索引擎提交查询 下载一些结果（例如，2-4 条） 得到并更新 representation (words and frequencies) 从新的 representation 中随机选择 query term(s)形成新的查询 为什么可行?因为词汇分布服从 Heaps’ Law 如果第一条查询非常糟糕怎么办？如在一个医学领域的语料库里找 car，可能并没有结果(如果是 boolean ranking 的话)，那么就重新选择一个查询？ 抽样的大小有什么影响一条 query 取多少文档呢？实验决定吧，2-4 篇应该就够了 在合作环境下随机采样只比 query-based sampling 好一点点 Resource selection两大类方法，无监督学习通常是通过对 P(ri|q) 排序来解决，监督算法通常通过分类解决。 Unsupervised Resource SelectionTask: 给定查询 q，决定要搜索的资源(resources) 无监督方法将这个问题看作 resource ranking 的问题。 估计 p(ri|q) 选择前 k 个资源– 通常 k 是给出的– 动态设置 k 是一个开放的研究问题 两种具体方法，content-based methods 和 query-based methods Content-based methods(基于内容的方法)– 对各个资源下 query 和 content 的相似度 $S(q,c)$ 来对资源进行排序– 有不同的方法来实现，区分点在于：» Representation type: bag of words vs. sampled documents» Ranking algorithm: e.g., CORI Query-based methods(基于查询的方法)– 对 query，搜索各个资源下的 query log，找出 match 的 query，然后求当前 query 和历史 query 的相似度 $S(q,q_{past})$，对资源进行排序– 之前用的并不多，因为缺少好的 query log Content-based methodsBag-of-words method基本思想是 将每个资源视为一个（非常大的）词袋(bag of words)，排序算法可以用 KL divergence 或者 query likelihood 等方法。eg. CORI 然而，Bag of words methods (e.g., CORI)是根据 resources 和 query 的相似度进行的排序，这并不是我们的初衷。这种方法 偏好具有较高 p(qi|Rj) 的资源，通常意义上也就是 homogeneous (通常很小)的资源。这并不是我们需要的，我们想要的是，选择能够返回更多相关文档的资源，sampled document method 更能达到这个目标。 Bag of words (“large documents”) 方法的特点 大文档更好的代表了 resource representation 偏好具有较大比例相关内容的资源– i.e., small or homogeneous resources 非常有效，很有竞争力 Sample documents method基本思想： 对每个资源采样然后合并得到一个 centralized index，记录每个文档来自哪个 resource。eg. ReDDE给定一个查询 搜索 centralized sample index 得到相关文档 取前 T 的文档 检查哪些资源提供了这些相关文档 估计每个资源中相关文档的数量• 计算资源 i 中高于阈值 T 的文档数量 n• n * resource_size / sample_size ReDDE 可以看作是 sample-based voting method，每个 top-ranked document 可以看作是对它属于的那个资源的一个投票。 特点： 高召回率: 选择包含更多相关文档的资源 高准确率: 选择能够返回更多的出现在合并结果集 top T 的文档的资源 有很多算法的变种– 来自更可靠/权威的资源的 sample 获得更多的投票– 更相关的 sample 获得更多的投票 CORI vs ReDDE ReDDE 相对而言更加准确– 通常效果更好，几乎不会有更糟的情况 当各个 collection size 的分布是 skewed 时，ReDDE 的性能优于 CORI– CORI 偏向小集合。他们更可能是同质的，它错过了大型，异质的 collections– ReDDE 对大型 collection 的偏见没那么强 CORI 比 ReDDE 更有效– 一个资源一个文档 vs. 一个资源多个文档 Supervised Resource Selection当我们有可用的训练数据时，就可以进行有监督的资源选择 利用广泛的特征 将任务框架化为分类问题 让机器学习算法学习如何给不同的特征分配权重 Main issues 特征工程 获取训练数据 确定要选择的资源数 FrameworkTask: 给定一个查询，选择一个或更多的 verticals 将问题定义为一个 “one-vs-all” 的分类任务 对每个 vertical 都训练一个分类器 对 “no vertical” (web only) 也训练一个分类器 E.g., Arguello, et al (2009) 用了逻辑回归模型 典型的选择策略 选择一个具有最高置信度(confidence score)的分类器 选择 n 个最好的分类器 选择所有置信度分数高于 threshold 的分类器 FeaturesQuery features Boolean: keywords and regular expressions– E.g., “weather”, “news”, “videos”, … Geographic: Probabilities associated with geographic entities– E.g., “Pittsburgh pizza” Category: query’s affinity to a set of topic categories– E.g., “Cancun vacations” Corpus FeaturesReDDE 是非常流行的资源排序算法 Clarity (Cronen-Townsend, et al., 2002)Clarity 用来预测给定语料库上的查询的有效性，本质上是 top-ranked 文档和完整集合之间的 KL divergence，如果排名靠前的文档看起来像是 collection 的 random sample，搜索结果将会很差 Query Log Features 人工评估/点击率 qlog feature 用查询日志中的 query 来构建语言模型 v 用 query likelihood 来建模 $P(q|v)=\\prod_t^q P(t|v)$ p(t | v) is a smoothed MLE Soft.ReDDE feature: 用查询日志中的 query 来构建语言模型 v 用 query 对外部的 collection 检索– E.g., wikipedia 选择前 n 个文档 文档 di 的投票是 KLD (di || v)– 与查询日志相似的文档具有更高的投票 Result merging主要问题：idf同一个 term，在不同数据库的 idf 不同怎么办？ scores不同数据库的 doc score 不是可比的怎么办？ ＝&gt; Map resource-specific scores to resource-neutral scores Result merging 用所有的 sampled documents 创建一个 index (offline) 从选定的资源里检索文档– 因为资源并不提供文档分数，所以对每个文档计算 sim (q, d)– 利用 index 的 corpus statistics 来计算每个文档的 authority score score(d) = f ( sim (q, d), authority (d) ) Semi-Supervised Learning 由资源 i 返回的一些文档可能同时出现在 sample index 里对这些文档我们有两个分数 Sample index (resource neutral) score Resource i (resource-specific) score这就是我们用来学习 f (resource-specific) = resource-neutral 的训练数据 对这个所需的 “normalization” 用线性函数进行建模，因为线性模型可以利用少量的数据进行训练，而且 Ad-hoc CORI 的合并就是线性的 使用线性回归(linear regression)推导出权重 f（resource-specific score）= a×dRi，j + b = resource-neutral score 每个(query, resource) pair 对应不同的函数 它有效么?目前为止是最好的选择，因为 mapping 是 query-specific 和 resource-specific 的。 有没有足够的训练数据?通常有，因为 resource selection 和 sample index 可以用相同的文档。如果没有，下载 1-3 篇文档来产生训练数据。 Large-Scale Search Architecture之前讲过 large-scale search architecture 的相关内容。我们可以把数据集分为两层 高价值 和 低价值，然后将每一层进行分区(shards)，再将分区分配给计算机。 事实上我们并不需要对每个查询都检索每一个分区，这样做成本很高，为什么不直接搜索最好/最合适的分区呢？ 通常带来的结果是： 高准确率 (尤其是 top ranks) 低召回率 (可能会错过许多有用的文档)– 只搜索了少量资源，这也是广泛应用的障碍 所以分为两步: 资源定义(Resource definition) 对文档分区 资源选择(Resource selection) 对特定 query 选择要搜索的分区 下面进行详细的介绍。 Resource definitionGoal: 搜索更少的分区得到更高的 recall Requirement:对于可能提交的任何 query，大多数的相关文档必须出现在同一个分区中 How:把 closely-associated documents 也就是相似（相同主题）的文档归到同一个分区。 Hypothesis: Closely-associated ≈ topically-related &amp; Each shard covers one topic/subject 对给定的语料库，应该使用哪些 topics/subjects? 人工开发类别? – LCSH, DMOZ, Reuters, … 自动学习 corpus-specific topics? – Clustering, LDA, PLSA, … 我们想要一个可以应用于任何语料库的解决方案，因此，需要能自动学习基于语料库的特定的主题。许多算法能产生语料库特定的“主题”： 聚类: E.g., k-means clustering 主题模型: E.g., Latent Dirichlet Allocation (LDA) 当然我们也要保证解决方案必须对 large collections 是有效的： 从 collection 的一个随机样本里创建主题 将其余文档分配给最相似的主题 Resource selectionGoal: 给定查询，选择最好的分区 两类重要的资源选择算法: Model-based: CORI, CRCS, Taily, … Sample-based: ReDDE, SUSHI, Rank-S, … 有很多好的算法 Sample-based 的算法被认为是最有效的 在初始工作中常常使用 ReDDE 变种 Taily 和 Rank-S 也经常被研究/考虑 对每个分区采样:将样本存储到 sample index 里 =&gt; offline 给定查询 搜索 sample index，得到 top documents Top documents 对它们所在的分区投票 将 query 发送到得到最多投票的分区=&gt; online Cost$C_{Total}$: 处理 inverted list 的数量 用于资源选择 用于分区选择 I/O 和计算成本 Selective search 分为两步： 选择要搜索的分区（resource selection） 搜索所选的分区 ReDDE 具有更高的计算成本 Key techniques Resource definition for selective search– How to partition a large corpus effectively Resource representation– How to represent the contents of each resource– Vocabulary-based, sample-documents-based, feature-based Resource selection– How to select the right resources for a particular query","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Diversity","url":"/2016/12/07/Search Engines笔记 - Diversity/","text":"CMU 11642 的课程笔记。一个 query 可能表现了不同的信息需求，之前的相关性模型可能带来的结果是大多文档只能满足同一个信息需求，所以有些用户满意了，有些 user 抓狂了。我们希望检索到的 document 是能够 diverse 的，这样的话可以尽可能的满足不同用户的需求。这一章就讲了怎么实现 diversity。 Relevance based ranking model之前的 相关性模型(Relevance based ranking model) 的目的是： 在每个 ranking 位置上最大化预期用户满意度 主要基于与原始查询的文本相似性 我们基于了这样一个假设： each document is independent of other documents in the ranking 它带来的检索结果是： 主要关注最可能出现的 intent 适用于一些用户，但另一些用户可能不满意 如果这条 query 清楚的表达了 user intent，那么这种方法能得到最佳的结果。然而事实往往是，一条 query 可能会有多种解释或者多种 user intents，如果我们返回的 documents 表达的都是错误的 intent 怎么办？用户得不到任何相关文档！这是相当糟糕的体验。 E.g.,12345678910111213multiple interpretationsQuery: discovery channel store– The Discovery Channel store homepage?– Discovery Channel store locations?– Toys and products sold by Discovery Channel stores?– Products based on the Animal Planet program?multiple tasks for the same interpretationQuery: Carnegie Mellon University– Find the home page of CMU (Navigational)– Find the location of CMU (Location)– Check recent news about CMU (News)– Find pictures of CMU (Pictures) 所以我们引入了 多样性 的概念。多样性是 健壮性(robustness) 和 相关性(relevance) 之间的权衡，它会 减少最有可能的 intent 的相关性 覆盖多个 intent 增加鲁棒性 下面描述了两个层次的多样性。 原始查询的解释(Interpretation of the original query) 这个查询是指什么？ 用户想知道这个 query 的哪一个方面的信息？ 每个解释的不同任务(Different tasks for each interpretation) 用户想要完成什么任务？图片？地图？视频？导航？ 这一章我们集中讲 diversification of interpretations。 Diversification Algorithms主要有两类算法。Implicit query intent 隐含在文档排名中 假设相似的文档涵盖了相似的 intent Explicit 显性定义了 query intent 对文档重新排序，以便覆盖所有的 query intent Implicit Methods一些特征： 不需要关于可能存在的 query intent 的先验知识 - 因此称为“隐式” 选择与查询匹配的文档然后重新排序，产生多样性排名 不偏好任何 query intent 受欢迎的 intent 没有得到比 rare intent 更重要 Maximum Marginal Relevance (MMR)主要思路：123456• Use the query to retrieve a ranking R of documents• Use MMR to rerank the top N documents (build a new ranking S) – Select the 1st document based on how well it satisfies the query – Select subsequent documents based on two criteria » How well it satisfies the query » How different it is from documents ranked above it MMR 是贪心算法(greedy algorithm)。在每一个 step，都选择一个文档插入最后的 ranking list。 R: The initial rankingS: Documents already selected for the diverse ranking – Documents ranked above this positionSim(di, dj): Similarity metric – E.g., vector space model or Jensen-Shannon Divergence 举个例子，假设$\\lambda = 0.6$，初始排名及其相关性分数如下1234567Initial Rankingd1, 0.80d2, 0.78d3, 0.76d4, 0.74d5, 0.72d6, 0.70 第一步，选择与 query 最相关的文档 d1，并从 R 中移除 d112Diversified Rankingd1 计算剩余文档与 {d1} 的相似度和对应的多样性分数 选择分数最高的文档作为多样性排名的第 2 篇文档，并从 R 中移除该文档123Diversified Rankingd1d5 分别计算剩余文档与已排序文档 {d1, d5} 的相似度，选相似度最大的值，计算 MMR 分数 选择分数最高的文档作为多样性排名的第 3 篇文档，并从 R 中移除该文档1234Diversified Rankingd1d5d3 分别计算剩余文档与已排序文档 {d1, d5, d3} 的相似度，选相似度最大的值，计算 MMR 分数 选择分数最高的文档作为多样性排名的第 4 篇文档，并从 R 中移除该文档12345Diversified Rankingd1d5d3d6 分别计算剩余文档与已排序文档 d1, d5, d3, d6 的相似度，选相似度最大的值，计算 MMR 分数 选择分数最高的文档作为多样性排名的第 5 篇文档，并从 R 中移除该文档123456Diversified Rankingd1d5d3d6d2 Repeat until all documents in the initial ranking are added to the diversified ranking 所以就有了最后的排名 {d1, d5, d3, d6, d2} MMR 也会用于其它的任务如文本摘要，因为它是符合摘要的基本要求的，即相关性和多样性的权衡。摘要结果与原文的相关性越高，摘要就接近全文中心意思，而多样性则使摘要内容更加的全面。直观和简单是这种方法最大的优点。 Similarity关于相似度的衡量。Anything-to-Anything SimilarityVector space 可以比较任意两个向量的相似度，应用广泛，如聚类。BM25 不能用 anything-to-anything similarity，但可以用 language modeling framework Probabilistic Similarity也有很多专门来计算 probability distribution similarity 的方法。KL divergence 就是其中很受欢迎的一种，然而它是不对称的，Jensen-Shannon Divergence 则是 KL divergence 的一个 symmetric and smoothed 的版本。 $$JS(x||y)={1 \\over 2} KL(x||M) + {1 \\over 2}KL(y|M)$$$$M={x+y \\over 2}$$ 放到两个 document 的比较里 它也经常会用在 anything-to-anything similarity tasks 中。 Learning to Rank for diversificationMMR 是无监督的，而 Learning-to-Rank 就是 MMR 的 supervised 版本。 如果直接用传统的 learning-to-rank 模型来优化一个多样性指标 (e.g., α-NDCG)，也就是用和相同模型、相同特征，但是用基于多样性的训练数据（e.g., pointwise, pairwise, or listwise training data），来学习怎样产生 diversity ranking，会发生什么？ 各种指标会得到不一致的结果 训练数据和测试数据会有不一样的 performance Why?因为传统 Le2R 忽略了文档之间的相关性，它只考虑 document-query 的相关性特征及 query independent 特征（e.g., pagerank），而缺少多样性特征如： 文档-文档的相似性特征 关于 sub-intents 的特征 因此，机器学习算法难以找到适用于多样性模型的合适的权重，相反，多样性的训练数据还会让学习模型感到困惑。所以有了一个解决方案： Relational-LeToR（R-LeToR），既考虑单个文档，又考虑文档与文档之间的关系，也就是说除传统 LeToR 需要的 relevance feature 之外，R-LeToR 还考虑了 relationship features，relationship 也就是相似度，计算的是候选文档与 higher-ranked documents 的相似度(和 MMR 的计算过程相似) 与传统 listwise Le2R 的区别是 ranking function 中多了 relational feature R： Relational featuresRelational features 由相关性函数得到，其输入是文档相似度。 文档间的相似度可以通过下面的方法计算： 文本相似度（Text similarity）:– E.g. KL-Divergence of document language models 主题相似度（Topic similarity）:– E.g. Cosine between docs’ topic distributions in topic models 类别相似度（Category similarity）:– E.g. Overlap of docs’ categories in a predefined ontology 链接相似度（Link similarity）:– E.g. whether docs have hyperlinks to each other URL similarity:– E.g. whether docs are from same website or not. 相关性函数可以是当前文档与 all higher-ranked doc 的： 最小相似度 平均相似度 最大相似度 Relational-ListMLEListMLE 是一种 ListWise LeToR，将一个 query 返回的整个文档排序列表作为输入，直接对排序结果列表进行优化，训练得到一个最优的评分函数，损失函数是 likelihood loss。关于 LeToR 的更多类型，这一篇不多做介绍。 ListMLE 可以轻松地处理各种 relational features。回忆下 ListMLE 的 sequential assumption 自上而下逐个挑选文档，这与 MMR 的 sequential assumption 相同 每个位置独立于先前的位置与 ListMLE 不同的是，Relational-ListMLE 通过 relational features 打破了这种独立性假设 Relational-ListMLE 的生成过程是： 从候选文档中迭代产生新的排序 给定候选文档集合 Si = {d1, …, dn}– 从 Si 中选择最适合出现在位置 i 上的文档 di多提一句，p-ListMLE 也打破了这个假设 Relational-ListMLE 的生成过程是： 从候选文档中迭代产生新的 ranking 给定候选文档集合 Si = {d1, …, dn}– 从 Si 中选择最适合出现在位置 i 上的文档 di Learning and Ranking学习的过程和 ListMLE 完全相同，损失函数仍然是 likelihood loss，用 SGD 优化。 排序时，因为文档依赖于之前的位置，无法像 ListMLE 一样直接计算 ranking score，所以 在 n 个位置的每一个位置上» 从剩余的文档中选择 P(di|Si,w) 最高的文档 » 更新与其他文档的相似性特征 (O(n)) 整个复杂度是 $O(n^2)$，而由于多样性算法是一种重排序方法，所以 n 不是很大，大多数情况下 n &lt;1000 PerformanceR-LeToR 是在 LeToR 基础上的一种最先进的技术，Relational-ListMLE 是唯一的一种监督的学习算法，因此可能比所有隐式和显式方法更好。然而正因为它是最近发表的，没有大量的证据，因此要小心使用。 Explicit MethodsQuery intents (subtopics) discovery怎么发现 query intents? 通过分析搜索日志。下一章会展开。非常挑战，因为 query intent 都很 personal，不同的人有不同的解释，也有很多种 possible subtopics。通常用对 top retrieved documents 进行聚类或 topic modeling 等方法来进行，但是效果并不好。 用已有的经验– 由 TREC 提供的 query intents– 由商业搜索引擎的 query suggestions／related queries 推断出的 query intents 123456Topic 1, type=faceted• Query: obama family tree• Description: Find information on President Barack Obama&apos;s family history, including genealogy, national origins, places and dates of birth, etc.• Subtopic, type=nav: Find the TIME magazine photo essay &quot;Barack Obama&apos;s Family Tree&quot;.• Subtopic, type=inf: Where did Barack Obama&apos;s parents and grandparents come from?• Subtopic, type=inf: Find biographical information on Barack Obama&apos;s mother. 注意两种类型的主题Ambiguous: query 的不相关解释– E.g., “michael jordan”, “avp”, “espn sports” Faceted: query 的相关解释– E.g., “arizona game and fish”, “obama family tree” xQuADxQuAD(eXplicit Query Aspect Diversification (xQuAD))Inputs– An initial ranking– 一组 query intents (e.g., from search engine suggestions) Observation: 单个文档可能覆盖多个 intents，尤其是对 faceted queries 而言。 Key idea: 选择能够满足尽可能多的 uncovered intents 的文档– Provide maximum coverage and minimum redundancy– MMR did this implicitly– xQuAD does it explicitly xQuAD characteristics 需要一组显性的 query intents 允许单个文档满足多个 query intents– 这些文档更有可能有高排名 多样性排名 equally 覆盖了每一个 intent– 也可以对 intent 加权，但实验表明 uniform weights 是最好的 每个 query q 都需要运行 q + {q1, …, qk} 这么多查询语句– 计算量略大 目前可用的最有效的方法之一 算法Assumptions:• 每个查询 q 都有 {q1, …, qk} 这么多 query intents• 这些 query intents 都是相互独立的 R: Initial ranking (produced by some other method)S: Diversified ranking (initially empty)τ: Desired length of diversified ranking$\\lambda$: Balance between relevance and diversity 用相关性模型得到文档集合 R 计算文档分数，得到分数最高的文档 d* 从 R 中移除 d* 把 d* 加入 S Selection criteria:relevance 和 diversity 的平衡$$(1-\\lambda)P(d|q) + \\lambda P(d,\\overline S|q)$$ Diversity component: 实例E.g.,Step 1: Step 2: Step 3: Step 4: Step 5: rankxQuAD 偏好能够满足多个 intents 的文档 Weighting queriesSantos, et al 研究了 weighting queries 的三种方法 Uniform weights: 1 / |Q| 类似于 CRCS 资源排序算法的方法– 与 ReDDE 相似– 与 qi 匹配的 top-ranked documents 的数量相关 基于在商业搜索引擎中匹配的文档的相对数量 在 TREC 2009 的数据中，Uniform 被认为是最有效的。 Some research resultsRelated queries 并没有什么用Suggested queries 更加有效 PM-2Proportionality Model 2 (PM-2)Inputs– An initial ranking– 一组 query intents (e.g., from search engine suggestions) Observation: 用于发现 query intents 的算法，将发现许多稀少或不流行的 intents，高召回率。– They shouldn’t get equal coverage in a diversified ranking Key idea: 每个 subtopic 的文档数量应与每个 subtopic 的 popularity 成正比 最小化冗余 subtopic 的 coverage 可以更好地匹配用户需求 PM-2 characteristics 需要一组显性的 query intents 允许单个文档满足多个 query intents– 这些文档更有可能有高排名 多样性排名按比例的覆盖每一个 intent– 加权是可能的，但均匀的权重是最好的 每个 query q 都需要运行 q + {q1, …, qk} 这么多查询语句可能计算量有点大 与 xQuAD 的相对性能取决于 datasets and explicit topics. 算法PM-2 的思想其实来源自选举制的比例代表制的一种方法：Sainte-Laguë method 123456• At each rank r – 选择下一个必须覆盖的查询意图 qi，来保持排名中的意图比例覆盖率 – 选择一个覆盖了意图 qi 的文档 d » 同时，文档 d 也可能涵盖其他查询意图 – 从原始排名 R 中删除文档 d – 把 d 加入多样化排名S 怎么计算下一个必须覆盖的查询意图 qi？$$qt[i]={v_i\\over 2s_i+1}$$ vi 是分配给这个意图的总文档数，实际等于 p(qi|q) x len(S)si 代表已经分配给这个意图的文档，初始值为 0最高的 quotient score 就对应下一个必须覆盖的意图 实例E.g., 原始的相关性排名 假设：λ=0.6p(qi|q)=0.5Ranking depth=8 Step 0: 初始化变量计算分配给各个意图的文档数 votes v[i]v[1] = 0.5×8 = 4v[2] = 0.5×8 = 4 初始化 slots assigned s[i]s[1] = 0s[2]=0 Step 1，计算 quotient scoreqt[1] = 4 / (2×0+1) = 4qt[2] = 4 / (2×0+1) = 4 选择分数高的意图作为下一个必须覆盖的意图$i^* = 1$ 计算 PM2 分数 d2 wins! Step 2slots assigned s[i]$$s[i]=s[i]+{P(d^*|q_i) \\over \\sum_qP(d^* |q_j)}$$s[1] = 0+0.8/(0.8+0.1) = 0.89s[2] = 0+0.1/(0.8+0.1) = 0.11 Quotient scores qt[i]$$qt[i]={v_i\\over 2s_i+1}$$qt[1] = 4 / (2×0.89+1) = 1.44qt[2] = 4 / (2×0.11+1) = 3.27 selected intent$$argmax_i qt[i]$$$i^* = 2$ d5 wins! Step 3s[1] = 0.89+0.3/(0.3+0.8) = 1.16s[2] = 0.11+0.8/(0.3+0.8) = 0.84 qt[1] = 4 / (2×1.16+1) = 1.20qt[2] = 4 / (2×0.84+1) = 1.49 $i^*=2$ d4 wins! Step 4s[1] = 1.16+0.2/(0.2+0.7) = 1.38s[2] = 0.84+0.7/(0.2+0.7) = 1.62 qt[1] = 4 / (2×1.38+1) = 1.06qt[2] = 4 / (2×1.62+1) = 0.95 $i^* = 1$ d1 wins! Repeat until all documents in the initial ranking are added to the diversified ranking xQuAD vs pm2xQuAD 选择涵盖多个 intents 的文档 给需要覆盖的 intents 赋予较高的权重 PM2 首先选择最需要覆盖的 intent 然后选择一个覆盖这个 intent 的文档 如果这个文档能覆盖其它 intents，那么给它加分 Summary显式方法比 MMR 更有效。但需要一个 query intents 的外部来源，从网络搜索引擎获取的 intents 往往不能令人满意，因为它总是依赖于某一个组织。xQuAD 和 PM-2 都是无监督的，效果不如有监督的模型 R-LeToR。 理想情况下，我们希望能结合这些方法的优点 无需使用外部资源 充分利用 subtopics 充分利用监督学习 Methods of identifying query intents Commercial search engine suggestions– Query suggestions &gt; related queries Still an open problem– Very hard without search log Characteristics MMR: Implicit, unsupervised, penalizes redundancy R-LeToR: Implicit, supervised, features to model redundancy xQuAD: Explicit, unsupervised, penalizes redundancy PM-2: Explicit, unsupervised, enforces proportionality Performance:R-LeToR &gt; PM-2 ≈ xQuAD &gt; MMR Diversity Evaluation MetricsPrecision-IA@k实际是 P@k 的变种。易于计算，易于理解。之前的模型里我们把 $q_i$ 当作 query 的第 i 个 term，而这里，$q_i$ 指代的是 query 的第 i 个 query intent。假设 query q 有 n 个 query intents {q1, …, qn}，每个 intent 出现的概率是 p(qi | q)，一般来说，p(qi | q) 是均匀分布的，也就是 1/n 的概率，不需要 uniform。计算步骤： 采用某种方法对 query q 检索到的文档进行排序 对每个 intent qi 计算 $P@k_{qi}$ 对 P@kqi 求平均得到 Precision-IA@k$Precision-IA@k=\\sum_{qi}P(qi|q)P@k_{qi}$ 评价：通常一个好的策略是给满足了多个 intetns 的文档更高的优先级 能提高 Precision-IA @ k 用一个文档满足多个 intent 是降低风险的有效方法 α-NDCG先来回顾下 NDCG 公式$$NDCG@k = Z_k \\sum_{i=1}^k{2^{R_i}-1 \\over log(1+i)}$$ 考虑了两点： Gain from a document worth R(k) at rank k(based on relevance): $G@k=2^{R(k)}$ Discount for selecting a document at rank k(based on rank): $D@G={1 \\over log_2(1+k)}$ 特点： 考虑了每个文档的位置 允许了多值(multi-valued)的相关性评估 忽略了排名的多样性 它的变种 α-NDCGUses an intent-aware gain calculation The gain vector for α-NDCG discounts intent redundancy 1-α controls the discount If α=0.5Value (j+1th reldoc, qi) = 0.5 ×Value (jth reldoc, qi)(each document is worth 1⁄2 the previous document)","tags":"nlp search-engines 信息检索 多样化"},{"title":"Graphical Models","url":"/2016/12/04/Graphical Models/","text":"CMU 10601 的课程笔记。EM 算法计算含有隐含变量的概率模型参数估计，能使用在一些无监督的聚类方法上。在 EM 算法总结提出以前就有该算法思想的方法提出，例如 HMM 中用的 Baum-Welch 算法。 Graphical ModelsKey idea Conditional independence assumptions useful (but Naive Bayes is extrem) Probabilistic graphical models are a joint probability distribution defined over a graph Two types of graphical models: Directed graphs (Bayesian Networks) Undirected graphs (Markov Random Fields) hard bias:Distribution shares conditional independent assumptions IndependenceMarginal IndependenceDefinition: X is marginally independent of Y if$$(\\forall i,j)P(X=x_i,Y=y_j)=P(X=x_i)P(Y=y_j)$$ 变种：$(\\forall i,j)P(X=x_i|Y=y_j)=P(X=x_i)$$(\\forall i,j)P(Y=y_j|X=x_i)=P(Y=y_j)$ Conditional IndependenceDefinition: X is conditional independent of Y given Z, if the probability distribution governing X is independent of the value of Y, given the value of Z$$(\\forall i,j,k)P(X=x_i|Y=y_j|Z=z_k)=P(X=x_i|Z=z_k)$$即$$P(X|Y,Z)=P(X|Z)$$ DGM(Directed Graphical Models)DGM = Bayes Nets = Bayes Belief NetworksDirected graph = (potentially very large) set of conditional independent assumptions = factorization of joint probability(Likelihood function) Bayesian Networks CausalityCausality =&gt; DCMcannot infer causality from DCMeg. A-&gt;B-&gt;C or C-&gt;B-&gt;A gives same DCM $C \\bot A|B =&gt; A \\bot C|B$ Types of DGMEg. Chain of eventsCloudy -&gt; Rain -&gt; WetgrassI(C;W)&gt;=0I(C;W|R)=0 $C \\bot W|R$ Eg. Multiple Effects Cloudy -&gt; Rain -&gt; SprinklerI(R;S)&gt;=0 $R NOT \\bot S$I(R,S|C)=0 $R \\bot S|C$ Eg. Multiple Causes Rain -&gt; WetgrassSprinkler -&gt; WetgrassI(R;S)=0 $R \\bot S$I(R,S|W)&gt;=0 $R NOT \\bot S|W$ “Explaining away”look one of the factor explains the result Factoring and Count parametersFactoring 主要靠的是 chain rule 和 conditional independence assumptions，计算参数则主要看每个节点的父节点数。without independent AssumptionsP(S,B,L,C,T,F)=P(S)P(B|S)P(L|S,B)P(C|S,B,L)P(T|S,B,L,C)P(F|S,B,L,C,T)# of paras 1+2+4+8+16+32 with these assumptions, condition only on immediate parent=P(S)P(B)P(L|S)P(C|S,B)P(T|S,B)P(T|L)P(F|S,L,C)# of paras 1+1+2+4+2+8=18dominate factor: largest number of parents that any one node has Example再具体一点分析，假设我们有一个警报系统，有以下元素组成123456An alarm system B – Did a burglary occur? E – Did an earthquake occur? A – Did the alarm go off? M – Mary calls J – John calls Factoring joint distributions 12345P(M,J,A,B,E) = P(M |J,A,B,E) P(J,A,B,E) = P(M | J,A,B,E) P(J | A,B,E) P(A| B,E) = P(M | J,A,B,E) P(J | A,B,E) P(A | B,E) P(B,E) P(M | J,A,B,E) P(J | A,B,E) P(A | B,E)P(B | E)P(E) Draw Bayesian Network 对上图来说，共需要 31 个参数。M: 2^4J: 2^3A: 2^2B: 2^1E: 2^0 Use knowledge of domain-&gt; P(B)P(E)P(A|B,E)P(J|A)P(M|A) 现在，需要 10 个参数（A:4, B:1, E:1, J:2, M:2），我们少用了 21 个参数！ Use distribution posterior $P(Xt|Xo,\\overline \\theta)$argmax $Xt = argmax \\ P(Xt|Xo,\\overline \\theta)$ Using the modelGiven the model (struct+params) input-&gt;output Likelihood function twice$P(X_k=0|X_1,..X_{k-1},X_{k+1}…X_p)$$P(X_k=1|X_1,..X_{k-1},X_{k+1}…X_p)$(if binary) normalize the two values, and gets the posterior Condition on X1,X3,X5,X7want to know: distribution over X2,X4,X6,X8need to cal$P(X_2=0,X_4=0,X_6=0,X_8=0,|X_1,..X_{k-1},X_{k+1}…X_p)$$P(X_2=0,X_4=0,X_6=0,X_8=1,|X_1,..X_{k-1},X_{k+1}…X_p)$…$P(X_2=1,X_4=1,X_6=1,X_8=1,|X_1,..X_{k-1},X_{k+1}…X_p)$cal all combinations, normalize, to get the posterior exp(# of unobserved values) Eg.1 Computing full joints$P(B,\\lnot E,A,J,\\lnot M)$ Eg.2 Compute partial joints$P(B|J, \\lnot M)$ $P(B|J, \\lnot M)={P(B,J, \\lnot M) \\over P(B,J, \\lnot M)+P(\\lnot B,J,\\lnot M)}$ Compute $P(B,J, \\lnot M)$Sum all instances with these settings (the sum is over the possible assignments to the other two variables, E and A) 有简化的方法如 Variable elimination，这里不展开。 Things we do with regard to a ML framework Using it (“inference”)DGM: DP, transforming the tree, approximate inference distribution posterior $P(Xt|Xo,\\overline \\theta)$argmax $Xt = argmax \\ P(Xt|Xo,\\overline \\theta)$ Parameter learning: Learning/Deriving/Fitting the parameters (select weights/transition…) &lt;= soft bias/loss function/objective function/optimization functionfrom completed data -&gt; easy: relative frequency+smoothingfrom incompleted data(some days may be missing) -&gt; hard: EM for 1,2 UGM consideration: largest number of click DGM consideration: max number of parents Structure learning: Learning/Deriving/Selecting (select neurons,graph…) &lt;= hard biasthe number of possible structure is hugevery very had, usually not enough datause greedy, AIC, BIC ML-Para learning in DGM$\\hat \\theta_{ML} = argmax \\ L(observed \\ data|\\overline \\theta)$12345 C R S WD1 0 0 0 1D2 0 1 1 1...Dn $P(C)={\\# of \\ C \\over N}$$P(S|C=1)={\\#(C=1|S=1) \\over \\#(C=1)}$Relative frequency + Smoothing Select the structureModel Hierarchymore and more expressive =&gt; complexity of model simple vs fitting tradeoffAIC: maxBIC: fewest para CAL:$\\delta log L(D|\\theta)$ Conditional Random FieldsCRF = UGM Trained Discriminatively$argmax \\ L(labels|inputs,\\theta)$ generative modeling$\\theta=argmax \\ L(D|\\theta)$MAP=argmax P(|x) discriminative method$argmin \\ ERR(classifier|D,\\theta)$better when training data is small","tags":"nlp machine-learning"},{"title":"EM算法","url":"/2016/12/04/EM算法/","text":"CMU 10601 的课程笔记。EM 算法计算含有隐含变量的概率模型参数估计，能使用在一些无监督的聚类方法上。在 EM 算法总结提出以前就有该算法思想的方法提出，例如 HMM 中用的 Baum-Welch 算法。 Mixtures of GaussiansMLE 的通用步骤：Steps: 写出似然函数； 对似然函数取对数，并整理； 求导数，令导数为0，得到似然方程； 解似然方程，得到的参数即为所求； 然而有的时候我们会陷入困境，因为似然方程没法求解，比如 Mixtures of Gaussians。 One GaussianGiven data: X1,…XnModeling assumption: Xi(independently) ~ Gaussian, $\\sigma^2$=1/2LE$$P(x_1,..,x_n|\\mu)={1 \\over \\sqrt{2 \\pi \\sigma^2}} e^{-(x_i-\\mu)^2 \\over 2 \\sigma^2} $$ MLE: $\\hat \\mu_{ML}= argmax \\ L(x_1,..,x_n|\\mu)$$\\mu_{ML} = {\\sum_{i=1}^n \\ x_i \\over n} = \\overline x_i$ K GaussiansGiven data: X1,…XnModeling assumption: Xi(independently) ~ Mixture of K Gaussians $\\sigma^2$=1/2, $\\mu_1,…\\mu_k$Prior probability over Gaussians: $\\lambda_1,…,\\lambda_k \\ 0 \\le \\lambda_j \\le 1 \\ \\sum \\lambda_j=1$, distribution of j is unknown, $\\lambda_j, \\mu_j$ is unknownLE$$\\begin{aligned}P(x_1,..,x_n|\\hat \\lambda,\\hat \\mu,\\sigma^2=0.5) &amp; = \\prod_i^n[\\sum_j^k P(Gaussian \\ j \\ was \\ chosen)P(xi|Gaussian \\ j \\ was \\ chosen)] \\\\ &amp; = \\prod_i^n[\\sum_j^k \\lambda_j{1 \\over \\sqrt{2 \\pi \\sigma^2}} e^{-(x_i-\\mu_j)^2 \\over 2 \\sigma_j^2}]\\end{aligned}$$ MLE: $(\\hat \\mu, \\hat \\lambda)_{ML}= argmax \\ L(x1,..,xn|\\hat \\lambda,\\hat \\mu,\\sigma^2=0.5)$ How to find MLE? “SOFT” K-MEANSsoft: our guesses are probabilities and taking values in [0,1]hard: represents a single best guess (taking values in {0,1} or {1,…k}) Special case of the EM Algorithm$\\sigma^2$=1/2 初始化初始化分布参数θ, $\\mu^{(0)}$,$\\lambda^{(0)}$ 重复 EM 步骤直到收敛1.E-stepFill in the missing variables with the expected values根据参数初始值或上一次迭代的模型参数来计算出隐性变量的后验概率，其实就是隐性变量的期望。作为隐藏变量的现估计值：$$w_j^{(i)}=P(z^{(i)}=j|x^{(i)};\\mu,\\lambda,\\sigma^2=0.5) $$ 2.M-StepRegular maximum likelihood estimation (MLE) using the values computed in the E step and the values of the other variables将似然函数最大化以获得新的参数值 $\\mu^{(l+1)}$,$\\lambda^{(l+1)}$ l: index over EM iterations j: index of Gaussians i: index of datapoints$$\\hat \\lambda_j={\\# j \\ was \\ chosen \\over n}={\\sum_{i=1}^n w_j^{(i)} \\over n}$$$$\\hat \\mu_j={\\sum_{i=1}^n w_j^{(i)} x^{(i)} \\over \\sum_{i=1}^n w_j^{(i)}}$$ EM Algorithm guarantees:$$L(D|\\theta^{[0]}) \\le L(D|\\theta^{[1]}) \\le L(D|\\theta^{[2]})…$$This is a Non-decreasing function. And if the likelihood function is bounded, the sequence will converge. Here the example is bounded, because $\\sigma$ is fixed.It might end up with local optimal. 例题 第一次 iteration 的表格表示 General EM algorithmX observed dataZ unobserved ‘data’Complete data Y=(X,Z)Likelihood function $L(X,Z|\\theta)$ known Problem: find MLE$$ \\begin{aligned} \\hat \\theta_{ML} &amp; = argmax \\ L(X|\\theta)= argmax \\sum_Z P(X,Z|\\theta) \\\\ &amp; = argmax \\sum_Z P(Z|\\theta)P(X|Z,\\theta) \\\\ &amp; = argmax \\sum_Z P(X|\\theta)P(Z|X,\\theta)P(X|Z,\\theta) \\end{aligned}$$ Chicken-egg Problem with regard to P(Z),$\\theta$先有鸡还是先有蛋的问题。当我们知道了哪些 datapoints 属于同一个高斯分布的时候，我们才能够对这个分布的参数作出靠谱的预测，然而现在 datapoints 混在了一起，我们不知道哪个属于哪个，也就没办法估计参数。反过来，只有当我们对 K 个分布的参数作了准确的估计的时候，才知道哪些 datapoints 属于同一个高斯分布。所以陷入了僵局，怎么办？不如就先随便整一个值出来，看你怎么变，然后我再根据你的变化调整我的变化，然后如此迭代着不断互相推导，最终就会收敛到一个解。这就是EM算法的基本思想。 -&gt; chicken stay, egg change EM solution Initialize $\\theta$ to some value EM 方程$$\\theta^{[l+1]}=argmax \\ E_{Z|\\theta^l}[logP(Z,X|\\theta)]$$E 就是 expectation 的 E, write expression for E as function of $\\theta$, expression: auxiliary function $Q(\\theta^{[l]}|\\theta)$M 就是 argmax 的 M, find the MAX over $\\theta$=&gt;Simple EM solution: E-step: express MLE as function of X’s and Z’sknow the value of Z, what would the ML solution M-step: replace each Z with $E[Z|\\theta]$ EM guarantees$$L(X|\\theta^{[l]}) \\le L(X|\\theta^{l+1})$$ If likelihood is bounded, the sequence will converge. Special but most commonly use:$L(X,Z|\\theta)$ is a member of the exponential family 适用情景When to use: Data is only partially observable Unsupervised clustering(target value unobservable) Supervised learning(some instance attributes unobservable) Some uses: Train Bayesian Belief Networks Unsupervised clustering(AUTOCLASS) Learning Hidden Markov Models 参考链接：从最大似然到EM算法浅解（EM算法）The EM Algorithm EM（Expectation-Maximization）算法","tags":"nlp machine-learning"},{"title":"论文笔记 - ReDDE Algorithm for Resource Selection","url":"/2016/11/29/Search Engines笔记 - ReDDE Algorithm for Resource Selection /","text":"对 Luo Si 和 Jamie Callan 的论文 Relevant Document Distribution Estimation Method for Resource Selection 做的一些笔记。之后会整理 Federated search 这一章的笔记。 Distributed information retrievalDistributed information retrieval 也叫做 Federated search，这种搜索引擎包含了多种搜索引擎或者数据库。论文表示 Distributed information retrieval 主要存在三个子问题。 Resource representation。即获取每个数据库的信息 Resource ranking。即对 resource databases 进行排序，对每个 query 选择 a small number of resources。 Result-merging。即对来自不同搜索引擎／数据库对结果进行 merge，产生最终展现给用户的 ranking list。 Database size 估计Database size 是资源描述的重要组成部分。先前的研究表明，评估相似度时对数据库大小进行归一化对结果很重要。resource selection error 也通常是因为 normalize 不同大小的数据库中的 term frequency 时的不合理。 database size 有很多种表现形式： size of vocabulary number of word occurrences number of documents … 论文中的数据库大小用文档数量来表示。目前有的估计 database size 的方法有 Capture-Recapture Method[11], gGIOSS[6], Iperirotis’s Hierarchical Database Sampling and Selection algorithm[8], D’Souza and Thom’s n-term indexing method[5], CORI resource selection algorithm[1,2] 等等。论文介绍了 Capture-Recapture Method，在此基础上提出了 Sample-Resample Method。 Capture-Recapture Method主要思想是通过抽取两个 sample，基于样本独立的假设以及此基础上的概率知识 P(A|B)=P(A) 来推断 database size。 假设：一个 collection 里有两个（或更多）独立的 sample。 N: population size A: the event that an item is included in the first sample which is of size n1 B: the event that an item is included in the second sample which is of size n2 m2: the number of items that appeared in both samples 于是有： $$P(A)={n_1 \\over N} \\qquad (1)$$$$P(B)={n_2 \\over N} \\qquad (2)$$$$P(A|B)={m_2 \\over n_2} \\qquad (3)$$ 因为这两个 sample 是独立的，所以有$$P(A|B)=P(A) \\qquad (4)$$ 所以$$\\hat N={n_1n_2 \\over m_2} \\qquad (5)$$ 通过随机发送 query 到数据库/搜索引擎然后从返回的 document ids 进行抽样，然后估计数据库大小。 论文指出，这种算法可能不现实，这主要是基于成本的考虑。比如说，当估计一个有 300,000 篇文档的数据库，采样过程使用 2000 条 query，每条 query 返回 1000 个 document ids，那么一共就有 2,000,000 (non-unique) documents 需要评估。这个 cost 无疑是巨大的。而我们希望用更低的成本来估计数据库大小。由此论文提出了 Sample-Resample Method。 Sample-Resample MethodCapture-Recapture 算法需要和数据库进行多次交互，Sample-Resample 算法减少了交互的次数。 相关前提假设假定 resource description 由 query-based sampling [13] 产生，每个 resource description list 列出了 抽样的文档数 (number of documents sampled) 抽样文档中包含的 term (the terms contained in sampled documents) 抽样文档中包含各个 term 的文档数 (the number of sampled documents containing each term) 并且，我们假定各个 search engine/database 列出了 match 当前 query 的所有文档数。 过程从当前数据库的 resource description 里随机抽取一个 term，然后把这个 term 当作 query (single-term query) 在当前 database 进行检索，这个过程又叫做 resampling。数据库会返回匹配这个 query 的文档数和一些排在前面的文档 (top-raked documents)。一些 notation 如下： Cj: database Cj_sample: documents sampled from the database when the resource description was created N_cj: size of Cj N_cj_sample: size of Cj sample qi: query term selected from the resouce description for Cj df_qicj: number of documents in Cj that contain qi df_qicj_samp: number of documents in Cj_sample that contain qi A: the event that a document sampled from the database contains term qi B: the event taht a document from the database contains qi 然后，我们就能得到下面的概率。 假设: 从数据库里抽取的样本具有代表性，能够很好的描述整个数据库在这个假设下，我们就可以推断出数据库大小。=&gt; P(A)~P(B)=&gt; Database Size Evaluation Metrics很简单的公式。$$AER={|N-N^\\ast|\\over N^\\ast} \\qquad (9)$$ AER: absolute error ratio $N^{\\ast}$: actual databse size N: estimate Cost重要的成本就是和搜索引擎进行的交互次数。 Liu 和 Yu 在 Capture-Recapture 算法[11]中假定数据库返回的排序列表有 1,000 个 document id。通常来说，像 AltaVista 和 Google 最初都只会返回 top 10 或 20 的结果。如果我们假定搜索引擎每页能返回 10-20 个结果，假定为 20，那么为了得到 1,000 个 docid，需要和数据库进行 50 次交互。当然，如果我们可以提前设定我们从 sample 里取多少条(top k documents)，并且搜索引擎可以让我们限定返回的结果数，那么就只需要和搜索引擎进行 1 次的交互啦，然而这个并不现实，一般搜索引擎不会提供这样的接口。 而 Sample-Resample 算法主要的成本来自于用于 resample 的 queries，每一个 resample query 都需要一次数据库交互，论文里对每个数据库只用了 5 个 resample queries，也就是 5 次交互。与 Capture-Recapture 算法相比 cost 大大降低。 ReDDE 算法资源选择的目的是找出一个包含了许多相关文档的一小撮数据库。如果我们能知道这些相关文档在不同数据库的分布，那么就可以根据每个数据库有的相关文档的数量，给数据库一个 ranking，这个 ranking 叫做 relevance based ranking(RBR)。 数据库 Cj 里与 query q 相关的文档数： Ncj 是数据库 Cj 里的文档总数，可以用 Sample-Resample 的方法估计出来，是估计值我们可以用 $\\hat N_{c_j}$ 来表示。 对于 P(di|Cj)，既然我们有一个 complete resource description，那么这个概率就是 1/Ncj。所以相关文档数就成了 现在就剩下了 P(rel|di)，给定一个文档求相关的概率。我们定义一个 centralized complete database，代表在分布式的 IR 系统里所有 available individual databases 的全集。P(rel|di)是给定一个文档，centralized complete database 返回的这篇文档与 query 相关的概率。这个概率分布可以用 step function 进行建模，也就是说在 ranked list 中排在 top k 的文档的 relevance probability 都是一个常量，其它所有文档的 relevance probability 都是 0。 Cq: query-independent constant rank_central(di): the rank of document di in the centralized complete database ratio: threshold, indicating how the algorithm focuses attention on different parts of the centralized complete DB ranking. 在论文中，ratio 用了 0.003，相当于在一个文档总数为 1,000,000 的数据库里取前 3,000 文档。实验表明，ReDDE 算法在 0.002-0.005 间有比较好的效果。 然而，一个 centralized complete database 难以获取，我们只能建立 centralized sample database 来作为 centralized complete database 的 representative subset，这里的文档来自于在 database resource description 建立的基础上进行的 query-based sample。之前的研究表明，centralized sample database 对 result merging 的归一化文档分数非常有效。 等式 12 和 13 代入 11 就可以计算出 $\\hat Rel_q(j)$，到此，我们就可以通过 normalize 等式 11 的值来估计数据库分布，从而为数据库排名。 实验这里略过了实验，有兴趣的同学可以查看原文。主要是验证了 ReDDE 算法的有效性，并且提出了，提高资源选择不一定能提高检索准确率的结论。 如果我们有一个 centralized complete database，一个搜索算法会返回 TOP 100 的文档，然而这个结果集只在所有文档中占一个非常非常小的比例，ReDDE 算法需要评估更大的比例。比如说，如果 ratio 是 0.003，total testbed size 是 1,000,000 文档，尽管目标是检索 100 篇相关文档，然而资源选择算法会得到在 centralized complete database 的 TOP 3,000 篇文档，优化 TOP 100 和优化 TOP 3,000 并不是一回事儿。当然你可以选择降低 ratio，然而这样的话我们就只能在一个 sampled documents 很少的情况下做决策，使用 small ratio 会使一小部分数据库有 nonzero estimates. 随之而来的改进版 ReDDE 算法，考虑两个 ratio，一个 smaller ratio 一个 larger ratio，对于有 large enough estimation value 的数据库我们用 smaller ratio 来排序，而其他的数据库我们用 larger ratio 来排序，于是对每个数据库，我们用等式 14 可以得到两个 estimation values（DistRel_r1j，DistRel_r2j），r1 的经验值是 0.0005，r2 的经验值是 0.003，过程如下： Rank all the databases that have DistRel_r1j &gt;= backoff_Thres For all the other databases rank them with the values DistRel_r2j. backoff_Thres 在实验中被设为 0.1。 结论CORI 算法是非常有效的一种资源排序算法，然而对很多小的数据库和一部分非常大的数据库组合的环境下(比如公司或者政府环境)效果并不好，于是才引入了 ReDDE 算法。 ReDDE 算法的基本思想是通过使用估计的数据库大小和一个 centralized sample database 来估计 available databases 下相关文档的分布。实验表明 ReDDE 算法在 rank 1-10 下至少能和 CORI 算法一样有效，有些情况下甚至更有效，当然在有很多数据库被搜索的情况下 CORI 算法还是有着优势。 另一个结论是提高资源选择不一定能提高检索准确率。实验表明，ReDDE 算法产生的最终的文档排序和 CORI 算法产生的最终的文档排序至少一样准确，甚至更好。 ReDDE 算法的不足是它采用了常量来对文档相关性建模，这些常量本身可能是一个 weakness。训练数据能够自动来决定 testbed-specific parameter settings，来提高准确性和广泛性，这一点还在研究中。 论文也提出了估计数据库大小对算法 Sample-Resample，与 Capture-Recapture 算法相比，Sample-Resample 算法在各种数据库尤其是大型数据库下稳定性更强。 REFERENCES[1] J. Callan. (2000). Distributed information retrieval. In W.B.Croft, editor, Advances in Information Retrieval. Kluwer Academic Publishers. (pp. 127-150).[2] J. Callan, W.B. Croft, and J. Broglio. (1995). TREC and TIPSTER experiments with INQUERY. Information Processing and Management, 31(3). (pp. 327-343).[3] N. Craswell. (2000). Methods for distributed information retrieval. Ph. D. thesis, The Australian Nation University.[4] A. Le Calv and J. Savoy. (2000). Database merging strategy based on logistic regression. Information Processing and Management, 36(3). (pp. 341-359).[5] D. D’Souza, J. Thom, and J. Zobel. (2000). A comparison of techniques for selecting text collections. In Proceedings of the Eleventh Australasian Database Conference (ADC).[6] L. Gravano, C. Chang, H. Garcia-Molina, and A. Paepcke.(1997). STARTS: Stanford proposal for internet metasearching. In Proceedings of the 20th ACM-SIGMOD International Conference on Management of Data.[7] J.C. French, A.L. Powell, J. Callan, C.L. Viles, T. Emmitt, K.J. Prey, and Y. Mou. (1999). Comparing the performance of database selection algorithms. In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.[8] P. Ipeirotis and L. Gravano. (2002). Distributed search over the hidden web: Hierarchical database sampling and selection. In Proceedings of the 28th International Conference on Very Large Databases (VLDB).[9] The lemur toolkit. http://www.cs.cmu.edu/~lemur[10] InvisibleWeb.com. http://www.invisibleweb.com/[11] K.L. Liu, C. Yu, W. Meng, A. Santos and C. Zhang. (2001). Discovering the representative of a search engine. In Proceedings of 10th ACM International Conference on Information and Knowledge Management (CIKM).[12] A.L. Powell, J.C. French, J. Callan, M. Connell, and C.L. Viles, (2000). The impact of database selection on distributed searching. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.[13] L. Si and J. Callan. (2002). Using sampled data and regression to merge search engine results. In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.[14] J. Xu and J. Callan. (1998). Effective retrieval with distributed collections. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.[15] S. Robertson and S. Walker. (1994). Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval. In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.","tags":"nlp search-engines 信息检索"},{"title":"Bayesian Learning","url":"/2016/11/28/Bayesian-Learning/","text":"CMU 10601 的课程笔记。朴素贝叶斯思想即对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。 Generative and discriminative algorithms Generativetry to model data, how data comes out, which disease cause with symptom with what probability - provide a profile for each disease给定输入 x，生成模型可以给出输入和输出的联合分布 P(x,y)，生成模型的目标是求联合分布 P(x,y)，然后求出条件概率分布 P(Y|X) 作为预测的模型 以朴素贝叶斯为例，生成模型的求解思路是：联合分布——-&gt;求解类别先验概率和类别条件概率 联合分布能提供更多的信息，需要更多的样本和更多计算 收敛速度比较快，当样本数量较多时，生成模型能更快地收敛于真实模型。 生成模型能够应付存在隐变量的情况，比如混合高斯模型就是含有隐变量的生成方法。 e.g. Naive Bayes, HMM Discriminativetry to find mapping symptom -&gt; disease reverse order 判别模型的求解思路是：条件分布——&gt;模型参数后验概率最大——-&gt;（似然函数参数先验）最大——-&gt;最大似然 直接学习 P(Y|X)，节省计算资源，另外，需要的样本数量也少于生成模型 准确率往往较生成模型高 e.g. Logistic Regression 实践中多数情况下判别模型效果更好 MLE and MAPMLE(maximum likelihood estimate): choose $\\theta$ that maximize D probability of observed data.$$\\theta = argmax \\ P(D|\\theta)$$ MAP(maximum a posterior estimate): choose $\\theta$ that is most probable given prior probability and the data.$$\\theta = argmax \\ P(\\theta|D)=argmax \\ {P(D|\\theta)P(\\theta) \\over P(D)}$$ Bayesian statistics主旨 Combine prior knowledge (prior probabilities) with observed data Provides “gold standard” for evaluating other learning algorithms Additional insight into Occam’s razor 图示 要记住的是: today’s posterior is tomorrow’s prior 公式$$P(h|D)= {P(D|h)P(h) \\over P(D)}$$P(h) = prior probability of hypothesis hP(D) = prior probability of training data DP(h|D) = probability of h given DP(D|h) = probability of D given h 推导非常简单12P(h,D) = P(h)P(D|h) = P(D)P(h|D) 一般来说，prior 不能是 0，否则 posterior 也会是 0 了。 Base rate neglectIgnore prior in reasoning If presented with related base rate information (i.e. generic, general information) and specific information (information only pertaining to a certain case), the mind tends to ignore the former and focus on the latter. MAP (Maximum a posteriori)判断 how well a hypothesis matches a data$h \\in H$$$h_{MAP} = argmax P(h|D) = argmax {P(D|h)P(h) \\over P(D)} = argmax P(D|h)P(h)$$ Example 1. Cancer通过例子来说明问题是：这个患者是否有癌症条件是： 一个患者接受了一个检验，显示是阳性的(positive)。 这个检验返回的 correct positive 概率是 98%，correct negative 的概率是 97%。 人群中 0.008 的人可能会患这个癌症。 首先用熟悉符号表示这个问题Hypothesis: $H = {cancer, \\lnot {cancer}}$Prior: $\\pi(cancer) = 0.008$, $\\pi (\\lnot cancer) = 0.992$L(D|h) 123h | pos | negc | 0.98 | 0.02nc | 0.03 | 0.97 右上角的是 false negative (negative result which is false)，又叫 miss左下角的是 false positive (positive result which is false)，又叫 alarmmiss 和 alarm 两者是一个 tradeoff，如果永远都说是 cancer，那么没有任何 miss，却有很多的 alarm 计算：$$ \\begin{aligned} P(c|D=pos) &amp; = {\\pi(c)L(pos|c) \\over P(pos)} \\\\ &amp; = {\\pi(c)L(pos|c) \\over \\sum_i P(pos|h_i)P(h_i)} \\\\ &amp; = {0.008*0.98 \\over 0.008*0.98+0.992*0.03} \\\\ &amp; = 0.208 \\end{aligned}$$ Example 2. Cancer cont.如果第二次检验的结果还是 positive，那么该患者患癌症的几率有多大？ Method 1: Sequential apply of Baye’s Rules前提是 $D1 \\bot D2 |h$此时的 Posterior:$\\pi(cancer) = 0.208$, $\\pi (\\lnot cancer) = 0.792$H, L(D|h) = SAMED2 = pos$$ \\begin{aligned} P(c|D2=pos) &amp; = {\\pi(c)L(pos|c) \\over P(pos)} \\\\ &amp; = {0.208*0.98 \\over 0.208*0.98+0.792*0.03} \\\\ &amp; = 0.895 \\end{aligned}$$ 每多做一次结果为 positive 的 test，最后的概率都会越大。 Method 2123h | ++ | +- | -+ | -- |c | 0.98*0.98 | 0.98*0.02 | 0.02*0.98 | 0.02*0.02 |nc | 0.03*0.03 | 0.03*0.97 | 0.97*0.03 | 0.97*0.97 | SummaryHypothesis H: a family of distributions indexed by $\\ge $ 1 parameters subjective because of prior returns a whole distribution$\\theta_{map} = argmax P(\\theta|D)$ Try to minimize MSE, $\\theta_{mean}$Try to minimize MAE, $\\theta_{median}$ Hard bias: choices of H familySoft bias: priors Frequentist statistics no notion of prior focus on likelihood L(D|h) MLP (Maximum likelihood principle)Given L() function family &amp; data, choose $$\\theta = argmax \\ L(D|\\theta)$$ Example 1. Binomial distribution X~B(n,p)X = {0,…n}$$P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}$$Given n, and result of n flips -&gt; k heads, how to estimate P? 简化$$ \\begin{aligned} P_{ML} &amp; = argmax \\ L(k \\ heads \\ out \\ of \\ n \\ flips | P) \\\\ &amp; = argmax \\binom {n}{k}P^k(1-P)^{n-k}\\\\ &amp; = argmax \\ klogP + (n-k)log(1-P) \\end{aligned}$$ 求导=&gt; $\\int {dll \\over dp} = k {1 \\over p} - (n-k) {1 \\over 1-p} = 0$=&gt; ${k \\over p} = {n-k \\over 1-p}$=&gt; $P_{ML} = {k \\over n}$ Example 2.GaussianFixed stdev, unkown mean X~N$(\\mu \\sigma^2)$$$P(X=x)={1 \\over \\sqrt{2 \\pi \\sigma^2}} e^{-(x_i-\\mu)^2 \\over 2 \\sigma^2}$$Given $\\sigma^2$ &amp; data x1,…xn $ \\in$ IR, drawn i,i,d (independently, identical distributed) 简化$$\\begin{aligned}\\hat \\mu_{ML} &amp; = argmax \\ \\prod_i^n {1 \\over \\sqrt{2 \\pi \\sigma^2}} e^{-(x_i-\\mu)^2 \\over 2 \\sigma^2} \\\\ &amp; = argmax \\sum_i^n {-(x_i - \\mu)^2 \\over 2 \\sigma^2} \\\\ &amp; = argmin \\sum_i^n (x_i-\\mu)^2\\end{aligned}$$ 求导=&gt; $\\int {dll \\over dp} = \\sum_{i=1}^n 2(x_i-\\mu)= 0$=&gt; $\\sum_{i=1}^n x_i-n\\mu$=&gt; $\\mu_{ML} = {\\sum_{i=1}^n \\ x_i \\over n} = \\overline x_i$=&gt; sample mean = max likelihood gaussian true mean Example 3. Linear regression$$y = f(x_1,..x_n) + \\epsilon$$ $$f(\\overline x)=\\sum_{j=1}^n \\beta_jx_j$$ASSUME $\\epsilon$~N $(\\mu, \\sigma^2)$ $\\epsilon = y - f(x_1,…x_n)$ ~ N $(\\mu, \\sigma^2)$ 简化$$\\begin{aligned}L(y_1, ….,y_n|x_1,…,x_n) &amp; = \\prod_i^n L(y_i|\\overline x_i) \\\\ &amp; = \\prod {1 \\over 2 \\pi \\sigma^2} e^{-(y_i-f(\\overline x_i)^2) \\over 2 \\sigma^2}\\end{aligned}$$ 求导$\\hat \\beta = argmax \\sum_{i=1}^n {-(y_i - \\overline x_i)^2 \\over 2 \\sigma^2}$ $= argmin \\ \\sum_{i=1}^n (y_i-f(\\overline x_i)^2)$ $= MSE(mean \\ squared \\ error)$ =&gt; MSE &lt;=&gt; Gaussian noise Special case in Bayesian$\\pi(\\theta) = constant$ (uniform prior)=&gt; $\\theta_{MAP} = argmax \\ \\pi(\\theta)L(D|\\theta) = \\theta_{ML}$ How to estimate P?我们希望 Estimator with enough data, should converge to the true value (asymptotical consistency) fast converge to the right answer (efficiency) low bias (usually no bias)我们希望 $E[\\hat \\theta(D)]=\\theta$。$bias(\\hat \\theta)=E[\\hat \\theta(D)]-\\theta$ 这里我们想让它为 0，但是如果这是 ML inductive bias，我们不希望它为 0. low variance (but can have high variants especially with little data) MDL (minimum length description principle)Encode 数据。比如说我们要传递 1-100 万之间的质数，那我们只用告诉对方这是质数，而不用把所有的质数列出来，如果我们要传递的是除了 2 和 3 的质数，那么我们要告诉对方这是质数，而且里面没有 2 和 3。放到 machine learning 里，假设双方都有一堆数据 X1..Xn(X有若干属性(x11,x22…xnn)，我们要通讯的是 Y 也就是 X 的标签，我们可以按顺序传送，这需要很多的 bits，或者可以建立一个 decision tree，这个 tree 可以 classify 大多数的数据，把 tree + exceptions 发送给对方就好，可以节省很多 bits。$h_{MDL}$ = argmin (bits to describe h + bits to describe exceptions) Naive Bayes ClassificationGoalf: X -&gt; Y &lt;=&gt; P(Y |X )X = ⟨X1,X2 …,Xn⟩ n 个属性Y = boolean value true or false 根据 Bayes rule, 来算 P(Y = yi|X)$$P(Y=y_i|X=x_k)={P(X=x_k|Y=y_i)P(Y=y_i) \\over \\sum_j P(X=x_k|Y=y_j)P(Y=y_j)}$$ 我们的目的是学习 P(Y|X)，来估计 P(X|Y) 和 P(Y)，用这些估计值，加上上面的 Bayes rule，就可以对新的 instance 分类。 Unbiased Learning of Bayes Classifiers is ImpracticalUnbiased Learning of Bayes Classifiers 是不实际的，因为它要估计的参数太多，计算量太大。当 Y is boolean and X is a vector of n boolean attributes 的情况下，我们为了得到 P(X|Y) 需要的估计的参数有： $$θ_{ij} ≡P(X =x_i|Y =y_j)$$ i takes on $2^n$ possible values (one for each of the possible vector values of X )j takes on 2 possible values (boolean) =&gt; $2^{n+1}$ parameters For any fixed j, the sum over i of $θ_{ij}$ must be one.i takes on $2^n-1$ possible values (one for each of the possible vector values of X )j takes on 2 possible values (boolean)=&gt; $2(2^n-1)$ parameters To obtain reliable estimates of each of these parameters, we will need to observe each of these distinct instances multiple times! This is clearly unrealistic in most practical learning domains. For example, if X is a vector containing 30 boolean features, then we will need to estimate more than 3 billion parameters. Naive Bayes AlgorithmNaive Bayes 的优势在于它能让我们对 P(X|Y) 建模时用更少的参数，$2(2^n-1)$ -&gt; 2n Naive bayes assumption (Independence assumption) Each $X_i$ is conditionally independent of each of the other $X_ks$ given Y, and also independent of each subset of the other $X_k$’s given Y. 在这个假设下，我们举个例子，X = ⟨X1,X2⟩ 时，可以得到 $$\\begin{aligned}P(X|Y) &amp; = P(X1,X2|Y) \\\\ &amp; = P(X1|X2,Y)P(X2|Y) \\\\ &amp; = P(X1|Y)P(X2|Y)\\end{aligned}$$ 更加 general 的形式 Factor L(|Y)$$P(X1,X2…Xn|Y)=\\prod_{i=1}^nP(X_i|Y)$$ 同样的，Y and the Xi are boolean variables，这时候，我们只需要 2n 个参数来定义 $P(X_i = x_{ik}|Y = y_j)$! 首先我们产生 label，然后从 label 我们产生每一个属性。我们可以用下面的图来表示这种关系。 这个假设经常会被打破，然而即使是 horrible assumption，Naive Bayes 的效果也非常好。tend to give extreme result Derivation of Naive Bayes Algorithm 在 conditional independent assumption 下，可以继续得到$$P(Y=y_k|X1…Xn)={P(Y=y_k)\\prod_i P(X_i|Y=y_k) \\over \\sum_j P(Y=y_j)\\prod_iP(Xi|Y=y_j)} \\ (2)$$ $$Y \\ &lt;= \\ argmax \\ {P(Y=y_k)\\prod_i P(X_i|Y=y_k) \\over \\sum_j P(Y=y_j)\\prod_iP(Xi|Y=y_j)}$$ 简化下就是$$Y \\ &lt;= \\ argmax \\ P(Y=y_k)\\prod_i P(X_i|Y=y_i=k) \\ (3)$$ Naive Bayes for Discrete-Valued InputsParametersn input attributes Xi each take on J possible discrete valuesY: a discrete variable taking on K possible values Learning task is to estimate two sets of parameters.$$\\theta_{ijk}≡P(X_i=x_{ij}|Y=y_k)$$ 这需要 nJK 个参数，对每个 j,k value 都满足 $1 = \\sum_j \\theta_{ijk}$，也就是 n(J-1)K 个参数。 另外我们要定义 prior probability over Y$$\\pi_k=P(Y=y_k)$$需要 K-1 个参数。 Estimate parameters有两种估计参数的方法。Maximum likelihood 和 Bayesian MAP。 MLE: 这种情况下有一个危险，当没有 example 符合条件的情况下，$\\theta$ 可能为 0，所以我们需要 smooth。 J: the number of distinct values Xi can take onl: determines the strength of this smoothing 同样的，估计 $\\pi_k$ K: the number of distinct values Y can take onl: determines the strength of the prior assumptions relative to the observed data D. MAP classifier:$Vmap = argmax P(v|a_1=x_1…a_n=x_n)=argmax P(v)L(a_1=x_1…a_n=x_n|v)$ 为了估计 prior，我们需要 O(k) 个 parameter，这一般不是问题。估计 L 的概率，我么需要 EXP(n) 个 parameter。 通过 Factor analysis 来减少 parameters Naive Bayes for Continuous Inputs当输入是连续的情况下，我们同样可以用(2)(3)来设计 Naive Bayes classifier，然而，由于 Xi 是连续的，我们必须用不同的方法来表示 P(Xi|Y) 的分布。通常的方法是假设 Xi 服从 Gaussian 分布，于是我们要定义 mean 和 standard deviation。 $$\\mu_{ik}=E[X_i|Y=y_k]$$ $$\\sigma^2_{ik}=E[(X_i-\\mu_{ik})^2|Y=y_k]$$这样我们需要估计 2nK 个参数。 prior:$$\\pi_k=P(Y=y_k)$$ Squashing因为 independency 的假设，我们会得到非常极端的数值，如真实概率是 0.7, NB 出来的结果可能是 0.99999，真实概率是 0.2，NB 出来的结果可能是 0.0000001。$$P^{\\alpha}(y) \\over \\sum_i^n P^{\\alpha}(y)$$ Naive Bayes Classifier vs Logistic Regression LR is discriminative classifier as LR directly estimates the parameters of P(Y|X). We can view the distribution P(Y|X) as directly discriminating the value of the target value Y for any given instance X. NB is generative classifier as NB directly estimates parameters for P(Y) and P(X|Y). We can view the distribution P(X|Y) as describing how to generat random instances X conditioned on the target attribute Y. NB is with greater bias but lower variance than LR. AlgorithmNaive_Bayes_Learn(examples) For each target value vj $\\hat P(vj) &lt;- estimate P(vj)$ For each attribute value ai of each attribute a $\\hat P(ai|vj) &lt;- estimate P(ai|vj)$ Classifier_New_Instance(x) $Vnb = argmax \\hat P(vj)\\prod \\hat P(ai|vj)$ Examplenew instance $$Vnb = argmax \\hat P(vj)\\prod \\hat P(ai|vj)$$ P(y)P(sun|y)P(cool|y)P(high|y)P(strong|y)=0.005P(n)P(sun|n)P(cool|n)P(high|n)P(strong|n)=0.021 Learn Naive Bayes Text算法 python 代码运行命令 python nb.py split.train split.test split.train / split.test 每行是一个 training file 文件名，有两个类别，con 和 lib。123456789101112131415con10.txtcon11.txtcon1.txtcon46.txtcon48.txtcon6.txtlib16.txtlib25.txtlib28.txtlib29.txtlib2.txtlib30.txtlib31.txtcon25.txtcon39.txt training file 每行是代表这个文件名类别的单词1234567RandomJottingsOctober302008Andyou 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import mathimport sysfrom collections import Counterfrom sets import Set# collect all distinct words and other tokens in examplesdef initiate(file): global conDoc, libDoc, conCounter, libCounter conCounter, libCounter = Counter(), Counter() conDoc, libDoc = 0, 0 f = open(file, &apos;r&apos;) files = f.readlines() for file in files: assert file.startswith(&apos;con&apos;) or file.startswith(&apos;lib&apos;) if file.startswith(&apos;con&apos;): conDoc += 1 conCounter = readTrain(file.strip(), conCounter, libCounter) else: libDoc += 1 libCounter = readTrain(file.strip(), libCounter, conCounter)def readTrain(trainFile, tokenDict, secondDict): f = open(trainFile, &apos;r&apos;) tokens = [line.strip().lower() for line in f] for token in tokens: tokenDict[token] += 1 if token not in secondDict: secondDict[token] = 0 return tokenDict# calculate the requeired P(vj) and P(wk|vj)probability termsdef train(file): global conDoc, libDoc, conCounter, libCounter, priorCon, priorLib initiate(file) # P(vj) = docsj/examples priorCon = math.log(conDoc / float(conDoc + libDoc)) priorLib = math.log(libDoc / float(conDoc + libDoc)) # total number of words in Vocabulary vocLen = len(Set(conCounter.keys()).union(Set(libCounter.keys()))) # P(wk|vj) = (nk+1)/(n+vocLen) conN = sum(conCounter.values()) + vocLen libN = sum(libCounter.values()) + vocLen conDefault = math.log(1.0 / conN) libDefault = math.log(1.0 / libN) for key in conCounter: conCounter[key] = math.log( float(conCounter[key] + 1) / conN) for key in libCounter: libCounter[key] = math.log( float(libCounter[key] + 1) / libN)def test(file): global conDoc, libDoc, conCounter, libCounter, priorCon, priorLib testFile = open(file) testNum, correct = 0, 0 for line in testFile: testNum += 1 libProb = priorLib conProb = priorCon conProb, libProb = readTest(line.strip(), conProb, libProb) # print conProb,libProb if conProb &gt; libProb: print &apos;C&apos; if line.startswith(&apos;con&apos;): correct += 1 else: print &apos;L&apos; if line.startswith(&apos;lib&apos;): correct += 1 accuracy = correct / float(testNum) print &quot;Accuracy: %.04f&quot; % accuracydef readTest(file, conProb, libProb): global conCounter, libCounter f = open(file, &apos;r&apos;) tokens = [line.strip().lower() for line in f] for token in tokens: if token in conCounter: conProb += conCounter[token] if token in libCounter: libProb += libCounter[token] return conProb, libProbif __name__ == &quot;__main__&quot;: trainFile = sys.argv[1] testFile = sys.argv[2] train(trainFile) test(testFile) Error and test of hypothesisTrue error of hypothesissample error 和 true error 是不一样的。从 X 中抽取的样本 S，hypothesis h 关于 S 的 sample error 是 h 的实例在 S 中所在的比例，true error 也就是 true error 指的是对按某个分布随机抽取的实例，h 对它错误分类的概率。 h was wrong on 3/20 TEST ~ DTrue error rate of $P(h(x)) \\neq c(x)$ x ~ D 可能样本里只有一个 instance 错误，但是真实中会有很多这样的 input。 如果 $\\hat \\theta_{error} = 0.15$ Compare two hypothesis计算 sample error 之间的差异，通过统计学理论计算。$Err(h_A) &gt;&lt;= Err(h_B)$ =&gt; Err(h_B) - Err(h_A) &gt; 0?Depend on sample Compare learning algorithmsLa: training set -&gt; $h_A$Lb: training set -&gt; $h_b$ Compare h_A(test set y) h_B(test set y) better on this training setavg performance of La is better than Lb True error, E[Err_{test~D}[$L_A$(train ~ D)]] this is hypothesis","tags":"nlp machine-learning"},{"title":"Hidden-Markov-Models","url":"/2016/11/26/Hidden-Markov-Models/","text":"CMU 10601 的课程笔记。上一章讲了 Bayesian networks，我们发现它对 joint distributions 建模很有用，然而却不能解释 temporal/sequence models，也没法解释循环问题。所以需要引入另一个模型，隐马尔可夫模型（Hidden Markov Model，HMM）。HMM 用来描述一个含有隐含未知参数的马尔可夫过程。难点是从可观察的参数中确定该过程的隐含参数，然后利用这些参数来作进一步的分析。 Markov Process要素 States: 所有可能出现的状态。$S={S_0, S_1, …S_n}$ Transition probabilities: 状态和状态间转换的概率。$P(q_t=S_i|q_{t-1}=S_j)$ 假设First order markov assumptionTransition probability depends only on current state即 $P(q_t=S_i|q_{t-1}=S_j,q_{t-2}=S_k) = P(q_t=S_i|q_{t-1}=S_j) = a_{ji}$$a_{ji} &gt;=0 \\ \\forall j,i$ 且 $\\sum_{i=0}^N a_{ji}=1 \\ \\forall j$即 $q_t \\bot q_j|q_{t-1} \\ j&lt;t-1$即 Markov Process only remembers one state at a time 不具备记忆特质（memorylessness），条件概率仅仅与系统的当前状态相关，而与它的过去历史或未来状态，都是独立、不相关 $P(q_1….q_T) = \\prod P(q_t|q1….q_{t-1}) = \\prod P(q_t|q_{t-1})$ 隐马尔可夫(HMM)用途 signal processing speech processing low level NLP: eg. POS tagging, phrase chunking, target information extraction 概念用一个例子来描述吧，网上有一篇帖子讲的非常好，这里就直接引用过来了。 假设我手里有三个不同的骰子。第一个骰子是我们平常见的骰子（称这个骰子为 D6），6个面，每个面（1，2，3，4，5，6）出现的概率是1/6。第二个骰子是个四面体（称这个骰子为 D4），每个面（1，2，3，4）出现的概率是1/4。第三个骰子有八个面（称这个骰子为 D8），每个面（1，2，3，4，5，6，7，8）出现的概率是1/8。 假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是1/3。然后我们掷骰子，得到一个数字，1，2，3，4，5，6，7，8中的一个。不停的重复上述过程，我们会得到一串数字，每个数字都是 1，2，3，4，5，6，7，8中的一个。例如我们可能得到这么一串数字（掷骰子10次）：1 6 3 5 2 7 3 5 2 4 这串数字叫做可见状态链(observations)。但是在隐马尔可夫模型中，我们不仅仅有这么一串可见状态链，还有一串隐含状态链。在这个例子里，这串隐含状态链就是你用的骰子的序列。比如，隐含状态链有可能是：D6 D8 D8 D6 D4 D8 D6 D6 D4 D8 (states) 一般来说，HMM中说到的马尔可夫链其实是指隐含状态链，因为隐含状态（骰子）之间存在转换概率（transition probability）。在我们这个例子里，D6 的下一个状态是 D4，D6，D8 的概率都是1/3。D4，D8的下一个状态是 D4，D6，D8 的转换概率也都一样是 1/3。这样设定是为了最开始容易说清楚，但是我们其实是可以随意设定转换概率的。比如，我们可以这样定义，D6 后面不能接 D4，D6 后面是 D6 的概率是0.9，是 D8 的概率是 0.1。这样就是一个新的 HMM。 同样的，尽管可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（emission probability）。就我们的例子来说，六面骰（D6）产生 1 的输出概率是 1/6。产生 2，3，4，5，6 的概率也都是 1/6。我们同样可以对输出概率进行其他定义。比如，我有一个被赌场动过手脚的六面骰子，掷出来是1的概率更大，是 1/2，掷出来是 2，3，4，5，6 的概率是 1/10。 要素定义一些 notation。 States(S): 隐含状态。$S={S_0, S_1, …S_n}$ Transition probabilities(A): 状态和状态间转换的概率P(Si-&gt;Sj)。$P(q_t=S_i|q_{t-1}=S_j)=a_{ji}$n*n matrix of transition probabilities Emission probabilities(B) / Output prob distribution (at state j for symbol k): 发射概率（隐状态表现为显状态的概率）。状态 j 下，表现为 k 的概率。$P(y_t=O_k|q_t=S_j)=b_j(k)$n*m matrix of emission probabilities Observations: 观测序列(可见状态)。$O={O_0, O_1, …O_n}$ Prior: 初始概率（隐状态） Probabilistic graphical models HMM 的问题与解决对于HMM来说，如果提前知道所有隐含状态之间的转换概率和所有隐含状态到所有可见状态之间的输出概率，做模拟是相当容易的。但是应用 HMM 模型时候呢，往往是缺失了一部分信息的，有时候你知道骰子有几种，每种骰子是什么，但是不知道掷出来的骰子序列；有时候你只是看到了很多次掷骰子的结果，剩下的什么都不知道。如果应用算法去估计这些缺失的信息，就成了一个很重要的问题。和 HMM 模型相关的算法主要分为三类，分别解决三种问题。 Evaluation Problem Problem: Compute probability of observation sequence given a model $P(O|\\lambda)$Given $\\lambda, \\overline O=O1,…Ot, =&gt; Calculate \\ P(\\overline O|\\lambda)$知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道掷出这个结果的概率。 Solution: Forward Algorithm, Viterbi Algorithm 问这个问题的目的在于检测观察到的结果是否和已知的模型吻合。如果很多次结果都对应了比较小的概率，那么就说明我们已知的模型很有可能是错的，有人偷偷把我们的骰子給换了。 Decoding Problem Problem: Find the state sequence Q which maximizesGiven $\\lambda = (A,B), \\overline O=O1,…Ot, =&gt; Calculate $$\\overline Q_{MAP}=argmax P(\\overline Q|\\overline O,\\lambda)=argmax {P(\\overline Q,\\overline O|\\lambda) \\over P(\\overline O|\\lambda)} = argmax P(\\overline Q,\\overline O|\\lambda)$知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道每次掷出来的都是哪种骰子（隐含状态链）。 Solution: Viterbi Algorithm 这个问题其实有两种解法，会给出两个不同的答案。每个答案都对，只不过这些答案的意义不一样。第一种解法求最大似然状态路径，说通俗点呢，就是我求一串骰子序列，这串骰子序列产生观测结果的概率最大。第二种解法呢，就不是求一组骰子序列了，而是求每次掷出的骰子分别是某种骰子的概率。比如说我看到结果后，我可以求得第一次掷骰子是D4的概率是0.5，D6的概率是0.3，D8的概率是0.2.第一种解法我会在下面说到，但是第二种解法我就不写在这里了，如果大家有兴趣，我们另开一个问题继续写吧。 Training(Learning) Problem Problem: Adjust model parameters to maximize probability of observed sequencesGiven $\\overline O=O1…Ot$ =&gt; Estimate $\\hat \\lambda_{ML} = argmax P(\\overline O|\\lambda)$知道骰子有几种（隐含状态数量），不知道每种骰子是什么（转换概率），观测到很多次掷骰子的结果（可见状态链），我想反推出每种骰子是什么（转换概率）。 Solution: Forward-Backward Algorithm 这个问题很重要，因为这是最常见的情况。很多时候我们只有可见结果，不知道 HMM 模型里的参数，我们需要从可见结果估计出这些参数，这是建模的一个必要步骤。 Estimate A, B$a_{ij_{ML}} = {\\#(i-&gt;j) \\over \\#(i)}$ + SMOOTHING$b_{j(Ok)_{ML}} = {\\#(j \\quad AND \\quad Ok) \\over \\#(j)}$ + SMOOTHING 算法Forward Algorithm 前向算法$\\alpha = P(O_1 O_2 … O_t, q_t = S_j|\\lambda)$基本逻辑是：穷举所有的骰子序列，还是计算每个骰子序列对应的概率，但是这回，把所有算出来的概率相加，得到的总概率就是我们要求的结果。我们还需要一个 prior, 来表示 no states before 的情况。 $P(\\overline O|\\lambda)=a_{q0q1}b_{q1(y1)}a_{q1q2}b_{q2(y2)}…a_{q_{t-1}qt}b_{qt(yt)}$即 $P(\\overline O|\\lambda)=\\sum_QP(\\overline O,\\overline Q|\\lambda)$ 递归的方法来计算 $\\alpha$ 图解 例子 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788from math import *from logsum import log_sumimport sysdef initiate(transFile, emitFile, priorFile): global states, trans, emit, prior states, trans = probFileHandler(transFile) noUse, emit = probFileHandler(emitFile) prior = priorFileHandler(priorFile) # print &apos;states &apos;, states # print &apos;trans &apos;, trans # print &apos;prior &apos;, priordef probFileHandler(myFile): # states S S = [] # transition or emit probability P = dict() # trans or emit f = open(myFile) for line in f: words = line.strip().split() S.append(words[0]) d = dict([[words[i].split(&apos;:&apos;)[0], log(float(words[i].split(&apos;:&apos;)[1]))] for i in range(1, len(words))]) P[words[0]] = d return S, Pdef priorFileHandler(myFile): f = open(myFile) prior = dict() for line in f: words = line.strip().split() prior[words[0]] = log(float(words[1])) return priordef forward(word, alpha): global states, trans, emit, prior res = [] # initial state if not alpha: for i in range(len(states)): curState = states[i] # use prior as trans_ji, at[j]*aji, use logsum res.append(prior[curState] + emit[curState][word]) # if not initial state, iterate else: for i in range(len(states)): curState_i = states[i] for j in range(len(states)): curState_j = states[j] trans_ji = trans[curState_j][curState_i] if j == 0: curRes = alpha[j] + trans_ji else: # sum up all at[j]*aji, use logsum curRes = log_sum(curRes, alpha[j] + trans_ji) # generate emit probability at t+1 at state i and multiply curRes += emit[curState_i][word] res.append(curRes) return resdef devFileHandler(myFile): f = open(myFile) for line in f: words = line.strip().split() alpha = [] for word in words: alpha = forward(word, alpha) res = alpha[0] # P(O|lambda)=alphaT*(endingStateN) for i in range(1, len(alpha)): res = log_sum(res, alpha[i]) print resif __name__ == &apos;__main__&apos;: devFile = sys.argv[1] transFile = sys.argv[2] emitFile = sys.argv[3] priorFile = sys.argv[4] initiate(transFile, emitFile, priorFile) devFileHandler(devFile) Backward Algorithm$\\beta_t(i)=P(O_{t+1}O_{t+2}…O_T|q_t=S_i, \\lambda)$ 同样，递归的方法来计算 $\\beta$ 例子 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283from math import *from logsum import log_sumimport sysdef initiate(transFile, emitFile, priorFile): global states, trans, emit, prior states, trans = probFileHandler(transFile) noUse, emit = probFileHandler(emitFile) prior = priorFileHandler(priorFile) # print &apos;states &apos;, states # print &apos;trans &apos;, trans # print &apos;prior &apos;, priordef probFileHandler(myFile): # states S S = [] # transition or emit probability P = dict() # trans or emit f = open(myFile) for line in f: words = line.strip().split() S.append(words[0]) d = dict([[words[i].split(&apos;:&apos;)[0], log(float(words[i].split(&apos;:&apos;)[1]))] for i in range(1, len(words))]) P[words[0]] = d return S, Pdef priorFileHandler(myFile): f = open(myFile) prior = dict() for line in f: words = line.strip().split() prior[words[0]] = log(float(words[1])) return priordef backward(word, beta): global states, trans, emit, prior res = [] for i in range(len(states)): curState_i = states[i] for j in range(len(states)): curState_j = states[j] # transpose matrix!!!! trans_ij = trans[curState_i][curState_j] if j == 0: curRes = beta[j] + trans_ij + emit[curState_j][word] else: # sum up all at[j]*aji*emit[j], use logsum curRes = log_sum( curRes, beta[j] + trans_ij + emit[curState_j][word]) res.append(curRes) return resdef devFileHandler(myFile): f = open(myFile) for line in f: words = line.strip().split() # initialize, all states could be ending states beta = [0.0 for i in range(len(states))] for i in range(len(words) - 1, 0, -1): beta = backward(words[i], beta) res = prior[states[0]] + emit[states[0]][words[0]] + beta[0] for i in range(1, len(beta)): res = log_sum(res, prior[states[i]] + emit[states[i]][words[0]] + beta[i]) print resif __name__ == &apos;__main__&apos;: devFile = sys.argv[1] transFile = sys.argv[2] emitFile = sys.argv[3] priorFile = sys.argv[4] initiate(transFile, emitFile, priorFile) devFileHandler(devFile) Viterbi AlgorithmViterbi 被广泛应用到分词，词性标注等应用场景。和 Forward algorithm 差不多，两点改变： 把 SUM 改成 MAX。 记录 MAX 的h状态。 例子 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697from math import *from logsum import log_sumimport sysimport copydef initiate(transFile, emitFile, priorFile): global states, trans, emit, prior states, trans = probFileHandler(transFile) noUse, emit = probFileHandler(emitFile) prior = priorFileHandler(priorFile) # print &apos;states &apos;, states # print &apos;trans &apos;, trans # print &apos;prior &apos;, priordef probFileHandler(myFile): # states S S = [] # transition or emit probability P = dict() # trans or emit f = open(myFile) for line in f: words = line.strip().split() S.append(words[0]) d = dict([[words[i].split(&apos;:&apos;)[0], log(float(words[i].split(&apos;:&apos;)[1]))] for i in range(1, len(words))]) P[words[0]] = d return S, Pdef priorFileHandler(myFile): f = open(myFile) prior = dict() for line in f: words = line.strip().split() prior[words[0]] = log(float(words[1])) return priordef viterbi(word, alpha, resPath): global states, trans, emit, prior res = [] curPath = [] # initial state if alpha == []: for i in range(len(states)): curState = states[i] # use prior as trans_ji, at[j]*aji, use logsum res.append(prior[curState] + emit[curState][word]) curPath.append([i]) # if not initial state, iterate else: for i in range(len(states)): curState_i = states[i] curMaxIndex = 0 for j in range(len(states)): curState_j = states[j] trans_ji = trans[curState_j][curState_i] if j == 0: curMax = alpha[j] + trans_ji + emit[curState_i][word] else: # sum up all at[j]*aji, use logsum curRes = alpha[j] + trans_ji + emit[curState_i][word] if curMax &lt; curRes: curMax = curRes curMaxIndex = j # generate emit probability at t+1 at state i and multiply #curMax += emit[curState_i][word] res.append(curMax) # choose max curPath.append(copy.deepcopy(resPath[curMaxIndex])) curPath[i].append(i) return res, curPathdef devFileHandler(myFile): f = open(myFile) for line in f: words = line.strip().split() alpha = [] resPath = [] for word in words: alpha, resPath = viterbi(word, alpha, resPath) final = resPath[alpha.index(max(alpha))] for i in range(len(words)): print words[i] + &apos;_&apos; + states[final[i]], printif __name__ == &apos;__main__&apos;: devFile = sys.argv[1] transFile = sys.argv[2] emitFile = sys.argv[3] priorFile = sys.argv[4] initiate(transFile, emitFile, priorFile) devFileHandler(devFile) Forward-Backward Algorithm算法 计算 $\\alpha$, $\\beta$,$\\Xi$ 时间复杂度 O(NNT) Baum-Welch Reestimation估计 $\\overline \\lambda$ $$\\overline a_{ij} = {expected \\ number \\ of \\ trans \\ from \\ Si \\ to \\ Sj \\over expected \\ number \\ of \\ trans \\ from \\ Si}$$=&gt; $$\\overline b_{j(k)} = {expected \\ number \\ of \\ times \\ in \\ state \\ j \\ with \\ symbol \\ k \\over expected \\ number \\ of \\ times \\ in \\ state \\ j } $$ 一文搞懂HMM（隐马尔可夫模型）","tags":"nlp machine-learning"},{"title":"深度学习-链式反向梯度传导","url":"/2016/11/23/神经网络-链式反向梯度传导/","text":"反向梯度传播实例。 计算顺序： 从 loss 向输入传播导数存储： 每层的导数 $(\\Delta y, \\Delta x)$ 结果进行存储，用于下一层导数的计算。 假设 $loss = ax_{1,t}+bx_{2,t}+cx_{3,t}+d-y$，当前参数 $m_0 = [a_0, b_0,c_0,d_0]$，那么计算梯度 $\\Delta m=[x_{1,t}, x_{2,t}, x_{3,t}, 1]$，也就是分别求偏导。参数的更新为 $m:=m-\\eta \\Delta m$ 下面的例子，黑色加深部分是前向计算的结果，我们的目的是求反向传播梯度。(原谅我 poor hand-writting :( ) 小结： 随机初始化参数 开启循环：t=0,1,2… 带入数据求出结果 $\\hat y_t$ 与真值比较得到 $loss=y-\\hat y_t$ 对各个变量求导得到 $\\Delta m$ 更新变量 m 如果 loss 足够小或者 t 循环结束，停止","tags":"deep-learning 反向传播"},{"title":"数据结构和算法 -- 动态规划","url":"/2016/11/12/动态规划/","text":"我们再次强调：动态编程的核心在于，如果在一个问题的解决方案中，子问题被重复计算，那么就可以利用记录中间结果，达到用空间换取时间的目的。 模板12345678910111213141516class Solution(object): def __init__(self): self.cache = dict() def f(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n in self.cache: return self.cache[n] if n == 0 or n == 1: return n self.cache[n] = self.f(n - 1) + self.f(n - 2) return self.cache[n] 例题70. Climbing StairsProblemYou are climbing a stair case. It takes n steps to reach to the top. Each time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top? Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&apos;&apos;&apos;Dynamic programming.Induction Rule:T(n)=T(n-1)+T(n-2)Base cases:if n &lt;= 0, then the number of ways should be zero.if n == 1, then there is only way to climb the stair.if n == 2, then there are two ways to climb the stairs. One solution is one step by another; the other one is two steps at one time.The key intuition to solve the problem is that given a number of stairs n, if we know the number ways to get to the points [n-1] and [n-2] respectively, denoted as n1 and n2 , then the total ways to get to the point [n] is n1 + n2. Because from the [n-1] point, we can take one single step to reach [n]. And from the [n-2] point, we could take two steps to get there. There is NO overlapping between these two solution sets, because we differ in the final step.Now given the above intuition, one can construct an array where each node stores the solution for each number n. Or if we look at it closer, it is clear that this is basically a fibonacci number, with the starting numbers as 1 and 2, instead of 1 and 1.Recursive method:- cache, time complexity: O(n), space complexity: O(n)Follow up:- space complexity: O(1) use two pointers&apos;&apos;&apos;class Solution(object): def __init__(self): self.cache = dict() # Recursive method &apos;&apos;&apos; def climbStairs(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n &lt;= 0: return 0 if n in self.cache: return self.cache[n] if n==1 or n==2: return n self.cache[n] = self.climbStairs(n-1) + self.climbStairs(n-2) return self.cache[n] &apos;&apos;&apos; # two pointers def climbStairs(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n &lt;= 0: return 0 if n == 1 or n == 2: return n pre,cur = 1, 2 for i in range(2,n): pre, cur = cur, pre+cur return cur ## ProblemFind the contiguous subarray within an array (containing at least one number) which has the largest sum. For example, given the array [-2,1,-3,4,-1,2,1,-5,4],the contiguous subarray [4,-1,2,1] has the largest sum = 6. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344&apos;&apos;&apos;Solution:- subarray: 2 pointers: head,tail- any repeated work? no any meaningless work? yes check the sum-array and we can find that the non-max-sum either subtract one more number or miss one more addition that is, for each element in the array, we have two options, either start from this element, or continue to sum up, no other options, and we choose maximum value of these two numbers. --&gt; cur_sum=max(cur_sum,nums[start]+cur_sum), max_sum=(cur_sum,max_sum)&apos;&apos;&apos;class Solution(object): def maxSubArray(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; cur_sum,max_sum=nums[0],nums[0] for start in range(1,len(nums)): cur_sum=max(nums[start],nums[start]+cur_sum) max_sum=max(cur_sum,max_sum) return max_sum &apos;&apos;&apos; # brute-force, time limit exceeded def maxSubArray(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; if len(nums)==0: return 0 global_sum=nums[0] for i in range(0,len(nums)-1): part_sum=nums[i] if part_sum&gt;global_sum: global_sum=part_sum for j in range(i+1,len(nums)): part_sum+=nums[j] if part_sum&gt;global_sum: global_sum=part_sum part_sum=nums[-1] if part_sum&gt;global_sum: global_sum=part_sum return global_sum &apos;&apos;&apos; 204. Count PrimesProblemDescription: Count the number of prime numbers less than a non-negative number, n. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&apos;&apos;&apos;Primitive idea:- for each number i from 2-n, exclusive, check if i can be divided by a natural number that is from 2-(i-1), inclusive- Time complexity: O(n^2)Followup:- repeated work? yes, for each number larger than 2, we divided it by 2, for each number larger than 3, we divided it by 3....- think of it in a reverse way, we can enumerate the multiples of p by counting to n from 2p in increments of p, and mark them in the list as non-prime;- Time complexity: O(nlog(logn)) The inner loop does n/i steps, where i is prime =&gt; the whole complexity is sum(n/i) = n * sum(1/i). According to prime harmonic series, the sum (1/i) where i is prime is log (log n). In total, O(n*log(log n)).- Space complexity: O(n)[Divergence of the sum of the reciprocals of the primes](https://en.wikipedia.org/wiki/Divergence_of_the_sum_of_the_reciprocals_of_the_primes)&apos;&apos;&apos;class Solution(object): def countPrimes(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n&lt;2: return 0 isPrime=[True]*n isPrime[0:2]=[False]*2 for i in range(2,int(n**0.5)+1): if isPrime[i]: isPrime[i*2:n:i]=[False]*((n-1-i*2)/i+1) return sum(isPrime) &apos;&apos;&apos; def countPrimes(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n&lt;2: return 0 count = 0 for i in range(2, n): if self.isPrime(i): count+=1 return count def isPrime(self,n): for i in range(2,n): if n % i == 0: return False return True &apos;&apos;&apos; 96. Unique Binary Search TreesProblemGiven n, how many structurally unique BST’s (binary search trees) that store values 1…n? For example,Given n = 3, there are a total of 5 unique BST’s. Solution 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&apos;&apos;&apos;Taking 1~n as root respectively:1 as root: # of trees = F(0) * F(n-1) // F(0) == 12 as root: # of trees = F(1) * F(n-2)3 as root: # of trees = F(2) * F(n-3)...n-1 as root: # of trees = F(n-2) * F(1)n as root: # of trees = F(n-1) * F(0)So, the formulation is:F(n) = F(0) * F(n-1) + F(1) * F(n-2) + F(2) * F(n-3) + ... + F(n-2) * F(1) + F(n-1) * F(0)# Recursive method - count(n)=sum(count(i)*count(n-i-1)) - use cache - time complexity: O(n!)-&gt;O(n)# No need to use recursive. Memorized Search -&gt; Dynamic Programming Inductive rule: count[n]=sum(count[i]*count[n-i-1])&apos;&apos;&apos;class Solution(object): &apos;&apos;&apos; # Recursive method def numTrees(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n&lt;=0: return 0 return self.count(n,dict()) def count(self,n,cache): if n==0 or n==1: return 1 if n in cache: return cache[n] cache[n] = sum([self.count(i,cache)*self.count(n-i-1,cache) for i in range(0,n)]) return cache[n] &apos;&apos;&apos; def numTrees(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n &lt;= 0: return 0 count = [0] * (n + 1) count[0] = 1 for i in range(1, n + 1): for j in range(0, i): count[i] += count[j] * count[i - j - 1] return count[n] 95. Unique Binary Search Trees IIProblemGiven an integer n, generate all structurally unique BST’s (binary search trees) that store values 1…n. For example,Given n = 3, your program should return all 5 unique BST’s shown below. 1 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\ 2 1 2 3 Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445&apos;&apos;&apos;recursive down pass all the nodes that can be selected as a new root down leftTree = self.helper(start, rootVal - 1) rightTree = self.helper(rootVal + 1, end)return up all possible trees under current rootcurrent level build all the possible trees (different combination of left and right treelist ) - for root i in leftTree and for root j in right tree, build a new root and connect with left and right subtree.&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def generateTrees(self, n): &quot;&quot;&quot; :type n: int :rtype: List[TreeNode] &quot;&quot;&quot; if n &lt;= 0: return [] return self.helper(1, n) def helper(self, start, end): # base case if start &gt; end: return [None] res = [] for rootVal in range(start, end + 1): leftTree = self.helper(start, rootVal - 1) rightTree = self.helper(rootVal + 1, end) for i in leftTree: for j in rightTree: root = TreeNode(rootVal) root.left = i root.right = j res.append(root) return res 72. Edit DistanceProblemGiven two words word1 and word2, find the minimum number of steps required to convert word1 to word2. (each operation is counted as 1 step.) You have the following 3 operations permitted on a word: a) Insert a characterb) Delete a characterc) Replace a character Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&apos;&apos;&apos;Recursion Rule -&gt; Memorized Search -&gt; DPTime complexity: O(len1*len2)Space complexity: O(len1*len2)&apos;&apos;&apos;class Solution(object): &apos;&apos;&apos; # Memorized Search def minDistance(self, word1, word2): &quot;&quot;&quot; :type word1: str :type word2: str :rtype: int &quot;&quot;&quot; if not word1 and not word2: return 0 if len(word1)==0: return len(word2) if len(word2)==0: return len(word1) return self.match(word1,word2,0,0,[[0 for col in range(len(word2))] for row in range(len(word1))]) def match(self,word1,word2,i,j,count): # base case if i==len(word1): return len(word2)-j if j==len(word2): return len(word1)-i # base case end if count[i][j]!=0: return count[i][j] if word1[i]==word2[j]: res=self.match(word1,word2,i+1,j+1,count) else: # insert insert=self.match(word1,word2,i,j+1,count) # delete delete=self.match(word1,word2,i+1,j,count) # replace replace=self.match(word1,word2,i+1,j+1,count) res=min(insert,delete,replace)+1 count[i][j]=res return res &apos;&apos;&apos; def minDistance(self, word1, word2): &quot;&quot;&quot; :type word1: str :type word2: str :rtype: int &quot;&quot;&quot; if not word1 and not word2: return 0 if len(word1) == 0: return len(word2) if len(word2) == 0: return len(word1) count = [[0 for col in range(len(word2) + 1)] for row in range(len(word1) + 1)] # initialize for i in range(len(word1) + 1): count[i][0] = i for j in range(len(word2) + 1): count[0][j] = j for i in range(len(word1)): for j in range(len(word2)): if word1[i] == word2[j]: count[i + 1][j + 1] = count[i][j] else: count[i + 1][j + 1] = min(count[i + 1][j], count[i][j + 1], count[i][j]) + 1 return count[-1][-1] 303. Range Sum Query - ImmutableProblemGiven an integer array nums, find the sum of the elements between indices i and j (i ≤ j), inclusive. Example:12345Given nums = [-2, 0, 3, -5, 2, -1]sumRange(0, 2) -&gt; 1sumRange(2, 5) -&gt; -1sumRange(0, 5) -&gt; -3 Note:You may assume that the array does not change.There are many calls to sumRange function. 123456789101112131415161718192021222324252627class NumArray(object): def __init__(self, nums): &quot;&quot;&quot; initialize your data structure here. :type nums: List[int] &quot;&quot;&quot; self.sumArray=[0] cur=0 for i in nums: cur+=i self.sumArray.append(cur) def sumRange(self, i, j): &quot;&quot;&quot; sum of elements nums[i..j], inclusive. :type i: int :type j: int :rtype: int &quot;&quot;&quot; return self.sumArray[j+1]-self.sumArray[i]# Your NumArray object will be instantiated and called as such:# numArray = NumArray(nums)# numArray.sumRange(0, 1)# numArray.sumRange(1, 2) Solution12 304. Range Sum Query 2D - ImmutableProblemGiven a 2D matrix matrix, find the sum of the elements inside the rectangle defined by its upper left corner (row1, col1) and lower right corner (row2, col2). Range Sum Query 2DThe above rectangle (with the red border) is defined by (row1, col1) = (2, 1) and (row2, col2) = (4, 3), which contains sum = 8. Example:123456789101112Given matrix = [ [3, 0, 1, 4, 2], [5, 6, 3, 2, 1], [1, 2, 0, 1, 5], [4, 1, 0, 1, 7], [1, 0, 3, 0, 5]]sumRegion(2, 1, 4, 3) -&gt; 8sumRegion(1, 1, 2, 2) -&gt; 11sumRegion(1, 2, 2, 4) -&gt; 12 Note:You may assume that the matrix does not change.There are many calls to sumRegion function.You may assume that row1 ≤ row2 and col1 ≤ col2. Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&apos;&apos;&apos;Solution: brute-force: O(n^2) time use idea from Range Sum Query - Immutable, for each row, store current sum value of all column value, takes O(n) time to set up, and for sumRange, loop the row and calculate the sum of rows result, also takes O(n) time improve: store current sum value of all values on the left and above of current value, takes O(n^2) to setup and O(1) time to get sumRange&apos;&apos;&apos;&apos;&apos;&apos;O(n^2) setup and O(1) sumRegion&apos;&apos;&apos;class NumMatrix(object): def __init__(self, matrix): &quot;&quot;&quot; initialize your data structure here. :type matrix: List[List[int]] &quot;&quot;&quot; if not matrix: return self.m=len(matrix) self.n=len(matrix[0]) self.matrix=[[0]*(self.n+1) for i in range(self.m+1)] for row in range(self.m): cur=0 for col in range(self.n): cur+=matrix[row][col] self.matrix[row+1][col+1]=cur for col in range(self.n+1): cur=0 for row in range(self.m+1): cur+=self.matrix[row][col] self.matrix[row][col]=cur def sumRegion(self, row1, col1, row2, col2): &quot;&quot;&quot; sum of elements matrix[(row1,col1)..(row2,col2)], inclusive. :type row1: int :type col1: int :type row2: int :type col2: int :rtype: int &quot;&quot;&quot; if not self.matrix: return 0 return self.matrix[row2+1][col2+1]-self.matrix[row1][col2+1]-(self.matrix[row2+1][col1]-self.matrix[row1][col1])&apos;&apos;&apos;O(n) setup and O(n) sumRegionclass NumMatrix(object): def __init__(self, matrix): &quot;&quot;&quot; initialize your data structure here. :type matrix: List[List[int]] &quot;&quot;&quot; self.matrix=[[0] for i in range(len(matrix))] for row in range(len(matrix)): cur=0 for col in matrix[row]: cur+=col self.matrix[row].append(cur) def sumRegion(self, row1, col1, row2, col2): &quot;&quot;&quot; sum of elements matrix[(row1,col1)..(row2,col2)], inclusive. :type row1: int :type col1: int :type row2: int :type col2: int :rtype: int &quot;&quot;&quot; cur=0 for row in xrange(row1,row2+1): cur+=self.matrix[row][col2+1]-self.matrix[row][col1] return cur &apos;&apos;&apos;# Your NumMatrix object will be instantiated and called as such:# numMatrix = NumMatrix(matrix)# numMatrix.sumRegion(0, 1, 2, 3)# numMatrix.sumRegion(1, 2, 3, 4)","tags":"动态规划"},{"title":"Search Engines笔记 - Personalization","url":"/2016/11/07/Search Engines笔记 - Personalization/","text":"CMU 11642 的课程笔记。关于个性化搜索引擎。 目前，有三种实现个性化搜索引擎的方法。 Topic-based personalization Long-term vs. short-term personalization Personalization for typical vs. atypical information needs 基本逻辑： Representation: 描述用户的兴趣/偏好 Learning: 从数据中学习兴趣/偏好 Ranking: 在检索算法中使用兴趣/偏好 Topic-based personalization假设： 用户的长期兴趣(high-level topics)可以从训练数据中得到 预处理： 在建立索引前，每篇文档都被分配了 [0…n] 之间的某个类别； 在建立索引的时候，类别被当作 feature 或者 metadata 保存起来 User representation: 根据用户的长期检索历史对用户建模 用户模型是在类别标签上的一个概率分布arts/movies: 1.1%, arts/television: 0.2%, arts/music: 2%, … 第 n 个用户的训练数据: p (q1, c1), p(q1, c2), … p(q2, c1) …p(qi, cj) = p(d is clicked &amp; d in category cj | q) 对排序列表进行 rerank，top n 的文档是两个分数的组合: 原始文档分数 文档类别和用户兴趣类别的匹配分数 Bing 用 25 天的数据，20 天数据做训练数据，5 天数据做测试数据，一共 102,417 条查询和 54，581 个用户，实验结果：123456789Bing vs. Personalized Bing• Metric: Mean reciprocal rank (MRR)• ODP classifier accuracy: 60% Micro-averaged F1, 86% coverage• Effect of personalization – 1-2% improvement in overall MRR – 17-18% improvement in MRR for results that change position• Effect of personalization on acronyms – 5% improvement in overall MRR – 17-22% improvement in MRR for results that change position Long-term vs. short-term personalization个性化可以基于三种类型的信息： Historic: 从用户长期的检索记录中获得的信息 Session: 用户一个 search session 的信息 Combination of historic and session: 两者合并的信息 可以把这三方面的信息看作用户历史记录的三个不同的 view。 Features:View features Cosine between view and document topic categories Cosine between matching queries (and subsets, and supersets)and document topic categories url click count url click counts for matching queries (and subsets andsupersets) Number of queries Number of sessions with this query Number of subset queries Number of superset queries Query features Ambiguity measures: Click entropy, topic entropy– How much do people click on different pages or topics forthis query? Difficulty measures: Position in session, length, frequency Document rank (not personalized) User profile: User topic entropy User query (and subset and superset) entropy User position entropy, user query position entropy 实验: 特征：每个 view 有 38 个特征，一共 102 个特征 数据集：2011年 7-8 月的搜索日志 方法：对原始结果集的前 10 篇文档重新排序，用 LambdaMART 算法(pairwise LeToR)，然后进行相关性评估。 Value of each view: Effect of personalization: 结论： Historic 信息在 session 早期的作用比较大 Session 信息在 session 晚期的作用比较大ssion Personalization 在 session 晚期的作用越来越弱－ 可能是因为用户的查询语句更加优化了 Personalization 在 session 晚期能够影响更多的 query Personalization for typical vs. atypical information needs很多个性化的技术假定 user profile 很少变化，然而当用户搜索 atypical 信息时就有问题了。 Detect atypical sessions: 创建 long-term user profile 衡量 profile 和 session 的 divergence Divergence of each session feature from this user’s historical norms Cosine distance between session and historical vocabularies Cosine distance between session and historical topic categories 然后收集特征，继续按之前 Long-term vs. short-term personalization 的方法来进行实验，最有效的特征： 待更新。","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Authority Metrics","url":"/2016/11/04/Search-Engines笔记-Authority-Metrics/","text":"CMU 11642 的课程笔记。这一章 Authority Metrics（权威指数），用来判断哪些来源的信息更值得信任。介绍 PageRank、Topic-Sensitive PageRank(TSPR)、T-Fresh、Hyperlink-Induced Topic Search(HITS) 四种指数计算方式。 链接分析链接分析思想最早起源于引文分析领域，通过分析文献之间的引用模式来量化学术论文的影响力。文献引用代表某篇学术论文对所引用论文的权威度的认可。类似的，对于 Web 网页，我们把超链接看成是一个网页对另一个网页的权威度的认可。当然，并不是所有引用都代表权威度认可，因为某个人可以建立多个 web 网页来指向同一个目标网页，人工来提高目标网页入链数。这种链接通常叫垃圾链接或链接作弊（link spam）。尽管如此，引用现象的普遍性和可靠性足以使搜索引擎通过精妙的链接分析方法推导出有用的排序因子。链接分析也被证明是在 web 采集中选择下一个采集网页的非常好的方法之一。给定查询下，链接分析结果已经成为 Web 搜索引擎在计算某个网页的组合得分中的一个因子。PageRank 和 HITS 就是常用的两种链接分析方法。 基本假设 指向页面 B 的锚文本是对 B 的一个很好的描述。 A 到 B 的超链接表示 A 的作者对 B 的认可。 锚文本什么是锚文本1&lt;a href=&quot;http://www.acm.org/jacm/&quot;&gt;Journal of the ACM.&lt;/a&gt; 这个 HTML 代码片段给出了一个指向 Journal of the ACM 的链接。链接指向 http://www.acm.org/jacm/，锚文本是 Journal of the ACM。 锚文本的作用Web 上随处可见的现象是，很多网页的内容并不包含对自身的精确描述，尤其是公司网页，因为它们往往是用作商业宣传而不是介绍公司内容。如 IBM 是计算机制造商，但公司主页 (www.ibm.com) 的 HTML 代码的任何地方都不包含词项 computer。这时候，锚文本的作用就体现出来了。锚文本的词项可以作为索引目标网页的词项，也就是说 computer 的 inverted list 包含了 www.ibm.com，这时再用一个特别的指示器表示这些词项在锚文本而不是网页内部，网页评分时也基于 term frequency 计算锚文本的 term weight，在多个锚文本中高频出现的词项(如 Click 和 here)会收到惩罚。除了锚文本，锚文本周围窗口的文本(extended anchor text)，通常也可以当成锚文本来使用。 副作用网站可以通过构造具有误导性的锚文本来指向自己，以此提高在某些 query term 的排名。 PageRankPageRank 是 query-independent 的，也就是说与用户输入的查询无关。PageRank 高的网页并不代表一定适合某个特定的 query。如 kanye west wikipedia 网页有很高的 PageRank，但并不适合 “obama family tree” 这个特定的 query。 Random Walk AlgorithmPageRank 可以被看作是一个随机游走的算法。基本思想是模拟一个悠闲的上网者，上网者首先随机选择一个网页打开，然后在这个网页上呆了几分钟后，跳转到该网页所指向的链接，这样无所事事、漫无目的地在网页上跳来跳去，PageRank 就是估计这个悠闲的上网者分布在各个网页上的概率。 随机选一个网页 A 。 网页 A 有 n 条出链（outlinks），这时候有两种方法进行下一步。 随机在出链中选一个到下一个网页。 随机从所有 web 网页里选一个其它网页(teleport)。（因为网页 A 可能没有出链） 不断重复以上过程。 随机游走中访问越频繁的网页越重要。计算方法 Voting AlgorithmPageRank 也可以被看作是一个 Voting algorithm。123While (Not done) For each page p p votes for each page that it links to 再具体些12345678For each page p current PR = 1 / |C| C: Number of nodes in the graph next PR = 0While (Not done) For each page p use p’s current PR to update the next PR of each outlink page For each page p current PR = next PR next PR = 0 每次循环，网页 Pi 可以左 PR(Pi) 次投票。 把投票平均分发给每一个它指向的网页。 如果两个网页在第 i 次循环中有相同的 PageRank:PR(p1)=0.4, p1 有 2 个 outlinks, 那么 p1 的每一个 vote 是 0.4/2=0.2PR(p2)=0.4, p2 有 4 个 outlinks, 那么 p2 的每一个 vote 是 0.4/4=0.1 在每一个循环中, PR 的计算方法都如之前的图示。 d 的选择假定 A 有两条出链，指向 B 和 C，B 和 C 各自有一条出链，都指向 A。如果 d=0.5，那么经历 14 次循环 PR 会 converge 如果 d=0.85，那么经历 58 次循环 PR 会 converge Transformation of PageRank有些 PageRank varies over a wide range，我们可以把这个 range 进行压缩和转化。如$$PR_T = log_{10}(PR)+11$$ 效果是 Google 的 PageRank 范围是 1-10，我们通常说的 PageRank 都是经过这种转化的 PageRank。 怎样产生 high PageRank 有很多入链 有很多来自具有高 PageRank 网页的入链 入链有很少的出链因为在每一次 propagation 时，一个网页的 PR 会被它的出链平分，所以一个有很多出链的入链网页并不是非常有帮助。 PageRank 的其它问题 同一个站点的网页链接算不算？ 新的网页的 PR 怎么算？ 怎么处理 sinks（没有出链的网页）? 怎么处理 link farms 和链接交换？ 还有一个问题就是 PR 是 topic-independent 的，一个网页可能有很高的 PR 但是对某个 query 来说却是一个很坏的选择。Topic-Sensitive PageRank(TSPR) 可以解决这个问题。 Topic-Sensitive PageRank(TSPR)之前考虑的 PageRank 是等概率跳到一个随机网页的情况，关于 topic PageRank，我们考虑的是非等概率跳到一个随机网页的情况，计算的是基于特定兴趣/主题的 PageRank。如一个体育迷希望有关体育主题的网页的排名高于非体育主题的网页，假定这些有关体育的网页在 web 图中彼此相近，那么随机游走过程中，一个喜欢体育网页的人就可能在这类网页上停留大量的时间，因此，体育类网页的稳态分布概率被提升。 主要逻辑是 在索引过程中，每一个网页都被自动分配一个 topic (用文本分类的方法)。 为每一个网页计算一个 topic-specific 的 PageRank。 每一个 query 都被分配一个 topic，根据用户在这个 search session 中浏览的网页来确定 topic。 对每一个页面，只考虑 topic-related PageRank，如 $PR_{sports}(d)$ 注： DMOZ 是一个著名的开放式分类目录，有很多可以用来做 training data 的网页。可以从 top-level 中定义 topics。 T-FreshPageRank rewards older web pages。old web 网页有更多的时间来积累 inlinks，有些 link 可能是来自已经废弃不用的网页，然而用户可能更偏好新的网页。网页快照提供了 freshness 的线索。 Page freshness：网页最近什么时候被更新过。Page text(↑)，url(↑)，anchor text(↑↑)，new link(↑↑↑) Link freshness：有多少 inlinks 来自 fresh page。 Decay freshness measures exponentially. follow a link 的概率取决于网页的新鲜度。有 fresh inlinks 的 fresh page 有更高的 authority score。 BM2500+T-Fresh vs BM2500+PageRankRelevance: +8% in P@10，+11-30% in NDCG@kFreshness: +8% in P@10，+10-12% in NDCG@k 其它相同作用的 model 如 TimedPageRank, T-Rank, BuzzRank, TemporalPageRank。 Hyperlink-Induced Topic Search(HITS)在泛主题搜索（broad-topic search），也就是 informational needs 时，主要有两种非常有用的网页结果。 Authority 网页：一些权威性的网页。 Hub 网页：导航型网页，本身不是权威型网页，而是对某个主题感兴趣的人花时间编辑整理出的权威型网页列表。可以通过这种导航型网页来帮我们找到权威型网页。 一个好的 hub 网页会同时指向多个好的 authority 网页，而一个好的 authority 网页同时会被多个好的 hub 网页所指向。给定某个查询，我们对每个网页给出两个得分，一个是 hub 值，一个是 authority 值，所以对任何一个查询，我们都能得到两个排序结果列表。所以，我们其实可以给出一个 hub 值和 authority 值的循环定义，然后通过迭代计算求解。 并不是对整个 web 计算 Hubs 和 Authority 分数。而是对一个小的 set 来进行计算，set 的创建方法如下： 收集 query q 的 top n 网页构成 the root set 用 root set 的入链和出链扩充这个 set。 之后在这个网页子集上来计算 hub 和 authority 值。这个 set 的好处是有一个 strong, query-specific focus，而且 set 规模相对较小，大概只有 200 个网页。然而这些 score 必须在 query time 时进行计算。 HITS 在大规模的搜索引擎中不会被使用 计算 spam 要比计算 PageRank 简单 创建一个有 high hub score 的网页很简单 运行成本比 PageRank 高。 HITS 通常用于别的目标。如找 communities 或是找一个 community 里的专家，因为它们会有 tightly-bound hubs 和 authorities。","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Document Structure","url":"/2016/11/04/Search Engines笔记 - Document Structure/","text":"CMU 11642 的课程笔记。文档的表示形式不只词袋一种，它可以有 fields，有 hierarchical structure(XML)，multiple representations of meaning, priors 等形式，这一章讲的就是检索模型怎么来处理这些复杂的文档表达。 Multiple representations of meaning Fields can be used to provide different representations of the same information 三种表达方法。 Vector space– 每个 representation 提供独立的 ranking score– 对每个分数求平均来得到一个最终的 ranking Okapi– Representations 以不同的方式来表达相同含义– 合并 representations 来得到一个更好的 representation Indri– 每个 representation 提供一个 p(t|d) 的估计– 有多种方法来合并这些估计 Vector spaceOption 1: 一个词袋模型，包含了各种 filed 词汇E.g., iPad::inlink, iPad::title, iPad::body, … 这让 length normalization 变得更为复杂，比如说 inlink text 可能会和 title 或者 body text 混在一起。一般不用这种方法。 Option 2: Several vector spaces$w_{title} *sim(query,title_i) +$$w_{body} *sim(query,body_i) +$$w_{inlink} *sim(query,inlink_i) +$$w_{url} *sim(query,url_i) $ 这种方法易于管理，也易于扩展，Lucene 也采用了这种方法，然而关于怎么设置 weights，并没有什么 guidance。 Okapi Evidence from each field should be weighted differently 一些 field 可能有更好的表达能力，如 inlink text，一些 field 可能更为冗长，如 body，所以不同的 fields 我们应该区别对待。 One solution• 把 query 看作 |F| 个词袋• 对 query 匹配每个 field，然后 add the score 然而 … 这打破了 BM25’s saturation assumption。在 |F| 个 field 里中出现了一次的字段，比在一个 field 里出现了|F|次的字段，有更大的影响，这并不是我们想要的。125 fields × 1 occurrence = 5 × 0.41 field × 5 occurrences = 0.77 Solution: 用一个复合加权的 representation，一篇文档就用一个词袋 $$tf_t=\\sum_fw_ftf_{t,f}$$$$doclen=\\sum_fw_fdoclen_f$$ F: the set of fields -&gt; 然后用标准的 BM25但是 … BM25 有常量，可能我们需要 tune them on a per-field basis，可以用 BM25F。 特性： 一个 vocabulary 涵盖了所有的 fields– 所以一个 term 有一个 global idf, 而不是一个 field-specific idf– 对各种文档都有适用么?» E.g., 专利，医疗记录等 Field-specific tuning constants 的影响很难理解 IndriIndri 模型。 #AND 和 #WAND 用来合并独立的概率#SUM 和 #WSUM 用不同方法来估计同一个概率 Hierarchical structure(XML)Hierarchical structure 的文档通常用 Bayesian inference networks 来解决，如 indri。首先对 flat 和 hierarchical structure 做一个区分。Flat元素之间是相互独立的，一个 term 只在包含了它的那个元素（通常是一个）里出现。检索目的通常是一篇文档。Hierarchical元素之间是相互关联的，通常是包含的关系，一个 term 在所有包含了它的元素里出现。检索目的可以是文档，也可以是元素。 Issues检索什么样的 element?• Document? Encounter? Diagnosis? 用怎样的 corpus statistics• Document vs. element 怎样组合来自不同 elements 的 evidence• Can we prefer patients that have several matching encounters? Exact-match vs. best-match document structure• 可能 query 并不能完全匹配文档结构 Ranking elementsOne option: Use Jelinek-Mercer smoothing$$P(q_i|e)=(1-\\lambda)P_{MLE}P(q_i|e)+ \\lambda P_{MLE}P(q_i|C)$$ 这种方法可能带来的问题是： 文档结构不规范，这种情况经常在 web 文档中出现，如果文档里本来包含了 query term 然而因为文档不规范而找不到相应的 element，那么 score 可能为 0。 query 可能太严格。– #AND[title](iphone)：不匹配 “Apple Cuts Phone Price”– #AND[paragraph](solutions to poverty)： “poverty” 和 “solutions” 可能出现在不同的段落里 解决方案是，多加一个 smoothing。 Multiple elements这里我们探讨右图的情况。 两种方法 Aggregation OR Combination。 Aggregation: Combine inverted lists Combination: Combine scores AggregationIndri 允许在 query 里指定 aggregation type term.element– 如果没有指定 element, 那么默认 element 为 Document– Example: apple.inlink 结果: 一个 inverted list 包含了一个 element 的所有 instance Example1#wand( #wsum (0.3 apple.title 0.2 apple.inlink 0.5 apple.body ) #wsum (0.3 ipad.title 0.2 ipad.inlink 0.5 ipad.body ) ) 问题：1#AND( breast.paragraph cancer.paragraph treatment.paragraph ) 对这一个查询，用 Aggregation 的话以下两篇文档会得到一样的分数，然而其实 D2 要比 D1 更相关。 Combination用 #MAX, #SUM, #OR 等 query operators 来合并 element scores。首先我们来认识一下 query。E.g.11#SUM[document] (#AND[sentence] (breast cancer treatment) ) 最外面的 element 是 document, 所以对 documents 进行排序 对每个 sentence 进行 #AND (breast cancer treatment) 运算，结果是一个 (sentence, score) 列表 对上一步产生的结果 #SUM 运算，结果是一个 (document, score) 列表 E.g.21#SUM[paragraph] (#AND[sentence] (breast cancer treatment) ) 最外面的 element 是 paragraph, 所以对 paragraphs 进行排序 对每个 sentence 进行 #AND (breast cancer treatment) 运算，结果是一个 (sentence, score) 列表 对上一步产生的结果 #SUM 运算，结果是一个 (paragraph, score) 列表 来考虑下不同的 combine query operator 产生的影响。 #MAX[document] (#AND[sentence](breast cancer treatment) )– 只考虑 best sentence#SUM[document] (#AND[sentence](breast cancer treatment) )– poorly matching sentences 会让分数变低#OR[document] (#AND[sentence](breast cancer treatment) )– 偏好有更多匹配的 sentences 的文档 • #MAX considers them equal• #AND prefers C4• #OR prefers C1• #AVERAGE prefers C4 Comparsion假定目标是检索有 paragraphs 讨论 breast cancer treatment 的文档Combination: Partial credit for sections that partially matchAggregation: The terms might not all be in the same section ExtentsUsing extents as evidence12345#AND( #OR[document]( #AND[sentence](iraq war)) bush #NEAR/1(exit strategy) ) • 检索的是 document• 偏好 ‘iraq’ and ‘war’ 在同一句话里的文档– 出现在 title 里会让分数有稍稍的提高，因为有 smoothing Using extents as a constraint12345#AND ( iraq.sentence war.sentence bush #NEAR/1(exit strategy) ) • 检索的是 document• 要求 ‘iraq’ and ‘war’ 必须出现在同一句话的文档 – 出现在文档的其它部分并不会有任何帮助 HLT Applications文档结构可以由 annotation processes 产生• E.g., named entity annotators, semantic role labelers, … Retrieval of elements, using semantic role annotations1234#and[sentence]( #and[target_verb]( Loves #and[./agent]( John ) #and[./patient]( Mary ) ) ) • ./element specifies that element is a child of the parent field Table retrieval 实际就是一个把 table 转化为 structure document 的问题。 SummariesFields• 用于 independent evidence (author, title, journal, …)• 用于 multiple representations (url, title, body, …)• 了解差异• 了解各个检索模型如何支持这些 fields• 了解在 query 中如何使用这些 fields Hierarchical structure• 怎样在多个 elements 都有匹配时 combine evidence• Exact-match vs. best-match document structure• 了解 Indri 怎样支持这些 elements• 了解在 query 中如何使用这些 elements","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Search logs","url":"/2016/11/04/Search Engines笔记 - Search logs/","text":"CMU 11642 的课程笔记。这一章开始的很多内容都是从论文的研究报告而来。重点是第四部分，怎样对 search log 划分 session，有哪些 feature 可以作为划分 session 的依据。 User information collection大多数搜索引擎会保存每一次搜索的信息，主要有下面的内容： query timestamp IP address of the search client possibly an id recorded in a cookie or obtained another way information about the operating system and browser clickthrough information 目前公开的 web search logs The Excite log(1997)18,113 users, 51,473 queries The AOL Log(2006)$&gt;$ 650,000 users, $&gt;$ 20 million queries Alta Vista(1999)285 million users, 1 billion queries Alta Vista(2001)$&gt;$ 7 million queries Query characteristicsQuery Length: Average terms per query: 3.5 terms Who queries Query Frequency: Query Frequency Follows a Power Law Power Law$$Frequency(q) = K*Rank(q)^{- \\alpha}$$ K: positive constant Rank(q): popularity rank(r=1 is the most popular) $\\alpha$: constant, about 2.4 for the Excite query log 和 Zipf’s law 一样的 shape，但不一样的斜率。 一小部分的 query 非常常见，而大部分的 query 非常少见。 =&gt; 通过 缓存 来提高搜索效率。 Vary over time最常见的 query 总是在不断变化 来自 google 的统计数据 每天的 query 中有 20% 在之前从未出现过。(占每天所有 unique query 的 50%) 8% 的 query 是名字(names) Model query Query topics: What比如说在雅虎目录下的分类。 User demographics: Who如用户的年龄、性别（用户提供）、收入、教育程度（从邮编等信息推断）等。 Session characteristics: Howeg. session length, number of queries/session, % of queries with low/high click entropy Represent users需要用到的工具: Pseudo documents, clustering, control vocabularyHow to represent users？ 在 “what” 维度上对用户进行聚类 在 (“who”,”how”) 维度上进一步 investigate groups 根据 group 的显著特征对其打上标签 根据用户的 query type 来对用户进行聚类： 从日志中得到 (user,query) pairs 为用户创建 pseudo documents标题: user id内容: 每条 query 的前 10 篇文档对应的 Yahoo! 分类目录 计算相似度e.g. JS divergence, cosine Types of users这一部分主要是介绍不同类型的用户特征，这些聚类结果有什么用？=&gt; 为下一步的个性化搜索引擎做准备。 Informational UsersHow:• More likely to issue non-navigational queries• Less likely to have single-click sessions• More likely to use query suggestions What:• Wide range of topics• Little interest in adult content Who:• More likely to be well-educated• More likely to have above-average income Navigational UsersHow:• More likely to issue navigational queries• More likely to have single-click sessions• Less likely to use query suggestions What:• Dominated by popular websites (Facebook, YouTube, Craigslist) Who• Mostly representative of the entire population Transactional UsersHow:• Somewhat similar to navigational users. But, multiple sites can perform the transaction• Diverse clicks• Short interaction with search engine What• Shopping, adult content, gaming Who:• Depends heavily on the type of transaction• Topic “recreation/games” associated with low income &amp; education 聚类结果 - Selected groupsBaby boomers:• 50 years old• Interested in finance• Simple navigational queries related to online banking Challenged youth:• Average age of 34• Low-income neighborhoods with low-level of education• Interested in music• Navigational sessions Liberal females:• Mostly female from areas that voted Democratic• Shopping queries• Long sessions (browsing and comparison) White conservatives:• Mostly male from areas that voted Republican• Interested in automotive, business, home &amp; garden Older users: Health / diseases &amp; conditions, gambling, travelPeople in their late 20s: Health / fitness, reproductive healthYounger people: Games, educationLow income: Music, comics &amp; animation, militaryAsian descent: Computers &amp; internet, programming &amp; development Some topics typically receive few clicks:• News &amp; media, society &amp; culture, computers &amp; internet People are more likely to click on suggestions for some topics• Health, science, arts People with higher educational levels:• Tend to have shorter sessions• Click on query suggestions less often• Are more likely to submit tail queries Segmenting search logs into sessions通常，我们会把 search log 划分为一个个基于 information need 的 dialoguedialogue 形式，实际就是用户发出初始查询，搜索引擎给出结果，用户不满意，重新修改查询语句再次搜索，然后得到新的结果，不断循环的过程。1234Person: queryEngine: search resultsPerson: reformulated queryEngine: new search results ... 那么问题来了，怎么来区分这些不同的 dialogues 呢？我们定义 information need = a search session(dialogue)，最简单粗暴划分 session 的方法就是通过时间，比如说三十分钟内一系列的用户行为就算作一个 session。 划分 session 可以考虑的因素： Time: Same session iff |timestamp (q2) – timestamp| (q1) &lt; ∆often ∆ = 30 minutes Common term: Same session iff q1 ∩ q2 ≠ ØProbably high Precision, low Recall Rewrite classes: Common reformulation patternsE.g., term added, deleted, or replacedProbably high Precision, low Recall Edit distance Co-occurrencee.g., PMI, Chi-square of queries in a query log Same clicksqueries have co-occurring clicks in a query log Document categoriesODP or Yahoo page category overlap of top 10 results Same/overlap retrieved documentsJSD similarity of top 10 resultscosine distance among results Classifiers… 训练一个分类器是最好的方法，对任意一对 queries 大概有 95-97% 的准确率。然而 heuristics 也不差，尤其是 edit distance 和 cosine distance among results 都非常有效，时间尺度通常会和其他 heuristic 合用，效果更佳。 各种 heuristic 都可以作为分类器的 Features Temporal– ≤ {5, 30, 60, 120} minutes, ∆ time, are_sequential Edit distance– Several character and token-based metrics Query log– Various types of (q1, q2) co-occurrence in a larger query log Web search– Cosine distance of top 50 search results for each query(“prisma”) 我们训练分类器一般需要完成两个任务 Boundary task: Given a pair of sequential queries Same task: Given a pair of queries Challenges用户的信息需求可能是跨越了几天甚至是几周的，比如用户写论文、找学校信息等，可能出现的情况是： 用户有交叉的任务如查 paper 的时候顺便查下中午吃什么 用户把一个任务分成若干个子任务分阶段完成比如今天查为什么，明天查怎么做 子任务可能看起来是独立的实际确实相关的","tags":"nlp search-engines 信息检索"},{"title":"Distributed Systems笔记－Cryptographic Protocols","url":"/2016/11/02/Cryptographic-Protocols/","text":"CMU 95702 Distributed Systems 笔记。简单介绍几种加密、签名方式。 AES 和 RSA 笔记 的续章。 Scenario 1 (Like WWII 和 TEA) 双方共享一把密钥。 A 用密钥对信息加密。$E(K_AB,M_i)$，发送给 B B 用 $D(K_AB,{M_i}K_AB)$ 解密读取信息。 问题是：双方如何同步密钥？怎么确定 B 收到的 ${M_i}K_AB$ 不是 replay of an old message? Scenario 2 (Like Kerberos) A 向第三方 S 索要一张和 B 通话的 ticket。 S 知道 A 的 password 所以他可以计算 $K_A$ S 发送给 A $\\{\\{Ticket\\}K_B,K_{AB}\\}, K_A$ A 知道自己的 password 所以可以计算 $K_A$，注意 A 的 password 不会在网络中传输。 A 可以计算出 $K_{AB}$ 和 $\\{Ticket\\}K_B$ A 向 B 发送一个读的请求，发送的信息是 $\\{Ticket\\}K_B$,Alice,Read B 用 $K_B$ 来读取 Ticket 的内容，Ticket 的内容是 $K_{AB}$，Alice A、B 可以用 session key 来交流了。 可以防止 replay，但 问题是: 难以 scale,S 必须知道 $K_A$, $K_B$,… S 是唯一可能导致失败的因素。 Kerberos 这一名词来源于希腊神话“三个头的狗——地狱之门守护者”系统设计上采用客户端/服务器结构与DES加密技术，并且能够进行相互认证，即客户端和服务器端均可对对方进行身份认证。可以用于防止窃听、防止 repla y攻击、保护数据完整性等场合，是一种应用对称密钥体制进行密钥管理的系统。 Needham-Schroeder protocol这层协议是 Kerberos 的基础，在这之后，Alice and Bob share a secret (KAB) Scenario 3 (Authentication)数字签名，用私钥签名，公钥解密。注意公钥加密比私钥慢 100-1000倍。很难找到 digest(M1) == digest(M2) A 发送 Message＋用密钥加密的 Message 的 digest。{Digest(M)}$K_Apriv$ B 收到签名的文件，取出 Message，计算 Message 的 digest。 B 用 A 的公钥 $K_Apub$ 解密 {Digest(M)}$K_Apriv$ 然后和自己算的 digest 比较，如果匹配，签名验证。 问题：如果 A 说他没有签名？说自己的私钥泄漏了？只要 A、B 互相信任，还是有用的。 Scenario 4 (Like SSL) A 和 B 想要建立一个共享的密钥 A 拿到 B 的公钥，这个公钥被可信任的第三方 T 签名认证了，所以这个公钥确实是 B 的。 A 确认第三方 T 对 $K_Bpub$ 签名了。怎么确认？A 和 T 都有 B 的 public key，T 把 $K_Bpub$ 加密后给 A，A 对其进行解密然后比对自己手上的 B 的 public key 看是不是一致。 A 生成了 $K_{AB}$ 并用 $K_Bpub$ 加密。 B 有很多公钥所以 A 发送公钥的名字。 A 发送了 key name $\\{K_{AB}\\}K_Bpub$ B 用这个 key name 选择了对应的私钥并计算 $\\{\\{K_{AB}\\}K_Bpub\\}K_Bpriv == K_{AB}$ 最后 A 和 B 共享了对称的钥匙 $K_{AB}$ 问题：在 A 第一次得到 B 的公钥时（A 认为这是 B 的公钥，然而这并不是，这是 C 也经过第三方 T 签名认证的公钥。 TLS 和这个相似 Message Authentication Codes(MACs)对称加密生成的数字签名。双方都有 Key(K)，sender 把 Key(K) 通过 MAC 算法加密后连同 message 一起给 receiver，receiver 比对收到的 MAC 和自己用 MAC 算法对自己这里的 Key(K) 加密后的 MAC 是否一致，如果一致，那么信息真实性和完整性就得到了证实。 用于数字签名，双方都算了一遍 MAC JAVA 里的 keystore 和 truststorekeystore: 存了公钥、私钥、证书truststore：存了公钥，只能存 server 发过来的东西","tags":"web-service"},{"title":"Distributed Systems笔记－middlewares","url":"/2016/11/02/Web-service-middlewares/","text":"CMU 95702 Distributed Systems 笔记。简单介绍分布式系统中解决 interoperability concern 的几种方案 Cobra’s CDR, Java serialization 和 XML/JSON。这章整理的比较简单。 一言以蔽之，middleware 是为了更好的与 remote server 交流。 Interoperability concern分布式系统里的互操作性问题。 Big/Little Endian byte ordering may differ Floating point representation may differ Binary vs Unicode如果 j=3, binary 表示就是 00…011，而 unicode 表示是 0000000000110011，如果两端没有达成一致，那么就会出错。The receiver had better know which one we are using。 假设我们用 C++ 写了 TCP server，那么我们可以写个 JAVA TCP connection 来连接 server 吗？可以！C++ 和 JAVA 都知道怎么 open 一个 TCP connection。 假设 client 把一个 java object 发给了 server，这个 object 的内容可以重新被封装成 c++ 的 object 吗？不可以！ 三种解决方案CORBA’s CDR双方都知道 message 的 data type 和 order。双方在交流前都有一个 IDL(Interface description language 接口描述语言)，这和 google 的 protocol buffers 差不多。XML, XSDL, WSDL 都可以作为 IDL。 如下面一段 C 的代码。12345struct Person &#123; string name; string place; long year;&#125; 我们可以让 CORBA Interface Compiler 来做合适的 marshalling 和 unmarshalling operation，无论是 C 还是 JAVA。CORBA’s CDR 的特点是 - 非常快！所以传送的信息不包括 data type，只有表格中的右边一栏数据。 Java serializationJava’s serialization 本身可以用来 marshal 和 unmarshal，所以并不需要 IDL。双方事先也不知道 data type。 如下面一段 Java 的代码。123456789public class Person implements Serializable&#123; string name; string place; long year; public Person(String nm,place,year) &#123; nm=name;this.place=place;this.year=year; &#125; // more methods&#125; Java 序列化的特点是有很多 data (如 class name, version number, data type 等)来 describe 真正的 data。 Web Service use of XML格式：12345&lt;p:person xmlns:p=“http://www.andrew.cmu.edu/~mm6”&gt; &lt;p:name&gt;Smith&lt;/p:name&gt; &lt;p:place&gt;London&lt;/p:place&gt; &lt;p:year&gt;1934&lt;/p:year&gt;&lt;/p:person&gt; 相对前两种方法来说会比较慢。因为它是 text 形式而前两种方法是 binary 形式。 HTTP header 需要声明 Content-Type: text/xml; charset: ISO-8859-1 可以表示任何 binary message，因为 binary data（图片和其它加密的元素）可以被表示成 Base64 必须遵循 XSDL 的语法。 支持各平台。 Web Service use of JSON格式：1234&#123; “person” : &#123; “name” : “Smith”“place”:”London”“year”:”1934”&#125;&#125; 可以表示任何 binary message，因为 binary data（图片和其它加密的元素）可以被表示成 Base64 必须遵循 JSON 的语法。 比较 Marshalling and external data representationbinary, xml/json text Interoperabilitycorba flexibility, java requires both sides, xml/json interoperable Security ReliabilityTCP: reliable as it checks if the message is arrivedUDP: not reliable Performancecorba &gt; java &gt; xml/json(package and unpackage) Remote references Full OOP Describe how the protocols of the internet allow for heterogeneity Describe how middleware allows for heterogenityhides low level implementation Pass pointers在分布式的 OOP 中，我们需要传送 pointers，包括以下信息。 UDP Based Request-Reply Protocol直接上图和代码。 代码：123456789101112131415Client side:public byte[] doOperation (RemoteObjectRef o, int methodId, byte[] arguments)sends a request message to the remote object and returns the reply.The arguments specify the remote object, the method to be invoked and thearguments of that method.Server side:public byte[] getRequest ();acquires a client request via the server port.coolOperationselect object, execute, methodpublic void sendReply (byte[] reply, InetAddress clientHost, int clientPort);sends the reply message reply to the client at its Internet address and port. Failure modeldoOperation 可能在 waiting 的时候 timeout，我们要做什么？ 返回给 caller 一个错误信息 response 可能会丢失，所以我们告诉 client 让 client try and try 直到确认服务器挂了。这带来的结果是 client 可能会收到同样的信息。 Handle duplicates根据 client 的 acknowledgement 来清空历史。 Request-Reply Message Structure12345messageType: int (0=Request, 1=Reply)requestId: intobjectReference: RemoteObjectRefmethodId: int or Methodargument: array of bytes","tags":"web-service"},{"title":"Distributed Systems笔记－Web Service Design Patterns","url":"/2016/11/02/Web-Service-Design-Patterns/","text":"CMU 95702 Distributed Systems 笔记。简单介绍 XML-RPC、SOAP、REST 三种 web 服务实现方案以及 RPC、Message、Resource 三种 patterns。 Web 服务实现方案主流的 Web 服务实现方案有以下三种，因为 XML-RPC 逐渐被 SOAP 取代，所以也可以说，主流的 Web 服务实现方案只有 REST 和 SOAP 两种。 REST：表征状态转移（Representational State Transfer SOAP：简单对象访问协议（Simple Object Access Protocol） XML-RPC：远程过程调用（Remote procedure call，RPC) XML-RPCXML-RPC 是一个远程过程调用（remote procedure call，RPC)的分布式计算协议，通过XML将调用函数封装，并使用 HTTP 协议作为传送机制。后来在新的功能不断被引入下，这个标准慢慢演变成为今日的 SOAP 协定。XML-RPC 协定是已登记的专利项目。XML-RPC 透过向装置了这个协定的服务器发出HTTP请求。发出请求的用户端一般都是需要向远端系统要求呼叫的软件。 eg. Long-lived image如果需要经常把大的图片传到前端，那么可以把图片的 cache-control 设置的大一些，如 30 天，如果需要更新图片，那么上传一张新的图片到新的 URI，然后再改变 HTML，指向新的 URI。 HTML1&lt;img src=&apos;/image/big-image.jpg&apos;\\&gt; Server12345HTTP/1.1 200 OkDate: Thu, 15 Aug 2008 23:26:31 GMTServer: ApacheContent-Length: 50753Cache-Control: max-age=259200 HTML1&lt;img src=&apos;/image/big-image2.jpg&apos;&gt;&lt;/pre&gt; SOAPSOAP(Simple Object Access Protocol) 是一套完整的实现 Web 服务的解决方案。 SOAP 方式的 Web 服务中的 Web 服务描述语言（WSDL）和简单对象访问协议（SOAP）一起构成了 SOAP 方式下的 Web 服务的结构单元。客户端通过 WSDL 可以了解 Web 服务公开了那些可以被执行的方法以及 Web 服务可以发送或接收的消息格式（解决了公布访问资源方法的问题）。客户端按照 SOAP 将调用位于远程系统上的服务所需信息序列化为消息（解决了如何调用远程方法的问题）。注意 WSDL 描述的服务以及SOAP消息都是符合统一标准的，都是机器可读的. WSDL 基于 XML 格式，用来描述 Web 服务。WSDL 文档可以看成是客户端和服务器之间的一个协约。使用 WSDL 工具，你可以自动处理这个过程，几乎不用手工编写代码就能够让应用程序整合新的服务。因此 WSDL 是 Web 服务体系结构的基础，因为它提供了一个通用语言，用来描述服务和整合这些服务的平台。 SOAP 本身提供了与 Web 服务交换信息的方法。SOAP 是序列化调用位于远程系统上的服务所需信息的标准方法，这些信息可以使用一种远程系统能够读懂的格式通过网络发送到远程系统，而不必关心远程系统运行于何种平台或者使用何种语言编写。SOAP 以 XML 格式提供了一个简单、轻量的用于在分散或分布环境中交换结构化和类型信息的机制。实际上它通过提供一个有标准组件的包模型和在模块中编码数据的机制，定义了一个简单的表示应用程序语义的机制。 用一个简单的例子来说明 SOAP 使用过程，一个 SOAP 消息可以发送到一个具有 Web Service 功能的 Web 站点，例如，一个含有房价信息的数据库，消息的参数中标明这是一个查询消息，此站点将返回一个 XML 格式的信息，其中包含了查询结果（价格，位置，特点，或者其他信息）。由于数据是用一种标准化的可分析的结构来传递的，所以可以直接被第三方站点所利用。 REST表征状态转移（Representional State Transfer），是 Roy Fielding（ HTTP规范的主要编写者之一）博士在2000年他的博士论文中提出来的一种软件架构风格。它并不是一个标准，而是通过表征（Representional）来描述传输状态的一种原则。其宗旨是从资源的角度来观察整个网络，分布在各处的资源由URI确定，而客户端的应用通过 URI 来获取资源的表征。获得这些表征致使这些应用程序转变了其状态。随着不断获取资源的表征，客户端应用不断地在转变着其状态。 REST 中没有用于描述资源（服务）列表，资源元数据的类似于WSDL的东西。所以我们需要其他策略去代替 WSDL 实现“公布访问资源方法的问题”。 由于没有类似于 SOAP 的权威性协议作为规范，因此各个网站的REST实现都自有一套，也正是因为这种各自实现的情况，在性能和可用性上会大大高于 SOAP 发布的 web service，但细节方面有太多没有约束的地方，其统一通用方面远远不及 SOAP。 举个例子：假设A组织，B组织都实现了Restful API来通过工号查询人员信息，因为没有统一的规范。 A的API 可能是这样：1http://A/api/person/001 B的API 可能是这样：1http://A/api/person/id=001 第三方客户端在实现远程调用的时候就必须考虑这些API的差异，分别查看A，B的API文档。 如果有个权威性协议作为规范做指导，规定这个API应该实现成下面这样，那么第三方客户端也只需按照这个标准去调用远程API，而不用查看A，B的API文档：1http://A/api/person/&#123;001&#125; 而 OData 就是这样的一个设计和使用 Restful API 的权威性协议. OData 定义了一些标准规则（像一个接口定义一堆方法一样），实现 Restful API 时候，必须实现这些标准规则（就像实现一个接口必须实现其所有方法一样）。第三方就可以根据 Odata 协议定义的规则去访问 Restful API。 特性Resources URIREST 的一个重要原则是 Addressability，每一个资源都有一个 URI。格式为 scheme://host:port/path?queryString#fragment。scheme 可以是 http、ftp、https 等。 Uniform Interfacemethods，用 http 的若干方法来操作资源。representation，提供了多种 formats 来表述网页，如 xml, json 等。http 用 content-type header 来定义格式。 Protocol client-server客户和服务器之间通过一个统一的接口来互相通讯。 stateless每一个 request 都是独立的，每次发送请求时客户端都需要提供足够的信息，服务端并不会保存有关客户的任何状态。 cacheableREST 的系统能恰当对请求进行缓存，尽量减少服务器和客户端之间的信息传输来提高性能 layered(intermediaries)客户端并不会固定和一个服务器打交道 HTTP method 的补充： GET - safe, idempotent, cacheable PUT - idempotent DELETE - idempotent HEAD - safe, idempotent POST cacheable：response 可以被缓存idempotent：该操作可以被执行多次safe：该操作并没有副作用（不会影响别的操作） HATEOASREST 另一个主要内容是 HATEOAS。HATEOS 用中文解释就是 超文本作为状态转移的引擎，这是一个 late binding 的例子。用户在浏览器输入 URL 向该资源发起一个 HTTP GET 请求，服务器会返回 response，在这个 response 中包含了下一步你该去哪里的信息，你可以在这个 response 中找到对其它资源的引用：链接、图片、脚本等。也就是说，一个典型的REST服务不需要额外的文档标示通过哪些URL访问特定类型的资源，而是通过服务端返回的响应来标示到底能在该资源上执行什么样的操作。一个REST服务的客户端也不需要知道任何有关哪里有什么样的资源这种信息。 举例来说，一个客户端可能会接收一个我们上面所描述的用于报表服务的主RESTful服务的引用： http://company1.com/report/ 如果是通过浏览器发出的请求，可能会返回一个包含如下引用的HTML文档： http://company1.com/report/sales 用户可以点击进入并找到可浏览的年份列表。要说明的是浏览器对于URL的结构并没有特别的认知，但它知道如何分析结果并以用户可以浏览的结果返回内容。 对于其它的MIME类型道理也是一样，比如以XML的格式请求2009年的季度报表： http://company1.com/reports/sales/2009/qtr 可能得到：123456&lt;reports&gt; &lt;description&gt;2009 Quarterly Reports&lt;/description&gt; &lt;report name=&quot;First Quarter&quot; src=&quot;http://company1.com/reports/sales/2009/qtr/1&quot;/&gt; &lt;report name=&quot;Second Quarter&quot; src=&quot;http://company1.com/reports/sales/2009/qtr/2&quot;/&gt; &lt;report name=&quot;Third Quarter&quot; src=&quot;http://company1.com/reports/sales/2009/qtr/3&quot;/&gt; &lt;/reports&gt; 可以将 URL 想成是贯穿信息空间的向量。每一个层次都进一步的将你指向最终的资源。不同的路径可能产生同样的结果。客户端需要知道如何分析这些结果，但通过对响应给出可识别的类型，我们可以触发合适的分析器。这一结构可通过爬虫降序的从引用来抓取，或者以某种接口展现给用户浏览。一个 RESTful 接口成为了客户端通过基于已知来请求信息的方式。它们以一个已知或者已发现的点作为开始，就像你浏览web一样来浏览信息。 这就是 HATEOS 所指代的。应用的状态在超文本响应中被转移和发现。就像浏览器需要知道HTML、图片、声音文件等等一样，一个RESTful客户端也需要知道如何分析解析资源引用的结果。然而，整个过程是简单、受约束、可伸缩并且灵活的——这正是我们所期望的网络软件系统的属性。 许多人搭建的”RESTful”系统都要求客户端事先知道URL的每一层次的意义。如果服务端将信息重组了，这些系统的客户端就会崩溃。真正体现了HATEOS的客户端与它们所通讯的服务器之间才更加能做到松耦合。 更多见面向资源的架构：REST的另一面 Linked Services Pattern是 HATEOAS 的核心。只发布一部分 root web services 的地址，在每个 response 中返回相关服务的地址，让客户端通过这种 response 来发现之后的 URI。 Only publish the addresses of a few root web services. Include the addresses of related services in each response. Let clients parse responses to discover subsequent service URIs. Network performance客户端 -&gt; 服务端。 client - proxy - gateways - origin server REST 的优势。 Efficiency缓存可以提高效率，并不需要到达 gateways 和 origin server；data control 意味着我们可以压缩数据来提高效率。 Scalability缓存：理由同上。无状态：如果服务器记录用户相关的状态，那么集群扩展时用户相关的状态就要及时地在集群中的各个服务器之间同步，对用户状态的同步将会是一个非常棘手的问题，当一个用户的相关状态在一个服务器上发生了更改，那么在什么时候，什么情况下对这些状态进行同步？如果该状态同步是同步进行的，那么同时刷新多个服务器上的用户状态将导致对用户请求的处理变得异常缓慢。如果该同步是异步的，那么用户在发送下一个请求时，其它服务器将可能由于用户状态不同步的原因无法正确地处理用户的请求。除此之外，如果集群进行了不停机的横向扩展，那么用户状态的同步需要如何完成？不同的 gateways，增加 intermediaries 非常方便。 User Perceived Performance通过 reduce media types，缓存等方式实现。 simplicity/evolvability/extensibility/customizability/configuration/reusability/visibility/portability/reliability 三种方案简单比较XML-RPC已慢慢的被SOAP所取代，现在很少采用了，但它还是有版权的。 成熟度上：SOAP在成熟度上优于REST 效率和易用性上：REST更胜一筹 安全性上：SOAP安全性高于REST，因为 REST 更关注的是效率和性能问题 总体上，因为 REST 模式的 Web 服务与复杂的 SOAP 和 XML-RPC 对比来讲明显的更加简洁，越来越多的 web 服务开始采用 REST 风格设计和实现。例如，Amazon.com 提供接近 REST 风格的 Web 服务进行图书查找；雅虎提供的 Web 服务也是REST风格的。REST 对于资源型服务接口来说很合适，同时特别适合对于效率要求很高，但是对于安全要求不高的场景。而 SOAP 的成熟性可以给需要提供给多开发语言的，对于安全性要求较高的接口设计带来便利。所以我觉得纯粹说什么设计模式将会占据主导地位没有什么意义，关键还是看应用场景，正是那句老话：适合的才是最好的 同时很重要一点就是不要扭曲了REST现在很多网站都跟风去开发 REST 风格的接口，其实都是在学其形，不知其心，最后弄得不伦不类，性能上不去，安全又保证不了，徒有一个看似象摸象样的皮囊。 三种主流的Web服务实现方案（REST+SOAP+XML-RPC）简述及比较 API stylesRPCRPC 是指远程过程调用，也就是说两台服务器A、B，一个应用部署在A服务器上，想要调用 B 服务器上应用提供的函数/方法，需要通过网络来表达调用的语义和传达调用的数据。 这时候的 message 包括 procedure name 和 parameter list，service descriptor 通常是 WSDL 和 XSDL 或者 non-XML approach(JSON-RPC)，作用是生成一个在 client 上的 service connector(proxy)。 Framework: SOAP, JAX-WS(java), WCF(Microsoft) RPC 模型是 tightly copuled system，如果 parameter list 改变了，那么 client 将会 break。如果 descriptor 改变了，那么必须重新生成 connector 来连接 client。 request/response 是 RPC 的默认模式，request/acknowlege 会 less coupled(seperation of concerns)，request 可以在队列中等待，之后再进行处理，这样可以提高 scalability。如果 client 不想再等待的时候 block，那么可以用 asynchronous response handler。 Why通过 http 调用别的机器上的进程／方法为什么 RPC 呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如不同的系统间的通讯，甚至不同的组织间的通讯。由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用. RPC 的协议有很多，比如最早的 CORBA，Java RMI，Web Service的 RPC 风格，Hessian，Thrift，甚至 Rest API。 通信细节 服务消费方（client）调用以本地调用方式调用服务； client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； server stub 收到消息后进行解码； server stub 根据解码结果调用本地的服务； 本地服务执行并将结果返回给 server stub； server stub 将返回结果打包成消息并发送至消费方； client stub 接收到消息，并进行解码； 服务消费方得到最终结果。 RPC的目标就是要2~8这些步骤都封装起来，让用户对这些细节透明。 Message通过 http 给别的机器发送 command 命令、通知、其它信息，不用和别的进程 direct coupling，也不用知道别的机器的方法的签名。message 只包含一个参数。 这时候的 message 不包括 procedure name 和 parameter list，service descriptor 通常是 WSDL 和 XSDL，作用是生成一个 service connector(proxy)，service 的主要任务是分发，要求 service 更加的聪明，能够评估消息内容并决定去执行哪个进程调用哪个方法。 response 包括了相关 service 的地址（url）。Framework: SOAP, WS-Policy, WS-Security 默认是 request/acknowledge 模式而不是 request/response。追加一条新的 message type 很简单。 Resource操作另一台机器上的数据，不用和别的进程 direct coupling，最小化 the need for domain specific api’s。消息内容是一个 http 方法，一个 uri，一个 media type。 Resource API 可能是 Restful 的。request/acknowledge 或者 request/response。会产生 Security risk 因为 uri is hackable 总结 如果要建一个分布式系统，high performance(speed) 是最主要的要求，那么以下选项选哪个？ REST sytle web service JAVA RMI SOAP based web service Javascript using JSON Plain old XML(POX) over HTTP 选 JAVA RMI，因为 java RMI 把 message 都编码成 binary 的形式，减少了在各终端的 conversion time。 Postel’s Law最后加一条 Postel’s Law。简单来说就是 对自己严格，对他人宽容。“发送时保守”是告诫 web 开发人员的，HTML代码应该写的尽可能符合标准，能够方便别人（浏览器）去解析。“接收时开放”主要是说对一个不遵循固定标准（如不遵循HTML标准）的网页，或者说网站中出现的一个或多个错误，浏览器仍能够尽可能的解析并呈现。另外，浏览器必须向后兼容也是“接收时开放”的一个典型例子，不能因为大家都用 HTML5 编写网站浏览器就不再支持之前的 HTML 版本。 参考链接：你应该知道的RPC原理REST简介WebService的两种方式SOAP和REST比较 (转)三种主流的Web服务实现方案（REST+SOAP+XML-RPC）简述及比较","tags":"web-service"},{"title":"Search Engines笔记 - Learning to Rank","url":"/2016/10/25/Search Engines笔记 - Learning to Rank/","text":"CMU 11642 的课程笔记。我们已经学习了很多检索方法，如果把这些方法结合起来，效果会不会更好呢？ 传统的排序模型相关度排序模型(Relevance Ranking Model)相关度排序模型根据查询和文档之间的相似度来对文档进行排序。常用的模型包括：布尔模型(Boolean Model)，向量空间模型(Vector Space Model)，隐语义分析(Latent Semantic Analysis)，BM25，LMIR 模型等等。 重要性排序模型(Importance Ranking Model)重要性排序模型考虑的是 query-independent 的因素，根据网页(亦即文档)之间的图结构来判断文档的权威程度(Authority Score)，典型的权威网站包括 Google，Yahoo! 等。常用的模型包括 PageRank，HITS，HillTop，TrustRank 等等。 Learning to RankWhy对于传统的排序模型，单个模型往往只能考虑某一个方面(相关度或者重要性)，所以只是用单个模型达不到要求。搜索引擎通常会组合多种排序模型来进行排序，但是，如何组合多个排序模型来形成一个新的排序模型，以及如何调节这些参数，都是一个很大的问题。使用机器学习的方法，我们可以把各个现有排序模型的输出作为特征，然后训练一个新的模型，并自动学得这个新的模型的参数，从而很方便的可以组合多个现有的排序模型来生成新的排序模型。 先来看看我们现在已经拥有的东西，这些都可以作为 feature Retrieval models: Vector space, BM25, language models, … Representations: Title, body, url, inlink, … Query templates: Sequential dependency models, … Query-independent evidence: PageRank, url depth, … 我们可以把 retrieval model 也当作 feature，然后用 machine learning 的算法将上面这些 evidence 综合起来。 结构 Framework Components从三个角度来讨论。 Features Training data Algorithm Features其实之前已经讲过，retrieval models, representations, query templates, query-independent evidence 都能作为特征。 Training dataL2R 的训练数据可以有三种形式，这三种形式的训练数据之间可以相互转换，详见[1]。 对于每个查询，各个文档的绝对相关值(非常相关，比较相关，不相关，等等) 对于每个查询，两两文档之间的相对相关值(文档1比文档2相关，文档4比文档3相关，等等) 对于每个查询，所有文档的按相关度排序的列表(文档1&gt;文档2&gt;文档3) 训练数据的获取有两种主要方法：人工标注和从日志文件中挖掘。 人工标注： 首先从搜索引擎的搜索记录中随机抽取一些查询，将这些查询提交给多个不同的搜索引擎，然后选取各个搜索引擎返回结果的前 K 个，最后由专业人员来对这些文档按照和查询的相关度进行标注。 从日志中挖掘： 搜索引擎都有大量的日志记录用户的行为，我们可以从中提取出 L2R 的训练数据。Joachims 提出了一种很有意思的方法：给定一个查询，搜索引擎返回的结果列表为 L ，用户点击的文档的集合为 C，如果一个文档 di 被点击过，另外一个文档 dj 没有被点击过，并且 dj 在结果列表中排在 di 之前，则 di&gt;dj 就是一条训练记录。亦即训练数据为：${di&gt;dj，di \\in C，dj \\in L-C，p(dj)&lt;p(di)}$，其中 p(d) 表示文档 d 在查询结果列表中的位置，越小表示越靠前。 Machine Learning AlgorithmL2R算法主要包括三种类别：PointWise，PairWise，ListWise。 Pointwise 训练数据是一个文档类别或分数 Accurate score ≠ accurate ranking 忽略文档的位置信息 Pairwise 训练数据是文档对的一个偏好(一对文档选哪个) Accurate preference ≠ accurate ranking 忽略文档的位置信息 Listwise 训练数据是文档的排名 难以直接优化 ranking metrics PointWise L2R只考虑给定查询下，单个文档的绝对相关度，而不考虑其他文档和给定查询的相关度。亦即给定查询 q 的一个真实文档序列，我们只需要考虑单个文档 di 和该查询的相关程度 ci。 Approach: 用 individual documents 训练模型Training data: x -&gt; scoreLearned model: h(x) -&gt; score Regression (e.g., linear regression) – Scores are { -1, +1 } or { 4, 3, 2, 1, 0 } Classification (e.g., SVM) – Categories are { -1, +1 } or { 4, 3, 2, 1, 0 } 局限： 要求 score 必须在一定范围内 E.g., { -1, +1 } or { 4, 3, 2, 1, 0 } 然而经过排序算法出来的分数往往不是这样的，它可能是 { 189, 57, 42, 16, 1}. 重要的是 order，而不是 score。 没有考虑到排序的一些特征，比如文档之间的排序结果针对的是给定查询下的文档集合，而 Pointwise 方法仅仅考虑单个文档的绝对相关度 在排序中，排在最前的几个文档对排序效果的影响非常重要，Pointwise 没有考虑这方面的影响 Pointwise方法主要包括以下算法：Pranking (NIPS 2002), OAP-BPM (EMCL 2003), Ranking with Large Margin Principles (NIPS 2002), Constraint Ordinal Regression (ICML 2005)。 Pairwise L2RPairwise 方法考虑给定查询下，两个文档之间的相对相关度。亦即给定查询 q 的一个真实文档序列，我们只需要考虑任意两个相关度不同的文档之间的相对相关度：di&gt;dj，或者 di&lt;dj。 Approach: 用文档对来训练模型Training data: prefer (x1, x2)Learned model: h (x1) &gt; h (x2) Pair valueBinary assessments { &gt;, &lt; } Loss function如果文档对顺序正确，为 0，否则为 1 Minimize the number of misclassified document pairs关注偏好，而不是 raw scores/labels E.g., Ranking SVM Properties of Ranking SVM 泛化能力强 Kernels 可以用来提高准确率– linear kernels 往往效果不错 继承了 SVM 的优势– 有许多开源工具– 有很多关于优化的研究– 训练速度快– 有理论保证 Pairwise方法主要包括以下几种算法：Learning to Retrieve Information (SCC 1995),Learning to Order Things (NIPS 1998),Ranking SVM (ICANN 1999),RankBoost (JMLR 2003), LDM (SIGIR 2005),RankNet (ICML 2005), Frank (SIGIR 2007),MHR(SIGIR 2007),Round Robin Ranking (ECML 2003),GBRank (SIGIR 2007),QBRank (NIPS 2007),MPRank (ICML 2007),IRSVM (SIGIR 2006) 。 Pairs在相关文档和不相关文档间能有很好的平衡的 queries 在训练数据中占主导地位 1234Number of pairs = |R| × |NR|q1 = 5R × 5NR = 25 pairs (10 documents: 5R,5NR)q2 = 9R × 1NR = 9 pairs (10 documents: 9R,1NR)q3 = 2R × 8NR = 16 pairs (10 documents: 2R,8NR) 相比于 Pointwise 方法，Pairwise 方法通过考虑两两文档之间的相对相关度来进行排序，有一定的进步。然而，因为一个 label 会产生很多的 training instances，所以 pairwise approach 容易受到 noisy labels 的影响。另外，Pairwise 使用的这种基于两两文档之间相对相关度的损失函数，和真正衡量排序效果的一些指标之间，可能存在很大的不同，有时甚至是负相关。 另外，有的Pairwise方法没有考虑到排序结果前几名对整个排序的重要性，也没有考虑不同查询对应的文档集合的大小对查询结果的影响(但是有的Pairwise方法对这些进行了改进，比如 IR SVM 就是对 Ranking SVM 针对以上缺点进行改进得到的算法)。 Listwise L2R与 Pointwise 和 Pairwise 方法不同，Listwise 方法直接考虑给定查询下的文档集合的整体序列，直接优化模型输出的文档序列，使得其尽可能接近真实文档序列。 Approach: 用文档序列来训练模型Training data: x1 &gt; x2 &gt; … &gt; xnLearned model: h (x1) &gt; h (x2) &gt; … Loss functionSome metric over the rankingE.g., NDCG@n, with n=1, 3, 5, 10, … – E.g., MAP@n Goal: Maximize the value of the metricDirectly align the model with the ranking target E.g., 直接优化 metrics 很难，因为一些常用的 metrics (e.g., NDCG@n) 不连续或者不是凸函数。 Two common strategies in listwise approaches: 找另一个直观且易于优化的指标– E.g. likelihood of ‘best’ rankings in training data 用 approximation 直接优化 evaluation metrics, with Listwise 算法主要包括以下几种算法：LambdaRank (NIPS 2006), AdaRank (SIGIR 2007), SVM-MAP (SIGIR 2007), SoftRank (LR4IR 2007), GPRank (LR4IR 2007), CCA (SIGIR 2007), RankCosine (IP&amp;M 2007), ListNet (ICML 2007), ListMLE (ICML 2008) 。 相比于 Pointwise 和 Pairwise 方法，Listwise 方法直接优化给定查询下，整个文档集合的序列，所以比较好的克服了以上算法的缺陷。Listwise 方法中的 LambdaMART(是对 RankNet 和 LambdaRank 的改进)在 Yahoo Learning to Rank Challenge 表现出最好的性能。 ListMLE(Listwise Maximum Likelihood Estimation) 直接优化 metric of interest，然而很难做到，因为一些指标不连续或者不可微，如基于位置的 metrics Simpler possibilities: 优化 metric 的 approximation 约束目标函数 直接优化目标函数(不能保证结果) SummaryPointwise 是三种方法里最弱的 Pairwise 和 listwise 几乎同样有效 Pairwise 有一个不完美的学习目标，但是容易实现– 最小化 pairwise errors, 但我们想要的是最好的 ranking－ 有理论保证的一个简单化的学习模型 Listwise 有一个完美的学习目标，但是更难实现– 学习目标与我们想要的完全相同－ 然而很难学习 Relative effectiveness: Listwise ≈ Pairwise &gt; Pointwise 许多 ML 算法使用 pointwise &amp; pairwise LeToR，因为易于开发，也比较有效。Listwise 算法可能最终更有效，然而成熟的解决方案比较少，现在仍然是一个开放的研究主题。 效果评价L2R 是用机器学习的方法来进行排序，所以评价 L2R 效果的指标就是评价排序的指标，主要包括一下几种： WTA(Winners take all) 对于给定的查询 q，如果模型返回的结果列表中，第一个文档是相关的，则 WTA(q)=1，否则为0. MRR(Mean Reciprocal Rank) 对于给定查询 q，如果第一个相关的文档的位置是 R(q)，则 MRR(q)=1/R(q)。 MAP(Mean Average Precision) 对于每个真实相关的文档 d，考虑其在模型排序结果中的位置 P(d)，统计该位置之前的文档集合的分类准确率，取所有这些准确率的平均值。 NDCG(Normalized Discounted Cumulative Gain) 是一种综合考虑模型排序结果和真实序列之间的关系的一种指标，也是最常用的衡量排序结果的指标，详见 Wikipedia。 RC(Rank Correlation) 使用相关度来衡量排序结果和真实序列之间的相似度，常用的指标是 Kendall’s Tau。 参考链接Learning to rankA Short Introduction to Learning to RankLearning to Rank 简介","tags":"nlp search-engines 信息检索"},{"title":"项目实战--搜索引擎","url":"/2016/10/22/项目实战-搜索引擎/","text":"CMU 11642 的 project。 项目介绍简介数据：ClueWeb09 dataset，共 553,202 篇文档，用 Lucene 建立的索引。部分框架是现成的，有 api 文档我们要做的是实现部分 operator 以及 ranking algorithm。 实现一个个性化的搜索引擎，具有以下能力： diversification query expansion learning to rank 支持的 operator:1#OR, #AND, #SYN, #NEAR/n, #WINDOW/n, #SUM #AND, #WAND, #WSUM, #WINDOW 支持的 fields:1&apos;url&apos;, &apos;keywords&apos; , &apos;title&apos;, &apos;body&apos;, &apos;inlink&apos; 支持的 ranking algorithmUnranked/Ranked boolean, Okapi BM25, Indri, Le2R(use SVM), diversification algorithm(xQuAD &amp; PM25), and etc. 输入程序输入: one parameter (name of parameter file) parameter file 必须包括以下参数：1234- queryFilePath= The path to the query file.- indexPath= The path to the Lucene index directory. Typically this will be something like &quot;indexPath=index&quot;.- trecEvalOutputPath= The path to the file where your software will write its output for trec_eval.- retrievalAlgorithm= &quot;UnrankedBoolean&quot; ／ &quot;RankedBoolean&quot; ／ &quot;BM25&quot; / &quot;Indri&quot; 可选参数用于 “BM25” / “Indri” 模型。12345- BM25:k_1= Values are real numbers &gt;= 0.0.- BM25:b= Values are real numbers between 0.0 and 1.0.- BM25:k_3= Values are real numbers &gt;= 0.0.- Indri:mu= Values are integers &gt;= 0.- Indri:lambda= Values are real numbers between 0.0 and 1.0 用于 query expansion。1234567- fb= Acceptable values are &quot;true&quot; and &quot;false&quot;. This value controls whether query expansion is performed (fb=true).- fbDocs= Acceptable values are integers &gt; 0. This value determines the number of documents to use for query expansion.- fbTerms= Acceptable values are integers &gt; 0. This value determines the number of terms that are added to the query.- fbMu= Acceptable values are integers &gt;= 0. This value determines the amount of smoothing used to calculate p(r|d).- fbOrigWeight= Acceptable values are between 0.0 and 1.0. This value determines the weight on the original query. The weight on the expanded query is (1-fbOrigWeight).- fbInitialRankingFile= The value is a string that contains the name of a file (in trec_eval input format) that contains an initial document ranking for the query.- fbExpansionQueryFile= The value is a string that contains the name of a file where your software must write its expansion query. The file format is described below. 用于 Le2R:（解释待修正）12345678910letor:trainingQueryFile= HW4-train.qry.txtletor:trainingQrelsFile= HW4-train.qrel.txtletor:trainingFeatureVectorsFile= HW4-train.vec.txtletor:pageRankFile= HW4.pk.txtletor:svmRankLearnPath= svm_rank/svm_rank_learnletor:svmRankClassifyPath= svm_rank/svm_rank_classifyletor:svmRankParamC= 0.001letor:svmRankModelFile= HW4-svm.model.txtletor:testingFeatureVectorsFile= HW4-test.vec.txtletor:testingDocumentScores= HW4-test.rank.txt 用于 diversification:（解释待修正）123456diversity=truediversity:maxInputRankingsLength=100diversity:maxResultRankingLength=50diversity:algorithm=xquaddiversity:intentsFile=q.intents.txtdiversity:lambda=1 输出程序输出：在 trecEvalOutputPath 指定的文件中：123456QueryID Q0 DocID Rank Score RunID10 Q0 clueweb09-enwp03-35-1378 1 16 run-110 Q0 clueweb09-enwp00-78-1360 2 11 run-110 Q0 clueweb09-enwp00-67-0958 3 9 run-1: : : : : :11 Q0 clueweb09-enwp00-63-1141 1 18 run-1 如果有 query expansion，在 fbExpansionQueryFile 指定的文件中：1234567qid1: query1qid2: query2 : :eg.1: #wand (0.73 obama 0.43 family 0.40 white 0.65 tree 0.33 politics ...)2: #wand (0.69 french 0.83 lick 0.76 indiana ...) 基本策略要求 从 query file 中逐条读取 query 将 query parse 为 query tree，internal nodes 是 operators，leaves 是 index terms 如果一个 query 没有 explicit operator，默认为 #OR 如果一个 query 没有 explicit field，默认为 body 对 query term 进行 stemming 和 stopwords 处理 评估 query，用 DAAT 策略，对 leaf node 的 evaluation 就是如果这个 term 的 inverted list 存在，就获取它，注意有些 query term 是没有 inverted list 的。 对所有文档按文档分数降序排序，如果分数相同，按 external document id 升序排序。 Operator不同模型支持的 operator 各有不同系统需要支持的 Operator 有 #OR, #AND, #SYN, #NEAR/n, #WINDOW/n, 对 BM25 模型来说，还需要支持 #SUM，对 Indri 模型来说，还需要支持 #AND, #WAND, #WSUM, #WINDOW Fields系统支持的 fields 有 ‘url’, ‘keywords’ (from the html ‘meta’ tag), ‘title’, ‘body’, 和 ‘inlink’ 5 种，query 形式为 apple.title。 Query123456#Operator( term_1.field term_2.field ... term_n.field )apples#AND (apple bananas)#OR (apple bananas)#NEAR/3 (apple pie)#NEAR/5 (pie apple) 排序模型Exact-matchBoolean retrieval 需要支持的 Operator 有 #OR, #AND, #SYN, #NEAR/n, #WINDOW/n #OR 只要有一个 query term 在文档中出现，就算 match，在 ranked boolean retrieval 中分数为所有匹配的 query term 的 tf 的最大值。 #AND 只有在所有 query term 都在文档中出现时，才算 match，在 ranked boolean retrieval 中分数为所有 query term 的 tf 的最小值。 #NEAR/n 如果每对相邻两个 query term 之间的距离小于 n，才算 match，在 ranked boolean retrieval 中分数为 match 的次数。（For example, #NEAR/2(a b c) matches “a b c”, “a x b c”, “a b x c”, and “a x b x c”, but not “a x x b c”）。 #WINDOW/n 和 #NEAR/n 类似，但是不要求顺序。 Search Engines笔记 - Exact-match retrieval Unranked boolean retrieval对每个文档来说，如果 match，分数为 1，不 match 就为 0。 Ranked boolean retrieval每个文档的分数是 query term 在该文档中的 term frequency。 Best-matchSearch Engines笔记 - Best-Match BM25需要支持的 Operator 有 #SYN, #NEAR/n, #SUM Indri需要支持的 Operator 有 #AND(Indri #and), #WAND, #WSUM, #WINDOW。默认的 operator 是 #AND，注意这里的 #AND 和 boolean retrieval 中的算法不一样。 Query expansion基本逻辑是把 initial query 当做 classifier，用它来 label 部分 data，得到 top-ranked documents，然后用 labeled data 来产生更优的 classifier。基本过程： 用原始 query 检索文档 取结果的前 N 篇文档作为训练集，这些文档相关度可能不高，然而我们的目的是学习 vocabulary pattern。 应用 relevance feedback algorithm 选取 term 和 term weight 组成新的 query 来检索文档 见 Search Engines笔记 - Pseudo Relevance Feedback Diversification具体见 Search Engines笔记 - Diversity Search Engines笔记 - Pseudo Relevance Feedback","tags":"mysql hbase webserver"},{"title":"Search Engines笔记 - Cache","url":"/2016/10/15/Search Engines笔记 - Cache/","text":"Web traffic is highly skewed，我们可以通过缓存提高 performance。缓存内容可以是 query, result page, inverted list。 Caching of Popular ResultsQuery distributionquery rank 和 frequency 符合长尾分布。Top 25 queries 占了 1% 的流量。在 distinct queries 里， 64% occur once 16% occur twice 7% occur three times 14% occur &gt;=3 times average query frequency: 4 RAM &amp; DISK 给 query cache 分配 RAM储存标准 queries，按字母顺序排列 term1.6GB cache 储存 40 million queries (40 bytes/query) 给 result page cache 分配磁盘一页 30KB uncompressed, 10KB compressed400GB cache 可以存 40 million result pages Cache misses use RAM only(very fast) Cache hits use RAM+disk比正常 evaluate query 要快只用一台机器 RAM only 给 query cache 分配 RAM储存标准 queries，按字母顺序排列 term9MB cache 储存 300,000 queries 给 result page cache 分配 RAM一页 30KB uncompressed, 10KB compressed2.1GB cache 存 210,000 compressed result pages Cache misses and hits only use RAM (very fast)因为缓存的比较少，所以更多的 query 会被 miss Could partition caches across multiple machines需要更复杂的 design Cache size?Markatos 提出，30% 的 queries 会与缓存里的 query 匹配，然而增加 cache size 只能非常小幅度的提高 hit rate。见下图：根据 UK2007 的 query log，44% 的 query 只出现了一次，56% 的 query 出现了超过一次，cache 这 56% 里的 query 有助于提高 performance，然而并不能帮助 first occurrence of a query。 Caching Inverted List根据 UK2007 的 query log，4% 的 query term 只出现了一次，96% 的 query term 出现不止一次，对 96% 里对 query term 进行 inverted list 的 cache 才是有用的。在每个 partition 上分配一部分 RAM (a few GB)给 inverted list。这里的重点在于 which terms should be cached? 两个原则： Terms that are frequent in a query log (improve the hit rage) Terms that don’t have massive inverted lists (consume limited cache space) 对 term 的排序： $$Score(t)={qtf(t) \\over df(t)}$$。","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Index Construction","url":"/2016/10/14/Search Engines笔记 - Index/","text":"CMU 11642 的课程笔记。这篇讲了搜索引擎中创建索引的主要原则、方法以及优化方案。 Overview Inverted list:索引包含了各种数据结构，如 term dictionary，inverted list 等。inverted list 是一个重点。搜索引擎所拥有的文档中出现的每一个单词都拥有一个 inverted list，记录这个单词在多少文档中出现，分别是哪些文档，每个文档分部出现多少次，分别出现在什么位置等信息。比如 Apple 这个词出现在文档 1，7，19，34，102。其中文档 1 中出现了3次，分别在位置 20，105，700。这样当搜索 Apple 时，搜索引擎就不用遍历所有的文档，只需要查找每个单词对应的 inverted list 就可以知道这个词在哪里出现了。 文档预处理:创建索引是个巨大工程。首先是对文档进行解析和处理。互联网上的文档格式各种各样，对每一种格式的文档都要有一个对应的解析器程序，这样才能忽略各种奇怪符号，提取出有用内容。每一个解析器的实现都是一个繁琐且困难的任务。对于解析后的干净文档，许多重要的自然语言处理算法就要派上用场。以英语为例，需要进行分词（tokenization，将一句话分割成一个个单词），词干提取（stemming， 将文本中出现的单词还原成它的原型），part-of-speech tagging（识别单词在一句话中的词性），创建 n-gram 模型等操作。此外还需要识别文档中的命名实体(named entity)，比如将“iphone 6”作为一个词，而不是 “iphone” 一个， “6” 一个。上述操作生成的信息都要存储下来。这样构造 inverted list 时就可以知道每个单词出现的位置，出现个数等信息。 生成索引:索引生成程序的一个设计目标就是高效。它要求被尽可能地运行在多个机器上。对于每个机器来说，索引程序一边扫描输入文档，一边在内存中更新索引的数据结构。当内存中得数据大小超过一定阀值时，这些内容被作为一个块(block)一次性写入硬盘文件中。当所有文档扫描结束后这些块会再被合并成一个大的 inverted file。因为每一个块都是排好序的，合并操作是线性的复杂度。因为数据量太大，可以用 MapReduce 把一个大的任务分割成许多小任务，并下发给多个 Mapper 程序，Mapper计算好的中间结果会发给多个 Reducer 程序继续处理，得到最终结果。这个计算模型允许成千上万台机器同时运算，从而极大提高了运算效率。 inverted list 要和访问机制(access mechanism)一起可以工作。访问机制定义了如何通过一个单词找到它所对应的 inverted list。大概可以使用两种数据结构：b-tree 或 Hash table。 Big facts: 索引中的单词和文档都用 integer 的 ID 表示而不是字符串，省空间省时间。 一般来说 corpus 比 RAM 要大，不能在内存中完成整个任务，所以一定会有部分写到磁盘中，访问磁盘数据比访问内存数据慢得多，所以可以做的是 只在必要的时候写入磁盘 压缩数据减少 I/O。数据从磁盘传输到内存是由系统总线而不是处理器来实现的，所以磁盘 I/O 时处理器仍然可以处理数据。 顺序读取（比 random access 快）。因为磁盘读写时，磁头移到数据所在的磁道有一段时间，大概 5ms，称为寻道时间，这段时间并不进行数据的传输，所以连续读取的数据应该连续存放来节省时间。 索引更新:互联网内容是不停变化的，这必然导致索引不停被更新。然而建立好的索引中，各个单词的反转列表是紧密的拼接在一起的，这使得更新变得非常困难。通常搜索引擎会积攒一批文件后才进行索引的更改，并且把索引分成静态和动态两个部分。程序把所有更改都写入动态部分，并且周期性地将动态部分合并进静态部分中。搜索时，动态和静态部分都会被访问。当从索引中删除一个文档时，这个文档中出现的词对应的反转列表都会被修改，开销极大。于是程序加入了“删除列表（delete lists）”来记录所有被删除的文档。搜索时会查询删除列表来把已经被删除的文档从搜索结果中移除。当删除列表足够大，垃圾回收机制会被触发，重新生成索引。 Single Processor(单机版)Block sort-based indexing(BSBI)基于块的排序索引方法(Block sort-based indexing algorithm) 过程如下: 将 corpus 分割成几个大小相等的部分 对每个部分的 (termId,docId)排序 一旦 in-memory buffer 满了，就把临时排序结果 flush 到磁盘中，然后重新初始化，重复2、3过程 将所有的中间文件合并成最终索引。(merge index blocks on disk) BSBI 的时间复杂度是 O(TlogT) Single-pass in-memory indexing(SPIMI)BSBI 需要将 term 映射成 id，对大规模的 corpus 来说，这种数据结构会很大以致在内存中难以存放，SPIMI 使用 term 本身，将每个块的词典写入磁盘，对于下一个块则重新采用新的词典，这样带来的好处是，只要硬盘空间足够大，SPIMI 就能索引任何大小的 corpus。 算法如下，反复调用 SPIMI-INVERT 函数直到将全部 corpus 处理完。token_stream 就是 term-docid stream。 BSBI 和 SPIMI 的一个区别是， SPIMI 直接在 inverted list 中增加一项，这个 inverted list 是动态增长对，大小会不断调整，而 BSBI 一开始就整理出所有的 termID-docID 并对它们进行排序。这样做的好处是： 不需要进行排序，处理速度更快 保留 inverted list 对 term 的归属关系，能节省内存，也不用保存 term id，所以每次单独的 SPIMI-INVERT 调用能够处理的块可以非常大，整个的索引构建过程也会因此非常高效。 SPIMI 的空间复杂度是 O(T)。 Distributed indexesSize of web search engine index一些假设： 网页数：500亿（2013年），假设 50％ 是 text 文本 平均网页大小：37K（2013年） 假设 non-text 网页的平均入链数：1K 索引大小约为原始文本大小的 20％ Text: 25billion 37K + 25billion 1K = 925TBIndex: 20% * 950TB = 185TB (call it 200TB for convenience) –&gt; 索引分布在 50 个 4TB 的磁盘驱动器上比较合理 Hardware一个 computer cluster，又叫做 rack，有 40-80 台机器，每个 rack 有自己内部的网络，对大公司像 google 而言，机器的选择遵循的原则是： 越便宜越好 每台计算机使用少量的普通磁盘 每台计算机使用比较大(not huge)的 RAM 因为一台机子坏了得立刻换一台机子上去，自动部署，随时投入使用。而对于小的组织像 cmu，机子就会买好一点的，一台坏了会去修，而不是直接换一台。 Partitioned indexes分布式索引用到了 sharding 和 replication 的原理。 Shardingindex 通常是被切片(sharding)的，每个分区包含了一堆不重复的文档集合，每个分区都被分到了一台机器，根据之前对索引大小的估计，就有 25 个分区(2 disks/node, 4TB/disk =&gt; 200TB) 。 那么 corpus 会怎样被分区呢？ 可以随机分配(random assignment)，也可以按来源（source-based assignment），总的来说，随机分配用的比较多，因为随机可以平衡不同分区的 query traffic，让每台机得到充分使用。 Replication索引通常被存了好几份 copy(replication)，为了提高并行能力和容错能力。 所以一个 index server 标准的配置： 40 machines in a rack 2*4TB disks/machine 320 TB of index/rack Query evalution分布式系统的 query 评估过程为 从每个分区中找出一台机器。 (select a machine for each index partition) 把 query 分配到选出的机器中，然后每台机器返回一个 ranked list of matches。 (broadcast the query to each selected machine) 一个 aggregator 将这些 ranked list 合并(merge-sort)成最终的有序文档集合。(an aggregator assembles them into a final ranked list of doc ids) 其它机器对每个结果来寻找 title, urls, etc.。（other machines looks up titles, URLs, etc., for each result, a similar partitioning/pooling strategy is used for documents） Tiered indexes另一种分布式的 index 是将 web page 进行分层，10% 为 tier 1，是高价值的网页，其余 90% 是 tier 2，是低价值的网页。query 过来我们先从 tier 1 找，如果 good results 不够，再往 tier 2 找。 所以问题来了，怎么找 top tier(s)？ page rank 较高的网页，或来自 page rank 较高的网站的网页 对之前的一些常见 query 非常重要的网页（排名高，点击率高，停留时间长） 网址较短的网页（更可能是主页） spam 分数较低的网页 Tiered index 的优势如下： 降低了大多数 query 的搜索成本，一个完整的搜索过程比 tier 1 的搜索要找 10x 的机器。 提高了大多数 query 的搜索质量，因为它更关注 “good” pages. 什么情况下会去找 tier 2? 匹配 query 的 Tier 1 的网页太少 query 非常少见 Index Construction建立分布式索引用的框架是 MapReduce，基本过程是 Input reader –&gt; Map –&gt; Combine –&gt; Shuffle –&gt; Reduce。从最基本的 binary inverted list 进行示范，format 是 (term,[docids]) 或者 (term,[docid,docid,…])，注意这里的 docid 是 internal document id（转化成了 integer） 而不是原来的 id。 Mapper每个 Map task 相当于一个 document parser input: a stream of documents output: a stream of (term,docid) tupleseg. (men,1)(and,1)(women,1)…(once,2)(upon,2) Shuffle／SortShuffle 的过程相当于 route tuples 到 Reducers 里。在 Shuffle/Sort 中，都是 shuffle/sort by key，而不是 by value。 input: (t5,docid1)(t1,docid3)(t1,docid1)… output: (t1,docid3)(t1,docid1)(t5,docid1)… RedcuerReducer 的作用就是将 stream of keys 转化成 streams of inverted lists。Reducer 会 sort values 也就是 docids，然后建立 inverted list，这里要保证的是最长的 inverted list 必须能够 fit in memory。 input: (men,1)(men,127)(men,49)(men,23)… ouput: (men,[df:492,docids:1,23,49,127,…]) Improvement这个流程下来的效率并不高，因为文档里所有 unique term 都会产生一个 tuple，像 WSJ’87-92 (533 MB of text) 就会产生 20 million 的 tuple，每个 tuple 都会 shuffle 到 reducers 里，进 reducer 前还要先 sort，这个过程特别耗时。所以我们会用 Combiner 来提高效率。Combiner 的作用和 reducer 差不多，不过它是在每个 mapper 里进行的，它把每个 mapper 里的 docid 先进行了合并。(t1,docid1)(t2,docid1)(t4,docid2)…-&gt;(t1,[docid1,docid18,…])。这样的好处是需要 shuffle 的 tuple 更少，需要 hash 的 key 更少，需要进行 movement operation 的数据也更少，另外，需要 reduce 的 tuple 更少，需要 sort 的 tuple 也更少。改进后的框架如下： Map:$(docid_1,content_1)$ -&gt; $(t_1,ilist_{1,1})(t_2,ilist_{2,1})(t_3,ilist_{3,1})$ Combine:Sort by t &amp; combine $(t_1 [ilist_{1,2} ilist_{1,3} ilist_{1,1},…])$-&gt;$(t_1,ilist_{1,27})$每个 output inverted list 包含了一系列文档 Shuffle by t Sort by t$(t_4 ilist_{4,1}) (t_1 ilist_{1,3})$-&gt;$(t_1,ilist_{1,2})(t_1,ilist_{1,4})(t_4,ilist_{4,1})$ Reduce$(t_1 [ilist_{1,2} ilist_{1,1} ilist_{1,4},…])$-&gt;$(t_1,ilist_final)$ $ilist_{i,j}$: the j’th inverted list fragment for term i 注意每个 reducer 里的 inverted list 都是完整的，每个 reducer 相当于存了个 result block，每个 block 包括不同的 term，每个 term 只在一个 block 里出现。 如果要创建 partitioned inverted list，只用在 key 里加上一个 partition id 即可。 Map:$(docid_1,content_1)$ -&gt; $([p,t_1],ilist_{1,1})([p,t_2],ilist_{2,1})([p,t_3],ilist_{3,1})$ Combine:Sort by t &amp; combine $([p,t_1] [ilist_{1,2} ilist_{1,3} ilist_{1,1},…])$-&gt;$([p,t_1],ilist_{1,27})$每个 output inverted list 包含了一系列文档 Shuffle by p Sort by [p,t]$([p,t_4] ilist_{4,1}) ([p,t_1] ilist_{1,3})$-&gt;$([p,t_1],ilist_{1,2})([p,t_1],ilist_{1,4})([p,t_4],ilist_{4,1})$ Reduce$([p,t_1] [ilist_{1,2} ilist_{1,1} ilist_{1,4},…])$-&gt;$([p,t_1],ilist_final)$ Inverted list compression概念上来讲 inverted list 看起来像一个 object 12345678910# appledf: 4356docid: 42tf: 3locs: 14 83 157 94docid: 94... 而实际上它在磁盘中只是一串数字 12345674356423148315794 通常 intered list 会被压缩，目的不同，选择的压缩方法也就不同。要节省空间我们就用 aggressive compression algorithms，要节省时间我们就用 simple compression algorithms。现在我们最主要的目的是节省 query 时间，用的压缩算法主要有 Gap encoding Restricted variable-length(RVL) encoding Delta GapDelta Gap 的基本思想是保存数字的差值而不是数字本身，意义在于 增加较小的数字的概率 更 skewed 的分布 降低信息熵 Variable Byte EncodingVariable Byte Encoding 存了一串 bytes，每个 byte 由开头 1 位 flag 和 7 位的 payload（the number）组成。flag 为 0，表示不是最后一个 byte，flag 为 1 表示这是最后一个 byte。通过连接 payload 来重建 number。 好处是编码和解码的效率都很高，可以找到第 n 位数字而不用 decode 之前的数字。 Example 123456789101112131415161718192021222324[0..2^7-1]: 1 byte : 1xxxxxxx[2^7...2^14-1]: 2 bytes: 0xxxxxxx1xxxxxxx[2^14...2^21-1]: 3 bytes: 0xxxxxxx0xxxxxxx1xxxxxxx...Decimal: 5Binary: 00000000 00000000 00000000 00000101# 照抄最后7位，第一位补上1Compressed: 10000101Decimal: 127Binary: 00000000 00000000 00000000 01111111# 照抄最后7位，第一位补上1Compressed: 11111111Decimal: 128Binary: 00000000 00000000 00000000 10000000# 照抄最后7位，第一位补上0，再往前找7位，照抄，第一位补上1Compressed: 00000000 10000001Decimal: 131Binary: 00000000 00000000 00000000 10000011# 照抄最后7位，第一位补上0，再往前找7位，照抄，第一位补上1Compressed: 00000011 10000001 Summary最高效的压缩算法比 variable byte encoding 节省 15%－20% 的空间，但是比 restricted variable length encoding 要慢。注意我们这里要把握的原则是 “Disks are cheap, and speed is important”，所以 Restricted variable length compression 还是非常通用的。 压缩不包含地址信息的 inverted file，所用空间是 original text 的 10%，压缩包含地址信息的 inverted file，所用空间是 original text 的 15%-20%。 Inverted list OptimizationSkip lists我们可以跳过一些文档来减少 I/O，减少计算。 Operators#NEAR,#WINDOW,#SYN,Boolean AND，skip lists 在这些 operator 中会非常有效。回顾 #NEAR 的算法，假设 query 是 #NEAR/3(a b)，包含 a 的第一个 docid 是 59356，包含 b 的第一个 docid 是 43，之前的做法是让 b 的 doc pointer 不断指向 next，直到 a,b 的pointer 指向同一篇文档，如果考虑 skip lists，就可以直接指向 a 的 docid，（调用 docIteratorAdvanceTo(doc_id_a)方法）。 Score calculation (Top-Docs)有些 inverted list 太长了，而大多 query 只需要返回 &lt;100 的文档，所以我们可以截取 inverted list 里 top docs 的部分，这样就能提高效率，代价是 更低的召回率。 怎么找到 Top-Docs tf PageRank 怎么对 Top-Docs 排序 Order by doc id Order by tf How many terms are frequent enough to have a top-docs list?根据 Zipf’s Law$$Rank * Frequency = A * N$$ 所以 ctf&gt;=800 的 term 大概占比 ${A*N/800 \\over A * N}=1/800=0.125%$ why 800?假设一个 inverted list 有5个 integer，没压缩就有 16 bytes，30%压缩比，压缩了有 5 bytes，linux filesystem page size是 4096 bytes, 所以有4096/5=819条 inverted list 能 fit in one page 假设 vocabulary 有 1,000,000 个 term，那么大概只有 1,250 个 top-docs lists，每个 list 大概 4-8KB，一共占 5-10 MB。 Multiple inverted lists per term有些 operator 并不需要 tf，像 unranked boolean operators， 有些 operator 并不需要 locations，像 #SUM,#WEIGHT,#AND,#OR,#ANDNOT,…，而 inverted lists with locations 会产生 I/O 浪费，对没有 location 的 inverted list，我们只用存 docid, tf 两个 integer，而对存了 location 的 inverted list,假定我们对每篇文档多用了 1.5 个 integer，那么我们其实浪费了 42% 的 I/O。 所以对于每个 term，我们可以存两份 inverted list，一份有 location，一份没有，对不需要 location 的 operator，我们就直接访问没有location 的 inverted list，这样就能避免不必要的 I/O，当然代价是额外的磁盘空间。 我们要对每个 term 都存两个 inverted list 吗？ 其实并不需要。因为大概只有 0.125% 对 term 有 topdocs/champion list，其它 term 对 inverted list 都很短。所以我们只用对 frequent terms 建两个 inverted list 就可以啦。 Index updatescorpus 并不是静态的，随着文档的增加，我们需要将新的 term 加入词典，对已有的 inverted list 进行更新，然而这个代价非常的大。最简单的索引更新方法是 周期性地对 corpus 进行索引重构，如果 corpus 更新次数不多，而且能接受新文档检索的一定延迟，也有足够资源支持建立新索引时让旧索引继续工作，那么周期性索引重构不失为一种好选择。 另外一种解决方法是保持两个索引：一个主索引，一个辅助索引，辅助索引用于存储新文档信息，保存在内存中，检索时可以同时遍历两个索引并将结果合并。如果有文档删除，可以把删除的 docid 记录在一个 delete list 里，在返回结果之前利用它过滤掉已经删除的文档。文档的更新通过先删除后重新插入实现。当辅助索引变得很大时，就将它合并到主索引中。 Storing document structureTreat each element as independent of other elements简单明了的结构，简单、高效，对 shallow structure 的 document 非常有效。 在这种结构下，我们分别保存每个 field 下的词汇，可以有一下两种形式 FIELD::TERM (FIELD,TERM) Treat elements as part of an element hierarchy$Document \\supset Section \\supset Subsection$ 非常灵活的结构，更好的符合用户需求，基本思想是 “Terms in “Subsection” should also appear in “Section”” 对 complex structure 非常有效。 Storing fields as trees 这种方式代价太高，I/O 和内存代价都很高。做个简单计算 120 bytes/node * 100 nodes/doc * 1,000,000 docs=2GB Storing fields as inverted lists多存一份 field 的 inverted list，包含 field 起始和终止位置。然后通过这个位置区间找到 term inverted list 中符合条件的 location。 Indri Index ComponentsStatistic files Term dictionaries Inverted files Compressed collection Lucene Index略 参考链接:Search Engines: 11-442 / 11-642本文图片来自书本 Introduction to Information Retrieval 和 Jamie Callen 的 slides。搜索引擎原理扫盲","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Pseudo Relevance Feedback","url":"/2016/10/10/Search Engines笔记 - Pseudo Relevance Feedback/","text":"CMU 11642 的课程笔记。怎样产生更好的 query 来得到更多的相关文档？从用户角度看，用户一开始会用 short query 来进行检索，在看到结果文档后通过增加或减少 term 以及调整 term weight 的方式进一步优化 query。而对系统而言，能自动产生更好的 query 的方式莫过于机器学习算法。 relevance feedback 其实是一个有监督的机器学习的问题，理想中我们要学习的是 f(document)–&gt;{relevant, not relevant}，然而一般我们学习的是 f(document)–&gt;score。训练集的大小一般来说 10-20 页是 good, 100-200 页就 great 了。 relevance feedback 并不经常被使用。一方面是因为用户不喜欢给评价(因训练数据会很少，准确度也不一定高)，另一方面是这种评价有风险，如果评估的文档很少，结果是 highly variable 的，stability 和 consistency 可能会受到影响。所以一般我们用的是 Pseudo-relevance feedback，一种无监督的机器学习方法。 Pseudo-relevance feedback基本逻辑是把原始查询当做分类起，用它来给部分数据打标签，得到 top-ranked documents，然后用 labeled data 来产生更优的 classifier。基本过程： 用原始 query 检索文档 取结果的前 N 篇文档作为训练集，这些文档相关度可能不高，然而我们的目的是学习 vocabulary pattern。 应用 relevance feedback algorithm 选取 term 和 term weight 组成新的 query 来检索文档 Okapi BM25过程： 用原始 query 检索文档 取前 N 篇文档的 term 作为 potential expansion terms 为每个 potential expansion term 计算分数 用前 m 个 term 创建新的 $query_{learned}$ 用新的 query 检索文档 Inference networks (Indri)过程： 用原始 query 检索文档 取前 N 篇文档的 term 作为 potential expansion terms 为每个 potential expansion term 计算分数 用前 m 个 term 创建新的 $Q_{learned}$ 合并 $Q_{original}$ 和 $Q_{learned}$ 创建 $Q_{expanded}$ 用新的 query 检索文档 对每个 expansion term，计算 p(t|I) 并没有对文档集合里的常见词做出惩罚，所以加上一个类似 idf 对 weight 最后的 expanded query 是$$Q_{expanded} ＝ \\#wand(wQ_{original}, (1-w)Q_{learned})$$ 需要的参数: fbdocs: number of judged documents fbterms: number of terms to add to the query, indri’s default is 10 $\\mu$: smoothing weight to use for new terms, indri’s default is 0 $w$: weight of the original query, indri’s default is 0.5 How many terms is enough标准答案来了: It depends! 因 query 而异。 Corpus其实原始查询和最终的查询语句可以在不同的语料上跑，比如说原始查询在 wikipedia 上跑，产生高质量的 expansion term，然后用扩充的 query 在 web 上跑，这能够显著提高 MAP 和 P@10。 直接上代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/** * @param score_list * @return * @throws IOException */private static String expandQuery(ScoreList score_list) throws IOException &#123; double fbMu = Double.parseDouble(parameters.get(&quot;fbMu&quot;)); int fbDocs = Integer.parseInt(parameters.get(&quot;fbDocs&quot;)); int fbTerms = Integer.parseInt(parameters.get(&quot;fbTerms&quot;)); int docNum = Math.min(fbDocs, score_list.size()); Map&lt;String, ArrayList&lt;Integer&gt;&gt; invertedList = new HashMap(); // map&lt;term, score&gt; Map&lt;String, Double&gt; termScore = new HashMap(); // get expanded term for (int i = 0; i &lt; docNum; i++) &#123; int doc_id = score_list.getDocid(i); TermVector vec = new TermVector(doc_id, &quot;body&quot;); // termVecMap.put(doc_id, vec); double docScore = score_list.getDocidScore(i); double docLen = Idx.getFieldLength(&quot;body&quot;, doc_id); // for each term for (int j = 1; j &lt; vec.stemsLength(); j++) &#123; String term = vec.stemString(j); // ignore any candidate expansion term that contains a period // (&apos;.&apos;) or a comma (&apos;,&apos;) if (term.contains(&quot;.&quot;) || term.contains(&quot;,&quot;)) &#123; continue; &#125; // update inverted list for current term if (invertedList.containsKey(term)) &#123; ArrayList&lt;Integer&gt; cur_inverted_list = invertedList.get(term); cur_inverted_list.add(doc_id); invertedList.put(term, cur_inverted_list); &#125; else &#123; ArrayList&lt;Integer&gt; cur_inverted_list = new ArrayList(); cur_inverted_list.add(doc_id); invertedList.put(term, cur_inverted_list); &#125; // score potential expansion term for current doc long tf = vec.stemFreq(j); long ctf = vec.totalStemFreq(j); double mle = ctf / (double) Idx.getSumOfFieldLengths(&quot;body&quot;); double Ptd = (tf + fbMu * mle) / (docLen + fbMu); double idf = Math.log(1 / mle); double cur_doc_score = Ptd * docScore * idf; if (termScore.containsKey(term)) &#123; termScore.put(term, termScore.get(term) + cur_doc_score); &#125; else &#123; termScore.put(term, cur_doc_score); &#125; &#125; &#125; // get top k terms PriorityQueue&lt;Map.Entry&lt;String, Double&gt;&gt; termScorePq = new PriorityQueue&lt;Map.Entry&lt;String, Double&gt;&gt;( termScore.size(), new Comparator&lt;Map.Entry&lt;String, Double&gt;&gt;() &#123; @Override public int compare(Map.Entry&lt;String, Double&gt; m1, Map.Entry&lt;String, Double&gt; m2) &#123; return m2.getValue().compareTo(m1.getValue()); &#125; &#125;); termScorePq.addAll(termScore.entrySet()); // get new query String learnedQuery = &quot;#wand ( &quot;; for (int i = 0; i &lt; fbTerms; i++) &#123; String score = String.format(&quot;%.4f&quot;, termScorePq.peek().getValue()); String term = termScorePq.peek().getKey(); learnedQuery = learnedQuery + &quot; &quot; + score + &quot; &quot; + term; termScorePq.poll(); &#125; learnedQuery += &quot; )&quot;; System.out.println(&quot;learnedQuery &quot; + learnedQuery); return learnedQuery;&#125; 处理 query file。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * Process the query file. * * @param queryFilePath * @param model * @throws Exception */static void processQueryFile(String queryFilePath, String trecEvalOutputPath, RetrievalModel model) throws Exception &#123; BufferedReader input = null; BufferedWriter output = null; BufferedWriter bw = null; try &#123; String qLine = null; input = new BufferedReader(new FileReader(queryFilePath)); output = new BufferedWriter(new FileWriter(trecEvalOutputPath)); bw = new BufferedWriter(new FileWriter(parameters.get(&quot;fbExpansionQueryFile&quot;))); // Each pass of the loop processes one query. while ((qLine = input.readLine()) != null) &#123; int d = qLine.indexOf(&apos;:&apos;); if (d &lt; 0) &#123; throw new IllegalArgumentException(&quot;Syntax error: Missing &apos;:&apos; in query line.&quot;); &#125; printMemoryUsage(false); String qid = qLine.substring(0, d); String query = qLine.substring(d + 1); System.out.println(&quot;Query &quot; + qLine); ScoreList r = null; String defaultOp = model.defaultQrySopName(); query = defaultOp + &quot;(&quot; + query + &quot;)&quot;; // if not expand query if (!(parameters.containsKey(&quot;fb&quot;) &amp;&amp; parameters.get(&quot;fb&quot;).equals(&quot;true&quot;))) &#123; r = processQuery(query, model); &#125; else &#123; // if expand query // check parameters if (!(parameters.containsKey(&quot;fbTerms&quot;) &amp;&amp; parameters.containsKey(&quot;fbMu&quot;) &amp;&amp; parameters.containsKey(&quot;fbOrigWeight&quot;) &amp;&amp; parameters.containsKey(&quot;fbExpansionQueryFile&quot;))) &#123; throw new IllegalArgumentException(&quot;Required parameters were missing from the parameter file.&quot;); &#125; // check if there&apos;s ranking file if (!parameters.containsKey(&quot;fbInitialRankingFile&quot;)) &#123; r = processQuery(query, model); r.sort(); &#125; else &#123; Map&lt;Integer, ScoreList&gt; score_list_map = readRankingFile( parameters.get(&quot;fbInitialRankingFile&quot;)); if (!score_list_map.containsKey(Integer.parseInt(qid))) &#123; throw new Exception(&quot;No query &quot; + qid + &quot; in ranking file!&quot;); &#125; r = score_list_map.get(Integer.parseInt(qid)); &#125;// r.sort(); String expandedQuery = expandQuery(r); printExpandedQuery(bw, qid, expandedQuery); double fbOrigWeight = Double.parseDouble(parameters.get(&quot;fbOrigWeight&quot;)); String newQuery = &quot;#wand (&quot; + String.valueOf(fbOrigWeight) + &quot; &quot; + query + &quot; &quot; + String.valueOf(1 - fbOrigWeight) + &quot; &quot; + expandedQuery + &quot; )&quot;; // System.out.println(&quot; new Query &quot; + newQuery); r = processQuery(newQuery, model); &#125; if (r != null) &#123; printResults(qid, r, output); &#125; &#125; &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; finally &#123; input.close(); output.close(); bw.close(); &#125;&#125; 如果有 initial ranking file。123456789101112131415161718192021222324252627282930313233/** * * @param fbInitialRankingFile * @return */private static Map&lt;Integer, ScoreList&gt; readRankingFile(String fbInitialRankingFile) &#123; // System.out.println(&quot;filename &quot;+fbInitialRankingFile); Map&lt;Integer, ScoreList&gt; scoreList_map = new HashMap&lt;&gt;(); try (BufferedReader br = new BufferedReader(new FileReader(fbInitialRankingFile))) &#123; String str; int last_qry = -1; ScoreList score_list = new ScoreList(); while ((str = br.readLine()) != null) &#123; String[] data = str.split(&quot; &quot;); int cur_qry = Integer.parseInt(data[0].trim()); if (last_qry == -1) &#123; last_qry = cur_qry; &#125; if (cur_qry != last_qry) &#123; scoreList_map.put(last_qry, score_list); last_qry = cur_qry; score_list = new ScoreList(); &#125; score_list.add(Idx.getInternalDocid(data[2].trim()), Double.parseDouble(data[4].trim())); &#125; // add the last query and scorelist scoreList_map.put(last_qry, score_list); &#125; catch (Exception e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return scoreList_map;&#125; Effectiveness Query expansion 平均能使 MAP 提高 20% 但同时也有可能让 1/3 的用户感到 annoy 所以通常来说，query expansion 会用在召回率很重要的场景，或者 average performance 很重要的场景，比如 legal retrieval, TREC, research paper 等。","tags":"nlp search-engines 信息检索"},{"title":"Hexo local search 错误解决","url":"/2016/10/07/Hexo local search错误解决/","text":"swiftype 适用期只有一个月，不要跟我说是高级用户一个月，就是一个月之后搜索就不能用了！！！转而回到 local search，就出现了之前没有出现的问题，好久才整出了办法，必须记录一下。 基本配置常用的是 local search。 安装 hexo-generator-search，在站点的根目录下执行以下命令： $ npm install hexo-generator-search --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post 问题1: ERROR Process failed: layout/.DS_Storehexo g 运行出现12ERROR Process failed: layout/.DS_StoreTypeError: Cannot read property &apos;compile&apos; of undefined 可能不影响大局，但还是会很不爽，解决办法不是简单粗暴的把 .DS_Store 删掉(command+delete)，这样是没用的，要在命令行里 rm -rf 删。查看隐藏文件的命令是 ls -al。 问题2: xmlParseEntityRef: no name在网站后输入/search.xml查看页面，出现 “error on line 7 at column 81: xmlParseEntityRef: no name” 错误。原因：标题中的 &amp; 会和 HTML tags 冲突！解决：把 &amp; 换掉啊换掉！","tags":"hexo"},{"title":"Search Engines笔记 - Information Needs","url":"/2016/10/02/Search Engines笔记 - Information Needs/","text":"CMU 11642 的课程笔记。这一篇概括了用户信息需求的分类、查询语句的结构以及查询的前期处理过程(非结构化的查询语句-&gt;结构化的查询语句)。 Query type Informational(39%)像 iphones 之类，用户想了解一个 topic。 Transactional(36%)像购物、买机票之类，用户想找个网站进行交易，但是并没有特定的 destination. Navigational(25%)像 CMU 网站之类的，用户有一个特定的想要浏览的 location/destination Query language一条标准的 query 分为 3 部分。 Source of information: fields, XML elements, metadata Query operators: AND, OR, NEAR/n, … Rules: 怎样使用这些 operators (顺序、权重等) 每一条 query 都会被转化成一个结构化的查询语句。 Query operators1234567Boolean operators: AND, OR, AND-NOTDistance operators: NEAR/n, WINDOW/n, SENTENCE/n, PARAGRAPH/nExtent(field) restrictions: BODY, TITLE, INLINK, ABSTRACT, AUTHOR,...Comparison operators: &lt;, &gt;, BEFORE, AFTER, ...Score operators: WEIGHT, AVERAGE, MAX, MIN, ...SynonymFilter-And-Rank(q1,q2): q1 forms a set, use q2 ranks it Query Processing查询处理，这里最常用的是 #NEAR 和 #SYNONYM，对于一些词组(phrases)，搜索引擎会用 #NEAR 进行规范化，如123die-cast -&gt; #NEAR/1 (die cast)virginia beach -&gt; #NEAR/1 (virginia beach)barack obama -&gt; #NEAR/3 (barack obama) 对于一些缩写，或者拼写错误，一般会用 #SYNONYM 进行调整，如123456# Abbreviationsvirginia -&gt; (virginia,va)# Spelliing correction:brittany -&gt; britneybrittany -&gt; #SYNONYM (brittany,britney) Query ReformulationSequential-Dependency Models(SDM) 会将非结构化的查询转化成结构化的查询语句，一个 SDM query 分为三部分: Bag of words matches作用是保证能找到东西。eg. #AND(q1,q2…qn) N-gram matches (ordered,phrase-like)给匹配的 n-gram 提供了额外的权重。eg. #NEAR/1(q1,q2) #NEAR/1(q2,q3)…#NEAR/1(qn-1,qn) Short window matches (unordered, sentence-like)给匹配的窗口提供了额外的权重。eg. #WINDOW/8(q1,q2)…#WINDOW/8(qn-1,qn) Eg.12345678User Query: sherwood regional libraryA sequential dependency model query: #wand( 0.5 #and( sherwood regional library ) 0.25 #and( #near/1( regional library ) #near/1( sherwood regional ) ) 0.25 #and( #window/8( regional library ) #window/8( sherwood regional ) ) ) Perl 代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#!/usr/bin/perl## Perl subroutine that generates Indri dependence model queries.## Written by: Don Metzler (metzler@cs.umass.edu)# Last update: 06/27/2005## Feel free to distribute, edit, modify, or mangle this code as you see fit. If you make any interesting# changes please email me a copy.## For more technical details, see:## * Metzler, D. and Croft, W.B., &quot;A Markov Random Field Model for Term Dependencies,&quot; ACM SIGIR 2005.## * Metzler, D., Strohman T., Turtle H., and Croft, W.B., &quot;Indri at TREC 2004: Terabyte Track&quot;, TREC 2004.## * http://ciir.cs.umass.edu/~metzler/## MODIFICATIONS# - Updated by Jamie Callan: 02/11/2015# Modified to support a less cryptic Indri-like query language.# #combine --&gt; #and, #1 --&gt; #near/1, #weight --&gt; #wand, and #uw --&gt; #window/## NOTES## * this script assumes that the query string has already been parsed and that all characters# that are not compatible with Indri&apos;s query language have been removed.## * it is not advisable to do a &apos;full dependence&apos; variant on long strings because of the exponential# number of terms that will result. it is suggested that the &apos;sequential dependence&apos; variant be# used for long strings. either that, or split up long strings into smaller cohesive chunks and# apply the &apos;full dependence&apos; variant to each of the chunks.## * the unordered features use a window size of 4 * number of terms within the phrase. this has been# found to work well across a wide range of collections and topics. however, this may need to be# modified on an individual basis.## example usageprint formulate_query( &quot;sherwood regional library&quot;, &quot;sd&quot;, 0.02, 0.49, 0.49 ) . &quot;\\n\\n&quot;;#print formulate_query( &quot;sherwood regional library&quot;, &quot;fd&quot;, 0.8, 0.1, 0.1 ) . &quot;\\n\\n&quot;;## formulates a query based on query text and feature weights## arguments:# * query - string containing original query terms separated by spaces# * type - string. &quot;sd&quot; for sequential dependence or &quot;fd&quot; for full dependence variant. defaults to &quot;fd&quot;.# * wt[0] - weight assigned to term features# * wt[1] - weight assigned to ordered (#near) features# * wt[2] - weight assigned to unordered (#window) features#sub formulate_query &#123; my ( $q, $type, @wt ) = @_; # trim whitespace from beginning and end of query string $q =~ s/^\\s+|\\s+$//g; my $queryT = &quot;#and( &quot;; my $queryO = &quot;#and(&quot;; my $queryU = &quot;#and(&quot;; # generate term features (f_T) my @terms = split(/\\s+/ , $q); my $term; foreach $term ( @terms ) &#123; $queryT .= &quot;$term &quot;; &#125; my $num_terms = @terms; # skip the rest of the processing if we&apos;re just # interested in term features or if we only have 1 term if( ( $wt[1] == 0.0 &amp;&amp; $wt[2] == 0.0 ) || $num_terms == 1 ) &#123; return $queryT . &quot;)&quot;; &#125; # generate the rest of the features my $start = 1; if( $type eq &quot;sd&quot; ) &#123; $start = 3; &#125; for( my $i = $start ; $i &lt; 2 ** $num_terms ; $i++ ) &#123; my $bin = unpack(&quot;B*&quot;, pack(&quot;N&quot;, $i)); # create binary representation of i my $num_extracted = 0; my $extracted_terms = &quot;&quot;; # get query terms corresponding to &apos;on&apos; bits for( my $j = 0 ; $j &lt; $num_terms ; $j++ ) &#123; my $bit = substr($bin, $j - $num_terms, 1); if( $bit eq &quot;1&quot; ) &#123; $extracted_terms .= &quot;$terms[$j] &quot;; $num_extracted++; &#125; &#125; if( $num_extracted == 1 ) &#123; next; &#125; # skip these, since we already took care of the term features... if( $bin =~ /^0+11+[^1]*$/ ) &#123; # words in contiguous phrase, ordered features (f_O) $queryO .= &quot; #near/1( $extracted_terms) &quot;; &#125; $queryU .= &quot; #window/&quot; . 4*$num_extracted . &quot;( $extracted_terms) &quot;; # every subset of terms, unordered features (f_U) if( $type eq &quot;sd&quot; ) &#123; $i *= 2; $i--; &#125; &#125; my $query = &quot;#wand(&quot;; if( $wt[0] != 0.0 &amp;&amp; $queryT ne &quot;#and( &quot; ) &#123; $query .= &quot; $wt[0] $queryT)&quot;; &#125; if( $wt[1] != 0.0 &amp;&amp; $queryO ne &quot;#and(&quot; ) &#123; $query .= &quot; $wt[1] $queryO)&quot;; &#125; if( $wt[2] != 0.0 &amp;&amp; $queryU ne &quot;#and(&quot; ) &#123; $query .= &quot; $wt[2] $queryU)&quot;; &#125; if( $query eq &quot;#wand(&quot; ) &#123; return &quot;&quot;; &#125; # return &quot;&quot; if we couldn&apos;t formulate anything return $query . &quot; )&quot;;&#125; 另外常用的模型还有 query expansion","tags":"nlp search-engines 信息检索"},{"title":"AES 和 RSA 笔记","url":"/2016/10/02/AES 和 RSA笔记/","text":"简单回顾 AES 和 RSA 算法。 Symmetric key 对称加密加密和解密均采用同一把密钥，而且通信双方都必须获得这把密钥。一方通过密钥将信息加密后，把密文传给另一方，另一方通过这个相同的密钥将密文解密，转换成可以理解的明文。常见的对称加密算法有DES、3DES、AES、Blowfish、IDEA、RC5、RC6、AES。 DES（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。 3DES（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。 AES（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高； 对称加密的最大优点是速度快，然而它也存在着诸多问题。 存在问题 要求提供一条安全的渠道使通讯双方在首次通讯时协商一个共同的密钥。直接的面对面协商可能是不现实而且难于实施的，所以双方可能需要借助于邮件和电话等其它相对不够安全的手段来进行协商； 密钥的数目难于管理。因为对于每一个合作者都需要使用不同的密钥，很难适应开放社会中大量的信息交流；而如果大家都使用同一个密钥，只要其中一个人密钥被盗窃了，那么整体加密的信息将都被破解了。 对称加密算法一般不能提供信息完整性的鉴别。它无法验证发送者和接受者的身份。 对称密钥的管理和分发工作是一件具有潜在危险的和烦琐的过程。对称加密是基于共同保守秘密来实现的，采用对称加密技术的贸易双方必须保证采用的是相同的密钥，保证彼此密钥的交换是安全可靠的，同时还要设定防止密钥泄密和更改密钥的程序。 AESAES加密过程涉及到4种操作：字节替代（SubBytes）、行移位（ShiftRows）、列混淆（MixColumns）和轮密钥加（AddRoundKey）。从上图可以看出：1）解密过程的每一步分别对应操作的逆操作，2）加解密所有操作的顺序正好是相反的。正是由于这两点保证了解密能够正确地恢复明文。加解密中每轮的密钥分别由初始密钥扩展得到。算法中16字节的明文、密文和轮密钥都以一个4x4的矩阵表示。 算法详解 Asymmetric key 非对称加密使用非对称加密算法，首先要有一对key，一个是private key私钥，另一个是public key公钥，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。可以把你的public key分发给想给你传密文的用户，然后用户使用该public key加密过的密文，只有使用你的 private key 才能解密，也就是说，只要你自己保存好你的 private key，就能确保，别人想给你发的密文不被破解，所以你不用担心别人的密钥被盗。 过程： 乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。 甲方获取乙方的公钥，然后用它对信息加密。 乙方得到加密后的信息，用私钥解密。 非对称加密算法对 symmetric key 进行了加密，保密性比较好，它消除了最终用户交换密钥的需要，而且能提供长期的 signatures。但加密和解密花费时间长、速度慢，在某些极端情况下，甚至能比非对称加密慢上1000倍。因此它不适合于对文件加密而只适用于对少量数据进行加密。 举个例子，如果企业中有n个用户，企业需要生成n对密钥，并分发n个公钥。由于公钥是可以公开的，用户只要保管好自己的私钥即可(企业分发后一般保存的是私钥,用户拿的是公钥)，因此加密密钥的分发将变得十分简单。同时，由于每个用户的私钥是唯一的，其他用户除了可以通过信息发送者的公钥来验证信息的来源是否真实，还可以确保发送者无法否认曾发送过该信息。 这种加密算法应用非常广泛，SSH, HTTPS, TLS，电子证书，电子签名，电子身份证等等。 RSA1977年，三位数学家Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做RSA算法。从那时直到现在，RSA算法一直是最广为使用的”非对称加密算法”。毫不夸张地说，只要有计算机网络的地方，就有RSA算法。这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长RSA密钥是768个二进制位。也就是说，长度超过768位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024位的RSA密钥基本安全，2048位的密钥极其安全。代码理解 RSA 算法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/* Demonstrate RSA in Java using BigIntegers */import java.math.BigInteger;import java.util.Random;/** * RSA Algorithm from CLR * * 1. Select at random two large prime numbers p and q. * 2. Compute n by the equation n = p * q. * 3. Compute phi(n)= (p - 1) * ( q - 1) * 4. Select a small odd integer e that is relatively prime to phi(n). * 5. Compute d as the multiplicative inverse of e modulo phi(n). A theorem in * number theory asserts that d exists and is uniquely defined. * 6. Publish the pair P = (e,n) as the RSA public key. * 7. Keep secret the pair S = (d,n) as the RSA secret key. * 8. To encrypt a message M compute C = M^e (mod n) * 9. To decrypt a message C compute M = C^d (mod n) */public class RSAExample &#123; public static void main(String[] args) &#123; // Each public and private key consists of an exponent and a modulus BigInteger n; // n is the modulus for both the private and public keys BigInteger e; // e is the exponent of the public key BigInteger d; // d is the exponent of the private key Random rnd = new Random(); // Step 1: Generate two large random primes. // We use 400 bits here, but best practice for security is 2048 bits. // Change 400 to 2048, recompile, and run the program again and you will // notice it takes much longer to do the math with that many bits. BigInteger p = new BigInteger(400,100,rnd); BigInteger q = new BigInteger(400,100,rnd); // Step 2: Compute n by the equation n = p * q. n = p.multiply(q); // Step 3: Compute phi(n) = (p-1) * (q-1) BigInteger phi = (p.subtract(BigInteger.ONE)).multiply(q.subtract(BigInteger.ONE)); // Step 4: Select a small odd integer e that is relatively prime to phi(n). // By convention the prime 65537 is used as the public exponent. e = new BigInteger (&quot;65537&quot;); // Step 5: Compute d as the multiplicative inverse of e modulo phi(n). d = e.modInverse(phi); System.out.println(&quot; e = &quot; + e); // Step 6: (e,n) is the RSA public key System.out.println(&quot; d = &quot; + d); // Step 7: (d,n) is the RSA private key System.out.println(&quot; n = &quot; + n); // Modulus for both keys // Encode a simple message. For example the letter &apos;A&apos; in UTF-8 is 65 BigInteger m = new BigInteger(&quot;65&quot;); // Step 8: To encrypt a message M compute C = M^e (mod n) BigInteger c = m.modPow(e, n); // Step 9: To decrypt a message C compute M = C^d (mod n) BigInteger clear = c.modPow(d, n); System.out.println(&quot;Cypher text = &quot; + c); System.out.println(&quot;Clear text = &quot; + clear); // Should be &quot;65&quot; // Step 8 (reprise) Encrypt the string &apos;Hello&apos; String s = &quot;RSA is way cool.&quot;; m = new BigInteger(s.getBytes()); // m is the original clear text c = m.modPow(e, n); // Do the encryption, c is the cypher text // Step 9 (reprise) Decrypt... clear = c.modPow(d, n); // Decrypt, clear is the resulting clear text String clearStr = new String(clear.toByteArray()); // Decode to a string System.out.println(&quot;Cypher text = &quot; + c); System.out.println(&quot;Clear text = &quot; + clearStr); &#125;&#125; 数学原理参见RSA算法原理（一）RSA算法原理（二）","tags":"加密"},{"title":"SHA-1和MD5 笔记","url":"/2016/10/01/SHA-1和MD5笔记/","text":"简单回顾 SHA-1 和 MD5 算法。 Hash 函数Hash 函数 H(M)， 作用于一任意长度的消息 M，返回一固定长度的散列值h:h=H(M)，作为初始消息的独一无二的“数字指纹”，从而能保证数据的完整性和惟一性。Hash算法是现代密码体系中的一个重要组成部分。由于非对称算法的运算速度较慢，所以在数字签名协议中，Hash 函数扮演了一个重要的角色。对 Hash 值，又称”数字摘要”进行数字签名，在统计上可以认为与对文件本身进行数字签名是等效的。hash函数并不完全可靠，不同文件产生相同 MD5 和 SHA1 的几率还是有的，只是不高。 通过 Hash 算法可实现数字签名实现，数字签名的原理是将要传送的明文通过一种函数运算（Hash）转换成报文摘要（不同的明文对应不同的报文摘要），报文摘要加密后与明文一起传送给接受方，接受方将接受的明文产生新的报文摘要与发送方的发来报文摘要解密比较，比较结果一致表示明文未被改动，如果不一致表示明文已被篡改。 Hash 函数的安全性在于其产生散列值的操作过程具有较强的单向性（不可逆性）。如果在输入序列中嵌入密码，那么任何人在不知道密码的情况下都不能产生正确的散列值，从而保证了其安全性。这符合了数字签名的特性，数字签名只能用非对称算法。 Hash 函数一般用于产生消息摘要，密钥加密等，常见的有： MD5（Message Digest Algorithm 5）：是RSA数据安全公司开发的一种单向散列算法。 SHA（Secure Hash Algorithm）：可以对任意长度的数据运算生成一个160位的数值； MD5MD5，一种不可逆的加密算法，目前是最牢靠的加密算法之一，尚没有能够逆运算的程序被开发出来，它对应任何字符串都可以加密成一段唯一的固定长度的代码。 MD5(RFC1321)是Rivest于1991年对MD4的改进版本。它对输入仍以 512 位分组，其输出是 4个32位字的级联，与 MD4 相同。MD5 比 MD4 来得复杂，并且速度较之要慢一点，但更安全，在抗分析和抗差分方面表现更好。 MD5 通常用于密码的加密存储，数字签名，文件完整性验证等。 Java 代码12345678910111213141516import java.security.NoSuchAlgorithmException;public static String computeHash(String input) &#123; byte[] hashed_str = null; String res = null; try &#123; java.security.MessageDigest alg = java.security.MessageDigest.getInstance(&quot;md5&quot;); alg.update(input.getBytes()); hashed_str = alg.digest(); res = javax.xml.bind.DatatypeConverter.printHexBinary(hashed_str); &#125; catch (NoSuchAlgorithmException ex) &#123; System.out.println(&quot;Exception: &quot; + ex); &#125; finally &#123; return res; &#125;&#125; SHA-1SHA-1，一种不可逆的、防冲突，并具有良好的雪崩效应的加密算法。该算法输入报文的最大长度不超过 2^64 位，产生的输出是一个 160 位的报文摘要。输入是按 512 位（64 字节）的分组进行处理的，并产生２０个字节的被称为信息认证代码或信息摘要的输出。 Java 代码12345678910111213141516import java.security.NoSuchAlgorithmException;public static String computeHash(String input) &#123; byte[] hashed_str = null; String res = null; try &#123; java.security.MessageDigest alg = java.security.MessageDigest.getInstance(&quot;SHA-1&quot;); alg.update(input.getBytes()); hashed_str = alg.digest(); res = javax.xml.bind.DatatypeConverter.printHexBinary(hashed_str); &#125; catch (NoSuchAlgorithmException ex) &#123; System.out.println(&quot;Exception: &quot; + ex); &#125; finally &#123; return res; &#125;&#125; SHA-1与MD5的比较因为二者均由MD4导出，SHA-1和MD5彼此很相似。相应的，他们的强度和其他特性也是相似，但还有以下几点不同： 强行攻击的安全性：SHA-1与MD5 的最大区别在于其摘要比MD5 摘要长 32 比特。对于强行攻击，产生任何一个报文使之摘要等于给定报文摘要的难度：MD5 是2128 数量级的操作，SHA-1 是2160 数量级的操作。因而,SHA-1 对强行攻击的强度更大。 速度：由于SHA-1 的循环步骤比MD5 多（80:64）且要处理的缓存大（160 比特:128 比特），SHA-1 的运行速度比MD5 慢。 最后上张比较图。 应用－网站用户名密码保存网站用户名密码的保存方式： 明文 hash 后保存，如 md5 MD5+Salt 方式,这个 salt 可以随机 网站用户名密码保存通常会用到 MD5 + Salt。salt 就是服务端在接收了客户输入的原字符串后再加一段自定义的字符串，然后对新产生的字符串一起进行加密，提高安全性。示例代码 参考链接数字签名算法MD5和SHA-1的比较","tags":"加密 hash"},{"title":"Search Engines笔记 - Best-Match","url":"/2016/09/30/Search Engines笔记 - Best-Match/","text":"CMU 11642 的课程笔记。Best match模型衡量的是一篇文档与 information need 的匹配程度，与 Exact match模型（匹配／不匹配）相比更注重用户体验，不管有没有匹配 Best match 都会返回文档结果。 这一篇考虑的是 query dependent 的分数，网页打分的依据是文档和查询的相关性分数，也就是信息检索得分(IR score)。有很多理论来计算 IR score，这里主要介绍以下 4 种理论： 向量空间 Vector space retrieval model(VSM) 概率理论 Probabilistic retrieval model(BM25) 统计语言模型 Statistical language model(query likelihood) 推理网络 Inference networks(Indri) 它们的公式其实都和 tf-idf 的公式相似。每个单词－文档组合都有一个tf-idf值。tf 表示此文档中这个单词出现的次数；df 表示含有这个单词的文档的数量。通常如果一个单词在文档中出现次数越多说明这个文档与这个单词相关性越大。但是有的单词太常用了，比如英文里“the”，“a” 在任何一个文档中都会大量出现。idf 就表示一个文档含有此单词的概率的倒数，用来消除常用词干扰。如果某个词或短语在一篇文章中出现的频率 TF 高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。 Document Priors 指与 query 无关的用来评估文档价值的 estimates(query independent)，主要的 document priors 有 spam score, PageRank, length of url 等，与上面的算法结合可以综合评估网页的分数。 VSM假设文档 d 对应的向量用 $\\overrightarrow {V}(d)$ 表示，每个维度对应一个 term，向量分量一般可以采用 tf-idf 权重计算方式。一组文档的集合看作向量空间的多个向量，每个 term 对应一个坐标轴，然后在向量空间下进行相似度计算。 思想文档与查询都是高维空间中的一个向量 文档是词语组成的向量 词语是文档组成的向量 查询是词语组成的向量 相似度计算相似度的计算方法。 Inner product Dice coefficient Jackard coefficient Cosine correlation 余弦相似度 (cosine similarity)直接向量差(overlap measures)衡量相似度会产生下面的问题， 并没有对向量长度进行归一化 所有的 term 都被看作是同等重要的 可能导致的结果是，两篇内容相似的文档向量的差向量可能很大，因为一篇文档可能比另一篇文档长很多。 最常用的 similarity metric 还是 cosine similarity. 关于 Vector Coefficient 我们需要考虑以下三点： Document term weight: 文档中每个 term 的重要性 ==&gt; tf -&gt; log(tf+1) Collection term weight: 文档集合中每个 term 的重要性 ==&gt; idf -&gt; $log{N \\over df}+1$ (avoid idf=0) Length normalization: 对文档长度进行的补偿 关于文档长度： 长文档由于更可能包含匹配词语，因而更可能相关 然而，如果两篇文档具有同样的相似值，用户更倾向于短文档，短文档更聚焦在用户信息需求上 因此相似性计算中应该考虑文档长度(进行规范化) 更进一步的 cosine-similarity，Inc.ltc 这个公式可以用作 #SUM 的计算，仅计算包含了查询词的文档的分数。 Length Bias大多数的 similarity metrics 都会有一个 length bias，就是说短文档的分数被高估了，长文档的分数被低估了， 所以我们需要 pivote document length normalization，可以采用 Lnu.Ltu metric. Lucene 应用Lucene 的检索过程： 使用布尔查询检索到一个文档集合 用 VSM 算法来对这个集合对文档进行排序 Simplified Lucene’s tf.idf Ranker 与 Inc.ltc 的不同 tf weight 用了 sqrt(tf) 而不是 log(tf)+1，stronger reward for frequent terms in document idf weight 用了 square 而不是 idf，stronger penalty for frequent terms across corpus 小结 Key idea: Measure similarity among weighted term vectors Vector Space Retrieval Model 没有告诉我们怎么 set term weights，没有告诉我们怎么确定 similarity，也没有告诉我们怎么支持 query-independent weights，它的优点是灵活，缺点也是灵活，所有的东西都要我们自己设置。 Okapi BM25BM25 十分重视 term frequency 和 document length，这里省略了公式推导过程，直接分析参数。 k1如果 k1 取 0，则对应 BIM 模型，document term frequency 完全没有影响，rare word (idf)和 repeated query terms(query tf) dominate；如果 k1 取较大值，对应使用原始的 term frequency。 bb (0&lt;=b&lt;1) 决定文档的缩放长度：b=1 表示基于文档长度对 term frequency 进行完全的缩放，b=0 表示归一化时不考虑文档长度因素，长文档更有可能排在前面。 k3如果查询很长，对于 query term 也可以采用类似的权重计算方法。对查询长度没有进行归一化（相当于b=0）。k3=0 表示 term frequency in query 并没有影响，(apple apple pie) 和 (apple pie) 完全一样。这一项通常是由用户确定的，对应的 operator 是 $WSUM 参数优化整个公式的参数可以通过在单独的开发测试集上搜索最优参数来最大化检索性能，如网格搜索方法（grid search）。现有的试验中，参数的合理取值范围是 k1,k3 取 1.2~2，b 取 0.75。 除了对用户查询提供 term frequency 计算方法外，在相关反馈中还可以考虑查询扩展，在已知的相关文档利用公式对 term 进行排序，并选取最靠前的多个 term 构成新的查询，再进行计算。 RSJ weightRSJ weight 和 idf 相似，都 favor rare words in corpus，因为 rare words 能更好的区分相关文档与不相关文档。RSJ 也有不足的地方。如果 df=N/2，那么 RSJ weight 就会变成 log(1)=0，匹配一个 term 对文档分数没有任何影响。如果 df&gt;N/2，RSJ weight=log(fraction)&lt;0，匹配一个经常出现的 term 会降低文档分数。 通常的解决方案是，把 RSJ weight 设置成 $Max(0，log{N-df+0.5 \\over df+0.5})$。如果我们用 idf 公式代替 RSJ weight，那么对 frequent words 的惩罚就会减小，尤其是对那些出现了 N/2 的词。 最近，Lucene 转变了 ranking 算法，变成了 BM25 Ranker Summary优点： 有很强的概率理论支持 在新的环境中参数可以被调整 在大量的 evalution 中都非常有效 缺点： 经验调整参数 Query Likelihood假定四个变量 d: document $\\theta_d$: language model for document d q: query $\\theta_q$: language model for query q q 和 $\\theta_q$，d 和 $\\theta_d$ 不是同一个东西，然而为了方便表示，我们就用 q 直接表示，p(d|q) 代替 p(d|$\\theta_q$) 我们生成两个模型，一个是 document 的语言模型，一个是 query 的语言模型，有两种方案来对文档进行排序 Rank d by $p(d|\\theta_q)$ (query likelihood) Rank d by similarity of $\\theta_d$ and $\\theta_q$ (KL divergence) Rank by P(d|q)给定一个 query，出现文档 d 的概率，query 一般很短，$\\theta_q$ 非常的稀疏，它包含了很少的 term frequency 信息，所以我们用 Bayes rule 来转换它。 $p(d|q)={p(q|d)p(d) \\over p(q)}$–&gt; 丢掉 document-independent term$p(q|d)p(d)$–&gt; 丢掉 constant term$p(q|d)$–&gt;$\\prod p(q_i|d)$ 于是问题就变成了怎么估计 $p(q_i|d)$ $p(q_i|d)$我们用最大似然 (Maximum likelihood estimation MLE)。$$P_{MLE}(q_i|d)={tf_{q_i,d} \\over length(d)}$$ 是一个好的估计吗？首先它基于一篇文档，所以结果可能没那么准确，如果 document 里没有出现 $q_i$，那么结果就是 0，这相当于一个 boolean AND，所以 $q_i$ 是对 document 的一个不错的描述，即使它不在 document 中。 所以我们要用 smoothing，来提高 MLE 的准确性，同时来预测没有出现过的词。 SmoothingJelinek-Mercer(“Mixture Model”) Smoothing$$p(q_i|d)=(1-\\lambda)p_{MLE}(q_i|d)+ \\lambda p_{MLE}(q_i|C)$$ C 代表整个 collection，$\\lambda$ 越小，smoothing 的作用越小，越适合短 query，$\\lambda$ 越大，smoothing 的作用越大，越适合长 query。为什么？对短文档而言，通常每一个 query term 都要匹配，所以 idf weighting 并没有那么重要，越小的 smoothing 越好，而对于长 query 而言，大部分 query term 必须匹配，而另一部分可以不 match，所以 idf weighting 会更重要，就可以多 smoothing 一点。 Jelinek-Mercer smoothing 的作用与 idf 类似，它能够区分文档集合里常见的和不常见的 term 。 看一个具体例子，有两个 query term，一个 frequent 一个 rare。 p(apple|C)=0.01, p(ipod|C)=0.001 两篇文档 doc1: doclen=50,$tf\\_{apple}=2$,$tf\\_{ipod}=3$ doc2: doclen=50,$tf\\_{apple}=3$,$tf\\_{ipod}=2$ 没有 smoothing 前，两篇文档的 p(q|d)都是 0.0024 2/50 ＊ 3/50=0.0024 3/50 ＊ 2/50=0.0024 JM Smooth 后，假设 $\\lambda=0.4$ doc1: p(q|d)=(0.6* 2/50 + 0.4*0.01) * (0.6 * 3/50 + 0.4*0.001)=0.001019 doc2: p(q|d)=(0.6* 3/50 + 0.4*0.01) * (0.6 * 2/50 + 0.4*0.001)=0.000976 这就发现，smooth 能够区分文档集合里常见的和不常见的 term。我们也可以计算 doclen=50,$tf_{apple}=2$,$tf_{ipod}=2$ 的情况，看多加入一个 apple 或 ipod 后 p(q|d) 发生了什么，同样的，unsmoothed effect 对常见的和不常见的 term 并没有差别，但是 smooth 带来了显著差异。 最后上张推导图 Bayesian Smoothing With Dirichlet Priors$$p(q_i|d)={tf_{q_i,d}+ \\mu p_{MLE}(q_i|C) \\over length(d)+ \\mu }$$ $\\mu$ 在 [1000-10000] 区间内比较好Bayesian smoothing 是对文档长度的平滑，对短文档而言，$p(q_i|d)$ 的概率分布更不平滑，需要更大的 $\\mu $，对长文档而言，概率分布更平滑，需要更小的 $\\mu$. Two-Stage Smoothing可以结合以上两种平滑方式，得到$$p(q_i|d)=(1- \\lambda ){tf_{q_i,d}+ \\mu p_{MLE}(q_i|C) \\over length(d)+ \\mu }+ \\lambda p_{MLE}(q_i|C)$$ Rank by similarityKL DivergenceKullback-Leibler 距离，也叫相对熵（Relative Entropy）。计算公式如下：$$KL(p||q)=\\sum p(x)log{p(x) \\over q(x)}$$ KL 距离不是对称的, KL(p||q)!=KL(q||p)，我们要计算的是 KL(q||d)，query 和 document 的相对熵，推导公式如下。 Comparsion两种方式其实是一样的，仔细看公式！Query likelihood ranks by$$p(q|d)=\\prod p(q_i|d)$$ KL diverge ranks by$$\\sum p(x)log{p(x) \\over q(x)}$$ Inference networks(Indri) document + smoothing parameter($\\alpha$ $\\beta$) -&gt; language model($\\theta$) -&gt; language model vocabulary(r) information needs(I)由 query(q) 表示，query 由 operator(c) 组成. 在 Indri 中，#AND 认为所有的 argument 都是独立概率， #WSUM 认为所有的 argument 都用来估计同一个概率。在实现 Indri 的 ranking algorithm 时，要注意的是我们必须实现一个 getDefaultScore，来处理 tf=0 的情况，以保证用户总能得到搜索结果。 Document PriorsDocument Priors 指与 query 无关的用来评估文档价值的 estimates (query-independent estimates of the value of each document)，一般是根据文档本身的性质来决定的，主要的 document priors 有 spam score, PageRank, length of url 等。在 BM25，query likelihood 和 KL divergence 中的使用。Indri 中，prior 在 Query likelihood 中的表示为 #and(#prior(url) a b c)，在 KL divergence 中的表示为 #and(#prior(url) #and(a b c))","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Document Representations","url":"/2016/09/25/Search Engines笔记 - Document Representation/","text":"CMU 11642 的课程笔记。这一篇讲两种 document representation 方法，Controlled vocabulary index terms vs Free-text or full-text index terms Overview Controlled vocabulary index terms从一个 well-defined classification scheme 中挑取 term，比较有名的开放分类目录有 dmoz。 Structurebroad vocabularies 来描述概括性的 topic; detailed vocabularies 来描述更加细节的 topic。一个 well-defined classification scheme 主要有以下构成： 用于识别文档主题的一组规则 指定的词库 一组索引的术语(term) 用于分配索引项的一组规则 Advantages and Disadvantages优点： 高的召回率 支持浏览和搜索 在一些领域非常流行（如医学，法律，专利等） 缺点： coverage vs detail tradeoff 人工创建和维护的成本很高 人们难以一致地分配文件 检索受限制 Free-text or full-text index terms从原文档或者相关文档中挑取 term。Free-text or full-text indexing 用的是 uncontrolled vocabulary。Free-text 和 full-text indexing 的区别在于前者只用了部分的 term 作为 index，而后者用了几乎所有的 term 来作为 index。 How to select terms? selected terms 人工选择 all terms 就不用考虑选择的问题 Advantages and Disadvantages优点： 索引词汇保证与文档的内容有很好的匹配 无需学习（可能会很复杂的）受控词表 可能比控制词汇更容易自动化 缺点： 更可能会导致词汇比匹配比如文档里有 automobile，query 说是 car，就不能 match Process Search engine uses shallow language analysis and heuristics to convert lexical tokens (usually words) into index terms (features) Heuristic methods: map tokens to indexing terms Stopwords一些 stopwords 如 the, a 并没有实际意义，删除 stopwords 可以减小 index size，提高准确性和效率，然而也会带来一些问题，如无法处理一些 query(eg. To be or not to be, let it be)。解决方案是我们把 index 的 stopwords 存下来，在处理 query 的时候去掉 query 里的 stopwords，如果 stopwords 在 query terms 里占比很高，或者用户明确要求留下 stopwords (eg. +the last)，就把 stopwords 留下。 优点： 丢掉不具有内容信息的词 大幅减少索引大小，减少检索时间 提高准确性 缺点： 难以满足某些特殊的 query (eg. To be or not to be, let it be) 创建 stopword list通过 frequency analysis 和 manual review 来完成。 基于频率对字典进行排序 检查最常用的 term 检查查询日志，查看哪些频繁的 term 可能很重要 Normalization通常我们需要对 token 进行规范化，比如大小写转换，以便下一步处理。 优点: 提高召回率，匹配更多查询 缺点： 如 Apple 可以用作公司名称，而 apple 将被视为一种水果。 Morphological analysis其实是一种映射。Map a token to another token (“stemming”,”conflation”) eg. images -&gt; image常用的 stemming algorithms 有 Porter, KSTEM 等，一般来说，Porter 和 KSTEM 能产生的差不多准确的 search results。Porter 更加的 aggressive，可能会出现一些不是词的词，而 KSTEM 更加的保守，很少会产生 smaller conflation classes，更加像”词”。对于 企业检索 而言，corpus 相对较小，recall 通常很重要，所以用户为了得到更多的相关文档，对 stemming mistakes 容忍度较高。而对于 网页检索 而言，corpus 很大，recall 并没有那么重要，precision 更重要，所以对 stemming/lemmatization mistakes 容忍度更低，所以并不使用。Google 之前是不做 stemming 的，现在似乎开始做了。 这些技术都是因语言而异的，不同的语言有不同的语法规则，不能一概而论。 优点: Conflating variations of a word 更准确地表示文档 匹配更广泛的查询 缺点： 效果不一致，Stemming 的结果可能不是词语 term 可能被错误地分组，不相关的词可能具有相同的 stem（例如，Apple,apple） 复杂的 morphological analysis 可能非常缓慢 Phrases对 phrase 的处理，一般有两种方案。 一种是 precoordinate(one inverted list)，把词组存为 index，比如 interest rate，inverted list 存成 interest_rate，在用户查询时 interest rate 时，替换成 interested_rate 进行 match。这种做法耗费了很多空间，怎样选择要存储的词组也是个问题，事实上可能会存很多永远不会被查询的词组。 另一种是 postcoordinate(more than one inverted lists)，对 query 进行 reformulation, 如 interest rate 变成 #NEAR/1(interest rate)，然后进行 match。这种方法查询时会有些慢，然而不必纠结于词组的选择。 De-compoundingcomputer-virus -&gt; computer,virus 优点 更准确地表示文档 匹配更广泛的查询 缺点 N-grams 像 “roe v. wade” 会变得没有意义 其它Basic lexical processing tokens stopwords morphologial processing (“stemming”) Other representations phrases, citations and inlink text, paths and urls Multiple representations","tags":"nlp search-engines 信息检索"},{"title":"Search Engines笔记 - Evaluating Search Effectiveness","url":"/2016/09/20/Search Engines笔记 - Evaluating Search Effectiveness/","text":"CMU 11642 的课程笔记。怎样评估 search engine 的效果？ Cranfield Methodology 获得 文档(documents) 集合 获得 信息需求(information needs) 集合 获得 相关性判断(relevance judgments) 计算(Measure) 各种方法找到相关文档的效果 比较(Compare) 各个方法的 effectiveness 所以有五个部分： 文档(documents) 信息需求(information needs) 相关性判断(relevance judgments) 指标(metrics) 对比(comparison of methods) 我们逐一来讨论 Test collectionsdocuments, information needs, relevance judgements 三部分合起来称为一个 test collection。常用的 test collections 有 这些 test collections 都非常实用，然而都有各自的 bias。 Information Needs一般来说，一个 test collection 有 50-200 个 information needs。information need 通常由 query 来体现，当然，也可以通过 search engines 中获得的 user behavior, user history, population behavior 来体现。那么，怎样获得 information needs 呢？ 通常有三种办法。 Ask 向用户询问他们要找什么，这当然是最优的方法。 Observe 通过 search log，根据 query, clicks 等来观察用户需要什么，然后根据观察结果来还原 information needs。 Guess 根据文档来猜这些文档能满足什么样的 information needs，这是 weakest option，但往往也是唯一的选择。 Relevance Assessment人为判断，通常是主观的。用不同的 techniques 检索出文档，然后人为判断每一种 technique 下的 top n 的文档，relevant set 就是这些判断为相关的文档的集合。 MetricsUnranked Boolean Retrieval ModelP,R,P@n,F1 都是 set-based measures。适合 unranked boolean retrieval model，适合文本分类，然而对 ranked retrieval model 没那么适用。 Precision and Recall$$Precision = {|Relevant \\cap Retrieved| \\over |Retrieved|} $$$$Recall = {|Relevant \\cap Retrieved| \\over |Relevant|}$$ Precision-recall curve 呈现明显的锯齿形状，因为如果返回的第 k+1 篇文档不相关，那么在 k+1 篇文档位置上的 recall 和前 k 篇文档位置上的 recall 一样，但是 precision 显然下降。反之，如果返回的第 k+1 篇文档相关，那么 recall 和 precision 都会增大，这时候曲线会呈锯齿形上升。将这些细微的变化去掉通常采用差值 理论上来讲，整个文档集都会被 rank，然后对整个文档集来计算 P&amp;R，然而这是没有必要的，所以引入了 P@n 和 MAP(Mean average precision)。 P@n非常好理解，排名前 n 的文档的 precision。如 P@5,P@10。带来的问题是并没有对 query 的难度进行 normalize。简单的 query 可能会有更多的相关文档，难的 query 能得到的相关文档更少。所以 P@n 的 stability 不如 MAP. F-Measure对 precision 和 recall 进行 weight$$F = {1 \\over \\alpha {1 \\over P} + (1- \\alpha) {1 \\over R}}$$如果 precision 和 recall 的权重相同，那就是 $F={2PR \\over P+R}$ Average ResultsMicro average across documents每篇文档的重要性相同，具有许多相关文档的查询占主导地位，machine learning 常用， IR 不常用，因为 class distribution 更加的 skewed。 Macro average across queries每个 query 的重要性相同，ad-hoc retrieval 最常用的 averaging method。 Ranked Retrieval Average Precision (AP) Mean Average Precision (MAP) Interpolated Average Precision AP and MAPMAP 是 single-value。AP 对单个需求，求返回结果中每篇相关文档位置上的 precision 的平均值。相当于某个 query 下对应的多条 precision-recall curve 下面积的平均值。对所有需求平均就能得到 MAP。MAP 可以在每个 recall 水平上提供单指标结果，具有非常好的 discrimination 和 stability。MAP 不需要选择固定的 recall 水平，也不需要插值，即使有些 query 的相关文档数很多而有些很少，最终的 MAP 显示每个 query 的作用却是相等的。单个系统在不同 information needs 的 MAP值相差较大（0.1-0.7），不同系统在同一 information need 上的 MAP 差异反而相对要小一些。 一道题解决。123AP1=(1+1+0.75+0.67)/4=0.855AP2=(1+0.84+0.5)/5=0.468MAP=(0.468+0.855)/2=0.6615 看一下 AP 和 MAP 的分布。 MAP 用的非常多，一方面是因为它能很好的体现系统的优劣，一般来说，如果 MAP(A)&gt;MAP(B)，那么 A 系统更有可能比 B 系统好，像 P@n 等其它 metrics 就不能如此肯定。另外，MAP 计算很快，和 NDCG 相比。 MRR (Mean Reciprocal Rank)有时候我们更关心第一篇相关文档。而排名较低的文档通常不会被浏览到。Reciprocal rank 指的是 1/rank of first relevant document。所以 MRR 就是对所有需求的 RR 值求平均。 适用场景举例：某个学生想找 cmu 11642 的课程主页。 NDCG (Normalized Discounted Cumulative Gain)Web search engines 中常用的方法。multi-valued relevance assessment，评估 ranking 的质量。$$NDCG@k = Z_k \\sum_{i=1}^k{2^{R_i}-1 \\over log(1+i)}$$ $R_i$ 指排名在 i 的相关文档的 relevance 分数 $Z_k$ normalize，所以 NDCG@k=1 时是一个 perfect ranking。$Z_k$ = 1/DCG@k for the “ideal” ranking 适用场景：可能有多个相关文档，且用户浏览文档的概率取决于页面的排名。eg. 顾客想要在网上买一台电脑，需要比较不同的型号、外观、价钱、排名。 RBP (Rank-Biased Precision)非常简单的 model，对用户行为进行建模。multi-valued relevance assessments，用 user’s persistence 来评估 rank 质量。$$RBP = (1-p) \\sum_{i=1}^n R_ip^{i-1}$$ p: user’s persistence n: 文档数量 Ri: 第 i 篇文档的排名 trec-evalad-hoc retrieval 的标准的评估工具。格式 Create test collections 收集大量的代表性文档(representative documents) 收集代表性信息需求(representative information needs)，至少 25 条， 最好 50-100 条 把信息需求转换成 query 集合，一个信息需求至少要有两三个 query 在每个搜索引擎上运行 query，保存 top N 的文档，至少每个查询 50 篇文档 合并同一个信息需求的所有 query 在不同搜索引擎上的结果并随机排序 雇佣人员来判断文档相关性，保证一条信息需求下的所有文档必须由同一个人来判断。 Evaluation in a Dynamic EnvironmentInterleaved testing Input: 两个 rankings，分别由不同方法产生 Output: 一个 ranking，由不同方法的所有 document 产生，一个好的 output 不会偏好任何一个方法。 Requirements: 用户不会注意到这一过程 对用户偏见不敏感 需要有反映用户偏好的用户行为 不应该改变用户的搜索体验 Procedure:One trial 用户提交 query 搜索引擎选择两种排序方法(“A” and “B”)，每种方法产生一个 document ranking 交替选择两种 document rankings 追踪 interleaved document ranking 的 click 情况 当用户停止点击的时候，根据被点击的文档给 “A” and “B” 两种方法分配 credit，确定在这一次 trial 中获胜的方法。 Repeat until enough trials are collected Balanced interleavingAssume that people read from top to bottom假设: 用户从上往下浏览文档 用户会点击看起来合适的文档 当用户觉得已经满意了或者是失望了时，他们会停止浏览 每种方法(“A” and “B”)呈现文档的概率是相同的 用户(random clicker)点击的文档来自 “A” 或者 “B”的概率都是 50% 算法： 算法非常简单。首先决定从哪个方法开始，然后交替把文档加入 interleaved ranking，如果遇到了已经评估过的文档，就直接 counter++，但是不把文档加进 interleaved ranking 里。 这样我们就得到了一个 ranking，然后我们还有一组数据是用户 click 的顺序。123456789I Ci1 i2 c1i3i4i5 c2i6i7i8 c_max $a_1,…,a_k$ 的集合与 $b_1,…b_k$ 的集合的并集包含了所有在 $i_1,…,i_{c_{max}}$ 中的文档，然后我们可以计算在 a’s top k 的点击数和 b’s top k 的点击数，得到最多 clicks 的方法获胜。$$\\Delta(A,B) = {wins(A)+0.5*ties(A,B) \\over wins(A)+wins(B)+ties(A,B)}$$ E.g., 然而 Balanced-Interleaving 也可能带来意想不到的结果，如下图，假设用户随机点击了一个 result，那么有 3/4 的结果都是对 B 有利的，为什么？因为 3/4 的文档在 B 里的 ranking 都比 A 高！ Team-draft interleaving算法： 每一轮都随机产生先取哪种方法，如果有重复，跳过，取下一个。 之后的步骤与 Balanced-Interleaving 相同。Team-draft 也可能产生难以预料的结果，如下图。 Metrics Abandonment rate: % of queries that receive no clicks Reformulation rate: % of queries that are reformulated Queries per session: Session == Information need Clicks per query, Clicks@1 pSAT-clicks: % of documents with dwell time &gt; 30 seconds pSkip: % of documents that are skipped Max Reciprocal Rank, Mean Reciprocal Rank Time to First Click, Time to Last Click Cranfield vs. Interleaving一般来说，我们更多的会使用 Cranfield，因为 Cranfield 更成熟，已经使用了很多年而且易于理解 Cranfield 支持大量的 metrics，能提供更多关于 ranking behavior 的信息 Cranfield 几乎在所有场景下都使用，而 Interleaving 需要有 query traffic 尽管如此，interleaving 仍然是一个很有用的工具，在下面的条件下可以使用。 Inexpensive, adaptive, sensitive to small differences","tags":"nlp search-engines 信息检索"},{"title":"数据结构和算法 -- 搜索","url":"/2016/09/20/数据结构和算法 -- 搜索/","text":"两种搜索方式，对 unordered array 用 linear search，对 ordered array 用 binary search。 二分查找 (Binary search)概念对于已排序的有序线性容器而言(比如数组，vector)，二分查找(Binary search)几乎总是最优的搜索方案。二分查找将容器等分为两部分，再根据中间节点与待搜索数据的相对大小关系，进一步搜索其中某一部分。二分查找的算法复杂度为O(logn)。对于局部有序的数据，也可以根据其局部有序的特性，尽可能地利用逼近、剪枝，使用二分查找的变种进行搜索。 二分寻找要注意的问题是： Which way should middle pointer go next Avoid infinite loop in the code 算法 Compare the number in the middle of the array with x. If it is equal, we are done. If the number is greater, we know to look in the second half of the array. If it is smaller, we know to look in the first half. We can repeat the search on the appropriate half of the array by comparing the middle element of that array with x, once again narrowing our search by a factor of 2. We repeat this process until we find x. This algorithm takes O(log n) time. ComplexityTime complexity: O(logN)Worst case: O(logN+1) -&gt; O(logN) 模板Recursive12345678910def binarySearch(data, start, end, key): if start &gt; end: return -1 mid = start + (end - start) / 2 if data[mid] == key: return mid if data[mid] &lt; key: return binarySearch(data, mid + 1, end, key) else: return binarySearch(data, start, mid - 1, key) Non-recursive12345678910111213def binarySearch(data, key): start = 0 end = len(data) - 1 while True: if start &gt; end: return -1 mid = start + (end - start) / 2 if data[mid] == key: return mid if data[mid] &lt; key: start = mid + 1 else: end = mid - 1 Find closest value123456789def binarySearch(house, heaters): left, right = 0, len(heaters) while left &lt; right: mid = left + (right - left) / 2 if heaters[mid] &lt; house: left = mid + 1 else: right = mid return left 例题69. Sqrt(x)ProblemImplement int sqrt(int x).Compute and return the square root of x. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&apos;&apos;&apos;Search n from 0 to x, every time increment 1, maintain a global varible pre to record the last n whose square is smaller than x, for each n, check if n*n&gt;x, if so, return pre. Takes O(n) time.Followup: Use binary search to find correct n. Takes O(logn) time.About overflow: use mid=start+(end-start)/2 mid * mid will overflow when mid &gt; sqrt(INT_MAX)&apos;&apos;&apos;class Solution(object): &apos;&apos;&apos; O(n) def mySqrt(self, x): &quot;&quot;&quot; :type x: int :rtype: int &quot;&quot;&quot; if x&lt;2: return x pre=0 for n in range(2,x): if n*n==x: return n if n*n&lt;x: pre=n else: return pre &apos;&apos;&apos; &apos;&apos;&apos; binary search O(logn) &apos;&apos;&apos; def mySqrt(self, x): &quot;&quot;&quot; :type x: int :rtype: int &quot;&quot;&quot; if not x or x &lt; 2: return x start = 0 end = x while start &lt;= end: mid = start + (end - start) / 2 if mid &lt;= x / mid and x / (mid + 1) &lt; mid + 1: return mid elif mid * mid &lt; x: start = mid + 1 else: end = mid - 1 &apos;&apos;&apos; Integer Newton def mySqrt(self, x): &quot;&quot;&quot; :type x: int :rtype: int &quot;&quot;&quot; if x&lt;2: return x r = x while r &gt; x/r: r = (r + x/r) / 2 return r &apos;&apos;&apos; Find first bad version You are a product manager and currently leading a team to develop a new product. Unfortunately, the latest version of your product fails the quality check. Since each version is developed based on the previous version, all the versions after a bad version are also bad.Suppose you have n versions [1, 2, …, n] and you want to find out the first bad one, which causes all the following ones to be bad.You are given an API bool isBadVersion(version) which will return whether version is bad. Implement a function to find the first bad version. You should minimize the number of calls to the API. 12345678910111213141516171819202122# The isBadVersion API is already defined for you.# @param version, an integer# @return a bool# def isBadVersion(version):class Solution(object): def firstBadVersion(self, n): &quot;&quot;&quot; :type n: int :rtype: int &quot;&quot;&quot; if n==0: return 0 start = 0 end = n while start &lt; end-1: mid = start + (start - end)/2 if isBadVersion(mid): end = mid else: start = mid return start if isBadVersion(start) else end Search a 2D Matrix Write an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:Integers in each row are sorted from left to right.The first integer of each row is greater than the last integer of the previous row.For example,Consider the following matrix:[ [1, 3, 5, 7], [10, 11, 16, 20], [23, 30, 34, 50]]Given target = 3, return true. 把这个 2D 数组拉平成 1D 就是一个单调递增的(sorted)的数组，这种情况下找一个数用 binary search 就好，时间复杂度是 O(log(mn))=O(logN)，要注意的就是 index 之间怎么转换，观察发现：2D -&gt; 1D (i,j) -&gt; i*n+j1D -&gt; 2D index -&gt; (index/n,index%n)123456789101112131415161718192021222324class Solution(object): def searchMatrix(self, matrix, target): &quot;&quot;&quot; :type matrix: List[List[int]] :type target: int :rtype: bool &quot;&quot;&quot; if not matrix: return False m = len(matrix) # row n = len(matrix[0]) # column start = 0 end = m*n-1 while start &lt;= end: mid = start + (start - end) / 2 if matrix[mid/n][mid%n] == target: return True if matrix[mid/n][mid%n] &gt; target: end = mid-1 else: start = mid+1 return False Search a 2D Matrix II问题再变难一点。 Search a 2D Matrix II QuestionEditorial Solution My SubmissionsTotal Accepted: 50080Total Submissions: 136871Difficulty: MediumWrite an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:Integers in each row are sorted in ascending from left to right.Integers in each column are sorted in ascending from top to bottom.For example,Consider the following matrix:[ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30]]Given target = 5, return true.Given target = 20, return false. 当然还是可以用 binary search 做，需要非常仔细。时间复杂度 max(O(mlogn,nlogm)),由 T(n)=2T(n/2)+cn 推导而来12345678910111213141516171819202122232425class Solution(object): def searchMatrix(self, matrix, target): &quot;&quot;&quot; :type matrix: List[List[int]] :type target: int :rtype: bool &quot;&quot;&quot; if not matrix: return False return self.helper(matrix,target,0,0,len(matrix)-1,len(matrix[0])-1) def helper(self,matrix,target,startX,startY,endX,endY): if startX&gt;endX or startY&gt;endY: return False midX=startX+(startX-endX)/2 midY=startY+(startX-endY)/2 mid = matrix[midX][midY] if mid == target: return True if mid &gt; target: return self.helper(matrix,target,startX,midY,midX-1,endY) or self.helper(matrix,target,startX,startY,endX,midY-1) else: return self.helper(matrix,target,midX+1,startY,endX,midY) or self.helper(matrix,target,startX,midY+1,endX,endY) return False 或者，不用 binary search，用比较通用的方法，很好理解，从 top rightmost 开始，比较与 target 的大小，if curr&gt;target，往左，if curr","tags":"搜索"},{"title":"数据结构和算法 -- 数组","url":"/2016/09/19/数据结构和算法 -- 数组/","text":"策略 &amp; 注意点array 在内存里是连续存储的，意味着 immutable length 和 no holes allowed。带来的优点是支持随机访问，缺点是当 resize array 的时候需要 copy 原有的所有元素，当删除一个不在末尾的元素时，又要 shift 很多元素。 数组最需要注意的： length 问题，最后一个数 array[len(array)-1] 指针问题，deepcopy or shallowcopy，对原数组进行多次变形并需纪录每次结果时，要注意 deepcopy 而不是存指针。res.append(list(nums))，如 permutation 这种题。 可以用虚拟边界 利用 array 的 index 可以做很多事情（利用 nums[i] 和 nums[nums[i]]）。如 Find the Duplicate Number，把 array 变成 linkedlist，或者 EfficiencyInsertion at back: O(1)Insertion at front: O(n)Insertion in middle: O(n)Searching (using linear search): O(n)Deletion: O(n)Access to an element with its index: O(1) python lists123456789101112131415161718192021222324252627The list data type has some more methods. Here are all of the methods of list objects:list.append(x)Add an item to the end of the list; equivalent to a[len(a):] = [x].list.extend(L)Extend the list by appending all the items in the given list; equivalent to a[len(a):] = L.list.insert(i, x)Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x).list.remove(x)Remove the first item from the list whose value is x. It is an error if there is no such item.list.pop([i])Remove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and returns the last item in the list. (The square brackets around the i in the method signature denote that the parameter is optional, not that you should type square brackets at that position. You will see this notation frequently in the Python Library Reference.)list.index(x)Return the index in the list of the first item whose value is x. It is an error if there is no such item.list.count(x)Return the number of times x appears in the list.list.sort(cmp=None, key=None, reverse=False)Sort the items of the list in place (the arguments can be used for sort customization, see sorted() for their explanation).list.reverse() Java Arrays在 java 里，array 有一个方法，clone()，属于 shallow copy。有一个 immutable field，length。Java Arrays 好用的方法123456789101112131415161718int[] a = &#123; 7, 1, 2, 3, 4, 5 &#125;;int[] b = &#123; 7, 1, 2, 3, 4, 5 &#125;;System.out.println(&quot;a equals b: &quot; + Arrays.equals(a, b));System.out.println(&quot;a: &quot; + Arrays.toString(a));Arrays.sort(a);int[] c = Arrays.copyOf(b, b.length);// public static void arraycopy(Object source, int srcIndex, Object// destination, int destIndex, int length)int[] d = new int[b.length];System.arraycopy(b, 0, d, 0, 3);int[] e = b.clone(); // shallow copy, only referenceSystem.out.println(&quot;Sorted a: &quot; + Arrays.toString(a));System.out.println(&quot;c (copied from b): &quot; + Arrays.toString(c));System.out.println(&quot;d (copied from b): &quot; + Arrays.toString(d));System.out.println(&quot;e (copied from b): &quot; + Arrays.toString(e)); outputs123456a equals b: truea: [7, 1, 2, 3, 4, 5]Sorted a: [1, 2, 3, 4, 5, 7]c (copied from b): [7, 1, 2, 3, 4, 5]d (copied from b): [7, 1, 2, 0, 0, 0]e (copied from b): [7, 1, 2, 3, 4, 5] Java List12345678add(object) : adds a new element to the endadd(index, object) : inserts a new element at the specifiedindexset(index, object) : replaces an existing element at thespecified index with the new element.get(index) : returns the element at the specified index.remove(index) : deletes the element at the specified index.size() : returns the number of elements. Java 7，ArrayList 用的是 doubling-up policy。也就是说，假定 ArrayList 的初始 capacity 为 4，那么加入第 n(n&lt;=4) 个元素的 running time 是 1，而加入第 5 个 item 时，running time 是 5 而不是 1，因为要重新创建一个 double-size list 再把原来的元素 copy 进去。同样的，加入第 9 个元素时的 running time 是 9 而不是 1。用 amortized 的方法可以发现 add(E e) 的操作的 running time 是一个常数，也就是 O(1)。 例题66. Plus OneProblemGiven a non-negative integer represented as a non-empty array of digits, plus one to the integer. You may assume the integer do not contain any leading zero, except the number 0 itself. The digits are stored such that the most significant digit is at the head of the list. Similar problems (M) Multiply Strings (E) Add Binary (M) Add Two Numbers (M) Plus One Linked List2.445. Add Two Numbers 369. Plus One Linked List43. Multiply Strings Solution1234567891011121314151617181920class Solution(object): def plusOne(self, digits): &quot;&quot;&quot; :type digits: List[int] :rtype: List[int] &quot;&quot;&quot; if digits[-1] != 9: digits[-1] += 1 return digits i = len(digits) - 1 while i &gt;= 0 and digits[i] == 9: digits[i] = 0 i -= 1 if i == -1: cur = [1] cur.extend(digits) return cur digits[i] += 1 return digits 67. Add BinaryProblemGiven two binary strings, return their sum (also a binary string). For example,a = “11”b = “1”Return “100”. Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&apos;&apos;&apos;Solution: 1. do it as we do the math make sure a is longer than b while pb&gt;=0, start from right to left, calculate sum value at each digit and update result and carry. cur=int(a[pa])+int(b[pb])+carry res=str(cur%2)+res carry=cur/2 while pa&gt;=0, do similar task cur=int(a[pa])+carry res=str(cur%2)+res carry=cur/2 deal with carry if carry==1 res=&apos;1&apos;+res 2. do it recursively when a[-1]==&apos;1&apos; and b[-1]==&apos;1&apos;, recursive case would be addBinary(self.addBinary(a[:-1],b[:-1]),&apos;1&apos;)+&apos;0&apos; current layer: &apos;0&apos; previous digit: a[:-1]+b[:-1]+&apos;1&apos; add previous digit as usual: addBinary(a[:-1],b[:-1]) add one: addBinary(prev,&apos;1&apos;) =&gt; addBinary(addBinary(a[:-1],b[:-1]),&apos;1&apos;)+&apos;0&apos;&apos;&apos;&apos;&apos;&apos;&apos;class Solution(object): def addBinary(self, a, b): &quot;&quot;&quot; :type a: str :type b: str :rtype: str &quot;&quot;&quot; if not a: return b if not b: return a if a[-1]==&apos;0&apos; and b[-1]==&apos;0&apos;: return self.addBinary(a[:-1],b[:-1])+&apos;0&apos; if a[-1]==&apos;1&apos; and b[-1]==&apos;1&apos;: return self.addBinary(self.addBinary(a[:-1],b[:-1]),&apos;1&apos;)+&apos;0&apos; else: return self.addBinary(a[:-1],b[:-1])+&apos;1&apos; &apos;&apos;&apos;class Solution(object): def addBinary(self, a, b): &quot;&quot;&quot; :type a: str :type b: str :rtype: str &quot;&quot;&quot; # make sure a is longer than b if len(a) &lt; len(b): a, b = b, a pa = len(a) - 1 pb = len(b) - 1 res, carry = &apos;&apos;, 0 while pb &gt;= 0: cur = int(a[pa]) + int(b[pb]) + carry carry = cur / 2 res = str(cur % 2) + res pb -= 1 pa -= 1 while pa &gt;= 0: cur = int(a[pa]) + carry carry = cur / 2 res = str(cur % 2) + res pa -= 1 if carry == 1: res = &apos;1&apos; + res return res 228. Summary RangesProblemGiven a sorted integer array without duplicates, return the summary of its ranges. For example, given [0,1,2,4,5,7], return [“0-&gt;2”,”4-&gt;5”,”7”]. Solution123456789101112131415161718192021222324class Solution(object): def summaryRanges(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[str] &quot;&quot;&quot; def joinStr(start,end): if start==end: return str(nums[start]) else: return str(nums[start])+&apos;-&gt;&apos;+str(nums[end]) if not nums: return [] res=[] start,end=0,0 while end+1&lt;len(nums): if nums[end]+1==nums[end+1]: end+=1 else: res.append(joinStr(start,end)) start=end+1 end=start res.append(joinStr(start,end)) return res 360. Sort Transformed ArrayProblemGiven a sorted array of integers nums and integer values a, b and c. Apply a function of the form f(x) = ax2 + bx + c to each element x in the array. The returned array must be in sorted order. Expected time complexity: O(n) Example:1234567nums = [-4, -2, 2, 4], a = 1, b = 3, c = 5,Result: [3, 9, 15, 33]nums = [-4, -2, 2, 4], a = -1, b = 3, c = 5Result: [-23, -5, 1, 7] Credits:Special thanks to @elmirap for adding this problem and creating all test cases. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123&apos;&apos;&apos;Notes: Because the input is sorted and the function is a second degree polynomial, simply applying the function will result in at most two increasing/decreasing runs. Which Python&apos;s sort function will recognize and simply reverse/merge in O(n). Refer links: https://en.wikipedia.org/wiki/Timsort http://blog.csdn.net/yangzhongblog/article/details/8184707Tips: heapq.merge(*iterables): Merge multiple sorted inputs into a single sorted output (for example, merge timestamped entries from multiple log files). Returns an iterator over the sorted values.&apos;&apos;&apos;# Method 1&apos;&apos;&apos;class Solution(object): def sortTransformedArray(self, nums, a, b, c): return sorted(a*x*x + b*x + c for x in nums) &apos;&apos;&apos; # Method 2: two parts solution&apos;&apos;&apos;from collections import dequeimport heapqclass Solution(object): def sortTransformedArray(self, nums, a, b, c): &quot;&quot;&quot; :type nums: List[int] :type a: int :type b: int :type c: int :rtype: List[int] &quot;&quot;&quot; &quot;&quot;&quot; # can simply use heapq.merge() def mergeLists(left,right): lp,rp=0,0 res=[] while lp&lt;len(left) and rp&lt;len(right): if left[lp]&lt;=right[rp]: res.append(left[lp]) lp+=1 else: res.append(right[rp]) rp+=1 while lp&lt;len(left): res.append(left[lp]) lp+=1 while rp&lt;len(right): res.append(right[rp]) rp+=1 return res &quot;&quot;&quot; if not nums: return None d=deque() if a==0: if b&gt;0: for n in nums: d.append(n*b+c) else: for n in nums: d.appendleft(n*b+c) else: left=deque() right=deque() if a&gt;0: line=float(-1*b)/(2*a) for n in nums: if n&lt;line: left.appendleft(a*n*n+b*n+c) else: right.append(a*n*n+b*n+c) else: line=float(-1*b)/(2*a) for n in nums: if n&lt;line: left.append(a*n*n+b*n+c) else: right.appendleft(a*n*n+b*n+c) #d=mergeLists(left,right) d=heapq.merge(left,right) return list(d) &apos;&apos;&apos;# Method 3: two pointers solutionclass Solution(object): def sortTransformedArray(self, nums, a, b, c): &quot;&quot;&quot; :type nums: List[int] :type a: int :type b: int :type c: int :rtype: List[int] &quot;&quot;&quot; def f(x): return a*x*x+b*x+c start,end=0,len(nums)-1 res=[] while start&lt;=end: resS,resE=f(nums[start]),f(nums[end]) if a&gt;0: if resS&lt;resE: res.append(resE) end-=1 else: res.append(resS) start+=1 else: if resS&gt;resE: res.append(resE) end-=1 else: res.append(resS) start+=1 if a&gt;0: return res[::-1] return res 346. Moving Average from Data StreamProblemGiven a stream of integers and a window size, calculate the moving average of all integers in the sliding window.For example,MovingAverage m = new MovingAverage(3);m.next(1) = 1m.next(10) = (1 + 10) / 2m.next(3) = (1 + 10 + 3) / 3m.next(5) = (10 + 3 + 5) / 3 Solution12345678910111213141516171819202122232425262728293031323334353637&apos;&apos;&apos;Solution:- maintain a deque of at most &apos;size&apos; length, for each next call, enque the number, calculate average, check if the length of deque is 3, if it is, popleft, and finally return the average. Time complexity O(n); Space complexity O(size)Follow-up:- make it O(1), save the sum each time, that is for each next call, enque the number, add to global sum, calculate average, check if the length of deque is 3, if it is, pop left, minus popped number from sum, and finally return the average.&apos;&apos;&apos;from collections import dequeclass MovingAverage(object): def __init__(self, size): &quot;&quot;&quot; Initialize your data structure here. :type size: int &quot;&quot;&quot; self.q=deque() self.size=size self.sum=0 def next(self, val): &quot;&quot;&quot; :type val: int :rtype: float &quot;&quot;&quot; self.q.append(val) self.sum+=val avg=self.sum/float(len(self.q)) if len(self.q)==self.size: self.sum-=self.q.popleft() return avg# Your MovingAverage object will be instantiated and called as such:# obj = MovingAverage(size)# param_1 = obj.next(val) 75. Sort Colorssubarray 问题 ProblemGiven an array with n objects colored red, white or blue, sort them so that objects of the same color are adjacent, with the colors in the order red, white and blue.Here, we will use the integers 0, 1, and 2 to represent the color red, white, and blue respectively.Note:You are not suppose to use the library’s sort function for this problem. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&apos;&apos;&apos;Solution:- quicksort? Time complexity: O(nlogn)- 3 numbers, so count and reset, Time complexity: O(n), Space complexity: O(3)-&gt;O(1), two-pass- subarray with different states, Time complexity: O(n)Attention:- for solution 3, boundary is tricky, remember pointer is not includedTest case:- [0]- [0,0,0]&apos;&apos;&apos;class Solution(object): def sortColors(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: void Do not return anything, modify nums in-place instead. &quot;&quot;&quot; if len(nums)&lt;=1: return left,right,cur=0,len(nums)-1,0 while cur&lt;=right: if nums[cur]==0: nums[cur],nums[left]=nums[left],nums[cur] left+=1 cur+=1 elif nums[cur]==2: nums[cur],nums[right]=nums[right],nums[cur] right-=1 else: cur+=1 &apos;&apos;&apos; # two-pass solution: count and reset def sortColors(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: void Do not return anything, modify nums in-place instead. &quot;&quot;&quot; if len(nums)&lt;1: return a0,a1,a2=0,0,0 for n in nums: if n==0: a0+=1 elif n==1: a1+=1 elif n==2: a2+=1 for i in range(len(nums)): if a0&gt;0: nums[i]=0 a0-=1 elif a1&gt;0: nums[i]=1 a1-=1 elif a2&gt;0: nums[i]=2 a2-=1 &apos;&apos;&apos; 53. Maximum SubarrayProblemFind the contiguous subarray within an array (containing at least one number) which has the largest sum.For example, given the array [-2,1,-3,4,-1,2,1,-5,4],the contiguous subarray [4,-1,2,1] has the largest sum = 6.More practice:If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle. Solution12345678910111213141516171819202122232425262728293031323334353637383940&apos;&apos;&apos;Solution:- subarray: 2 pointers: head,tail- any repeated work? no any meaningless work? yes check the sum-array and we can find that the non-max-sum either subtract one more number or miss one more addition --&gt; cur_sum=max(cur_sum,nums[start]+cur_sum)&apos;&apos;&apos;class Solution(object): def maxSubArray(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; cur_sum,max_sum=nums[0],nums[0] for start in range(1,len(nums)): cur_sum=max(nums[start],nums[start]+cur_sum) max_sum=max(cur_sum,max_sum) return max_sum &apos;&apos;&apos; # brute-force, time limit exceeded def maxSubArray(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; if len(nums)==0: return 0 global_sum=nums[0] for i in range(0,len(nums)-1): part_sum=nums[i] if part_sum&gt;global_sum: global_sum=part_sum for j in range(i+1,len(nums)): part_sum+=nums[j] if part_sum&gt;global_sum: global_sum=part_sum part_sum=nums[-1] if part_sum&gt;global_sum: global_sum=part_sum return global_sum &apos;&apos;&apos; Snapchat 面经ProblemReturns unsorted part of an array.For example, input -&gt; [1,2,5,7,6,4,9], output -&gt; [5,7,6,4] Solution1234567891011121314151617181920212223242526272829303132&apos;&apos;&apos;Solution: Easiest way is to sort the array and compare it with the original array, get the first and last digit of different number, and return the list. It takes O(nlogn) time.Followup -&gt; O(n) time Use two pointers, lastDigit and firstDigit, and two global variables, curMax and curMin For a sorted array, if we start for left to right curMax should be current number, and if we start from right to left, curMin should be current number. So starts from left to right, keep track of curMax, first update curMax, and then check if current number is current max, if not, update lastDigit, repeat till we finish the loop. Then starts from right to left, keep track of curMin, first update curMin, and then check if current number is current min, if not, update firstDigit, repeat till we finish the loop. Return array[firstDigit,lastDigit+1] Time complexity: O(n)&apos;&apos;&apos;def solution(array): if not array: return [] # keep track of current maximum and minimum lastDigit, firstDigit = 0, len(array) - 1 curMax, curMin = array[0], array[len(array) - 1] for i in xrange(len(array)): curMax = max(array[i], curMax) if array[i] &lt; curMax: lastDigit = i for i in xrange(len(array) - 1, -1, -1): curMin = min(array[i], curMin) if array[i] &gt; curMin: firstDigit = i return array[firstDigit:lastDigit + 1]print solution([])print solution([1, 2, 5, 7, 6, 4, 9])print solution([1, 2, 5, 5, 1]) Finding sum of Absolute Difference of Every pair of integer from an arrayProblemGiven an array, find the sum of the absolute difference of every pair of integers.For example: Given a[]= {2, 3, 5, 7 };output would be (3-2) + (5-2) + (7-2) + (5-3) + (7-3) + (7-5) = 17.It must be done better than O(n^2).The original array isn’t necessarily sorted. Solution123456789101112131415161718&apos;&apos;&apos;First, sort the array. Let&apos;s say the sorted array looks like [-5, 2, 3, 5]. To consider only distinct pairs, for each element, pair it with only the elements that came before it. That means that the contribution of 3 to the total result is abs(3 - 2) + abs(3 - (-5)). Because the array is sorted, all the elements that came before are smaller or equal, so this can safely be rewritten as 3 * 2 - (2 + (-5)). In general terms, the contribution of arr[i] to the sum is arr[i] * i - sum (arr[0...i-1]). Fortunately, we can maintain the sum term as we go, avoiding expensive recomputation. We&apos;ll get the answer when we sum the contributions of each arr[i].This code runs in O(n)O(n) time after sorting, so the overall algorithm is O(nlogn)O(nlog⁡n), unless the data you have makes it easy to sort faster than that.Depending on the meaning of the term &quot;distinct pairs&quot;, you may need to dedupe the array before running the linear pass over the data. That is, if on an input like [1, 2, 1, 2, 3], you wouldn&apos;t want to count (2, 1) several times (even though there&apos;s several ways the pair can form), then you should just dedupe the input. Convert [1, 2, 1, 2, 3] to [1, 2, 3].&apos;&apos;&apos;def solution(arr): if not arr: return 0 arr.sort() total = 0 arraySum = 0 for i in range(0, len(arr)): total += (arr[i] * i - arraySum) arraySum += arr[i] return total 11. Container With Most WaterProblemGiven n non-negative integers a1, a2, …, an, where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water. Note: You may not slant the container and n is at least 2. Solution123456789101112131415161718192021222324252627282930&apos;&apos;&apos;Solution: check every possible container (each combination of (i,j) where i,j &lt; len(height)) v=(j-i)*min(height[i],height[j]) cur_max=max(v,cur_max) takes O(n^2) timeFollowup: make it O(n) if we choose i=0 and an any other number in array, we can ensure v&lt;height[0]*l where l=len(height), same reason, if we choose j=len(height)-1 and an any other number in array, we can ensure v&lt;height[-1]*l thus, we start from i=0 and j=len(height)-1 and get a container with volume v1, then in order to get a larger container, we wanna a heigher boundary(height), so we discard the smaller number between height[i] and height[j], and get a new volume v2, repeat this process till i==j&apos;&apos;&apos;class Solution(object): def maxArea(self, height): &quot;&quot;&quot; :type height: List[int] :rtype: int &quot;&quot;&quot; if not height or len(height)==1: return 0 start,end=0,len(height)-1 cur_max=float(&apos;-inf&apos;) while start&lt;end: cur=(end-start)*min(height[start],height[end]) cur_max=max(cur,cur_max) if height[start]&gt;height[end]: end-=1 else: start+=1 return cur_max 84. Largest Rectangle in HistogramProblemGiven n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Above is a histogram where width of each bar is 1, given height = [2,1,5,6,2,3]. The largest rectangle is shown in the shaded area, which has area = 10 unit. For example,Given heights = [2,1,5,6,2,3],return 10. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&apos;&apos;&apos;Solution:A simple solution is to one by one consider all bars as starting points and calculate area of all rectangles starting with every bar. Finally return maximum of all possible areas. Time complexity of this solution would be O(n^2).We can use Divide and Conquer to solve this in O(nLogn) time. The idea is to find the minimum value in the given array. Once we have index of the minimum value, the max area is maximum of following three values.a) Maximum area in left side of minimum value (Not including the min value)b) Maximum area in right side of minimum value (Not including the min value)c) Number of bars multiplied by minimum value.The areas in left and right of minimum value bar can be calculated recursively. If we use linear search to find the minimum value, then the worst case time complexity of this algorithm becomes O(n^2). In worst case, we always have (n-1) elements in one side and 0 elements in other side and if the finding minimum takes O(n) time, we get the recurrence similar to worst case of Quick Sort.Followup:- O(n)? - avoid repeated work - identify a rectangle: identify 2 boundaries - if cur&gt;stack.peek() --&gt; offer, else --&gt; continously poll For every bar ‘x’, we calculate the area with ‘x’ as the smallest bar in the rectangle. If we calculate such area for every bar ‘x’ and find the maximum of all areas, our task is done. How to calculate area with ‘x’ as smallest bar? We need to know index of the first smaller (smaller than ‘x’) bar on left of ‘x’ and index of first smaller bar on right of ‘x’. Let us call these indexes as ‘left index’ and ‘right index’ respectively. We traverse all bars from left to right, maintain a stack of bars. Every bar is pushed to stack once. A bar is popped from stack when a bar of smaller height is seen. When a bar is popped, we calculate the area with the popped bar as smallest bar. How do we get left and right indexes of the popped bar – the current index tells us the ‘right index’ and index of previous item in stack is the ‘left index’. Following is the complete algorithm. 1) Create an empty stack. 2) Start from first bar, and do following for every bar ‘hist[i]’ where ‘i’ varies from 0 to n-1. ……a) If stack is empty or hist[i] is higher than the bar at top of stack, then push ‘i’ to stack. ……b) If this bar is smaller than the top of stack, then keep removing the top of stack while top of the stack is greater. Let the removed bar be hist[tp]. Calculate area of rectangle with hist[tp] as smallest bar. For hist[tp], the ‘left index’ is previous (previous to tp) item in stack and ‘right index’ is ‘i’ (current index). 3) If the stack is not empty, then one by one remove all bars from stack and do step 2.b for every removed bar.Corner case: [0]&apos;&apos;&apos;class Solution(object): def largestRectangleArea(self, heights): &quot;&quot;&quot; :type heights: List[int] :rtype: int &quot;&quot;&quot; if not heights: return 0 stack=[] max_area=0 for i in range(len(heights)+1): while stack and (i==len(heights) or heights[i]&lt;heights[stack[-1]]): height=heights[stack.pop()] leftBound=0 if not stack else stack[-1]+1 rightBound=i cur_area=(rightBound-leftBound)*height max_area=max(cur_area,max_area) stack.append(i) return max_area &apos;&apos;&apos; # primitive, 2 loops def largestRectangleArea(self, heights): &quot;&quot;&quot; :type heights: List[int] :rtype: int &quot;&quot;&quot; if not heights: return 0 max_area=0 for i in range(len(heights)): max_area=max(heights[i],max_area) min_height=heights[i] for j in range(i,len(heights)): min_height=min(min_height,heights[j]) max_area=max(min_height*(j-i+1),max_area) return max_area &apos;&apos;&apos; &apos;&apos;&apos; # DP: avg: O(nlogn) worst: O(n^2) def largestRectangleArea(self, heights): &quot;&quot;&quot; :type heights: List[int] :rtype: int &quot;&quot;&quot; # DP Solution def maxArea(left,right): if right-left==1: return heights[left] if right==left: return 0 minHeight=min(heights[left:right]) minHeightIndex=heights[left:right].index(minHeight)+left maxLeft=maxArea(left,minHeightIndex) maxRight=maxArea(minHeightIndex+1,right) cur=minHeight*(right-left) return max(maxLeft,maxRight,cur) if not heights: return 0 return maxArea(0,len(heights)) &apos;&apos;&apos; 463. Island PerimeterProblemYou are given a map in form of a two-dimensional integer grid where 1 represents land and 0 represents water. Grid cells are connected horizontally/vertically (not diagonally). The grid is completely surrounded by water, and there is exactly one island (i.e., one or more connected land cells). The island doesn’t have “lakes” (water inside that isn’t connected to the water around the island). One cell is a square with side length 1. The grid is rectangular, width and height don’t exceed 100. Determine the perimeter of the island. Example:1234567[[0,1,0,0], [1,1,1,0], [0,1,0,0], [1,1,0,0]]Answer: 16Explanation: The perimeter is the 16 yellow stripes in the image below: Solution12345678910111213141516171819202122232425262728293031323334353637class Solution(object): &apos;&apos;&apos; def islandPerimeter(self, grid): &quot;&quot;&quot; :type grid: List[List[int]] :rtype: int &quot;&quot;&quot; newGrid=[[0]*(len(grid[0])+2) for i in range(len(grid)+2)] for i in range(len(grid)): for j in range(len(grid[0])): newGrid[i+1][j+1]=grid[i][j] res=0 for i in range(1,len(newGrid)-1): for j in range(1,len(newGrid[0])-1): if newGrid[i][j]==1: # check around if newGrid[i][j-1]==0: res+=1 if newGrid[i][j+1]==0: res+=1 if newGrid[i-1][j]==0: res+=1 if newGrid[i+1][j]==0: res+=1 return res &apos;&apos;&apos; &apos;&apos;&apos; Simplify version &apos;&apos;&apos; def islandPerimeter(self, grid): def water_around(y, x): return ((x == 0 or grid[y][x-1] == 0) + (x == len(grid[0])-1 or grid[y][x+1] == 0) + (y == 0 or grid[y-1][x] == 0) + (y == len(grid)-1 or grid[y+1][x] == 0) ) return sum(water_around(y, x) for y in xrange(len(grid)) for x in xrange(len(grid[0])) if grid[y][x]) 448. Find All Numbers Disappeared in an ArrayProblemGiven an array of integers where 1 ≤ a[i] ≤ n (n = size of array), some elements appear twice and others appear once. Find all the elements of [1, n] inclusive that do not appear in this array. Could you do it without extra space and in O(n) runtime? You may assume the returned list does not count as extra space. Example:12345Input:[4,3,2,7,8,2,3,1]Output:[5,6] Tags: ArraySimilar Problems: (H) First Missing Positive (M) Find All Duplicates in an Array Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102&apos;&apos;&apos;Soltuion: Bucket sort. The idea is simple, we&apos;re gonna make all numbers into the corrent position. Each element w should be put into the w th position of the array.If nums[i] != i + 1 and nums[i] != nums[nums[i] - 1], then we swap nums[i] with nums[nums[i] - 1], for example, nums[0] = 4 and nums[3] = 7, then we swap nums[0] with nums[3]. So In the end the array will be sorted and if nums[i] != i + 1, then i + 1 is missing. The example run as follows [4,3,2,7,8,2,3,1] [7,3,2,4,8,2,3,1] [3,3,2,4,8,2,7,1] [2,3,3,4,8,2,7,1] [3,2,3,4,8,2,7,1] [3,2,3,4,1,2,7,8] [1,2,3,4,3,2,7,8] Since every swap we put at least one number to its correct position, the time is O(n)Special case: [2,2]&apos;&apos;&apos;class Solution(object): &apos;&apos;&apos; brute-force: O(n^2) def findDisappearedNumbers(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; if not nums: return [] res=[] for i in range(1,len(nums)+1): if i not in nums: res.append(i) return res &apos;&apos;&apos; &apos;&apos;&apos; Sort: O(nlogn) def findDisappearedNumbers(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; if not nums: return [] nums.sort() i=0 n=len(nums) res=[] for cur in nums: if cur==i: continue if cur==i+1: i+=1 continue while i &lt; cur-1: i+=1 res.append(i) i=cur while i&lt;n: i+=1 res.append(i) return res &apos;&apos;&apos; Sort: O(n) def findDisappearedNumbers(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; if not nums: return [] for i in range(len(nums)): while nums[i] != nums[nums[i] - 1]: nums[nums[i] - 1], nums[i] = nums[i], nums[nums[i] - 1] res = [] print nums for i, num in enumerate(nums): if i + 1 != num: res.append(i + 1) return res &apos;&apos;&apos; def findDisappearedNumbers(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; # Use nums as hashmap # For each number i in nums, mark the number that i points as negative. # Then filter the list, get all the indexes that points to a positive number for i in range(len(nums)): index = abs(nums[i]) - 1 nums[index] = - abs(nums[index]) return [i + 1 for i in range(len(nums)) if nums[i] &gt; 0] &apos;&apos;&apos; 442. Find All Duplicates in an ArrayProblemGiven an array of integers, 1 ≤ a[i] ≤ n (n = size of array), some elements appear twice and others appear once. Find all the elements that appear twice in this array. Could you do it without extra space and in O(n) runtime? Example:12345Input:[4,3,2,7,8,2,3,1]Output:[2,3] Tags: ArraySimilar Problems: (E) Find All Numbers Disappeared in an Array Solution1234567891011121314151617181920212223242526272829303132333435&apos;&apos;&apos;Solution: Bucket sort. Each element w should be put into the w th position of the array.&apos;&apos;&apos;class Solution(object): &apos;&apos;&apos; def findDuplicates(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; hashset=set() res=[] for n in nums: if n in hashset: res.append(n) else: hashset.add(n) return res &apos;&apos;&apos; def findDuplicates(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[int] &quot;&quot;&quot; if not nums: return [] res=[] for i in range(len(nums)): while nums[i] != nums[nums[i]-1]: nums[nums[i]-1],nums[i]=nums[i],nums[nums[i]-1] for i,n in enumerate(nums): if i+1 != n: res.append(n) return res 41. First Missing PositiveProblemGiven an unsorted integer array, find the first missing positive integer. For example,Given [1,2,0] return 3,and [3,4,-1,1] return 2. Your algorithm should run in O(n) time and uses constant space. Tags: ArraySimilar Problems: (M) Missing Number (H) Find the Duplicate Number (E) Find All Numbers Disappeared in an Array Solution123456789101112131415161718192021222324&apos;&apos;&apos;Solution: Bucket sort is the only way. As only the elements between 1...n are useful, each element w should be put into the w th position of the array. As it is possible there is some other element v in the w th position, take the v out before overwriting and then iteratively use the same logic on v and go on. Time complexity: each element is looped 2 times and swapped 1 time, so the whole time compexity is O(n) Space: O(1) apparently&apos;&apos;&apos;class Solution(object): def firstMissingPositive(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; n = len(nums) for i in xrange(len(nums)): while nums[i] &gt; 0 and nums[i] &lt;= n and nums[i] != nums[nums[i] - 1]: nums[nums[i] - 1], nums[i] = nums[i], nums[nums[i] - 1] for i, num in enumerate(nums): if i + 1 != num: return i + 1 return n + 1 287. Find the Duplicate NumberProblemGiven an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), prove that at least one duplicate number must exist. Assume that there is only one duplicate number, find the duplicate one. Note:You must not modify the array (assume the array is read only).You must use only constant, O(1) extra space.Your runtime complexity should be less than O(n2).There is only one duplicate number in the array, but it could be repeated more than once. Tags: Binary Search Array Two PointersSimilar Problems: (H) First Missing Positive (E) Single Number (M) Linked List Cycle II (M) Missing Number Solution123456789101112131415161718192021222324&apos;&apos;&apos;Solution: The main idea is the same with problem Linked List Cycle II. Use two pointers the fast and the slow. The fast one goes forward two steps each time, while the slow one goes only step each time. They must meet the same item when slow==fast. In fact, they meet in a circle, the duplicate number must be the entry point of the circle when visiting the array from nums[0]. Next we just need to find the entry point. We use a point(we can use the fast one before) to visit form begining with one step each time, do the same job to slow. When fast==slow, they meet at the entry point of the circle.&apos;&apos;&apos;class Solution(object): def findDuplicate(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; if not nums: return -1 fast = nums[nums[0]] slow = nums[0] while slow != fast: slow = nums[slow] fast = nums[nums[fast]] head = 0 while head != slow: head = nums[head] slow = nums[slow] return slow","tags":"数组"},{"title":"数据结构和算法 -- TWO-SUM 问题和python dict","url":"/2016/09/18/数据结构和算法 -- TWO-SUM 问题和 python dict/","text":"打尽 two-sum 问题。 策略 &amp; 注意点Assumption array is sorted? each input would have exactly one solution? duplicates in array? return index is sorted? 策略 头尾指针，经典模板 12345678while start&lt;end: sum=numbers[start]+numbers[end] if sum==target: return [start,end] if sum&gt;target: end-=1 else: start+=1 加上去重的模板： 1234567891011121314while start&lt;end: cur_sum=nums[start]+nums[end] if cur_sum&lt;target: start+=1 elif cur_sum&gt;target: end-=1 else: cur_res.append([nums[0],nums[start],nums[end]]) start+=1 end-=1 while start&lt;end and nums[start]==nums[start-1]: start+=1 while start&lt;end and nums[end]==nums[end+1]: end-=1 Hashmap 来 search target-nums[i]，1－pass 先 check 在不在 map 中，不在就放进去。 注意点 涉及 index 一般就不先 sort 了，因为会 disrupt the order 如果上来就把整个 list 转成 hashmap，之后在 search，那么就要注意 val==target-val 的情况了，也要判断 val 出现几次（hashmap 必须考虑 key 是否会重复） 要去重的问题用两个 pointer 可以顺便去重，但要注意保证大条件 start&lt;end 注意数字可能是 negative，初始化变量不要想当然的为0，计算 difference 的时候用 abs(n) 绝对值。 python dict 的用法，哪些 O(1) 哪些 O(n) 例题1. Two Sum Given an array of integers, return indices of the two numbers such that they add up to a specific target.You may assume that each input would have exactly one solution.Example:Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&apos;&apos;&apos;Check assumption:- array is not sorted- each input would have exactly one solution- duplicates in array- return index is not sortedCorner case:- len(nums)&lt;2 or nums==NoneSolution:- Loop array, search target-nums[i] for each nums[j] on the right. Time complexity: O(n^2)Attention:- we cannot sort array, compare target and sum and move pointers to get the answer as it would disrupt the order- array.index(value) returns first match, but this may not be what you expectOptimization:- While loop, use hashmap&lt;target-nums[i],i&gt; to store remaining index and value, so that the second loop will have O(1) time complexity, and the total complexity would be O(n). The cost is space complexity. This is two-pass solution.- Two-pass --&gt; One pass. While loop, for each i, check if it is in hashmap, if not, add it to the hashmap, if exists, return index.&apos;&apos;&apos;class Solution(object): # with hashmap def twoSum(self, nums, target): &quot;&quot;&quot; :type nums: List[int] :type target: int :rtype: List[int] &quot;&quot;&quot; if not nums or len(nums)&lt;2: return None hashmap=dict() for index,value in enumerate(nums): if target-value in hashmap: return[index,hashmap[target-value]] hashmap[value]=index return None &apos;&apos;&apos; # two loops def twoSum(self, nums, target): &quot;&quot;&quot; :type nums: List[int] :type target: int :rtype: List[int] &quot;&quot;&quot; if not nums or len(nums)&lt;2: return None for index1,value in enumerate(nums): for index2 in range(index1+1,len(nums)): if nums[index2]==target-value: return [index1,index2] return None &apos;&apos;&apos; 167. Two Sum II - Input array is sorted Given an array of integers that is already sorted in ascending order, find two numbers such that they add up to a specific target number.The function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Please note that your returned answers (both index1 and index2) are not zero-based.You may assume that each input would have exactly one solution.Input: numbers={2, 7, 11, 15}, target=9Output: index1=1, index2=2 1234567891011121314151617181920class Solution(object): def twoSum(self, numbers, target): &quot;&quot;&quot; :type numbers: List[int] :type target: int :rtype: List[int] &quot;&quot;&quot; if not numbers or len(numbers)&lt;2: return None start=0 end=len(numbers)-1 while start&lt;end: sum=numbers[start]+numbers[end] if sum==target: return [start+1,end+1] if sum&gt;target: end-=1 else: start+=1 return None 170. Two Sum III - Data structure design Design and implement a TwoSum class. It should support the following operations: add and find.add - Add the number to an internal data structure.find - Find if there exists any pair of numbers which sum is equal to the value.For example,add(1); add(3); add(5);find(4) -&gt; truefind(7) -&gt; false 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&apos;&apos;&apos;Data structure:- hashmap&lt;number,frequency&gt;. Use hashmap because duplicates matter!Corner case:- hashmap is NoneAttention:- avoid case val==target-valTime complexity:- add() O(1)- find() O(n)About python dictionary:- Do not use dict.keys!In Python 2 dict.keys() creates the whole list of keys first that&apos;s why it is an O(N) operation, while key in dict is an O(1) operation.&gt;&gt;&gt; dic = dict.fromkeys(range(10**5))&gt;&gt;&gt; %timeit 10000 in dic1000000 loops, best of 3: 170 ns per loop&gt;&gt;&gt; %timeit 10000 in dic.keys()100 loops, best of 3: 4.98 ms per loop&gt;&gt;&gt; %timeit 10000 in dic.iterkeys()1000 loops, best of 3: 402 us per loop&gt;&gt;&gt; %timeit 10000 in dic.viewkeys()1000000 loops, best of 3: 457 ns per loop- Use dict.get(key,default=None)!self.hashmap[number]=self.hashmap.get(number,0)+1&apos;&apos;&apos;class TwoSum(object): def __init__(self): &quot;&quot;&quot; initialize your data structure here &quot;&quot;&quot; self.hashmap=dict() def add(self, number): &quot;&quot;&quot; Add the number to an internal data structure. :rtype: nothing &quot;&quot;&quot; &apos;&apos;&apos; if self.hashmap.has_key(number): self.hashmap[number]+=1 else: self.hashmap[number]=1 &apos;&apos;&apos; self.hashmap[number]=self.hashmap.get(number,0)+1 def find(self, value): &quot;&quot;&quot; Find if there exists any pair of numbers which sum is equal to the value. :type value: int :rtype: bool &quot;&quot;&quot; if not self.hashmap: return False for v in self.hashmap: if value-v in self.hashmap: if self.hashmap[v]&gt;1 or v!=value-v: return True return False# Your TwoSum object will be instantiated and called as such:# twoSum = TwoSum()# twoSum.add(number)# twoSum.find(value) 15. 3Sum Given an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.Note: The solution set must not contain duplicate triplets.For example, given array S = [-1, 0, 1, 2, -1, -4],A solution set is:[ [-1, 0, 1], [-1, -1, 2]] 123456789101112131415161718192021222324252627282930313233343536373839404142434445&apos;&apos;&apos;Solution:- convert to 2-sum problem, avoid duplicate triplets: sort the array, move pointers to skip duplicatesAttention:- when avoiding duplicates, keep in mind start&lt;end, consider corner case [0,0,0] with 0&apos;&apos;&apos;class Solution(object): def threeSum(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: List[List[int]] &quot;&quot;&quot; if len(nums)&lt;3: return [] nums=sorted(nums) result=[] for i in range(len(nums)-2): if i&gt;0 and nums[i]==nums[i-1]: continue result+=self.twoSum(nums[i:],0-nums[i]) return result def twoSum(self,nums,target): if len(nums)&lt;3: return [] start,end=1,len(nums)-1 cur_res=[] while start&lt;end: cur_sum=nums[start]+nums[end] if cur_sum&lt;target: start+=1 elif cur_sum&gt;target: end-=1 else: cur_res.append([nums[0],nums[start],nums[end]]) start+=1 end-=1 while start&lt;end and nums[start]==nums[start-1]: start+=1 while start&lt;end and nums[end]==nums[end+1]: end-=1 return cur_res 259. 3Sum Smaller Given an array of n integers nums and a target, find the number of index triplets i, j, k with 0 &lt;= i &lt; j &lt; k &lt; n that satisfy the condition nums[i] + nums[j] + nums[k] &lt; target.For example, given nums = [-2, 0, 1, 3], and target = 2.Return 2. Because there are two triplets which sums are less than 2:[-2, 0, 1][-2, 0, 3]Follow up:Could you solve it in O(n2) runtime? 1234567891011121314151617181920212223242526272829&apos;&apos;&apos;Same with normal 3sum problem, just consider all possibilities.Solution:- sort nums, for nums[i] in nums, search if nums[start]+nums[end]&lt;target-nums[i] for nums[i+1:], if it is, count+=end-start and keep going&apos;&apos;&apos;class Solution(object): def threeSumSmaller(self, nums, target): &quot;&quot;&quot; :type nums: List[int] :type target: int :rtype: int &quot;&quot;&quot; if len(nums)&lt;3: return 0 count=0 nums=sorted(nums) for i in range(len(nums)): start=i+1 end=len(nums)-1 while start&lt;end: cur_sum=nums[start]+nums[end] new_target=target-nums[i] if cur_sum&lt;new_target: count+=end-start start+=1 else: end-=1 return count 16. 3Sum Closest Given an array S of n integers, find three integers in S such that the sum is closest to a given number, target. Return the sum of the three integers. You may assume that each input would have exactly one solution. For example, given array S = {-1 2 1 -4}, and target = 1. The sum that is closest to the target is 2. (-1 + 2 + 1 = 2). 12345678910111213141516171819202122232425262728293031323334&apos;&apos;&apos;Simliar to 3sum problem, but have a global_diff to record current minimum difference (remember it should be absolute value) and global_sum to record current closet result&apos;&apos;&apos;class Solution(object): def threeSumClosest(self, nums, target): &quot;&quot;&quot; :type nums: List[int] :type target: int :rtype: int &quot;&quot;&quot; if len(nums)&lt;3: return None nums=sorted(nums) global_diff=abs(target-nums[0]) global_sum=sum(nums[0:3]) for i in range(len(nums)-2): start=i+1 end=len(nums)-1 cur_target=target-nums[i] while start&lt;end: sum2=nums[start]+nums[end] if sum2&lt;cur_target: if abs(cur_target-sum2)&lt;global_diff: global_sum=sum2+nums[i] global_diff=abs(cur_target-sum2) start+=1 elif sum2&gt;cur_target: if abs(sum2-cur_target)&lt;global_diff: global_diff=abs(sum2-cur_target) global_sum=sum2+nums[i] end-=1 else: return target return global_sum 18. 4Sum Given an array S of n integers, are there elements a, b, c, and d in S such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target.Note: The solution set must not contain duplicate quadruplets.For example, given array S = [1, 0, -1, 0, -2, 2], and target = 0.A solution set is:[ [-1, 0, 0, 1], [-2, -1, 1, 2], [-2, 0, 0, 2]] 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution(object): def fourSum(self, nums, target): &quot;&quot;&quot; :type nums: List[int] :type target: int :rtype: List[List[int]] &quot;&quot;&quot; if len(nums)&lt;4: return [] res=[] nums=sorted(nums) for i in range(len(nums)-3): if i&gt;0 and nums[i]==nums[i-1]: continue res+=self.sum_3(nums[i:],target-nums[i]) return res def sum_3(self,nums,target): if len(nums)&lt;4: return [] res=[] cur=nums[0] nums=nums[1:] for i in range(len(nums)-2): if i&gt;0 and nums[i]==nums[i-1]: continue new_target=target-nums[i] start=i+1 end=len(nums)-1 while start&lt;end: cur_sum=nums[start]+nums[end] if cur_sum&gt;new_target: end-=1 elif cur_sum&lt;new_target: start+=1 else: res.append([cur,nums[i],nums[start],nums[end]]) start+=1 end-=1 while start&lt;end and nums[start]==nums[start-1]: start+=1 while start&lt;end and nums[end]==nums[end+1]: end-=1 return res dict 详解内置函数和方法序号函数及描述1cmp(dict1, dict2)比较两个字典元素。2len(dict)计算字典元素个数，即键的总数。3str(dict)输出字典可打印的字符串表示。4type(variable)返回输入的变量类型，如果变量是字典就返回字典类型。 Python字典包含了以下内置方法： 序号函数及描述1radiansdict.clear()删除字典内所有元素 2radiansdict.copy()返回一个字典的浅复制3radiansdict.fromkeys() 创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值4radiansdict.get(key, default=None)返回指定键的值，如果值不在字典中返回default值5radiansdict.has_key(key)如果键在字典dict里返回true，否则返回false6radiansdict.items()以列表返回可遍历的(键, 值) 元组数组7radiansdict.keys()以列表返回一个字典所有的键8radiansdict.setdefault(key, default=None)和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default9radiansdict.update(dict2)把字典dict2的键/值对更新到dict里10radiansdict.values()以列表返回字典中的所有值 时间复杂度下表 python 3 中 dictinoary (包括 dict 和 defaultdict) 的时间复杂度，要注意的 d.keys() 在 python 2 中的复杂度是 O(n)，因为它返回的是一个 list Operation Example Class Notes Index d[k] O(1) —————————— Store d[k] = v O(1) —————————— Length len(d) O(1) —————————— Delete del d[k] O(1) —————————— get/setdefault d.method O(1) —————————— Pop d.pop(k) O(1) —————————— Pop item d.popitem() O(1) —————————— Clear d.clear() O(1) similar to s = {} or = dict() Views d.keys() O(1) —————————— Construction dict(…) O(len(…)) depends # (key,value) 2-tuples Iteration for k in d: O(N) all forms: keys, values, items So, most dict operations are O(1). defaultdicts support all operations that dicts support, with the same complexity classes (because it inherits all the operations); this assumes that calling the constructor when a values isn’t found in the defaultdict is O(1) - which is true for int(), list(), set(), … (the things commonly used) 参考链接Python TimeComplexityComplexity of Python Operations","tags":"python array two-sum"},{"title":"数据结构和算法 -- 树","url":"/2016/09/17/数据结构和算法 -- 树/","text":"最大最小值python 里找 float 的最小值，float(‘-inf’)，最大值，float(‘inf’)找 int 的最大最小值123import sysmax = sys.maxintmin = -sys.maxint-1 其它class 里创建 helper 方法第一个参数传 self, 调用 self.helper()python 的三元运算符，python 的 max 方法。 基础概念 Root: The node at the top of the tree Parent: When any node (except the root) has exactly one edge running upward to another node. The node above is called parent of the node. Child: Any node may have one or more lines running downward to other nodes. These nodes below the given node called its children. Edge: connection between one node to another. Leaf: A node that has no children is called a leaf. There can be only one root in a tree but there can be many leaves. Level: The level of a node is defined by 1 + the number of connections between the node and the root. Path: – a sequence of nodes and edges connecting a node with a descendant. Height of node – The height of a node is the number of edges on the longest downward path between that node and a leaf. Height of tree –The height of a tree is the number of edges on the longest downward path between the root and a leaf. Depth –The depth of a node is the number of edges from the node to the tree’s root node. complexityinsertion, 平均 O(logN)，左树找到 SPOT,右树找到 SPOT,一次砍一半，就是 O(logN)deletion,平均情况 O(logN)多一些，先搜索到元素，O(logN)，没找到就 end，找到，分 4 种，记录元素是 left 还是 right leaf parent 对应指针指到 null 仅有左边 child，parent 对应指针指到左 child,元素指针全部删除 仅有右边 child，parent 对应指针指到右 child,元素指针全部删除 有左右两个 child，先找 successor，就是右子树的最小严肃，从要删除的元素往下一路向左，找到最左元素，定为 successor，然后如果 successor 有右树，将其连到 parent 的左树上，successor 新的右树，连到被删除元素的右树上。 Binary search tree 二叉搜索树二叉搜索树每个节点比其左子树元素大，比其右子树元素小。 The left subtree of a node contains only nodes with keys less than node’s key.The right subtree of a node contains only nodes with keys greater than node’s key. 二叉搜索树的作用：保持元素顺序，相当于是一个排序好的 list，插入删除操作，比排序的 list 快，维护元素顺序或对元素排序时，非常适用。 Balanced binary tree 平衡树树结构越接近一个链条，各操作就越像线性结构，就越失去了树结构独特的优势，所以引入了平衡树 遍历方法 深度优先（DFS）先根(preorder)，中根(inorder)，后根(postorder) 广度优先（BFS）优先遍历完同层，是一个 queue 结构，先 dequeue 根节点 q，按照层序 enqueue 其 children，visit(q)然后 dequeue 根部新根节点。继续 enqueue，重复刀 dequeue 空为止。所有 node 都被 enqueue 和 dequeue 一遍，复杂度是 O(2n)，即 O(n) stack &amp; DFS先根(144.Binary Tree Preorder Traversal)注意 conner case root==None 的时候返回的是[],不是 root(None)。1234567891011121314151617# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def preorderTraversal(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: List[int] &quot;&quot;&quot; if root is None: return [] else: return [root.val]+self.preorderTraversal(root.left)+self.preorderTraversal(root.right) 中根(94.Binary Tree Inorder Traversal)123456789class Solution(object): def inorderTraversal(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: List[int] &quot;&quot;&quot; if root is None: return [] return self.inorderTraversal(root.left)+[root.val]+self.inorderTraversal(root.right) 后根(145.Binary Tree Postorder Traversal)123456789class Solution(object): def postorderTraversal(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: List[int] &quot;&quot;&quot; if root is None: return [] return self.postorderTraversal(root.left)+self.postorderTraversal(root.right)+[root.val] queue &amp; BFS(102. Binary Tree Level Order Traversal)ProblemGiven a binary tree, return the level order traversal of its nodes’ values. (ie, from left to right, level by level).For example:Given binary tree [3,9,20,null,null,15,7], 3 / \\ 9 20/ \\15 7return its level order traversal as:[[3],[9,20],[15,7]] 遍历当前的 queue, 把每个 node value 存到 list，将每个 node 的 left 和 right node 存到 queue，遍历完后将当前 list 加进 result 里。问题是怎么遍历当前 queue，通过纪录每个 layer（也就是 queue）的长度来实现。corner case: root == None, return [] Time complexity: O(n)，每个 node enqueue 一次，dequeue 一次Space complexity: O(n)，worst space,最后一次，满树，大概 O(n/2) Solution123456789101112131415161718192021def levelOrder(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: List[List[int]] &quot;&quot;&quot; if not root: return [] q = deque([root]) result = [] while q: layer = [] size = len(q) for i in range(size): node = q.popleft() layer.append(node.val) if node.left: q.append(node.left) if node.right: q.append(node.right) result.append(layer) return result 解题策略Divide and conquer树和图的很多问题，可以分解成子问题递归求解（divide and conquer），一般思路是综合节点本身，左子树，右子树三方的局部解得到全局解。 要注意的是，传节点的时候 设置出口，ending case，一般是 node==None； Recursive down Return up Current layer 构造递归的时候，可以 suppose all subtrees are handled. 特定路径的问题关于寻找特定路径的问题，通常需要回溯思想，我们往往需要设计一个 helper function，传入当前节点和其它需要记录的参数。 树和其他数据结构的相互转换树 –&gt; 其它数据结构：树的遍历，合并局部解来得到全局解其它数据结构 –&gt; 树：递归将数据结构的两部分分别转换成子树，再合并。 寻找特定节点此类题目通常会传入一个当前节点，要求找到与此节点具有一定关系的特定节点：例如前驱、后继、左／右兄弟等。 对于这类题目，首先可以了解一下常见特定节点的定义及性质。在存在指向父节点指针的情况下，通常可以由当前节点出发，向上倒推解决。如果节点没有父节点指针，一般需要从根节点出发向下搜索，搜索的过程就是DFS。 注意点Error control: 确定 node.left, node.right 是否为 None，尤其是 leverl order traversal 中。 connection between nodes 在原来的 tree 上更改箭头，这样更清楚要不要抛弃某些箭头。 例题101. Symmetric TreeProblemGiven a binary tree, check whether it is a mirror of itself (ie, symmetric around its center). For example, this binary tree [1,2,2,3,4,4,3] is symmetric: 1 / \\ 2 2 / \\ / \\3 4 4 3But the following [1,2,2,null,3,null,3] is not: 1 / \\ 2 2 \\ \\ 3 3Note:Bonus points if you could solve it both recursively and iteratively. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899&apos;&apos;&apos;Solution:- primitive idea: level order traversal, use deque, check popleft()==pop(), but should consider how to handle [1,2,2,null,3,null,3], the easiest way is to treat it as a complete tree, keep None there this is two-pass solution, with O(n) space complexity and O(n) time complexity- make it one-passFollowup:- without stack: use recursive&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Nonefrom collections import dequeclass Solution(object): def isSymmetric(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: bool &quot;&quot;&quot; if not root: return True return self.helper(root.left, root.right) def helper(self, left, right): if not left or not right: if left == right: return True else: return False if left.val == right.val: return self.helper(left.left, right.right) and self.helper(left.right, right.left) return False &apos;&apos;&apos; # two-pass solution with deque def isSymmetric(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: bool &quot;&quot;&quot; if not root: return True # level order traversal result=deque() queue=deque([root]) while queue: size=len(queue) layer=deque() for i in range(size): node=queue.popleft() if not node: layer.append(None) continue layer.append(node.val) queue.append(node.left) queue.append(node.right) result.append(layer) # pop root and last level(all None) result.popleft() result.pop() while result: layer=result.pop() while layer: if layer.pop()!=layer.popleft(): return False return True &apos;&apos;&apos; &apos;&apos;&apos; # one-pass solution with deque def isSymmetric(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: bool &quot;&quot;&quot; if not root: return True queue=deque([root.left,root.right]) while queue: left=queue.popleft() right=queue.pop() if not left and not right: continue if not left or not right or left.val!=right.val: return False queue.appendleft(left.left) queue.appendleft(left.right) queue.append(right.right) queue.append(right.left) return True &apos;&apos;&apos; 156. Binary tree upside downProblemGiven a binary tree where all the right nodes are either leaf nodes with a sibling (a left node that shares the same parent node) or empty, flip it upside down and turn it into a tree where the original right nodes turned into left leaf nodes. Return the new root.For example:Given a binary tree {1,2,3,4,5}, 1 / \\ 2 3/ \\4 5return the root of the binary tree [4,5,2,#,#,3,1]. 4 / \\ 5 2 / \\ 3 1 Assumption: input tree is validConner Case: Null root –&gt; Null new root SolutionStack 解法Time compexity: O(n)Space complexity: O(n/2)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&apos;&apos;&apos;Solution:- with stack: store all nodes along the left path in a stack, and flit it. root=&gt;root.left, root.left=&gt;root.right, root.right=&gt;root- recursive: assume lower layers are handled (we can pass root.left as parameter and call the function till leftmost node), handle current layer onlyAttention:- draw connection between nodes at original tree, so that you won&apos;t forget to clear pointers after each flip, and transfer root control.&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Nonedef upsideDownBinaryTree(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: TreeNode &quot;&quot;&quot; if not root: return root stack = [] # store all nodes along the path in stack while root: stack.append(root) root = root.left # start from leftmost leaf newRoot = stack.pop() head = newRoot while stack: parent = stack.pop() head.left = parent.right # parent head.right = parent head = parent parent.left = None parent.right = None return newRoot Recursive 解法Identical subproblem, lower level first通过 root.left 过渡到下一个子问题，从下往上12345678910111213141516171819def upsideDownBinaryTree(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: TreeNode &quot;&quot;&quot; # stop case if not root or not root.left: return root # assume all lower levels are handled newRoot = self.upsideDownBinaryTree(root.left) # handle current level root.left.left = root.right root.left.right = root root.left = None root.right = None return newRoot 98. Valid binary search treeProblemGiven a binary tree, determine if it is a valid binary search tree (BST).Assume a BST is defined as follows:The left subtree of a node contains only nodes with keys less than the node’s key.The right subtree of a node contains only nodes with keys greater than the node’s key.Both the left and right subtrees must also be binary search trees.Example 1: 2 / \\ 1 3Binary tree [2,1,3], return true.Example 2: 1 / \\ 2 3 SolutionInorder traversal根据二叉搜索树的性质，我们知道二叉搜索树中序遍历之后是一个 sorted list，所以最直观的方法就是中序遍历存到一个 list，然后看它是不是 sorted。这样的空间复杂度是 O(N)，时间复杂度由排序算法决定。 Global max用 global max 能让空间复杂度变成 O(1)？这个还不知道。。12345678910111213141516171819202122232425262728# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def isValidBST(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: bool &quot;&quot;&quot; if not root: return True list = self.getList(root) max = float(&apos;inf&apos;) while list: node = list.pop() if node &gt;= max: return False max = node return True def getList(self, root): if not root: return [] return self.getList(root.left)+[root.val]+self.getList(root.right) Range分解子问题，每一个 node 都大于它的 left child 并且小于它的 right child。所以可以写一个 helper function，传入 (node, min, max) 来判断 node 在不在正确的区间里。主要问题如下： how to compare cross-layer how to get a valid range for each nodeimplementation: pass parameter top-to-bottom, helper(current_node,min,max) 注意小知识点，python 里找 float 的最小值，float(‘-inf’)，最大值，float(‘inf’) 1234567891011121314class Solution(object): def isValidBST(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: bool &quot;&quot;&quot; def isBST(root, max=float(&apos;inf&apos;), min=float(&apos;-inf&apos;)): if not root: return True if root.val &gt;= max or root.val &lt;= min: return False return isBST(root.left, root.val, min) and isBST(root.right, max, root.val) return isBST(root) 333. Largest BST SubtreeProblemGiven a binary tree, find the largest subtree which is a Binary Search Tree (BST), where largest means subtree with largest number of nodes in it. Note:A subtree must include all of its descendants.Here’s an example: 10 / \\ 5 15 / \\ \\ 1 8 7The Largest BST Subtree in this case is the highlighted one.The return value is the subtree’s size, which is 3. Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&apos;&apos;&apos;Solution: brute-force: O(n^2)Followup: make it O(n) Current layer: if both left subtree and right subtree are BST and left.max&lt;=root.val&lt;=right.min,then current subtree is BST and size=left.size+right.size+1,else,current subtree is not BST and size=max(left.size,right.size) Recursive down: base case: if not root recursive case: left=recursive(root.left), right=recursive(root.right) Return up: return res which includes: - isBST: if current subtree is BST - max: max value of left subtree - min: min value of right subtree&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): &apos;&apos;&apos; brute-force: O(n^2) def largestBSTSubtree(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: int &quot;&quot;&quot; def isBST(root, max=float(&apos;inf&apos;), min=float(&apos;-inf&apos;)): if not root: return True if root.val &gt;= max or root.val &lt;= min: return False return isBST(root.left, root.val, min) and isBST(root.right, max, root.val) def size(root): if not root: return 0 return size(root.left) + size(root.right) + 1 if isBST(root): return size(root) return max(self.largestBSTSubtree(root.left), self.largestBSTSubtree(root.right)) &apos;&apos;&apos;class Solution(object): def largestBSTSubtree(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: int &quot;&quot;&quot; class Result(object): def __init__(self,myMax=float(&apos;-inf&apos;),myMin=float(&apos;inf&apos;)): self.isBST=True self.max=myMax self.min=myMin self.size=0 def recursive(root): res=Result() # base case if not root: return res # recursive case left=recursive(root.left) right=recursive(root.right) res.max=max(root.val,right.max) res.min=min(root.val,left.min) # current layer if left.isBST and right.isBST and left.max&lt;=root.val and right.min&gt;=root.val: res.size=left.size+right.size+1 res.isBST=True else: res.isBST=False res.size=max(left.size,right.size) return res res= recursive(root) return res.size 298. Binary Tree Longest Consecutive SequenceProblemGiven a binary tree, find the length of the longest consecutive sequence path.The path refers to any sequence of nodes from some starting node to any node in the tree along the parent-child connections. The longest consecutive path need to be from parent to child (cannot be the reverse).For example, 1 \\ 3 / \\ 2 4 \\ 5Longest consecutive sequence path is 3-4-5, so return 3. 2 \\ 3 / 2 / 1Longest consecutive sequence path is 2-3,not3-2-1, so return 2. 直接想到的是，preorder 遍历，得到 list，用 count 更新 current max。然而这是有问题的！以 example 为例，遍历后的 list 是 [1,3,2,4,5],它把 2,4 连起来了，但是 2,4 属于不同的分支，所以不能这么做。 换一种思路，用 recursion 的方法，左子树的 max length, 右子树的 max length，和本身目前的 max length，求最大值。 第一个传进去的是什么？float(‘inf’) Solution1234567891011121314151617181920212223&apos;&apos;&apos;recurse downhelper(node.left, global_max, node.val)helper(node.right, global_max, node.val)return upmax (curr_lengh, left_max_length, right_max_length)current levelglobal_max = node.val == lastVal + 1 : length + 1 : 1&apos;&apos;&apos;class Solution(object): def longestConsecutive(self, root): if not root: return 0 return self.helper(root, 1, float(&apos;inf&apos;)) def helper(self, node, global_max, lastVal): if not node: return global_max global_max = global_max + 1 if node.val == lastVal + 1 else 1 return max(global_max, self.helper(node.left, global_max, node.val), self.helper(node.right, global_max, node.val)) 待补充trie or prefix tree，full binary tree，complete binary tree，heap 222. Count Complete Tree NodesProblemGiven a complete binary tree, count the number of nodes. Definition of a complete binary tree from Wikipedia:In a complete binary tree every level, except possibly the last, is completely filled, and all nodes in the last level are as far left as possible. It can have between 1 and 2h nodes inclusive at the last level h. SolutionTime complexity: O(h^2)12345678910111213141516171819202122232425262728293031323334353637383940414243444546&apos;&apos;&apos;Primitive idea: traversal, BFS, DFS(preorder, inorder, postorder), takes O(n) time.Faster: List all posibilities of a complete trees and we can conlude there&apos;re two cases one is the height of left subtree equals that of right subtree, in this case, the right subtree is always full, another case is that the height of left subtree is smaller than that of right subtree, then the left subtree is full. It&apos;s easy to count the nodes of full tree. We can use recursive method to solve this problem. That is, if height(left)==height(right): count(root)=2**leftH-1+1+count(root.right) else: count(root)==2**rightH-1+1+count(root.left) Time complexity: O(logn^2)Tips: 1&lt;&lt;h is faster than 2**h but remember to use () due to precedence be careful about getHeight method if not root should return -1 instead of 0&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def countNodes(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: int &quot;&quot;&quot; def getHeight(root): if not root: return-1 return getHeight(root.left) + 1 # base case if not root: return 0 # recursive case leftH = getHeight(root) rightH = getHeight(root.right) + 1 # left subtree is full if leftH == rightH: return (1 &lt;&lt; leftH) + self.countNodes(root.right) # right subtree is full else: return (1 &lt;&lt; rightH) + self.countNodes(root.left) 270. Closest Binary Search Tree ValueProblemGiven a non-empty binary search tree and a target value, find the value in the BST that is closest to the target. Note:Given target value is a floating point.You are guaranteed to have only one unique value in the BST that is closest to the target. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&apos;&apos;&apos;- Solution: keeps a global closest variable and update it when doing the search. Time complexity: O(logN). Space complexity: O(1)&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): def closestValue(self, root, target): &quot;&quot;&quot; :type root: TreeNode :type target: float :rtype: int &quot;&quot;&quot; if not root: return None closest=root.val diff=abs(root.val-target) while root: if abs(root.val-target)&lt;diff: diff=abs(root.val-target) closest=root.val root=root.right if root.val&lt;target else root.left return closest &apos;&apos;&apos; def closestValue(self, root, target): &quot;&quot;&quot; :type root: TreeNode :type target: float :rtype: int &quot;&quot;&quot; if not root: return None if not root.left and not root.right: return root.val def inorderTraversal(root): if not root: return [] return inorderTraversal(root.left)+[root.val]+inorderTraversal(root.right) vals=inorderTraversal(root) for i in range(len(vals)): if target&lt;vals[i]: if abs(target-vals[i])&lt;abs(target-vals[i-1]): return vals[i] else: return vals[i-1] return vals[-1] &apos;&apos;&apos; 272. Closest Binary Search Tree Value IIProblemGiven a non-empty binary search tree and a target value, find k values in the BST that are closest to the target. Note:Given target value is a floating point.You may assume k is always valid, that is: k ≤ total nodes.You are guaranteed to have only one unique set of k values in the BST that are closest to the target.Follow up:Assume that the BST is balanced, could you solve it in less than O(n) runtime (where n = total nodes)? Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&apos;&apos;&apos;assume k is smaller than the # of nodes in BSTWrong solution: Recall Closest Binary Search Tree Value I, maybe we can maintain a k-size of diff priorityqueue and k-size of closest priorityqueue and do the pop and push the same way as problem I? -&gt; We can do that but only when H&gt;=k where H is the height of BST, but when H&lt;k, we should add more values into closest, it&apos;s hard to decide or to track these nodes because we may need to access the predecessors. -&gt; So we may think of two helper function getSuccessor, getPredecessor,- Solution 1: - have an in-order traversal and get a sorted array, then find the closest value to the target in the sorted array, and look forward and backwards to get k closest values. - or, same idea, have two stacks one stores the values that are smaller than the target, and the other stores the values that are larger than the target, and finally merge it - O(n) time complexity- Solution 2: - first find the closest value cur to target, while k&lt;0, find the closest smaller value to the cur and the closest larger value to the cur, compare them to find the the closest value to the target and add it to the result list till there&apos;re k values in the result - O(klogn) time complexityCorner case: - Solution 1 must consider case when target&lt;0&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Nonefrom collections import dequeclass Solution(object): # O(klogn) def closestKValues(self, root, target, k): &quot;&quot;&quot; :type root: TreeNode :type target: float :type k: int :rtype: List[int] &quot;&quot;&quot; if not root: return None closest=self.getClosestVal(root,target) res=[closest.val] k-=1 # merge k values s=self.getSmaller(root,closest.val) l=self.getLarger(root,closest.val) while k&gt;0: if not s: res.append(l.val) l=self.getLarger(root,l.val) elif not l: res.append(s.val) s=self.getSmaller(root,s.val) elif abs(s.val-target)&lt;abs(l.val-target): res.append(s.val) s=self.getSmaller(root,s.val) else: res.append(l.val) l=self.getLarger(root,l.val) k-=1; return res def getSmaller(self,root,t): s=None while root: if root.val&lt;t: s=root root=root.right else: root=root.left return s def getLarger(self,root,t): l=None while root: if root.val&gt;t: l=root root=root.left else: root=root.right return l def getClosestVal(self,root,target): closest=root diff=abs(root.val-target) while root: if abs(root.val-target)&lt;diff: diff=abs(root.val-target) closest=root root=root.right if root.val&lt;target else root.left return closest &apos;&apos;&apos; # O(n) def closestKValues(self, root, target, k): &quot;&quot;&quot; :type root: TreeNode :type target: float :type k: int :rtype: List[int] &quot;&quot;&quot; if not root: return None def dfs(root): if not root: return [] return dfs(root.left)+[root.val]+dfs(root.right) values=dfs(root) # get smaller values and larger values res,smaller,larger=[],[],[] for v in values: if v&lt;target: smaller.append(v) elif v&gt;target: larger.append(v) else: res.append(v) k-=1 # merge k values if target&lt;0: smaller=smaller[::-1] larger=larger[::-1] while k&gt;0: if not smaller: res.append(larger.pop()) elif not larger: res.append(smaller.pop()) elif abs(smaller[-1]-target)&lt;abs(larger[-1]-target): res.append(smaller.pop()) else: res.append(larger.pop()) k-=1; return res &apos;&apos;&apos; 366. Find Leaves of Binary TreeProblemGiven a binary tree, collect a tree’s nodes as if you were doing this: Collect and remove all leaves, repeat until the tree is empty. Example:Given binary tree 1 / \\ 2 3 / \\ 4 5Returns [4, 5, 3], [2], [1]. Explanation:1.Removing the leaves [4, 5, 3] would result in this tree: 1 / 2 2.Now removing the leaf [2] would result in this tree: 1 3.Now removing the leaf [1] would result in the empty tree: [] Returns [4, 5, 3], [2], [1]. Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&apos;&apos;&apos;Solution: brute-force string encoding(preorder): 124##5##3##Followup: make it O(n) nodes with the same height should be leaves for each turn&apos;&apos;&apos;# Definition for a binary tree node.# class TreeNode(object):# def __init__(self, x):# self.val = x# self.left = None# self.right = Noneclass Solution(object): &apos;&apos;&apos; def findLeaves(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: List[List[int]] &quot;&quot;&quot; if not root: return [] def getHeight(root): if not root: return 0 return max(getHeight(root.left),getHeight(root.right))+1 def traverse(root): global res if not root: return 0 lev=max(traverse(root.left),traverse(root.right))+1 res[lev-1].append(root.val) return lev global res h=getHeight(root) res=[list() for i in range(h)] traverse(root) return res &apos;&apos;&apos; def findLeaves(self, root): &quot;&quot;&quot; :type root: TreeNode :rtype: List[List[int]] &quot;&quot;&quot; if not root: return [] def traverse(root, res): if not root: return 0 lev = max(traverse(root.left, res), traverse(root.right, res)) + 1 res[lev].append(root.val) return lev res = collections.defaultdict(list) traverse(root, res) return res.values() 307. Range Sum Query - Mutable (Binary indexed tree)ProblemGiven an integer array nums, find the sum of the elements between indices i and j (i ≤ j), inclusive. The update(i, val) function modifies nums by updating the element at index i to val.Example:Given nums = [1, 3, 5] sumRange(0, 2) -&gt; 9update(1, 2)sumRange(0, 2) -&gt; 8Note:The array is only modifiable by the update function.You may assume the number of calls to update and sumRange function is distributed evenly. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&apos;&apos;&apos;update: O(1)sumRange: O(n)class NumArray(object): def __init__(self, nums): &quot;&quot;&quot; initialize your data structure here. :type nums: List[int] &quot;&quot;&quot; self.nums=nums def update(self, i, val): &quot;&quot;&quot; :type i: int :type val: int :rtype: int &quot;&quot;&quot; self.nums[i]=val def sumRange(self, i, j): &quot;&quot;&quot; sum of elements nums[i..j], inclusive. :type i: int :type j: int :rtype: int &quot;&quot;&quot; return sum(self.nums[i:j+1]) &apos;&apos;&apos;&apos;&apos;&apos;Use self.bit to represent Binary Indexed Tree. Section sums are stored in self.c[1..len(nums)]. x &amp; -x is lowbit function, which will return x&apos;s rightmost bit 1, e.g. lowbit(7) = 1, lowbit(20) = 4.Both update and sumRange takes O(logn) time.See http://www.cnblogs.com/grandyang/p/4985506.html&apos;&apos;&apos;class NumArray(object): def __init__(self, nums): self.n = len(nums) self.nums, self.bit = [0] * (self.n + 1), [0] * (self.n + 1) for i,n in enumerate(nums): self.update(i,n) def update(self, i, val): diff, self.nums[i] = val - self.nums[i], val i += 1 while i &lt;= self.n: self.bit[i] += diff i += (i &amp; -i) def sumRange(self, i, j): res, j = 0, j + 1 while j: res += self.bit[j] j -= (j &amp; -j) while i: res -= self.bit[i] i -= (i &amp; -i) return res","tags":"树"},{"title":"Search Engines笔记 - Query Processing","url":"/2016/09/11/Search Engines笔记 - Query Processing/","text":"CMU 11642 的课程笔记。搜索引擎是怎么处理 query 的？三种方法，Term-at-a-time(TAAT)，Document-at-a-time(DAAT)，TAAT/DAAT hybrids。 TAAT主要思路： 处理完一个 inverted list 再处理下一个。 每处理完一个 inverted list，部分更新 document score。 优点： 易于理解 高效 缺点： 难以控制内存每个 operator 都会同时在内存里存 3 个 list(arg1,arg2,result)每个深度为 d 的 query 都会同时在内存里存 d+2 个 list。 可能会 run out of memory包含有 frequent term 的 query (很长的 inverted list)复杂的 query (更多的 inverted list)同时处理多个 query 的系统 所以 TAAT 很少用在 large-scale systems。 Eg.#AND(a b #OR (c #NEAR/3(d e)) f)转化成 query tree1234 AND(a b OR f) (c NEAR/3 (d e)) 1234567891011Retrieve aRetrieve ba AND b -&gt; Result(AND_1)Retrieve cRetrieve dRetrieve ed NEAR/3 e -&gt; Result(NEAR)c OR Result(NEAR) -&gt; Result(OR)Result(AND_1) AND Result(OR) -&gt; Result(AND_2)Retrieve fResult(AND_2) AND f -&gt; Result(Q) Memory usage内存中同时存在 5 个 list123size(a AND b) +size(c) +size(d) + size(e) + size(d NEAR/3 e) bytes DAAT主要思路： 处理完一篇文档后，再处理下一篇文档。 每处理一篇文档，就算出 complete score 找到所有 term 的 inverted list，每个 inverted list 分配一个 iterator，分配一个空的 result list。之后找到每个 inverted list 当前的 doc id，取最小的 doc id，算出当前分数，保存到 result list 中，然后把这个 iterator 往下移一个 doc id，重复这个过程。 简化一下，主要就重复两件事： update the score advance the pointer 代码描述123q.initialize()while (q.hasNext()) q.evalNext() returns next [docid,score] tuple 优点： 易于进行内存管理需要同时 access 所有 args 的 inverted list (seems bad)，然而，这些 inverted list 可以以 block 的形式分批从 disk 读进 RAM。等当前 block 处理完了再读下一个 block，这样处理一个 query 所需的内存就取决于 block 的大小。 可以进行很多 query evaluation 的优化低分文档只进行 partial evaluation 所以 TAAT 经常用在 large-scale systems。 TAAT/DAAT hybrids平衡 Efficiency 和 memory control。Eg. block-based TAAT(compute TAAT over blocks of document ids)","tags":"nlp search-engines 信息检索"},{"title":"数据结构和算法 -- 栈和队列","url":"/2016/09/08/数据结构和算法 -- 栈和队列/","text":"Stack implementation实现一个 stack 可以用两种数据结构，array(dynamic or fixed) 或者是 linked list。 dynamic array 的优势是支持 random access，因为可以通过 index 获取数据，然而 stack 主要作用是 pop，所以 dynamic array 的这个优势 gains you little。dynamic array 另一个优势是 resize，这个非常的 time-consuming 因为需要 copy array to a new one。 linked list 会为每一个元素分配内存，这比 dynamic array 的 resize 更费时，因此基于 dynamic array 的 stack 通常要比基于 linked list 的 stack 快一些。然而，基于 linked list 的 stack 更容易实现。 Proper functionality基本方法： pushallocate new element, checks for failure, sets the data of the new element, places it at the top of the stack, adjust the stack pointer popcheck the stack isn’t empty, fetches data from top element, adjusts the stack pointer, free the element that is no longer on the stack 完整方法： createStackpush a null pointer deleteStackcall pop repeatedly Error handling pop如果 stack 为空，返回 null? 问题是需要保证 stack 里没有存 null pointer；返回 special value(or negative value)？问题是需要 assume stack 里没有这些元素。感觉 raise error 比较简单。 push如果传进去的值为 null，raise error 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# implement a stack using linkedlistclass Stack(object): class Node(object): def __init__(self, val=None, next=None): self.val = val self.next = next def __init__(self): self.head = None &apos;&apos;&apos; check the stack isn&apos;t empty, fetches data from top element, adjusts the stack pointer, free the element that is no longer on the stack &apos;&apos;&apos; def pop(self): if not self.head: raise ValueError(&quot;Empty stack!&quot;) val = self.head.val self.head = self.head.next return val &apos;&apos;&apos; allocate new element, checks for failure, sets the data of the new element, places it at the top of the stack, adjust the stack pointer &apos;&apos;&apos; def push(self, val): if not val: raise ValueError(&quot;Invalid value!&quot;) node = self.Node(val, self.head) self.head = node&apos;&apos;&apos;push a null pointer&apos;&apos;&apos;def createStack(stack): stack.head = Node() return True&apos;&apos;&apos;call pop repeatedly&apos;&apos;&apos;def deleteStack(stack): while stack.head: stack.pop() return Truestack=Stack()stack.push(1)stack.push(2)stack.push(3)print stack.pop()print stack.pop()print stack.pop()print stack.pop() 12345678910111213141516171819202122232425262728293031323334# implement a stack using fixed-size arrayclass Stack(object): def __init__(self, capacity=None): if capacity: self.elements = [None] * capacity else: self.elements = [None] * 10 # set the top to be -1, indicating the stack is empty self.top = -1 def isEmpty(self): return self.top == -1 def push(self, item): if self.top == len(self.elements): raise ValueError(&quot;Full stack!&quot;) self.top += 1 self.elements[self.top] = item def pop(self): if self.isEmpty(): raise ValueError(&quot;Empty stack!&quot;) # get the element on the top item = self.elements[self.top] self.elements[self.top] = None # reduce the top variable self.top -= 1 return item def peek(self): if self.isEmpty(): raise ValueError(&quot;Empty stack!&quot;) return self.elements[self.top] Queue implementation12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# implement a queue using fixed-size arrayclass Queue(object): def __init__(self, capacity=None): if capacity: self.elements = [None] * capacity else: self.elements = [None] * 5 self.front = 0 self.back = -1 self.nItems = 0 def enqueue(self, item): if self.isFull(): raise ValueError(&quot;Queue is full&quot;) self.back += 1 index = self.back % len(self.elements) self.elements[index] = item self.nItems += 1 def dequeue(self): if self.isEmpty(): raise ValueError(&quot;Queue is empty&quot;) index = self.front % len(self.elements) result = self.elements[index] self.elements[index] = None self.front = index + 1 self.nItems -= 1 return result def peekFront(self): if self.isEmpty(): raise ValueError(&quot;Queue is empty&quot;) return self.elements[self.front % len(self.elements)] def isEmpty(self): return self.nItems == 0 def isFull(self): return self.nItems == len(self.elements)q=Queue()q.enqueue(4)q.enqueue(5)q.enqueue(6)print q.elementsq.dequeue()print q.elementsq.dequeue()print q.elementsq.enqueue(10)q.enqueue(11)q.enqueue(12)print q.elements Leetcode 实例232.Implement Queue using StacksProblemImplement the following operations of a queue using stacks.push(x) – Push element x to the back of queue.pop() – Removes the element from in front of queue.peek() – Get the front element.empty() – Return whether the queue is empty.Notes:You must use only standard operations of a stack – which means only push to top, peek/pop from top, size, and is empty operations are valid.Depending on your language, stack may not be supported natively. You may simulate a stack by using a list or deque (double-ended queue), as long as you use only standard operations of a stack.You may assume that all operations are valid (for example, no pop or peek operations will be called on an empty queue). Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Queue(object): def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack1=list() self.stack2=list() def push(self, x): &quot;&quot;&quot; :type x: int :rtype: nothing &quot;&quot;&quot; self.stack1.append(x) def pop(self): &quot;&quot;&quot; :rtype: nothing &quot;&quot;&quot; self.helper() return self.stack2.pop() def peek(self): &quot;&quot;&quot; :rtype: int &quot;&quot;&quot; self.helper() &apos;&apos;&apos; element=self.stack2.pop() self.stack2.append(element) return element &apos;&apos;&apos; return self.stack2[-1] def empty(self): &quot;&quot;&quot; :rtype: bool &quot;&quot;&quot; if self.stack1 or self.stack2: return False return True def helper(self): if not self.stack2: while self.stack1: self.stack2.append(self.stack1.pop()) 225.Implement Stack using QueuesProblemImplement the following operations of a stack using queues.push(x) – Push element x onto stack.pop() – Removes the element on top of the stack.top() – Get the top element.empty() – Return whether the stack is empty.Notes:You must use only standard operations of a queue – which means only push to back, peek/pop from front, size, and is empty operations are valid.Depending on your language, queue may not be supported natively. You may simulate a queue by using a list or deque (double-ended queue), as long as you use only standard operations of a queue.You may assume that all operations are valid (for example, no pop or top operations will be called on an empty stack).Update (2015-06-11):The class name of the Java function had been updated to MyStack instead of Stack. 用两个队列，push: O(n)，pop: O(1)，top: O(1) Solution1234567891011121314151617181920212223242526272829303132333435363738394041from collections import dequeclass Stack(object): def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.queue1=deque() self.queue2=deque() def push(self, x): &quot;&quot;&quot; :type x: int :rtype: nothing &quot;&quot;&quot; if not self.queue2: self.queue2.append(x) while self.queue1: self.queue2.append(self.queue1.popleft()) self.queue1,self.queue2=self.queue2,self.queue1 def pop(self): &quot;&quot;&quot; :rtype: nothing &quot;&quot;&quot; self.queue1.popleft() def top(self): &quot;&quot;&quot; :rtype: int &quot;&quot;&quot; return self.queue1[0] def empty(self): &quot;&quot;&quot; :rtype: bool &quot;&quot;&quot; if not self.queue1: return True return False 155. Min StackProblemDesign a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) – Push element x onto stack.pop() – Removes the element on top of the stack.top() – Get the top element.getMin() – Retrieve the minimum element in the stack.Example:12345678MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin(); --&gt; Returns -3.minStack.pop();minStack.top(); --&gt; Returns 0.minStack.getMin(); --&gt; Returns -2. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104&apos;&apos;&apos;Solution: Primitive idea would be to use a global varible to record current minimum value when push, but when pop value, the minimum value may change. One solution is when pop we empty the list and redo the push action for n-1 values but thus it takes O(n) time.Followup: It would be perfect if we can keep track of the minmum value at each &apos;timestamp&apos;. We can use tuple to record current minimum value for each value when push a new element.&apos;&apos;&apos;&apos;&apos;&apos;class MinStack(object): def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack=list() self.min=float(&apos;inf&apos;) def push(self, x): &quot;&quot;&quot; :type x: int :rtype: void &quot;&quot;&quot; self.stack.append(x) self.min=min(self.min,x) def pop(self): &quot;&quot;&quot; :rtype: void &quot;&quot;&quot; if not self.stack: return None if self.top()==self.min: cur=self.stack[::] self.stack=[] self.min=float(&apos;inf&apos;) for i in range(len(cur)-1): self.push(cur[i]) else: del self.stack[-1] def top(self): &quot;&quot;&quot; :rtype: int &quot;&quot;&quot; if not self.stack: return None return self.stack[-1] def getMin(self): &quot;&quot;&quot; :rtype: int &quot;&quot;&quot; return self.min&apos;&apos;&apos;class MinStack(object): def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack=list() def push(self, x): &quot;&quot;&quot; :type x: int :rtype: void &quot;&quot;&quot; if not self.stack: self.stack.append((x,x)) return self.stack.append((x,min(x,self.getMin()))) def pop(self): &quot;&quot;&quot; :rtype: void &quot;&quot;&quot; if not self.stack: return None return self.stack.pop()[0] def top(self): &quot;&quot;&quot; :rtype: int &quot;&quot;&quot; if not self.stack: return None return self.stack[-1][0] def getMin(self): &quot;&quot;&quot; :rtype: int &quot;&quot;&quot; return self.stack[-1][-1]# Your MinStack object will be instantiated and called as such:# obj = MinStack()# obj.push(x)# obj.pop()# param_3 = obj.top()# param_4 = obj.getMin() 20.Valid ParenthesesProblemGiven a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid. The brackets must close in the correct order, “()” and “()[]{}” are all valid but “(]” and “([)]” are not. Solution123456789101112131415161718192021222324&apos;&apos;&apos;Solution:- check when right meet; just need the last unpaired left =&gt; first in,last out =&gt; stack- create a dictionary for parenthese pairs, for each element in s, if it exists in dictionary.keys(), then append it into the stack, else, pop from the stack and check if the popped value and current element is a pair. Time complexity: O(n)- remember to check if stack is empty in every check and also in final check (look back for previous left parentheses)&apos;&apos;&apos;class Solution(object): def isValid(self, s): &quot;&quot;&quot; :type s: str :rtype: bool &quot;&quot;&quot; if not s: return None dictionary=&#123;&apos;(&apos;:&apos;)&apos;,&apos;[&apos;:&apos;]&apos;,&apos;&#123;&apos;:&apos;&#125;&apos;&#125; s=list(s) stack=[] for i in s: if i in dictionary: stack.append(i) else: if not stack or dictionary[stack.pop()]!=i: return False return not stack 150. Evaluate Reverse Polish NotationProblemEvaluate the value of an arithmetic expression in Reverse Polish Notation. Valid operators are +, -, *, /. Each operand may be an integer or another expression. Some examples: [“2”, “1”, “+”, “3”, “*“] -&gt; ((2 + 1) * 3) -&gt; 9 [“4”, “13”, “5”, “/“, “+”] -&gt; (4 + (13 / 5)) -&gt; 6 Solution12345678910111213141516171819202122232425262728293031&apos;&apos;&apos;Solution:- each operation requires two operands and one operator, operator always appear after operands, so we search element from left to right, store numbers in the stack till we meet up with an operator, and with the operator, we pop two elements from the stack and caculate the results and push it back to stack, and continue, till the end of tokens, finally return the final value of the stack.Attention(negative integer division):- division in python, pls consider when one of the operand is negative, you would get surprising result. eg. -7/2=-4. in order to avoid that, use int(float(a)/b) whenever there&apos;s a division operation&apos;&apos;&apos;class Solution(object): def evalRPN(self, tokens): &quot;&quot;&quot; :type tokens: List[str] :rtype: int &quot;&quot;&quot; stack=[] for t in tokens: if t==&apos;+&apos;: stack.append(stack.pop()+stack.pop()) elif t==&apos;-&apos;: a=stack.pop() b=stack.pop() stack.append(b-a) elif t==&apos;*&apos;: stack.append(stack.pop()*stack.pop()) elif t==&apos;/&apos;: a=stack.pop() b=stack.pop() stack.append(int(float(b)/a)) else: stack.append(int(t)) return stack.pop() Followup1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&apos;&apos;&apos;Followup:- infix notation ( =&gt; operator stack number =&gt; number stack ) =&gt; pop and calculate till a &apos;(&apos; is met +,- =&gt; higher precedence met-&gt; push into the operator stack, lower precedence met-&gt; calculate higher operator in stack first and then push- test case: input: [&quot;(&quot;,&quot;(&quot;,&quot;3&quot;,&quot;+&quot;,&quot;4&quot;,&quot;)&quot;,&quot;*&quot;,&quot;(&quot;,&quot;4&quot;,&quot;+&quot;,&quot;1&quot;,&quot;)&quot;,&quot;-&quot;,&quot;4&quot;,&quot;*&quot;,&quot;2&quot;,&quot;)&quot;,&quot;+&quot;,&quot;1&quot;] output: 28&apos;&apos;&apos;class Solution(object): def evalRPN(self,tokens): &quot;&quot;&quot; :type tokens: List[str] :rtype: int &quot;&quot;&quot; op_stack=[] num_stack=[] for i in tokens: # case &apos;(&apos; if i==&apos;(&apos;: op_stack.append(i) # case &apos;)&apos; elif i==&apos;)&apos;: while op_stack[-1]!=&apos;(&apos;: num_stack.append(self.cal(op_stack.pop(),num_stack.pop(),num_stack.pop())) op_stack.pop() # case &apos;+&apos;,&apos;-&apos;,&apos;*&apos;,&apos;/&apos; elif i==&apos;+&apos; or i==&apos;-&apos; or i==&apos;*&apos; or i==&apos;/&apos;: while op_stack and self.isLowerThan(i,op_stack[-1]): num_stack.append(self.cal(op_stack.pop(),num_stack.pop(),num_stack.pop())) op_stack.append(i) # case number else: num_stack.append(int(i)) while op_stack: num_stack.append(self.cal(op_stack.pop(),num_stack.pop(),num_stack.pop())) return num_stack.pop() def cal(self,op,num1,num2): if op==&apos;+&apos;: return num1+num2 if op==&apos;-&apos;: return num2-num1 if op==&apos;*&apos;: return num1*num2 if op==&apos;/&apos;: return int(float(num2)/num1) raise ValueError(&quot;Not valid operator&quot;) def isLowerThan(self,op1,op2): if (op1==&apos;+&apos; or op1==&apos;-&apos;) and (op2==&apos;*&apos; or op2==&apos;/&apos;): return True return False 71. Simplify PathProblemGiven an absolute path for a file (Unix-style), simplify it. For example,path = “/home/“, =&gt; “/home”path = “/a/./b/../../c/“, =&gt; “/c”click to show corner cases. Corner Cases:Did you consider the case where path = “/../“?In this case, you should return “/“.Another corner case is the path might contain multiple slashes ‘/‘ together, such as “/home//foo/“.In this case, you should ignore redundant slashes and return “/home/foo”. Solution12345678910111213141516171819202122&apos;&apos;&apos;Solution:- ignore &apos;.&apos;, when met &apos;..&apos;, pop from stack if stack is not empty, and finally join the stackAttention:- corner case: /../a =&gt; /a- always remember if you wanna pop from a stack check if it is empty first&apos;&apos;&apos;class Solution(object): def simplifyPath(self, path): &quot;&quot;&quot; :type path: str :rtype: str &quot;&quot;&quot; vals=path.split(&apos;/&apos;) stack=[] for v in vals: if v==&apos;&apos; or v==&apos;.&apos;: continue if v==&apos;..&apos;: if stack: stack.pop() else: stack.append(v) return &apos;/&apos;+&apos;/&apos;.join(stack) 84. Largest Rectangle in HistogramProblemGiven n non-negative integers representing the histogram’s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram. Above is a histogram where width of each bar is 1, given height = [2,1,5,6,2,3]. The largest rectangle is shown in the shaded area, which has area = 10 unit. For example,Given heights = [2,1,5,6,2,3],return 10. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&apos;&apos;&apos;Solution:- primitive idea: find all rectangles and get max one, time complexity O(n^2)Followup:- O(n)? - avoid repeated work - identify a rectangle: identify 2 boundaries - if cur&gt;stack.peek() --&gt; offer, else --&gt; continously pollCorner case: [0]&apos;&apos;&apos;class Solution(object): def largestRectangleArea(self, heights): &quot;&quot;&quot; :type heights: List[int] :rtype: int &quot;&quot;&quot; if not heights: return 0 stack=[] max_area=0 for i in range(len(heights)+1): cur=0 if i==len(heights) else heights[i] while stack and cur&lt;=heights[stack[-1]]: height=heights[stack.pop()] leftBound=0 if not stack else stack[-1]+1 rightBound=i cur_area=(rightBound-leftBound)*height max_area=max(cur_area,max_area) stack.append(i) return max_area &apos;&apos;&apos; # primitive, 2 loops def largestRectangleArea(self, heights): &quot;&quot;&quot; :type heights: List[int] :rtype: int &quot;&quot;&quot; if not heights: return 0 max_area=0 for i in range(len(heights)): max_area=max(heights[i],max_area) min_height=heights[i] for j in range(i,len(heights)): min_height=min(min_height,heights[j]) max_area=max(min_height*(j-i+1),max_area) return max_area &apos;&apos;&apos; Python stack &amp; deque这篇用到的 python 的知识点/需要注意的地方。 use lists as stacksLIFOadd, use append()retrieve, use pop()123456789101112131415&gt;&gt;&gt; stack = [3, 4, 5]&gt;&gt;&gt; stack.append(6)&gt;&gt;&gt; stack.append(7)&gt;&gt;&gt; stack[3, 4, 5, 6, 7]&gt;&gt;&gt; stack.pop()7&gt;&gt;&gt; stack[3, 4, 5, 6]&gt;&gt;&gt; stack.pop()6&gt;&gt;&gt; stack.pop()5&gt;&gt;&gt; stack[3, 4] use lists as queuesFIFO，python list 作 queue 并不 efficent，用 collections.deque12345678910&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; queue = deque([&quot;Eric&quot;, &quot;John&quot;, &quot;Michael&quot;])&gt;&gt;&gt; queue.append(&quot;Terry&quot;) # Terry arrives&gt;&gt;&gt; queue.append(&quot;Graham&quot;) # Graham arrives&gt;&gt;&gt; queue.popleft() # The first to arrive now leaves&apos;Eric&apos;&gt;&gt;&gt; queue.pop() # The second to arrive now leaves&apos;Graham&apos;&gt;&gt;&gt; queue # Remaining queue in order of arrivaldeque([&apos;John&apos;, &apos;Michael&apos;, &apos;Terry&apos;])","tags":"栈 队列"},{"title":"数据结构和算法 -- 排序算法","url":"/2016/09/07/数据结构和算法 -- 排序算法/","text":"往往排序是作为其他算法的预处理算法，其重要性却不容小觑。本篇讲冒泡排序／选择排序／插入排序／希尔排序／归并排序／快速排序／桶排序／计数排序。 概览 algorithm in-place worst average best space complexity remark bubble yes $N^2$ $N^2$ N $O(1)$ —— selection yes $N^2$ $N^2$ $N^2$ $O(1)$ —— insertion yes $N^2$ $N^2$ N $O(1)$ —— shell yes —– ——- N $O(1)$ —— merge $NlogN$ $NlogN$ $NlogN$ $O(N)$ —— quick yes $N^2$ $NlogN$ $NlogN$ $O(logN)$ —— heap yes $NlogN$ $NlogN$ $NlogN$ $O(1)$ —— Bubble sort 冒泡排序冒泡排序的原理非常简单，重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。内部稳定排序，时间复杂度 $O(N^2)$，空间复杂度 $O(1)$ 步骤： 比较相邻的元素。如果前一个比后一个大，就交换他们两个。 对第 0 个到第 n-1 个数据做同样的工作。这时，最大的数就“浮”到了数组最后的位置上。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 每轮操作都将一个最大的数“浮”到最后的位置，也就是每轮都有最后 N-i 个数已经排序，所以内循环是从 1 到 N-i。 基本款1234567891011121314151617181920212223#=======================================================================# Time Complexity of Solution:# Best O(n^2); Average O(n^2); Worst O(n^2).## Approach:# Bubblesort is an elementarray sorting algorithm. The idea is to# imagine bubbling the smallest elements of a (vertical) array to the# top; then bubble the next smallest; then so on until the entire# array is sorted. Bubble sort is worse than both insertion sort and# selection sort. It moves elements as many times as insertion sort# (bad) and it takes as long as selection sort (bad). On the positive# side, bubble sort is easy to understand. Also there are highly# improved variants of bubble sort.#=======================================================================def bubble_sort(array): n = len(array) for i in range(n): for j in range(1, n - i): if array[j - 1] &gt; array[j]: array[j - 1], array[j] = array[j], array[j - 1] return array 优化一优化1：某一趟遍历如果没有数据交换，则说明已经排好序了，因此不用再进行迭代了。用一个标记记录这个状态即可。1234567891011def bubble_sort2(array): n = len(array) for i in range(n): sorted = True for j in range(1, n - i): if array[j - 1] &gt; array[j]: flag = False array[j - 1], array[j] = array[j], array[j - 1] if sorted: return array # or break return array 优化二优化2：记录某次遍历时最后发生数据交换的位置，这个位置之后的数据显然已经有序，不用再排序了。因此通过记录最后发生数据交换的位置就可以确定下次循环的范围了。12345678910111213def bubble_sort3(array): n = len(array) k = n for i in range(n): flag = False # 有没有交换 for j in range(1, k): # 只遍历到最后交换的位置 if array[j - 1] &gt; array[j]: flag = True k = j # 记录最后的交换位置 array[j - 1], array[j] = array[j], array[j - 1] if not flag: return array # or break return array Selection sort 选择排序选择排序无疑是最简单直观的排序。内部不稳定排序，时间复杂度 $O(N^2)$，空间复杂度 $O(1)$ 步骤： 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 1234567891011121314151617181920#=======================================================================# Time Complexity of Solution:# Best O(n^2); Average O(n^2); Worst O(n^2).## Approach:# Selection sort is a step up from insertion sort from a memory# viewpoint. It only swaps elements that need to be swapped. In terms# of time complexity, however, insertion sort is better.#=======================================================================def select_sort(array): n = len(array) for i in range(n): min = i for j in range(i + 1, n): if array[j] &lt; array[min]: min = j array[i], array[min] = array[min], array[i] return array Insertion sort 插入排序每轮在已经排好的序列中插入一个新的数字。插入排序的工作原理是，对于每个未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。内部稳定排序，时间复杂度 $O(N^2)$，空间复杂度 $O(1)$步骤： 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果被扫描的元素（已排序）大于新元素，将该元素后移一位 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 将新元素插入到该位置后 重复步骤2~5 12345678910111213141516171819202122#=======================================================================# Time Complexity of Solution:# Best O(n); Average O(n^2); Worst O(n^2).## Approach:# Insertion sort is good for collections that are very small# or nearly sorted. Otherwise it&apos;s not a good sorting algorithm:# it moves data around too much. Each time an insertion is made,# all elements in a greater position are shifted.#=======================================================================def insertion_sort(array): n = len(array) for i in range(1, n): val = array[i] position = i while position &gt; 0 and array[position - 1] &gt; val: array[position] = array[position - 1] position -= 1 array[position] = val return array Shell Sort 希尔排序希尔排序，也称递减增量排序算法，实质是分组插入排序。内部非稳定排序算法。时间复杂度不定，空间复杂度$O(1)$ 希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。 例如，假设有这样一组数[ 13 14 94 33 82 25 59 94 65 23 45 27 73 25 39 10 ]，如果我们以步长为5开始进行排序，我们可以通过将这列表放在有5列的表中来更好地描述算法，这样他们就应该看起来是这样： 13 14 94 33 82 25 59 94 65 23 45 27 73 25 39 10 然后我们对每列进行排序： 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 将上述四行数字，依序接在一起时我们得到：[ 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 ]。这时10已经移至正确位置了，然后再以3为步长进行排序： 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 排序之后变为： 10 14 13 25 23 33 27 25 59 39 65 73 45 94 82 94 最后以1步长进行排序（此时就是简单的插入排序了）。 12345678910111213def shell_sort(array): n = len(array) gap = n / 2 # 初始步长 while gap &gt; 0: for i in range(gap, n):# 每一列进行插入排序 , 从gap 到 n-1 position = i val = array[i] while position &gt; 0 and array[position - 1] &gt; val: array[position] = array[position - 1] position -= 1 array[position] = val gap = gap / 2 # 重新设置步长 return array 上面源码的步长的选择是从n/2开始，每次再减半，直至为0。步长的选择直接决定了希尔排序的复杂度 Merge Sort 归并排序归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，解决子集的排序问题，再合并两个有序数组。由于基本的逻辑思维结构是二叉树，也叫二路归并排序。 先考虑合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。 再考虑递归分解，基本思路是将数组分解成 left 和 right，如果这两个数组内部数据是有序的，那么就可以用上面合并数组的方法将这两个数组合并排序。如何让这两个数组内部是有序的？可以再二分，直至分解出的小组只含有一个元素时为止，此时认为该小组内部已有序。然后合并排序相邻二个小组即可。 外部稳定排序。时间复杂度 $O(nlog(n))$，空间复杂度 $O(n)$。堆排序和快速排序的复杂度也都是 $O(nlog(n))$，但它们是不稳定的。在排序算法中，时间复杂度是 $O(nlog(n))$ 的排序算法只有归并排序。 基本款12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#=======================================================================# Time Complexity of Solution:# Best = Average = Worst = O(nlog(n)).## Approach:# Merge sort is a divide and conquer algorithm. In the divide and# conquer paradigm, a problem is broken into pieces where each piece# still retains all the properties of the larger problem -- except# its size. To solve the original problem, each piece is solved# individually; then the pieces are merged back together.## For illustration, imagine needing to sort an array of 200 elements# using selection sort. Since selection sort takes O(n^2), it would# take about 40,000 time units to sort the array. Now imagine# splitting the array into ten equal pieces and sorting each piece# individually still using selection sort. Now it would take 400# time units to sort each piece; for a grand total of 4000.# Once each piece is sorted, merging them back together would take# about 200 time units; for a grand total of 200+4000 = 4,200.# Clearly 4,200 is an impressive improvement over 40,000. Now# imagine greater. Imagine splitting the original array into# groups of two and then sorting them. In the end, it would take about# 1,000 time units to sort the array. That&apos;s how merge sort works.## NOTE to the Python experts:# While it might seem more &quot;Pythonic&quot; to take such approach as## mid = len(aList) / 2# left = mergesort(aList[:mid])# right = mergesort(aList[mid:])## That approach take too much memory for creating sublists.#=======================================================================def merge_sort(array): if len(array) &lt;= 1: return array mid = len(array) / 2 left = merge_sort(array[:mid]) right = merge_sort(array[mid:]) return merge(left, right)def merge(left, right): l, r = 0, 0 result = [] while l &lt; len(left) and r &lt; len(right): if left[l] &lt; right[r]: result.append(left[l]) l += 1 else: result.append(right[r]) r += 1 # 如果有遗留没有比较的 result += left[l:] result += right[r:] return result 优化结合其他排序在数组长度比较短的情况下，不进行递归，而是采用其他排序方案，如 high - low &lt; 50 时，可以用快速／插入排序，适合整体时间最优 建立索引实际过程中，可能排序的不是 int, 而是一个结构体，在此情况下，可以通过记录数组下标(index)来代替申请新内存空间，从而避免 A 和辅助数组间的频繁数据移动。 应用归并排序非常适合做外排序(external sorting)。 例1: 9 路归并排序用 100M 内存对 900M 数据进行排序 读入 100M 数据至内存，用常规方式（堆排序）排序 将排序后的数据写入磁盘 重复前两个步骤，得到 9 个 100M 的文件块。 将 100M 内存划分为 10 块，前 9 份为输入缓冲区，最后一个为输出缓冲区。如将 9 个 100M 的文件块每个分前 10M 放到输入缓冲区，然后同时指向第一个元素，把最小的那个放到输出缓冲区，然后指针后移一位。 执行 9 路归并算法，将结果输出到输出缓冲区。 输出缓冲区满，写入目标文件，清空缓冲区 输入缓冲区空，读入相应文件的下一份数据。 例2: 逆序数问题给定一个数组 A[0..N-1]，如果对于两个元素 a[i],a[j]，有 ia[i]，那么称 a[i],a[j] 为逆序对，一个数组中包含的逆序对的数目为逆序数。如 3,10,2,6 的逆序数为 3。如何求数组的逆序数？ 当然可以选择暴力求解，两个循环，对每个数都要扫描它前面的所有数，时间复杂度为 $O(N^2)$i -&gt; [0,N-1]j -&gt; [i+1,N-1] 这里也可以用归并排序的思想。比如观察归并排序——合并数列(1，3，5)与(2，4)： 先取出前面数列中的1。 然后取出后面数列中的2，明显这个2和前面的3，5都可以组成逆序数对即3和2，5和2都是逆序数对。 然后取出前面数列中的3。 然后取出后面数列中的4，同理，可知这个4和前面数列中的5可以组成一个逆序数对。 1234567891011121314151617181920212223242526272829def merge_sort(array): if len(array) &lt;= 1: return array mid = len(array) / 2 left = merge_sort(array[:mid]) right = merge_sort(array[mid:]) count = 0 return merge(left, right)count = 0def merge(left, right): global count l, r = 0, 0 result = [] while l &lt; len(left) and r &lt; len(right): if left[l] &lt;= right[r]: result.append(left[l]) l += 1 else: result.append(right[r]) r += 1 count += len(left) - l result += left[l:] result += right[r:] return resultprint count # count 即为逆序数 其他思考思考：原地排序？让空间复杂度为 $O(1)$ Quick sort 快速排序快速排序通常明显比同为Ο(nlogn)的其他算法更快，因此常被采用，而且快排采用了分治法的思想，所以在很多笔试面试中能经常看到快排的影子。可见掌握快排的重要性。内部不稳定排序，最差时间复杂度 $O(N^2)$，平均时间复杂度 $O(nlogn)$步骤： 从数列中挑出一个元素作为基准数。 分区过程，将比基准数大的放到右边，小于或等于它的数都放到左边。 再对左右区间递归执行第二步，直至各区间只有一个数。 基本款1234567891011121314151617181920212223242526272829303132333435#=======================================================================# Time Complexity of Solution:# Best = Average = O(nlog(n)); Worst = O(n^2).## Approach:# Quicksort is admirably known as the algorithm that sorts an array# while preparing to sort it. For contrast, recall that merge sort# start partitions an array into smaller pieces, then sorts each piece,# then merge the pieces back. Quicksort actually sorts the array# during the partition phase.## Quicksort works by selecting an element called a pivot and splitting# the array around that pivot such that all the elements in, say, the# left sub-array are less than pivot and all the elements in the right# sub-array are greater than pivot. The splitting continues until the# array can no longer be broken into pieces. That&apos;s it. Quicksort is# done.## All this fussing about quicksort sorting while preparing to sort# may give the impression that it is better than mergesort, but its# not. In practice their time complexity is about the same -- with# one funny exception. Because quicksort picks its pivot randomly,# there is a practically impossible possibility that the algorithm# may take O(n^2) to compute.## The aforementioned notwithstanding, quicksort is better than# mergesort if you consider memory usage. Quicksort is an in-place# algorithm, requiring no additional storage to work.#=======================================================================def quick_sort(array): if len(array) &lt; 2: return array lesser = quick_sort([x for x in array[1:] if x &lt;= array[0]]) bigger = quick_sort([x for x in array[1:] if x &gt; array[0]]) return sum([lesser, [array[0]], bigger], []) 上面的代码选择第一个数作为基准数。 应用正整数数字序列，求最大 K 个数。输入项：一个无序的数字序列，和一个数字 K输出项：K 个数字，代表最大的 K 个数字是什么逻辑：将无序数列插入到二叉排序数中，采用中序遍历的方式输出前 K 个数字。 Heap sort 堆排序堆排序在 top K 问题中使用比较频繁。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树 。内部不稳定排序，时间复杂度 $O(nlogn)$，空间复杂度 $O(1)$ 步骤： 构造最大堆（Build_Max_Heap）：若数组下标范围为0~n，考虑到单独一个元素是最大堆，则从下标n/2开始的元素均为最大堆。于是只要从n/2-1开始，向前依次构造最大堆，这样就能保证，构造到某个节点时，它的左右子树都已经是最大堆。 堆排序（HeapSort）：由于堆是用数组模拟的。得到一个最大堆后，数组内部并不是有序的。因此需要将堆化数组有序化。思想是移除根节点，并做最大堆调整的递归运算。第一次将heap[0]与heap[n-1]交换，再对heap[0…n-2]做最大堆调整。第二次将heap[0]与heap[n-2]交换，再对heap[0…n-3]做最大堆调整。重复该操作直至heap[0]和heap[1]交换。由于每次都是将最大的数并入到后面的有序区间，故操作完后整个数组就是有序的了。 最大堆调整（Max_Heapify）：该方法是提供给上述两个过程调用的。目的是将堆的末端子节点作调整，使得子节点永远小于父节点。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#=======================================================================# Time Complexity of Solution:# Best O(nlog(n)); Average O(nlog(n)); Worst O(nlog(n)).## Approach:# Heap sort happens in two phases. In the start phase, the array# is transformed into a heap. A heap is a binary tree where# 1) each node is greater than each of its children# 2) the tree is perfectly balanced# 3) all leaves are in the leftmost position available.# In phase two the heap is continuously reduced to a sorted array:# 1) while the heap is not empty# - remove the top of the head into an array# - fix the heap.# Heap sort was invented by John Williams not by B. R. Heap.## MoveDown:# The movedown method checks and verifies that the structure is a heap.## Technical Details:# A heap is based on an array just as a hashmap is based on an# array. For a heap, the children of an element n are at index# 2n+1 for the left child and 2n+2 for the right child.## The movedown function checks that an element is greater than its# children. If not the values of element and child are swapped. The# function continues to check and swap until the element is at a# position where it is greater than its children.#=======================================================================def heap_sort(array): # convert aList to heap 构造最大堆 n = len(array) leastParent = n / 2 - 1 # n的父节点下标 for i in range(leastParent, -1, -1): max_heapify(array, i, n - 1) # 小堆转化为最大堆 # flatten heap into sorted array 将最大堆转化为有序数组 for i in range(n - 1, 0, -1): if array[0] &gt; array[i]: array[i], array[0] = array[0], array[i] max_heapify(array, 0, i - 1) # 调整最大堆 return array# 最大堆调整：将堆的末端子节点作调整，使得子节点永远小于父节点# start 为当前需要调整最大堆的位置，end为调整边界def max_heapify(array, start, end): largest = 2 * start + 1 # consider left child is larger than right while largest &lt;= end: # right child exists and is larger than left child if largest &lt; end and array[largest] &lt; array[largest + 1]: largest += 1 # right child is larger than parent if array[largest] &gt; array[start]: array[largest], array[start] = array[start], array[largest] # move down to largest child start = largest largest = 2 * start + 1 else: return Bucket Sort 桶排序桶排序和归并排序非常类似，也使用了归并的思想。大致步骤如下：外部排序，稳定性取决于桶内排序算法。时间复杂度与分桶数量 K 有关步骤： 设置一个定量的数组当作空桶。桶排序的特点就是数据要有范围（桶不能无限多）。 Divide - 从待排序数组中取出元素，将元素按照一定的规则塞进对应的桶子去。 对每个非空桶进行排序，通常可在塞元素入桶时进行插入排序。 Conquer - 从非空桶把元素再放回原来的数组中。” 假设输入数据服从均匀分布，然后将输入数据均匀地分配到有限数量的桶中，然后对每个桶再分别排序，对每个桶再使用插入排序算法，最后将每个桶中的数据有序的组合起来。前面了解到基数排序假设输入数据属于一个小区间内的整数，而桶排序则是假设输入是由一个随机过程生成，该过程将元素均匀的分布在一个区间[a,b]上。由于桶排序和计数排序一样均对输入的数据进行了某些假设限制，因此比一般的基于比较的排序算法复杂度低。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#=======================================================================# Time Complexity of Solution:# Best Case O(n); Average Case O(n); Worst Case O(n).## Approach:# If it sounds too good to be true, then most likely it&apos;s not true.# Bucketsort is not an exception to this adage. For bucketsort to# work at its blazing efficiency, there are multiple prerequisites.# First the hash function that is used to partition the elements need# to be very good and must produce ordered hash: if i &lt; k then# hash(i) &lt; hash(k). Second, the elements to be sorted must be# uniformly distributed.## The aforementioned aside, bucket sort is actually very good# considering that counting sort is reasonably speaking its upper# bound. And counting sort is very fast. The particular distinction# for bucket sort is that it uses a hash function to partition the# keys of the input array, so that multiple keys may hash to the same# bucket. Hence each bucket must effectively be a growable list;# similar to radix sort.## Numerous Internet sites, including university pages, have# erroneously written counting sort code and call them bucket sort.# Bucket sort uses a hash function to distribute keys; counting sort# creates a bucket for each key. Indeed there are perhaps greater# similarities between radix sort and bucket sort, than there are# between counting sort and bucket sort.## In the presented program insertionsort is used to sort# each bucket. This is to inculcate that the bucket sort algorithm# does not specify which sorting technique to use on the buckets.# A programmer may choose to continuously use bucket sort on each# bucket until the collection is sorted (in the manner of the radix# sort program below). Whichever sorting method is used on the# buckets, bucket sort still tends toward O(n).#=======================================================================def bucket_sort(array): # get hash codes code = hashing(array) # number of buckets: math.sqrt(len(array)) buckets = [list() for _ in range(code[1])] # distribute data into buckets: O(n) for i in array: x = re_hashing(i, code) buck = buckets[x] buck.append(i) # Sort each bucket: O(n). # I mentioned above that the worst case for bucket sort is counting # sort. That&apos;s because in the worst case, bucket sort may end up # with one bucket per key. In such case, sorting each bucket would # take 1^2 = O(1). Even after allowing for some probabilistic # variance, to sort each bucket would still take 2-1/n, which is # still a constant. Hence, sorting all the buckets takes O(n). for bucket in buckets: insertion_sort(bucket) ndx = 0 # merge the buckets: O(n) for i in range(len(buckets)): print buckets[i] for v in buckets[i]: array[ndx] = v ndx += 1 return arrayimport mathdef hashing(array): m = array[0] for i in range(1, len(array)): if(m &lt; array[i]): m = array[i] result = [m, int(math.sqrt(len(array)))] print result return resultdef re_hashing(i, code): # 桶是从小到大排的 return int(i / code[0] * (code[1] - 1)) Counting Sort 计数排序桶的个数＝待排序个数，就是计数排序，是桶排序的特例。计数排序，顾名思义，就是对待排序数组按元素进行计数。使用前提是需要先知道待排序数组的元素范围，将这些一定范围的元素置于新数组中，新数组的大小为待排序数组中最大元素与最小元素的差值。 本质是空间换时间，空间复杂度 O(max-min)。本质是哈希过程前提：数据是 int 值 步骤： 定新数组大小——找出待排序的数组中最大和最小的元素 统计次数——统计数组中每个值为i的元素出现的次数，存入新数组C的第i项 对统计次数逐个累加——对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加） 反向填充目标数组——将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1 其中反向填充主要是为了避免重复元素落入新数组的同一索引处。 参考链接：https://www.bittiger.io/blog/post/4Q4iNNbRYXkWkrAM3#quicksort","tags":"排序"},{"title":"Search Engines笔记 - Exact-match retrieval","url":"/2016/09/06/Search Engines笔记 - Exact-match retrieval/","text":"CMU 11642 的课程笔记。Exact match retrieval models 对专家来说很适用，它假定人能将需求描述为一个 boolean query，文档要么完全匹配要么完全不匹配，不匹配的文档分数就为 0。 Unranked Boolean Modeldocument score 为 1 或者 0，也就是匹配或者不匹配，没有匹配程度的分数，返回结果通常简单的按时间顺序排列。很多系统在用，像 WestLaw, PubMed 等，因为它速度非常快，对一些问答系统来说，unranked boolean model 足够用了。 Ranked Boolean Model为文档计算特定分数，文档 j 对 query $Q_{AND}(q_1…q_n)$ 的分数，一般取最小值。$score(Q_{AND}(q_1…q_n),d_j) = MIN(score(q_1,d_j),score(q_n,d_j))$ 文档 j 对 query $Q_{OR}(q_1…q_n)$ 的分数，一般计算 MEAN 或者 MAX，实践中 MEAN 比 MAX 更有效。$score(Q_{OR}(q_1…q_n),d_j) = MAX(score(q_1,d_j),score(q_n,d_j))$$score(Q_{OR}(q_1…q_n),d_j) = MEAN(score(q_1,d_j),score(q_n,d_j))$ 优点： 效率高 可预测，可解释，结构化的查询语句 当用户非常清楚自己需要的是怎样的文档时非常有用 也可以用其它的 term weighting 方法 缺点： 仍然是完全匹配模型 很难在 Precision 和 Recall 间得到平衡 检索结果是按照文档有多么冗余的（redundantly）匹配 query 来排序的 Inverted listBinary inverted lists用于 unranked retrievalOperators: AND, OR, AND-NOT, FIELD Frequency inverted lists用于 ranked retrievalOperators: AND, OR, AND-NOT, FIELD, SUM, SYNONYM Positional inverted lists用于 ranked retrievalOperators: AND, OR, AND-NOT, NEAR/n, SENTENCE/n, PASSAGE/n, WINDOW/n Fixed-length inverted list早期的搜索引擎会用，它的优点是 易于管理 bit-vector operations 速度快，并行化容易 然而…效率不高。假定 inverted list 长度为 |C| bits (C 是 corpus 里的文档总数)，那么在某个 inverted list 里为 1 的 bits 的个数就是 df(多少篇文档出现了这个 term)，我们看 term with median tf 的 df，记作 $df_{median}$，观察一些语料可以发现，$|C|&gt;&gt;|df_{median}|$，(Wall Street Journal，|C|=174K, $df_{median}=2$) Data structureB tree(B+ tree, B* tree, etc) $O(log n)$ 易于扩展 可以用于完全匹配(exact-match lookup)，范围寻找(range lookup)，前缀寻找（prefix lookup） Hash table $O(1)$ 不易于扩展 用于完全匹配(exact-match lookup) Term dictionarystring –&gt; integer，速度更快。 问题：多少存在内存，多少存在硬盘 frequent terms in RAM (eg.,ctf&gt;=1,000) less frequent terms to dis (eg.,ctf&lt;1,000) ctf &lt; 1000，根据 Zipf’s law 算出 99.9% 的词可以存在硬盘。${(A*N/1)-(A*N/1000) \\over (A*N)}={999 \\over 1000}=99.9%$","tags":"nlp search-engines 信息检索"},{"title":"数据结构和算法 -- 链表","url":"/2016/09/04/数据结构和算法 -- 链表/","text":"链表实现／移除节点／链表相加／链表部分翻转／链表改序/链表去重／链表划分／链表的环/链表公共节点问题/链表复制。 简介线性表是最基本、最简单、也是最常用的一种数据结构。线性表中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的。数组 immutable length 和 no holes allowed 的特性带来的结果就是当 resize array 的时候需要 copy 原有的所有元素，当删除一个不在末尾的元素时，又要 shift 很多元素。而 Linked list 解决了这个问题，它的代价是需要额外的 4 bytes(32bit machine) 来储存指向下一个 node 的 reference，另外不允许随机访问元素。 线性表的两种存储方式 顺序存储结构：随机读取，访问时是 O(1) 链式存储结构：插入和删除 O(1)，访问时最坏是 O(n) 线性表的分类（根据指针域） 单向链表(Singly linked list) 双向链表(Doubly linked list) 循环链表(Circular linked list) 这一篇主要讲的是链表（linked list）。链表是一种常见的线性数据结构。单向链表(singly linked list)，每个节点有一个 next 指针指向后一个节点，还有一个成员变量用以存储数值；双向链表(doubly Linked List)，多了一个 prev 指针指向前一个节点。与数组类似，搜索链表需要O(n)的时间复杂度，但是链表不能通过常数时间 O(1) 读取第 k 个数据。链表的优势在于能够以较高的效率在任意位置插入或删除一个节点。 ComplexityLinked listaddFirst: O(1)insertBefore or insertAfter: O(n)delete: O(n)search: O(n) Arraylocate: O(1)insert/delete: O(N)search: not sorted -&gt; linear search =&gt; O(N), sorted -&gt; binary search =&gt; O(logN)iteration: O(N) 基本策略涉及头节点当涉及对头节点的操作，考虑创建哑节点 修改单向链表的操作考虑哪个节点的next指针会受到影响，则需要修正该指针； 反转链表要把反转后的最后一个节点（即第一个节点）指向 null 删除某个节点 由于需要知道前继节点的信息，而前继节点可能会导致表头产生变化，所以需要一些技巧 Dummy Node 全部操作结束后，判断是否有环；若有，则置其中一端为 null 快慢指针快速找出未知长度单链表的中间节点／涉及在链表中寻找特定位置 设置两个指针 *fast 和 *slow 都指向头节点 *fast 移动速度是 *slow 的两倍 *fast 指向末尾节点时，*slow 正好就在中间 判断单链表是否有环 设置两个指针 *fast 和 *slow 都指向头节点 *fast 移动速度是 *slow 的两倍 如果 *fast == null 说明该单链表不是循环链表 如果 *fast == *slow 说明该链表是循环链表 找倒数第 N 个节点 设置两个指针 fast 和 slow 都指向头节点 *fast 先移动 N 步，然后两个指针一起前进 *fast 到达末尾时，*slow 即为倒数第 N 个节点 检验有效性访问某个节点 cur.next 时，要检验 cur 是否为 null。（同理，访问 cur.next.next，检验 cur.next） 链表实现Singly-linked list Implementation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# implement a singly-linked listclass Node(object): def __init__(self, val=None, next=None): self.val = val self.next = nextclass LinkedList(object): def __init__(self, head=None): self.head = head def addFirst(self, val): self.head = Node(val, self.head) return True def addLast(self, item): # if the list empty if not self.head: addFirst(val) return False # traverse to find the last element tmp = self.head while tmp.next: tmp = tmp.next # finally, add the new element into the list tmp.next = Node(item, None) return True def insertAfter(self, key, item): # find the location first with the given key tmp = self.head while tmp and tmp.val != key: tmp = tmp.next # as long as the key is in the list if tmp: toBeInserted = Node(item, tmp.next) tmp.next = toBeInserted return True return False def insertBefore(self, key, item): # if the list is empty if not self.head: return False # if head has the key if self.head.val == key: addFirst(key) return True # key is not in the head prev = None cur = self.head while cur and cur.val != key: prev, cur = cur, cur.next # found it, then add new node into next of the previous if cur: prev.next = Node(item, cur) return True return False def size(self): length = 0 cur = self.head while cur: cur = cur.next length += 1 return length def remove(self, key): if not self.head or not key: return False # if the key is found from the head element if self.head.val == key: head = head.next return True cur = self.head prev = None while cur and cur.val != key: prev = cur cur = cur.next # as long as key is found if cur: prev.next = cur.next return True return False &apos;&apos;&apos; while cur.next: if cur.next == data: cur.next = cur.next.next return True cur = cur.next return False #raise ValueError(&quot;Data not in list&quot;) &apos;&apos;&apos; def deleteList(self): self.head = None return True def search(self, data): cur = self.head while cur and cur.val != data: cur = cur.next return cur def printAll(self): cur = self.head while cur: print cur.val, cur = cur.next print Leetcode 实例移除节点(19.Remove Nth Node From End of List)ProblemGiven a linked list, remove the nth node from the end of list and return its head. For example, Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2. After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5.Note:Given n will always be valid.Try to do this in one pass. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&apos;&apos;&apos;A singly list is a particularly poor choice for a data structure when you frequently need to find the mth-to-last element!Assumption:- m is less than the length of linked list? if not, check first!Solution:You cannot traverse backward through a singly linked list, so may be we can store elements into another data structure so that we can look back, or for this problem, we can traverse from beginning of list.Two-pass solution:- first get the length of linked list, and then find the node before (length-n)th node, and node.next=node.next.next- use dummy nodeFollow-up:one-pass solution:- how to access nth node from the end? use two pointers, fast and slow, keep the distance n between fast and slow node&apos;&apos;&apos;# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def removeNthFromEnd(self, head, n): &quot;&quot;&quot; :type head: ListNode :type n: int :rtype: ListNode &quot;&quot;&quot; if not head or not head.next: return None dummy=ListNode(0) dummy.next=head slow,fast=dummy,dummy for i in range(n): fast=fast.next while fast.next: fast,slow=fast.next,slow.next slow.next=slow.next.next return dummy.next &apos;&apos;&apos; # Two pass solution def removeNthFromEnd(self, head, n): &quot;&quot;&quot; :type head: ListNode :type n: int :rtype: ListNode &quot;&quot;&quot; if not head or not head.next: return None length=0 dummy=ListNode(0) dummy.next=head pointer1,pointer2=dummy,dummy while pointer1.next: length+=1 pointer1=pointer1.next # find nth node for i in range(length-n): pointer2=pointer2.next pointer2.next=pointer2.next.next return dummy.next &apos;&apos;&apos; 链表相加(2.445. Add Two Numbers; 369. Plus One Linked List)Problem(I)You are given two linked lists representing two non-negative numbers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list.Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8 Similar problems (M) Multiply Strings (E) Add Binary (M) Add Two Numbers (M) Plus One Linked List66.Plus One 67.Add Binary43. Multiply Strings Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = None&apos;&apos;&apos;# Straight-forwardclass Solution(object): def addTwoNumbers(self, l1, l2): &quot;&quot;&quot; :type l1: ListNode :type l2: ListNode :rtype: ListNode &quot;&quot;&quot; # make sure a l1 is longer than l2 p1, p2 = l1, l2 while p1 and p2: p1 = p1.next p2 = p2.next if p1: p1, p2 = l1, l2 else: p1, p2 = l2, l1 # cal carry = 0 res = ListNode(0) cur = res while p2: sum = p1.val + p2.val + carry carry = sum / 10 sum %= 10 cur.next = ListNode(sum) cur = cur.next p1, p2 = p1.next, p2.next while p1: sum = p1.val + carry carry = sum / 10 sum %= 10 cur.next = ListNode(sum) cur = cur.next p1 = p1.next if carry == 1: cur.next = ListNode(1) return res.next &apos;&apos;&apos;# improved, doesn&apos;t need to know which list is longerclass Solution(object): def addTwoNumbers(self, l1, l2): &quot;&quot;&quot; :type l1: ListNode :type l2: ListNode :rtype: ListNode &quot;&quot;&quot; head = ListNode(0) output = head carry = 0 while True: if l1: carry += l1.val l1 = l1.next if l2: carry += l2.val l2 = l2.next output.val = carry % 10 carry = carry / 10 if l1 or l2 or carry: output.next = ListNode(0) output = output.next else: break return head 注意考虑两个数位数不同的情况。因为两位数相加进位最多影响后一位，不会影响 i+2 位，所以发现一个链表为空后，直接结束循环，最后只用进位和较长链表的当前节点相加，之后较长链表的 i+2 位直接照搬。用这个结构可以实现大整数的计算。 Problem(II)You are given two non-empty linked lists representing two non-negative integers. The most significant digit comes first and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Follow up:What if you cannot modify the input lists? In other words, reversing the lists is not allowed. Example:12Input: (7 -&gt; 2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 8 -&gt; 0 -&gt; 7 Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def addTwoNumbers(self, l1, l2): &quot;&quot;&quot; :type l1: ListNode :type l2: ListNode :rtype: ListNode &quot;&quot;&quot; p1, p2 = l1, l2 s1, s2 = [], [] while p1: s1.append(p1.val) p1 = p1.next while p2: s2.append(p2.val) p2 = p2.next &apos;&apos;&apos; # method 1: use a stack carry=0 res=[] while True: if not s1 and not s2 and carry==0: break if s1: carry+=s1.pop() if s2: carry+=s2.pop() res.append(carry%10) carry/=10 cur=ListNode(0) tmp=cur while res: tmp.next=ListNode(res.pop()) tmp=tmp.next return cur.next &apos;&apos;&apos; # method 2: Linkedlist addFirst carry = 0 cur = ListNode(None) while True: if not s1 and not s2 and carry == 0: break if s1: carry += s1.pop() if s2: carry += s2.pop() head = ListNode(carry % 10) head.next = cur if cur.val != None else None cur = head carry /= 10 return cur Problem(III)Given a non-negative integer represented as non-empty a singly linked list of digits, plus one to the integer. You may assume the integer do not contain any leading zero, except the number 0 itself. The digits are stored such that the most significant digit is at the head of the list. Example:12345Input:1-&gt;2-&gt;3Output:1-&gt;2-&gt;4 Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = None&apos;&apos;&apos;# use stack, O(n) space and O(n) timeclass Solution(object): def plusOne(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; stack=[] res=ListNode(0) tmp=res while head: stack.append(head.val) head=head.next if stack[-1]&lt;9: stack[-1]+=1 else: i=len(stack)-1 while i&gt;=0 and stack[i]==9: stack[i]=0 i-=1 if i&lt;0: tmp.next=ListNode(1) tmp=tmp.next else: stack[i]+=1 for i in stack: tmp.next=ListNode(i) tmp=tmp.next return res.next &apos;&apos;&apos;&apos;&apos;&apos;# Do it recursivelyclass Solution(object): def plusOne(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; def add(head): if not head: return 1 carry = head.val + add(head.next) head.val = carry % 10 return carry / 10 carry = add(head) if carry == 1: tmp = ListNode(1) tmp.next = head head = tmp return head &apos;&apos;&apos;# find the first node that is not 9: O(n) time and O(1) spaceclass Solution(object): def plusOne(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; cur = head notNine = None # find the first node that is not 9 while cur: if cur.val != 9: notNine = cur cur = cur.next # plus 1 if not notNine: notNine = ListNode(1) notNine.next = head head = notNine else: notNine.val += 1 # update digits cur = notNine.next while cur: cur.val = 0 cur = cur.next return head 链表的翻转(206.92.Reverse Linked List)Problem(I)Reverse a singly linked list.Hint:A linked list can be reversed either iteratively or recursively. Could you implement both? 初步思考每次走到最后一个数，把它放到最前面1234561 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5=&gt;5 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 44 -&gt; 5 -&gt; 1 -&gt; 2 -&gt; 3...5 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 1 时间复杂度 $O(n^2)$ 头插法1234561 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5=&gt;2 -&gt; 1 -&gt; 3 -&gt; 4 -&gt; 53 -&gt; 2 -&gt; 1 -&gt; 4 -&gt; 5...5 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 1 时间复杂度 $O(n)$，空间复杂度 $O(1)$ 要注意的是，把翻转后的最后一个节点（即原来的第一个节点）指向 Null(None)。访问某个节点 cur.next，要检验 cur 是否为 None. 12345671 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5=&gt;1 -&gt; None -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 52 -&gt; 1 -&gt; None -&gt; 3 -&gt; 4 -&gt; 53 -&gt; 2 -&gt; 1 -&gt; None -&gt; 4 -&gt; 5...5 -&gt; 4 -&gt; 3 -&gt; 2 -&gt; 1 -&gt; None 迭代法12345678910111213class Solution(object): def reverseList(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; dummy = None while head: curr = head head = head.next curr.next= dummy dummy = curr return dummy 更简单。12345678910class Solution(object): def reverseList(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; dummy = None while head: head.next,dummy,head=dummy,head,head.next # head.next=dummy 必须在 head=head.next之前 return dummy 递归1234567891011121314class Solution(object): def reverseList(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; return self._reverse(head) def _reverse(self, node, prev=None): if not node: return prev n = node.next node.next = prev return self._reverse(n, node) Problem(II)Reverse a linked list from position m to n. Do it in-place and in one-pass.For example:Given 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL, m = 2 and n = 4,return 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;NULL.Note:Given m, n satisfy the following condition:1 ≤ m ≤ n ≤ length of list. oup, 最后要返回的是 oup.next 指针dummy 指针，在原来的 m-1 位置cur 指针，在原来的 n 位置reverse，在原来的 m 位置 dummy 指针，空转 m-1 次，找到第 m-1 个节点，即开始翻转的第一个结点的前一个；利用 cur, reverse 按完全翻转的方法翻转[m,n]部分最后修改两个指针，dummy.next 指向 reverse，dummy.next.next 指向第 n+1 个节点。 Solution123456789101112131415161718192021222324252627282930class Solution(object): def reverseBetween(self, head, m, n): &quot;&quot;&quot; :type head: ListNode :type m: int :type n: int :rtype: ListNode &quot;&quot;&quot; if m==n: return head # [1,m-1] nodes oup = ListNode(0) oup.next = head dummy = oup for i in range(m-1): dummy = dummy.next # reverse [m,n] nodes reverse = None cur = dummy.next for i in range(m,n+1): cur.next,reverse,cur = reverse,cur,cur.next # [n,end] nodes dummy.next.next = cur dummy.next = reverse return oup.next 链表改序（143. Reorder List）ProblemGiven a singly linked list L: L0→L1→…→Ln-1→Ln,reorder it to: L0→Ln→L1→Ln-1→L2→Ln-2→… You must do this in-place without altering the nodes’ values. For example,Given {1,2,3,4}, reorder it to {1,4,2,3}. Solution1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&apos;&apos;&apos;Solution:- Two-pass store all nodes in a stack, create a dummy node, every time while i &lt; len(linked list), linked one node from linked list and one node from stack, and finally deal with odd or even number of lengthFollowup:- One-pass and O(1) - find middle: use fast,slow pointers - reverse second half list: 1-&gt;2-&gt;3-&gt;4-&gt;null =&gt; null&lt;-1&lt;-2&lt;-3&lt;-4, for each node, point the next node of current to previous one, update the previous and next node, do the same thing - merge two lists&apos;&apos;&apos;# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def reorderList(self,head): if not head: return None # find middle fast,slow=head,head while fast and fast.next: fast=fast.next.next slow=slow.next # reverse list pre=None cur=slow while cur: # one line solution pre, cur.next, cur = node, pre, cur.next next=cur.next cur.next=pre pre=cur cur=next # merge list first,second=head,pre while second.next: first.next,first=second,first.next second.next,second=first,second.next return &apos;&apos;&apos; def reorderList(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: void Do not return anything, modify head in-place instead. &quot;&quot;&quot; if not head or not head.next: return stack=[] dummy=ListNode(0) dummy.next=head while dummy.next: stack.append(dummy.next) dummy=dummy.next dummy=ListNode(0) dummy.next=head length=len(stack) half_len=len(stack)/2 for i in range(half_len): node,dummy=dummy.next.next,dummy.next # dummy.next,dummy=stack.pop(),dummy.next # this is wrong. suppose a=0,a,b=3,a =&gt; a=3,b=0 dummy.next=stack.pop() dummy,dummy.next=dummy.next,node if length%2==1: dummy.next.next=None else: dummy.next=None &apos;&apos;&apos; 排序链表去重(82.83. Remove Duplicates from Sorted List I&amp;II)Problem(I)Given a sorted linked list, delete all duplicates such that each element appear only once.For example,Given 1-&gt;1-&gt;2, return 1-&gt;2.Given 1-&gt;1-&gt;2-&gt;3-&gt;3, return 1-&gt;2-&gt;3. Solution12345678910111213class Solution(object): def deleteDuplicates(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; dummy = head while head and head.next: if head.val == head.next.val: head.next = head.next.next else: head = head.next return dummy 注意用到 head.next 一定要判断前一个节点 head 是否为空，同理，head.next.next 判断 head.next 是否为空。 Problem(II)Given a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list.For example,Given 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5, return 1-&gt;2-&gt;5.Given 1-&gt;1-&gt;1-&gt;2-&gt;3, return 2-&gt;3. Solution12345678910111213141516171819class Solution(object): def deleteDuplicates(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; dummy = ListNode(0) cur = dummy while head: while head.next and head.val == head.next.val: head = head.next if not head.next or head.val != head.next.val: break else: cur.next = head cur = head head = head.next cur.next = None return dummy.next 考虑的 bad case: [1,1],[1,1,1]，所以最后的 cur.next = None 不能少，否则还会返回 [1] 链表的合并(21. Merge Two Sorted Lists)快速排序对链表结构适用，然而不是所有排序都适合使用链表存储，如堆排序，不断寻找数组的 n/2 和 n 位置，用链表不大方便。 ProblemMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists. SolutionRecursive时间复杂度 O(N),空间复杂度 O(1)123456789101112131415161718class Solution(object): def mergeTwoLists(self, l1, l2): &quot;&quot;&quot; :type l1: ListNode :type l2: ListNode :rtype: ListNode &quot;&quot;&quot; if l2 is None: return l1 if l1 is None: return l2 if l1.val &lt; l2.val: head = l1 head.next = self.mergeTwoLists(l1.next,l2) else: head = l2 head.next = self.mergeTwoLists(l1,l2.next) return head 链表的划分（89.Partition List）ProblemGiven a linked list and a value x, partition it such that all nodes less than x come before nodes greater than or equal to x.You should preserve the original relative order of the nodes in each of the two partitions.For example,Given 1-&gt;4-&gt;3-&gt;2-&gt;5-&gt;2 and x = 3,return 1-&gt;2-&gt;2-&gt;4-&gt;3-&gt;5. Solution用两个指针 left,right，小于 x 的用 left，大于 x 的用 right，最后连接 left,right123456789101112131415161718192021222324252627# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = None&apos;&apos;&apos;Solution:- create two lists less and greater, for each node in linkedlist, if it is less than x, add to less, else, add to greater, finally merge two lists. Time complexity: O(n), space complexity: O(1)&apos;&apos;&apos;class Solution(object): def partition(self,head,x): if not head: return None less,greater=ListNode(0),ListNode(0) less_cur,greater_cur=less,greater while head: if head.val&lt;x: less_cur.next=head less_cur=less_cur.next else: greater_cur.next=head greater_cur=greater_cur.next head=head.next less_cur.next=greater.next greater_cur.next=None return less.next 这里要注意的是最后 right 要指向空，不然考虑 case [2,1]，会陷入[1,2,1,2…]的死循环中，因为 right_cur.next 指向了 head，形成了环。 链表的环 (141.142.Linked List Cycle I &amp; II)Problem(I)Given a linked list, determine if it has a cycle in it. Follow up:Can you solve it without using extra space? Solution12345678910111213141516171819202122232425262728293031323334353637383940414243444546# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = None&apos;&apos;&apos;Solution:- For every node in linkedlist, check if it is in hashset, if not, add it, else, return True. Time complexity: O(n)Followup:- no extra space slow and fast pointers&apos;&apos;&apos;class Solution(object): def hasCycle(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: bool &quot;&quot;&quot; if not head: return False fast,slow=head,head while fast and fast.next: fast=fast.next.next slow=slow.next if fast==slow: return True return False &apos;&apos;&apos; def hasCycle(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: bool &quot;&quot;&quot; if not head: return False nodelist=set() while head.next: if head in nodelist: return True nodelist.add(head) head=head.next return False &apos;&apos;&apos; Problem(II)Given a linked list, return the node where the cycle begins. If there is no cycle, return null. Note: Do not modify the linked list. Follow up:Can you solve it without using extra space? Solution1234567891011121314151617181920212223242526272829303132333435363738&apos;&apos;&apos;Solution:- check if there&apos;s cycle- Let&apos;s say, the cycle starts at node u, and the length of the cycle is L, Moreover, after x steps, fast catches slow, and the length between current node and u is p. then we can get for slow pointer, x=u+aL+p, for fast pointer, 2x=u+bL+p, =&gt; 2x-x=(b-a)L =&gt; x=nL. Now, think about that, at step x, if we travels u more steps, where are we? =&gt; u+x=u+nL. =&gt; We are at the start of the cycle, because we have covered the first u nodes once and the entire cycle n times.Followup:- find the length of cycle let slow move foward till meet with fast again&apos;&apos;&apos;# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def detectCycle(self, head): &quot;&quot;&quot; :type head: ListNode :rtype: ListNode &quot;&quot;&quot; if not head: return None fast,slow=head,head while True: if not fast or not fast.next:return None fast=fast.next.next slow=slow.next if fast==slow: break while head != fast: head,fast=head.next,fast.next return head 单链公共节点问题ProblemWrite a program to find the node at which the intersection of two singly linked lists begins. 假设两个链表长度为 m，n，认为 m &gt; n，两链表的第一个公共节点到尾节点一定是重合的。于是，可以分别遍历两个链表得到链表长度 m,n, 长链表空转 m-n 次，然后两链表齐头并进，同步遍历，直到找到公共节点。时间复杂度为 $O(m+n)$ 如果链表存在环，则需要用快慢指针的方式计算公共节点。两个指针，每次分别移动 1 个／2 个节点。 Solution12345678910111213141516171819202122232425262728293031# Definition for singly-linked list.# class ListNode(object):# def __init__(self, x):# self.val = x# self.next = Noneclass Solution(object): def getIntersectionNode(self, headA, headB): &quot;&quot;&quot; :type head1, head1: ListNode :rtype: ListNode &quot;&quot;&quot; curA,curB = headA,headB lenA,lenB=0,0 while curA: lenA += 1 curA = curA.next while curB: lenB += 1 curB = curB.next curA,curB = headA,headB if lenA &gt; lenB: for i in range(lenA-lenB): curA = curA.next else: for i in range(lenB-lenA): curB = curB.next while curA != curB: curA = curA.next curB = curB.next return curA 一个从代码层面来讲的简洁版本。12345678910111213141516171819202122class Solution: # @param two ListNodes # @return the intersected ListNode def getIntersectionNode(self, headA, headB): if headA is None or headB is None: return None pa = headA # 2 pointers pb = headB while pa is not pb: # if either pointer hits the end, switch head and continue the second traversal, # if not hit the end, just move on to next pa = headB if pa is None else pa.next pb = headA if pb is None else pb.next return pa # only 2 ways to get out of the loop, they meet or the both hit the end=None# the idea is if you switch head, the possible difference between length would be countered.# On the second traversal, they either hit or miss.# if they meet, pa or pb would be the node we are looking for,# if they didn&apos;t meet, they will hit the end at the same iteration, pa == pb == None, return either one of them is the same,None 链表复制(138. Copy List with Random Pointer)ProblemA linked list is given such that each node contains an additional random pointer which could point to any node in the list or null. Return a deep copy of the list. Solution123456789101112131415161718192021222324252627282930313233343536373839404142434445&apos;&apos;&apos;Solution:- two-pass: consider normal copy of linkedlist, do similar stuff. first copy nodes and next pointer, then copy random pointer how to find new nodes in second pass? find with O(1) time =&gt; hashmap- one-pass: first copy all nodes and store them into hashmap, then connect all nodes. time complexity: O(n), space complexity: O(n)Followup:- without hashmap?&apos;&apos;&apos;# Definition for singly-linked list with a random pointer.# class RandomListNode(object):# def __init__(self, x):# self.label = x# self.next = None# self.random = Noneclass Solution(object): # copy nodes and next pointer def copyRandomList(self, head): &quot;&quot;&quot; :type head: RandomListNode :rtype: RandomListNode &quot;&quot;&quot; if not head: return None cur=head hashmap=&#123;&#125; while cur: # create nodes if cur not in hashmap: curCopy=RandomListNode(cur.label) hashmap[cur]=curCopy if cur.next and cur.next not in hashmap: nextCopy=RandomListNode(cur.next.label) hashmap[cur.next]=nextCopy if cur.random and cur.random not in hashmap: randomCopy=RandomListNode(cur.random.label) hashmap[cur.random]=randomCopy # connect nodes if cur.next: hashmap[cur].next=hashmap[cur.next] if cur.random: hashmap[cur].random=hashmap[cur.random] # next round cur=cur.next return hashmap[head] 参考链接：编程起跑线 第 5 课 链表Implementing a Singly Linked List in Python","tags":"链表"},{"title":"聊天机器人和智能客服(笔记)","url":"/2016/08/20/聊天机器人和智能客服(笔记)/","text":"张辉智能客服分享会笔记以及三个月客服机器人实习的感悟。 聊天机器人这一部分内容来自微信公众号机器之心《深度|Google Brain研究员详解聊天机器人：面临的深度学习技术问题以及基于TensorFlow的开发实践》，商业模式部分来自公众号大数据文摘《聊天机器人如何盈利？这里有七种可能的商业模式》 模型分类基于检索式模型 vs 生成式模型基于检索式模型（更简单）使用了预定义回复库和某种启发式方法来根据输入和语境做出合适的回复。这种启发式方法可以像基于规则的表达式匹配一样简单，也可以像机器学习分类器集一样复杂。这些系统不会产生任何新文本，他们只是从固定的集合中挑选一种回复而已。 生成式模型（更困难）不依赖于预定义回复库。他们从零开始生成新回复。生成式模型通常基于机器翻译技术，但区别于语言翻译，我们把一个输入「翻译」成一个输出「回复」。 两种方式都有明显的优势和劣势。由于采用人工制作的回复库，基于检索式方法不会犯语法错误。然而它们可能无法处理没见过的情况，因为它们没有合适的预定义回复。同样，这些模型不能重新提到上下文中的实体信息，如先前对话中提到过的名字。生成式模型更「聪明」。它们可以重新提及输入中的实体并带给你一种正和人类对话的感觉。然而，这些模型很难训练，很可能会犯语法错误（特别是长句），而且通常要求大量的训练数据。 基于检索式模型或生成式模型都可以应用深度学习技术，但是相关研究似乎正转向生成式方向。像序列到序列（Sequence to Sequence）这样的深度学习架构是唯一可以适用于产生文本的，并且研究者希望在这个领域取得快速进步。然而，我们仍处于构建工作良好的生成式模型的早期阶段。现在的生产系统更可能是基于检索式的。 长对话 vs 短对话对话越长，就越难使它自动化。一方面，短文本对话（更简单）的目标是单独回复一个简单的输入。例如，你可能收到一个用户的特定问题并回复合适的答案。而长对话（更困难）要求你经历多个转折并需要记录说过什么话。客户支持类对话通常是包含多个问题的长对话流。 开域(open domain) vs 闭域(closeddomain)在开域（更困难）环境中，用户可以进行任何对话。不需要明确定义的目标或意图。像Twitter 和 Reddit 这种社交媒体网站上的对话通常是开域的——它们可以是任何主题。话题的无限数量和用于产生合理回复的一定量的知识使开域成为了一个艰难的问题。 在闭域（更简单）设定中，因为系统试图达成一个非常明确的目标，可能输入和输出的空间会有所限制。例如客户技术支持或购物助手就属于闭域的范畴。这些系统不需要能谈论政治，它们只需要尽可能高效地完成它们特定的任务。当然，用户仍然可以进行任何他们想要的对话，但是这样的系统不需要能处理所有情况，并且用户也不期望它能处理。 普遍难题在构建大部分属于活跃研究领域的会话代理方面存在着许多明显和不明显的难题。 整合语境为了生成明智的回复，系统可能需要整合语言语境（linguistic context）和物理语境（physical context）。在长对话中，人们记录已经被说过的话和已经交换过的信息。这是结合语言语境的例子。最普遍的方法是将对话嵌入一个向量中，但在长对话上进行这样的操作是很有挑战性的。「使用生成式分层神经网络模型构建端到端对话系统」和「神经网络对话模型的注意与意图」两个实验中都选择了这个研究方向。此外还可能需要整合其它类型的语境数据，例如日期/时间、位置或用户信息。 一致人格当生成回复时，对于语义相同的输入，代理应该生成相同的回答。例如，你想在「你多大了？」和「你的年龄是多少？」上得到同样的回答。这听起来很简单，但是将固定的知识或者「人格」整合进模型是非常困难的研究难题。许多系统学习如何生成语义合理的回复，但是它们没有被训练如何生成语义上一致的回复。这一般是因为它们是基于多个不同用户的数据训练的。「基于个人的神经对话模型」这样的模型是明确的对人格建模的方向上的第一步。 模型评估评估一个对话代理的理想方式是衡量它是否完成了它的任务，例如，在给定对话中解决客户支持问题。但是获取这样的标签成本高昂，因为它们要求人类的判断和评估。某些时候并不存在明确定义的目标，比如开域模型中的情况。通常像 BLEU 这样被用于机器翻译且是基于文本匹配的标准并不能胜任，因为智能的回复可以包括完全不同的单词或短语。实际上，在 How NOT To Evaluate Your Dialogue System: An Empirical Study of UnsupervisedEvaluation Metrics for Dialogue Response Generation 中，研究者发现没有一个通用的度量能真正与人类判断一一对应。 意图和多样性生成式系统的普遍问题是它们往往能生成像「太好了！」或「我不知道」这样的能适用于许多输入情况的普遍回复。谷歌的智能回复（Smart Reply ）早期版本常常用「我爱你」回复一切。一定程度上这是系统根据数据和实际训练目标/算法训练的结果。然而，人类通常使用针对输入的回复并带有意图。因为生成系统（特别是开域系统）是不被训练成有特定意图的，所以它们缺乏这种多样性。 实际工作情况纵观现在所有最前沿的研究，我们发展到哪里了？这些系统的实际工作情况如何？让我们再看看我们的分类法。一个基于检索式开域系统显然是不可能实现的，因为你不能人工制作出足够的回复来覆盖所有情况。生成式开域系统几乎是人工通用智能（AGI: Artificial General Intelligence），因为它需要处理所有可能的场景。我们离 AGI 还非常遥远（但是这个领域有许多研究正在进行）。 这就让我们的问题进入了生成式和基于检索式方法都适用的受限的领域。对话越长，语境就越重要，问题就变得越困难。 现任百度首席科学家吴恩达说得很好： 当今深度学习的价值在你可以获得许多数据的狭窄领域内。有一件事它做不到：进行有意义的对话。存在一些演示，并且如果你仔细挑选这些对话，看起来就像它正在进行有意义的对话，但是如果你亲自尝试，它就会快速偏离轨道。 许多公司从外包他们的对话业务给人类工作者开始，并承诺一旦他们收集到了足够的数据，他们就会使其「自动化」。只有当他们在一个相当狭窄的领域中这样操作时，这才有可能发生——比如呼叫 Uber 的聊天界面。任何稍微多点开域的事（像销售邮件）就超出了我们现在的能力范围。然而，我们也可以利用这些系统建议和改正回复来辅助人类工作者。这就更符合实际了。 生产系统的语法错误成本很高并会赶走用户。所以，大多数系统可能最好还是使用不会有语法错误和不礼貌回答的基于检索式方法。如果公司能想办法得到大量的数据，那么生成式模型就将是可行的——但是，必须需要其它技术的辅助来防止它们像微软的 Tay 一样脱轨。 商业模式商业模式一：BaaS（Bots as a Services，聊天机器人即服务）B2B 领域的聊天机器人主要是帮助用户和团队更有效率地开展工作、管理任务或解决团队沟通方面出现的问题。所以 B2B 领域的聊天机器人可能会复制目前已经存在的 B2B 软件领域的商业模式。 对于 B2B 聊天机器人而言，我个人坚信，SaaS 式的免费增值模式可能会成为它最可行的商业模式。对于一些聊天机器人来说，根据你购买的增值服务的不同，那么你能使用到的聊天机器人的功能也是不同的。根据市场调研公司 Forrester 发布的数据，在 2016年，SaaS 和基于云的商业应用服务的营收有望达到 328 亿美元。因此可以想象，B2B 聊天机器人市场的营收应该也不会低。Slack 平台上的大部分应用基本都是基础功能免费，要想使用更高级的功能则需要付费。 SaaS 产品的商业模式是 B2B 领域的客户都非常熟悉的。在此基础上，聊天机器人未来可能会采取更为复杂的定价模式。 商业模式二：聊天机器人 + 赞助内容和原生内容因为 BuzzFeed、VICE 等的出现，原生内容和原生广告在过去几年里慢慢变成了一个大趋势。原生内容或赞助内容是这样一种模式：媒体公司（如 BuzzFeed）将那些付费品牌商家的赞助内容直接发布到自己的内容频道上，让读者阅读的时候感觉这篇内容好像是媒体自己创作发布的内容而非品牌商发布的广告。下面这个例子就是杜蕾斯在 BuzzFeed 上发布的原生广告内容： 现在设想一下你正在咨询一个烹饪方面的聊天机器人，聊天机器人基于自己的原生功能可能会回答你说，在某些菜谱中，使用香菜代替茴香是可以的，然后会发给你一篇文章《这五道用 ‘是拉差辣椒酱’（一种泰式料理常用的香甜辣椒酱）烹饪的菜，吃后绝对让你惊叹不已》。当然了，这里的是拉差辣椒酱就是赞助内容。 这种原生广告的效果要比传统的横幅广告的效果要好很多。这种类型的广告对品牌商和出版商都有益。未来，你可能会看到这种广告形式将被出版商应用到聊天机器人里。 商业模式三：利用聊天机器人做联盟网络营销联盟广告营销最近很多年已经成为一种非常流行的商业化策略。联盟广告营销指的是一种网站 A 为网站 B 设置推广链接，然后从为网站 B 带来的销售额中获取一定提成的一种广告系统。 Forrester 发布的数据报告显示，2016年，美国在联盟广告营销上的花费将达到 45 亿美元。联盟广告营销也可以作为聊天机器人的一种商业模式。举个例子，对于聊天机器人的开发商，你可以开发一款健身方面的聊天机器人，在如何保持健康的身体方面为用户提供专业的建议，然后给用户发送一些附有商业推广链接的健身方面的产品。 购物聊天机器人 Kip 现在已经开始采用这种商业化策略了。用户可以问 Kip “巧克力” 或 “咖啡” 等很多产品方面的问题，然后它会回复一些产品的购买链接，如下图所示：用户如果通过 Kip 发的链接购买产品，那么 Kip 团队就能从销售收入中收取一定的提成。 商业模式四：用聊天机器人做用户调研 （DisOrDatBot 截图）最近美国总统大选正在如火如荼地进行中，想了解千禧一代都是怎么看待美国总统大选的吗？你可以付费使用一些聊天机器人来进行这方面的调研。虽然我现在还没有看到有人利用聊天机器人做这方面的事，但我觉得如果有专门的 Q&amp;A 聊天机器人来专门帮助人们做调研的话还是非常靠谱的。 目前像 DisOrDatBot 这样的聊天机器人已经开始向用户问一下调研类问题了。想象一下你作为一次活动的策划者，现在正在发愁究竟邀请哪支乐队来你所在的城市进行表演，是邀请电台司令乐队（Radiahead）还是五分钱乐队（Nickelback，加拿大的著名乐队），这时，与其花很多钱请调研公司帮你做调研，还不如使用 DisOrDatBot 进行调研，看你所在城市的用户到底喜欢哪支乐队。 如果你已经开发了一个定期给一群小众用户提供有价值内容的聊天机器人，那些想触及这些用户或是想向这群用户销售产品的公司可能会比较有兴趣通过你的聊天机器人做调研。 商业模式五：将聊天机器人用于潜在客户开发中我预测，聊天机器人未来将会被应用到潜在客户开发中，一开始主要利用内容去开发潜在客户。通过在房产所有权、保险、婚礼和理财等方面为用户提供专业的信息、想法和见解，聊天机器人然后将自己获得的这些用户信息给到那些销售相关产品和服务的公司。 举个例子，加入你正在和一个 “生活聊天机器人” 聊天，向聊天机器人咨询一些购房方面的问题，随着聊天的深入，聊天机器人搜集了更多有关你的信息，包括你手头有多少首付资金、你想在哪里购房定居、你是否在职、你购买的是否是你的第一套房产等等。在和聊天机器人建立起一定的关系后，聊天机器人于是问你下面这个问题： “你是否介意我介绍一家比较适合你的房产公司和你联系？” 在经过你的同意之后，聊天机器人就会将你的信息给到你所在地区的一家房地产公司。这家房产公司第二天就会和你联系沟通你的购房需求。然后这家房产公司会给聊天机器人开发商一定的佣金作为为其开发潜在客户的报酬。 商业模式六：纯粹用于零售销售的聊天机器人 （Kit 上的 H&amp;M 零售聊天机器人）聊天机器人最直接的一种使用场景是商家直接向消费者（B2C）销售产品。想象一下，沃尔玛、Harry’ s、Target、Amazon 和京东等开发了这样一种聊天机器人，你可以问聊天机器人是否销售 “牙膏” 或 “刮胡刀” 等，然后聊天机器人会直接回复你这些商品的购买链接，所以用户在于聊天机器人的交流中就能直接完成商品的购买。 商业模式七：按完成的咨询次数或任务收费人们都希望得到专业的好建议，也愿意为好建议付费。随着聊天机器人变得越来越专业和智能，我认为未来人们会在生活中的很多方面都希望得到聊天机器人的建议和帮助，并愿意为这些建议付费。例如，如果你需要生活方面的建议，你可以和 “Oprah 聊天机器人” 交流，如果你需要获得汽车方面的信息，那么你可以和 “机械聊天机器人” 交流，如果你希望获得匿名的婚姻咨询，你可以和 “婚姻聊天机器人” 交流咨询。当然了，为了得到聊天机器人的建议，你是需要支付一定的费用的。 论文推荐Neural Responding Machine for Short-Text Conversation (2015-03)A Neural Conversational Model (2015-06)A Neural Network Approach to Context-Sensitive Generation of Conversational Responses (2015-06)The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems (2015-06)Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models (2015-07)A Diversity-Promoting Objective Function for Neural Conversation Models (2015-10)Attention with Intention for a Neural Network Conversation Model (2015-10)Improved Deep Learning Baselines for Ubuntu Corpus Dialogs (2015-10)A Survey of Available Corpora for Building Data-Driven Dialogue Systems (2015-12)Incorporating Copying Mechanism in Sequence-to-Sequence Learning (2016-03)A Persona-Based Neural Conversation Model (2016-03)How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation (2016-03) 客服机器人与聊天机器人的不同回答问题的范围和方式不同聊天机器人： 发散。可以回答广泛的问题，回答也是发散的。客服机器人： 收敛。关注焦点在于聚焦的业务范围内有多大的问题处理能力。 使用门槛不同聊天机器人： 不需要给他准备非常多的专业知识，多放一些常识库、问答库和寒暄库的知识，多放一些笑话和段子然后推出去为大家做一些即时的服务就可以了，当然也可以让他继续学习和优化。客服机器人： 专业知识库。 特质 开放问题的收敛能力智能客服机器人应有归纳问题的能力。能够尽量把客户的问题引导到正确的轨道上来。 自学习的能力智能客服机器人应有自学习的能力。它可以根据知识库以及工单进行批量学习，同时能够根据人工服务过程进行单次学习。 人工指导学习的能力我们可以对智能客服机器人进行相应的测试，并可以对其进行调教。 归纳聚类的能力智能客服机器人可以根据客户问的问题与现有知识进行匹配，并能够将匹配度低的问题聚类交由人工来进行回答及维护。人工回答后智能客服机器人能够同步学习，并生成新的问答类型，在下次回到中可以自行解决。 设计原则基于业务 不靠谱问题–&gt; 收敛，回归。eg.提供相似问题1、2、3–&gt; 无法收敛？转人工 靠谱问题–&gt; 定位，回答 总之一句话：不离本行不废话！ 快速收敛 输入问题的时候就能快速收敛(显示提示列表让用户选择) 对不靠谱问题即时收敛，提供可能的相似问题 二八原则对于很多企业的客户服务来说，80%的客户问题集中在20%的问题类型里。所以要集中攻克的是 – 不停训练智能客服机器人让它能够应对这10%的问题类型中各种刁钻的问法。 知识支撑与自学习客服机器人至少要有的3个知识库: 寒暄库 行业知识库 基于用户体验的知识库 问题多少情感含量？客服机器人与人工服务应该是能进行无缝对接的，因此它的感性层面应该等同于人工客服，在不能回答问题的时候也要彬彬有礼，在寒暄的时候要含蓄内敛不能太过浮夸、奔放。客服机器人掌握的度应该是和人工客服一样，能让客户“如沐春风”的。 是否拒绝谩骂类客户？然而接触了这么多用户问题，也发现有一部分人纯粹是来发牢骚甚至是骂人的，并不期待回答，对于这种情况如何处理？个人认为，“客户是上帝”，然而企业也必须尊重员工，不能任由人工客服承受无理的客服的谩骂，既然机器人和人工客服无缝对接，那么机器人也不应该“承受”这些，而应巧妙的拒绝客户，结束对话。 是否上下文关联？尽可能在一次交互里解决问题。因为通过多次询问后客户的场景往往是混乱的，难以识别。 流程简化的原理、流程输入：客户问题–&gt; 分词、权重–&gt; 语义分析–&gt; 匹配知识–&gt; 要素补足–&gt; 精确匹配–&gt; 回复内容输出: 标准问题 中间可能有的意外是匹配程度低，机器人难以给出准确回复，这时要走另一条线，来发现新的问题，完善服务。精确匹配–&gt; 匹配度低–&gt; 传递到人工–&gt; 人工解答–&gt; 产生新的知识点–&gt; 转交给客服机器人 技术一代：关键词二代：规则+搜索三代：语义网+自学习 目前停留在二代，三代大多还在实验室阶段。 如何精确匹配？ 局部（文本相关）维度设计： 命中核心词？其他字段？权重设计：如何给各维度分配权重？ 全局检索排序：哪个最相关？哪个最有可能相关？","tags":"nlp"},{"title":"实习总结之 sentence embedding","url":"/2016/08/05/实习总结之 sentence embedding/","text":"5-7月的实习，总的来说主要做了三件事情，一是语料的补充，具体表现是通过编写分布式爬虫从各种渠道爬取相关语料，二是特征提取，这一阶段测试了各种模型，doc2vec, lda, LSI, RNN, CNN 等等，试图在 word2vec 词向量基础上，产生质量更高的 sentence embedding,这也是本篇的重点所在。三是新问题发现，主要是通过聚类算法的实验实现。难点在于用什么语料聚类以及如何产生自动化标签。其他的工作也就是打打杂，处理、过滤、验证各种数据，产生训练集、测试集，以及做各种 demo 界面，比较简单。 最终还是发现 doc2vec, lda 产生的 sentence embedding 质量太低，在充足并相关的语料下，用 word2vec 得到的词向量效果还是很不错的，sentence embedding 最终的产生还是通过 RNN。这篇重点是 CNN，因为这是我自己负责的，之后会上一篇 RNN 的版本。 CNN基本介绍见 卷积神经网络 CNN 笔记 来源：Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.(http://www.aclweb.org/anthology/D14-1181) 达到了 94.5% 的准确率，并不如 RNN，因为 CNN 模型的 focus 通常是长文本而不是短句，这里的情景是短句 FAQ，这也是效果不如 RNN 的一个原因。 CNN 一些入门介绍见 CNN 及 TensorFlow 实战 MINST Why CNN句子可以切分为很多词，词和词组合之后会产生局部语意，句子可以分成若干个有『局部语意』的小块。nlp 里面一个很重要的矛盾就是粒度和语意的矛盾。如果粒度过大，则太稀疏没法玩，粒度过小则意思就不对了。CNN 通过卷积，把每 k 个词组合之后的语意放在一起，得到更为准确的句向量。 实现数据格式论文提出的输入类型有以下四种： CNN-rand: 所有的 word vector 都是随机初始化的，同时当做训练过程中优化的参数； CNN-static: 所有的 word vector 直接使用 Word2Vec 工具得到的结果，并且是固定不变的； CNN-non-static: 所有的 word vector 直接使用 Word2Vec 工具得到的结果，这些 word vector 也当做是可优化的参数，在训练过程中被 Fine tuned； CNN-multichannel: CNN-static 和 CNN-non-static 的混合版本，即两种类型的输入； 一般来说 non-static vector 要优于 static vector。我们实验用的是随机初始化方法，数据 format： 用户问题\\t标准问题id 模型输入层输入层是句子中的词语对应的 word vector 依次（从上到下）排列的矩阵，句子有 n 个词，vector的维数为 k ，矩阵就是 n×k。 第一层卷积层输入层通过卷积操作得到若干个 Feature Map，卷积窗口的大小为 h×k ，其中 h 表示纵向词语的个数，而 k 表示 word vector 的维数。如果 h=2，就是相邻的两个word做一次卷积。通过这样一个大型的卷积窗口，得到若干个列数为 1 的Feature Map。 卷积之后的结果经过激活函数 f 得到 feature，记为$c_i$。它是由$x_{i:i+h−1}$相邻的 h 个 words 卷积得到的值，再 activation 之后的值，也是当前层的输出。 卷积之后的值：$w⋅x_{i:i+h−1}+b$输出的 feature 值 $c_i=f(w⋅x_{i:i+h−1}+b)$,这就是我们的 sentence embedding窗口大小：h这样之后，一个 n 长度的sentence就有$[x_{1:h}， x_{2:h+1}，x_{3:h+2}，…，x_{n−h+1:n}]$这些 word windows，卷积后的结果就是 c = $[c1,c2,…,c_{n−h+1}]$，维度为(1，n-h+1)然后进行池化 max pooling，选出最重要的 feature。pooling scheme可以根据句子的长度来选择。 池化层接下来的池化层，才用 Max-over-time Pooling 的方法。从之前一维的 Feature Map 中提出最大的值，论文中解释最大值代表着最重要的信号。可以看出，这种Pooling方式可以解决可变长度的句子输入问题（因为不管Feature Map中有多少个值，只需要提取其中的最大值）。 最终池化层的输出为各个Feature Map的最大值们，即一个一维的向量。 全连接 + Softmax层池化层的一维向量的输出通过全连接的方式，连接一个Softmax层，Softmax层可根据任务的需要设置（通常反映着最终类别上的概率分布）。 调参建议对 Ye Zhang 等人基于 Kim Y 的模型做了大量的调参实验之后的结论： 由于模型训练过程中的随机性因素，如随机初始化的权重参数，mini-batch，随机梯度下降优化算法等，造成模型在数据集上的结果有一定的浮动，如准确率(accuracy)能达到 1.5% 的浮动，而AUC 则有 3.4% 的浮动； 词向量是使用 word2vec 还是 GloVe，对实验结果有一定的影响，具体哪个更好依赖于任务本身； Filter的大小对模型性能有较大的影响，并且Filter的参数应该是可以更新的； Feature Map的数量也有一定影响，但是需要兼顾模型的训练效率； 1-max pooling的方式已经足够好了，相比于其他的pooling方式而言； dropout 非常重要，能够带来 2-4% 的效果提升 multichannel 的效果没有预期的好 调参建议如下： 使用non-static版本的 word2vec 或者 GloVe 要比单纯的 one-hot representation 取得的效果好得多； 为了找到最优的过滤器(Filter)大小，可以使用线性搜索的方法。通常过滤器的大小范围在1-10之间，当然对于长句，使用更大的过滤器也是有必要的； Feature Map的数量在100-600之间； 可以尽量多尝试激活函数，实验发现 ReLU 和 tanh 两种激活函数表现较佳； 使用简单的 1-max pooling 就已经足够了，可以没必要设置太复杂的 pooling 方式； 当发现增加 Feature Map 的数量使得模型的性能下降时，可以考虑增大正则的力度，如调高dropout的概率； 为了检验模型的性能水平，多次反复的交叉验证是必要的，这可以确保模型的高性能并不是偶然。 需要确定的参数： input word vector representations; filter region size(s); the number of feature maps; the activation function(s); the pooling strategy; regularization terms (dropout/l2). 激活函数tanh 目标函数交叉熵 遗留问题还想着能不能用字向量取代词向量，一可以避免分词的麻烦，二可以解决未登录词的问题，这样在测试的时候就很少会遇到Unknown的字向量的问题。另外由于卷积的作用，字向量效果并不一定比词向量差。之后有时间做实验后会更新。 其他实验LDALDA 最大的特点是需要大量的语料，否则数据维度远大于样本数，效果会很差。另外，LDA 适合比较高层次的主题，对稍微细一点的粒度，效果可能就没那么好了。 Doc2vec能产生很好的词向量，却不能产生很好的句向量。推测原因是句子太短。 参考链接卷积神经网络(CNN)在句子建模上的应用","tags":"nlp tensorflow doc2vec 句向量"},{"title":"项目实战--云计算Twitter Analytics Web Service","url":"/2016/07/28/项目实战--云计算Twitter Analytics Web Service/","text":"CMU 15619 Cloud Computing 的 team project，拖了很久，最终还是鼓起勇气整理了。时隔三个多月，回头来看，找到了更多可以优化的点，本篇内容许多是和同伴讨论整理后得出，借鉴了小土刀的博客，然而现在找不到具体地址了抱歉。 项目介绍简介搭建性能高、可靠性好的 web 服务，前端负责处理请求，处理较高负载（大约每秒至少30000次请求） 数据预处理：对大数据集（约1TB）进行预处理，包括过滤脏数据、敏感词、处理停顿词、计算情感分析权重值等，在 hadoop 平台上实现ETL； 后端：保存清理后的 twitter 数据，评估 SQL (MySQL) 和 NoSQL (HBase) 在不同类型的数据、不同大小的数据集下的 performance。 前端：接收并响应不同类型的 HTTP GET 请求 要求：给定预算，最优化性能。 四种 query 类型Query1要求： 对加密信息进行破译，返回正确信息。难度系数： 低。这一阶段主要是用来熟悉各种 web 框架，包括 Undertow, Vert.X, Netty 等，比较性能选定合适框架。 Request: GET /q1?key=&message= Response: TEAMID,TEAM_AWS_ACCOUNT_ID\\n yyyy-MM-dd HH:mm:ss\\n [The decrypted message M]\\n Query2要求： 处理大量的读请求。难度系数： 高。对数据格式有较高要求，如何处理不同语言，各种特殊符号，如何处理敏感词、停顿词、计算情感分析权重值、过滤脏数据等。对性能有较高要求，如何设计前后端来处理高并发的读请求。 Request: GET /q2?userid=uid&hashtag=hashtag Response: TEAMID,TEAM_AWS_ACCOUNT_ID\\n Sentiment_density1:Tweet_time1:Tweet_id1:Censored_text1\\n Sentiment_density2:Tweet_time2:Tweet_id2:Censored_text2\\n Sentiment_density3:Tweet_time3:Tweet_id3:Censored_text3\\n ... Query3要求： 给定一定范围的 user id 和 日期，计算关键词出现的次数。处理大量的写请求。难度系数： 中。依旧是性能的要求。 Request: GET/q3?start_date=yyyy-mm-dd&end_date=yyyy-mm-dd&start_userid=uid&end_userid=uid&words=w1,w2,w3 Response: TEAMID,TEAM_AWS_ACCOUNT_ID\\n w1:count1\\n w2:count2\\n w3:count3\\n Query4要求： 处理高并发读写请求，有一致性要求。难度系数： 高。 Request:GET: q4?tweetid=&op=set&seq=&fields=&payload= SET: q4?tweetid=&op=set&seq=&fields=&payload= Response:GET: q4?tweetid=&op=get&seq=&fields=&payload= SET： TEAMID,TEAM_AWS_ACCOUNT_ID\\n success\\n 应用场景这篇博客是针对 query 2 进行的反思，进一步明确应用场景。 数据是 5100W 条左右带 tag 的 tweet 只有读请求，每次需要返回指定用户用指定 tag 发送的 tweet 有一定的预算限制（不能任意开机器来凑性能） 前端使用 Undertow，后端是部署在 Amazon 的 MySQL 和 Hbase 充分理解应用场景非常非常非常重要，至少需要明确服务具体接收的请求的格式和具体需要返回的内容是什么；是偏向读还是偏向写，还是读写比较均衡；数据量大概是多少…之后才能进行针对性的优化设计。 通用优化纵观整个 Request-response 流程，分以下几个步骤： a. Load Generator to Load Balancer (if any, else merge with b.)b. Load Balancer to Web Servicec. Parsing requestd. Web Service to DBe. At DB (execution)f. DB to Web Serviceg. Parsing DB responseh. Web Service to LBi. LB to LG i 部分我们不需要考虑，因为这个场景并没有用任何渲染引擎，就是单纯返回一段数据而已；c 部分设涉及了解密算法，优化从代码层面入手。数据库（e）与网络传输（b、d、f、h）部分，是主要的瓶颈所在，我们一点一点来分析。 网络传输优化b、d、f、h 部分，实际就是网络部分优化，b、h 涉及 front-end，d、f 涉及 back-end。对后端而言，因为是 只读操作，所以不需要考虑一致性问题，可以做的是 努力增加并发数 使用 ELB 增加多台前端，多台机器并发请求； 同理，多台后端分发数据库请求。 每台机器增加线程数（当然要在内存的允许范围内），但是加到一定程度也就足够了（毕竟带宽是有限的）； 减少每次传输所需要的带宽如在后端对数据进行压缩，在前端进行解压缩，以减少数据传输所需带宽。 这一部分优化的另一个方向是设计缓存，减少对后台的请求。这里的缓存不是说数据库的缓存查询，而是前端对 response 的缓存，目的是对一些请求不用查询数据库就能返回 response，采用的方式通常是 temporal and spatial locality。 有缓存，那么肯定就有预热，预热的重要性在于，把常用的记录缓存下来，为了多一些的缓存，可以是开一个内存优化的机器，比其他系列多一倍内存。 对于 g 的优化，很简单，联系业务场景，读比较多，因此可以对数据进行预处理后（整理成 response 的格式）再存入数据库，用空间换时间。 数据库优化MySQL 选择合适的存储引擎在 MySQL 中有两个存储引擎 MyISAM 和 InnoDB，每个引擎都有利有弊。MyISAM 偏好读操作。适合于需要大量查询的应用，对于有大量写操作并不是很好。update一个字段，整个表都会被锁起来，而其他进程包括读进程都无法操作。MyISAM 对于SELECT COUNT(*) 这类的计算是超快无比的。InnoDB 偏好写操作。是一个非常复杂的存储引擎，对于一些小的应用，它会比 MyISAM 还慢。他是它支持“行锁” ，于是在写操作比较多的时候，会更优秀。并且，他还支持更多的高级应用，比如：事务。 sharding and replicationsharding 是对数据分区存储在不同数据库里，需要考虑的是怎么分区，需要设定规则，可能导致的问题是请求不均衡；replication 比较简单，同一份数据多备份几分，最简单采用 round-robin 分配请求就可以了。 建立 index根据使用频率决定哪些字段需要建立索引，选择经常作为连接条件、筛选条件、聚合查询、排序的字段作为索引的候选字段。 字段设计尽量不要允许 NULL，除非必要，可以用 NOT NULL+DEFAULT 代替。少用TEXT和IMAGE，二进制字段的读写是比较慢的，而且，读取的方法也不多，大部分情况下最好不用。另外，mysql有一个analyse query的功能，可以来帮助你加快速度，比如数据类型的调整，不过这是建立在数据量很大的情况下 查询语句横向来看，不要写 SELECT *的语句，而是选择需要的字段；纵向来看，合理写 WHERE 子句，不要写没有WHERE的SQL语句；开启查询缓存； 参数配置配置文件 /etc/my.cnf max_connections 默认的151，可以修改为3000（750M）max_connections 是指 MySql 的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySql会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。可以过’conn%’通配符查看当前状态的连接数量，以定夺该值的大小。MySQL服务器允许的最大连接数16384；查看系统当前最大连接数 show variables like ‘max_connections’; thread_concurrency 应该设定为CPU核数的2倍thread_concurrency 的值的正确与否, 对mysql的性能影响很大, 在多个cpu(或多核)的情况下，错误设置了 thread_concurrency 的值, 会导致mysql不能充分利用多cpu(或多核), 出现同一时刻只能一个cpu(或核)在工作的情况。 back_log 默认的50，可以修改为500.（每个连接256kb,占用：125M）back_log 值指出在 MySQL 暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到 max_connections 时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过 back_log，将不被授予连接资源。back_log 值不能超过TCP/IP连接的侦听队列的大小。若超过则无效，查看当前系统的TCP/IP连接的侦听队列的大小命令：cat /proc/sys/net/ipv4/tcp_max_syn_backlog。对于 Linux 系统推荐设置为小于 512 的整数。show variables like ‘back_log’; 查看当前数量 HBase Rowkey 设计Rowkey 一定要尽量短 （如：时间用时间戳整数表示、编码压缩） key-value 的设计把一些重要的筛选信息左移到合适的位置，从而在不改变数据量的情况下，提高查询性能，尽量把查询维度或信息存储在行健中，因为它筛选数据的效率最高。理由：HBase 的 Rowkey 是数据行的唯一标识，必须通过它进行数据行访问，目前有三种方式，单行键访问、行键范围访问、全表扫描访问。数据按行键的方式排序存储，依次按位比较，数值较大的排列在后，例如 int 方式的排序：1，10，100，11，12，2，20…，906，…。 增加数据节点Hbase 在行方向上水平划分成 N 个 Region，每个表一开始只有一个 Region，数据量增多，Region 自动分裂为两个，不同 Region 分布在不同 Server 上，但同一个不会拆分到不同 Server。一个 region 只能由一个服务器管理，所以总是添加到同一个 region 上，会造成读写热点，从而使集群性能下降。解决方法，比如我们有9台服务器，那么我们就把0-9均匀加到行健前缀，这样就会被平均的分到不同的 region 服务器上了，好处是，因为相连的数据都分布到不同的服务器上了，用户可以多线程并行的读取数据，这样查询的吞吐量会提高。 参数配置 分配合适的内存给 RegionServer 服务在不影响其他服务的情况下，越大越好。例如在 HBase 的 conf 目录下的 hbase-env.sh 的最后添加 export HBASE_REGIONSERVER_OPTS=”-Xmx16000m $HBASE_REGIONSERVER_OPTS”其中 16000m 为分配给 RegionServer 的内存大小。 RegionServer 的请求处理 IO 线程数较少的 IO 线程适用于处理单次请求内存消耗较高的 Big Put 场景 (大容量单次 Put 或设置了较大 cache 的 Scan，均属于 Big Put) 或 ReigonServer 的内存比较紧张的场景。较多的 IO 线程，适用于单次请求内存消耗低，TPS 要求 (每秒事务处理量 (TransactionPerSecond)) 非常高的场景。设置该值的时候，以监控内存为主要参考。在 hbase-site.xml 配置文件中配置项为 hbase.regionserver.handler.count。200 调整 Block Cachehfile.block.cache.size：RS的block cache的内存大小限制，默认值0.25，在偏向读的业务中，可以适当调大该值，具体配置时需试hbase集群服务的业务特征，结合memstore的内存占比进行综合考虑。 进一步优化 – 架构设计上一部分的优化并不能解决所有问题，至少不能解决多少 front-end 机器，多少 back-end 机器。进一步的优化更多的是依靠实验、依靠监控和日志分析。 场景给定预算，优化性能。一般思路：auto-scaling 方式，在高峰期增加机器，低谷期减少机器 困难模拟 2 分钟 ＝ 现实 1 小时 –&gt; 30 倍缩放现实 2 小时的高峰期对应只有 4 分钟，然而坑爹的是！！！aws 申请机器到使用，有 3-5 分钟的延迟，这个延迟并不会被缩放，也就是说你看到高峰立即响应、增加机器，等到机器投入使用了，高峰就过了。。。所以，要么提前 3-5 分钟预测到高峰期，要么，简单粗暴开够机器，等着。 怎么预测？可以通过观察监控数据，拟合流量曲线。然而设想是美好的，现实是残酷的。模拟实验有时会让服务器假装『挂掉』，这样有一段时间就无法处理任何请求，所以……所以难以拟合。 能做的，只有设定 baseline，调整参数（前后端各有几台机器），不断实验，找最优解了，这里的原则是 充分利用硬件资源。 在预算条件下，对每台机器，其 CPU，内存，带宽等资源都要尽可能的使用，如果资源不平衡，就说明钱没有花在刀刃上，可以考虑更换不同类型的机器，Amazon 提供了『通用』，『内存优化』和『计算优化』这几种不同的机器，可以根据监控的数据，根据前后端不同的任务来决定具体使用什么类型的机器。 监控怎么调整参数？答案就是看监控。重要指标：CPU / 内存 / 网络从这三个角度的数据观察规律，或者用 aws 的 cloud watch 设定一些阈值，设置自动提醒，当然也可以自己写脚本，省钱！ 日志一般来说，不同的 web 服务，用户的请求模式总体来说是有一定规律的。对于 Twitter 数据的分析，就有热门/冷门的用户/hashtag/单词/时间段（比方说有重大事件发生的日子，tweet 的数量可能会更多） 我们应该根据具体的需求，通过统计大致了解数据分布。比方说其中一个请求是返回某用户包含某 hashtag 的 tweet，那么我们最好需要了解哪些用户热门，哪些 hashtag 热门，然后根据这些特点来设计数据库结构、设计缓存。就 Hbase 而言，可以根据这些日志，进行数据库中不同 region 在不同 regionserver 的平衡，充分利用 HBase 的能力。 设计举例前端使用 ELB(负载均衡) + 2 台机器，后端使用 1(master) + 3(slave) 的模式可能是最科学的，这样可以尽可能得减轻前端单机压力。 参考链接：MySQL性能优化的最佳20+条经验MySQL性能优化之参数配置HBase 数据库检索性能优化策略","tags":"mysql hbase webserver"},{"title":"项目实战--App Recommender System","url":"/2016/07/22/项目实战--App Recommender System/","text":"该项目从华为应用市场爬取 app 数据，存到 MongoDB 中，再经过推荐算法更新数据，展示到前端。项目综合了之前讲到的所有爬虫技巧，来源自 BitTiger 的组织。项目共分为 爬虫模块、推荐模块、网站模块 三部分。 技术需求文档爬虫模块从 http://appstore.huawei.com/more/all 爬取总排行榜所有APP数据 Title AppId 缩略图 介绍 从 http://appstore.huawei.com/topics/ 爬取所有专题每个专题包括 Title AppId List 每个包含在专题中的APP，都爬取 Title AppId 缩略图 介绍 从http://appstore.huawei.com/ 做为种子，抓取所有App信息 App List的信息 App 的信息 推荐模块根据输入的App List，输出与这个List最相关的App List 基础数据：AppId List的集合 输入AppId List 输出AppId List 网站模块首页 - A List of most popular Apps（类似于AppStore的Top Charts） Title 缩略图 介绍的前20个字符 详情页 Title 缩略图 完整介绍 相关推荐的App List 爬虫模块简介Skill Python scrapy mongodb proxy scrapyjs Performance 100 pages/second(vs 30k/second) 爬取要点： 利用 Proxy 更换 user-agentsrcapy 发出请求的 user agent 的默认值为Scrapy／version，和普通浏览器的不同，所以网站就会识别出这不是真的用户而是爬虫，就会屏蔽这些请求。所以我们就使用 proxy 随机模拟了不同的 user agent 来“欺骗”网站，才能成功地爬取页面。这一部分是使用 Scrapy middleware 实现的。博客 利用 scrapy-redis 分布式架构加快爬取速度博客 怎样获取更多数据 通过相似 app 通过搜索 扩展链接 解析涉及到 ‘下一页’ 的爬取，见爬虫总结-五-其他技巧 使用 scrapy-splash 部分的实例。 存储文件appstore.dat 存储基本信息，格式 id \\t title \\t intro 12345C5683 微信 华为手机服务:激活华为会员，立享精彩权益！ 更新到手机服务最新版本、免费激活会员，立享高级专属售后服务特权、VIP客服热线，还有160G免费空间、海量衣食住行礼包、华为商城优惠券等你抢！ “手机服务”为华为终端用户提供一站式售后服务，集成华为会员、在线寄修、预约维修、在线客服等十多项丰富的在线服务，旨在为亿万华为终端用户提供优质、省心、快捷的服务。 主要C262 去哪儿旅行 旅游 旅游，去哪儿 去哪儿，酒店 酒店，机票 机票、火车票火车票，门票门票，度假度假，线路线路，快到碗里来！ 去哪儿旅行—总有你要的低价！ 作为中国领先的无线和在线旅游平台，去哪儿旅行支持用户低价购买近60万条国内国际航线，42万家国内酒店、16万家国际酒店；超100万条国内外度假线路和2万种景点门票；享受国内160座城市，以及国外86座城市的C10059090 华为游戏中心 华为游戏中心是华为公司提供的安卓游戏下载平台，所有游戏都经过专业的测评团队层层检测，为您推荐最安全质量最高的游戏内容， 目前我们有20万游戏聚众平台，个性化专题定制，和丰富多元的游戏礼包，还有游戏论坛供大家互动，华为游戏中心不单服务所有华为用户，还支持国内主流安卓机型。 新版本特性： 1、新增 资讯频道，最新热点、最强攻略、最全视频，完C57236 今日头条 今天，看今日头条 今日头条，超过 4 亿用户选择的新闻资讯 App ！ 单用户每日使用时长超过60分钟 每天社交平台分享量达550万次 颠覆传统阅读——人“搜索”资讯的模式，运用大数据算法，精准推荐你感兴趣的内容，从此不受冗杂信息困扰，畅游个性化信息海洋，让你的阅读更加有用高效。 【海量内容源】 聚合超过5000C10217244 华为钱包 华为钱包:1.“红酒”频道，精选莫塞尔多款进口红酒，享受华为特惠价格，让你足不出户品尝世界各地的葡萄佳酿！ 2. “钱包”有生活服务、花币中心、红酒等频道，聚合优质服务，提供超值体验。 3. NFC线下支付，集手机支付和线下刷卡为一体，享受安全快捷的支付体验，省去了随身携带钱包、现金和银行卡的麻烦。（NFC支付功能当前支持荣耀V8全网通版、Mate S appstore_re.dat 存储推荐信息，格式 id \\t url \\t title \\t recommended_appid 1234C5683 http://appstore.huawei.com:80/app/C5683 微信 C2543:QQ同步助手,C9319:QQ,C5373:支付宝,C2682:搜狗输入法,C3466:酷狗音乐,C54626:铃声多多,C2861:同花顺炒股,C36902:WiFi万能钥匙,C104688:腾讯新闻,C21976:UC浏览器,C5683:微信,C9319:QQ,C7166:微博,C10085602:花粉俱乐部,C23563:陌陌,C10154337:易信,C37549:189邮箱,C2543:QQ同步助手,C10405418:QQ邮箱,C19185:百度贴吧,C262 http://appstore.huawei.com:80/app/C262 去哪儿旅行 C6006:蚂蜂窝自由行,C5157:携程旅行,C30591:途牛旅游,C10770:阿里旅行,C69056:驴妈妈旅游,C10027123:航旅纵横,C12192:同程旅游,C10141560:飞常准,C10017070:高铁管家,C10226376:神州专车,C3382:百度地图,C20911:高德地图,C262:去哪儿旅行,C5157:携程旅行,C10047107:滴滴出行,C5745:天翼导航,C3403:高德导航,C10239309:优步 - Uber,C39196:艺龙旅行,C10043914:和地图,C10059090 http://appstore.huawei.com:80/app/C10059090 华为游戏中心 C10217244:华为钱包,C10085602:花粉俱乐部,C10173884:天龙八部3D,C10055832:华为文件管理,C10207207:华为云服务,C10049053:华为商城,C10242764:梦幻西游,C27162:华为应用市场,C10126869:刀塔传奇,C66323:华为备份,C36902:WiFi万能钥匙,C27162:华为应用市场,C10055832:华为文件管理,C66323:华为备份,C21976:UC浏览器,C10067631:华为手机服务,C20679:QQ浏览器,C10207207:华为云服务,C10059090:华为游戏中心,C10132067:华为帐号,C57236 http://appstore.huawei.com:80/app/C57236 今日头条 C19168:凤凰新闻,C9147:网易新闻,C2022:搜狐新闻,C104688:腾讯新闻,C31975:墨迹天气,C40238:内涵段子,C3386:汽车之家,C20960:搜狐视频,C3382:百度地图,C2217:我查查,C57236:今日头条,C9147:网易新闻,C2022:搜狐新闻,C104688:腾讯新闻,C179773:爱读掌阅,C149006:塔读文学,C28837:ZAKER,C86189:爱动漫,C2034:天翼阅读,C10084466:咪咕阅读, app_info.json 存储 app 所有信息12&#123;&quot;title&quot;: &quot;华为商城&quot;, &quot;url&quot;: &quot;http://appstore.huawei.com:80/app/C10049053&quot;, &quot;app_id&quot;: &quot;C10049053&quot;, &quot;recommended&quot;: &quot;C10085602:花粉俱乐部,C10217244:华为钱包,C10168550:亲情关怀,C10055832:华为文件管理,C10060708:华为支付,C10067631:华为手机服务,C10132067:华为帐号,C10465316:华为众测,C10207207:华为云服务,C66323:华为备份,C34075:手机淘宝,C10049053:华为商城,C5206:美团团购,C10608:大众点评,C57804:天猫,C20252:手机京东,C9136:唯品会,C10116109:百度糯米,C41277:苏宁易购,C10284106:美丽说,&quot;, &quot;score&quot;: &quot;8&quot;, &quot;thumbnail_url&quot;: &quot;http://appimg.hicloud.com/hwmarket/files/application/icon144/ea05c760d27f4b58bd6e8b8e88fdc127.png&quot;, &quot;intro&quot;: &quot;【华为商城客户端 我的掌上购机神器】 预约抢购华为、荣耀新品，华为官方商城，值得信赖！HUAWEI P9、荣耀V8、荣耀畅玩5X、HUAWEI Mate8、荣耀7等众多热门手机及丰富的配件，每月促销活动不断，红包疯狂送，抽奖玩不停！ 1、掌上购机神器 每周三移动端专场，手机抢购更便捷； 闹钟提醒，手机抢购不再错过；&lt;b&quot;, &quot;developer&quot;: &quot;华为终端有限公司&quot;&#125;&#123;&quot;title&quot;: &quot;微博&quot;, &quot;url&quot;: &quot;http://appstore.huawei.com:80/app/C7166&quot;, &quot;app_id&quot;: &quot;C7166&quot;, &quot;recommended&quot;: &quot;C10084137:新浪微博(G3版…,C6056298:VSCO Cam™,C19185:百度贴吧,C10159988:in,C10047082:知乎,C10204517:MIX,C10125085:哔哩哔哩动画,C10318669:PicsArt,C10231827:快看漫画,C10168892:网易云音乐,C5683:微信,C9319:QQ,C7166:微博,C10085602:花粉俱乐部,C23563:陌陌,C10154337:易信,C37549:189邮箱,C2543:QQ同步助手,C10405418:QQ邮箱,C19185:百度贴吧,&quot;, &quot;score&quot;: &quot;10&quot;, &quot;thumbnail_url&quot;: &quot;http://appimg.hicloud.com/hwmarket/files/application/icon144/a885314b6da5496084f009a43226dabf.png&quot;, &quot;intro&quot;: &quot;关于百果园： 百果园，深耕水果行业15年水果连锁品牌，首创水果分级标准。 从2001年百果园创立之日起，信守“一生只做一件事，一心一意做水果”的承诺，15年辛勤耕耘，只为让全天下人享受水果好生活。 目前已经在云南、四川、陕西、山西、山东、江苏、海南等省份以及美国、新西兰等国家建立了100多个水果生产基地，同时配有从果园到门店&quot;, &quot;developer&quot;: &quot;新浪网技术（中国）有限公司&quot;&#125; MongoDBMongoDB 中新建 database appstore，新建 collections user_download_history 和 app_info，导入相应文件。将文件导入 MongoDB。 $ mongoimport --db appstore --collection user_download_history --drop --file user_download_history.json $ mongoimport --db appstore --collection app_info --drop --file app_info.json 123&gt; db.app_info.find()&#123; &quot;_id&quot; : ObjectId(&quot;577cbfade677be6b09d8dc2c&quot;), &quot;score&quot; : &quot;8&quot;, &quot;title&quot; : &quot;果汁四溅&quot;, &quot;url&quot; : &quot;http://appstore.huawei.com:80/app/C10204319&quot;, &quot;app_id&quot; : &quot;C10204319&quot;, &quot;thumbnail_url&quot; : &quot;http://appimg.hicloud.com/hwmarket/files/application/icon144/f986a241d80d46fcb4fecc1e85121a60.png&quot;, &quot;intro&quot; : &quot;【果汁四溅】年度最“溅”的消除游戏！首发大奖10台iphone6溅到你手！ ★全球50多个国家APP商店推荐★ ★30个国家桌面游戏排名第一★ ★5000万玩家五星好评★ 游戏特色： 【七大新玩法，酷炫拽！叼咋天！】 【250关挑战极限！救救水果君】 【果汁爆溅，萌翻全场！】 首发&quot;, &quot;developer&quot; : &quot;深圳市唯变科技开发有限公司&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;577cbfade677be6b09d8dc2d&quot;), &quot;score&quot; : &quot;9&quot;, &quot;title&quot; : &quot;泡泡龙亚特兰蒂斯&quot;, &quot;url&quot; : &quot;http://appstore.huawei.com:80/app/C10145675&quot;, &quot;app_id&quot; : &quot;C10145675&quot;, &quot;thumbnail_url&quot; : &quot;http://appimg.hicloud.com/hwmarket/files/application/icon144/cb3c6ce12b73424990921097fe20a7b1.png&quot;, &quot;intro&quot; : &quot;泡泡龙亚特兰蒂斯:一款令人着迷的泡泡龙游戏。在经典的游戏模式中增加了独有的BOSS战，每个场景都 有独特的守护者等待你的挑战。多种多样的奇趣道具供你使用。打BOSS，秀操作，耍道具让你爱不释手。欢乐之旅由一段美丽的故事带你进入。前所未有的体验，带给你神奇的亚特兰蒂斯之旅。&quot;, &quot;developer&quot; : &quot;深圳市灵游科技有限公司&quot; &#125; 123&gt; db.user_download_history.find()&#123; &quot;_id&quot; : ObjectId(&quot;5691f793f0fe47e651ba1a52&quot;), &quot;user_id&quot; : 3, &quot;download_history&quot; : [ &quot;C10249215&quot;, &quot;C10221865&quot;, &quot;C10269239&quot;, &quot;C10157957&quot;, &quot;C10148546&quot;, &quot;C10241662&quot;, &quot;C10203747&quot;, &quot;C10144080&quot;, &quot;C10136202&quot;, &quot;C10271994&quot; ] &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5691f793f0fe47e651ba1a53&quot;), &quot;user_id&quot; : 4, &quot;download_history&quot; : [ &quot;C10026769&quot;, &quot;C10053551&quot;, &quot;C10237091&quot;, &quot;C10141383&quot;, &quot;C10162014&quot;, &quot;C10148546&quot; ] &#125; 推荐模块简介Skill Python collaborative-filtering algorithm cosine_similarity Performance 1 second/app(vs with 10ms/app) 推荐算法协同过滤算法简述基于用户的协同过滤算法（User CF）强调 把和你有相似爱好的其他的用户的物品推荐给你基于用户对物品的偏好找到相邻邻居用户，然后将邻居用户喜欢的推荐给当前用户。 过程： 将一个用户对所有物品的偏好作为一个向量来计算用户之间的相似度，找到和目标用户兴趣相似的用户集合； 找到这个集合中的用户喜欢的，且目标用户没有访问过的物品，计算得到一个排序的物品列表作为推荐。 优点和适用场景： 可以发现用户感兴趣的热门物品 用户有新行为，不一定造成推荐结果的立即变化 适用于用户较少的场合，否则用户相似度矩阵计算代价很大 适合时效性较强，用户个性化兴趣不太明显的领域 缺点： 数据稀疏性。一个大型的电子商务推荐系统一般有非常多的物品，用户可能买的其中不到1%的物品，不同用户之间买的物品重叠性较低，导致算法无法找到一个用户的邻居，即偏好相似的用户。 算法扩展性。最近邻居算法的计算量随着用户和物品数量的增加而增加，不适合数据量大的情况使用。 对新用户不友好，对新物品友好，因为用户相似度矩阵不能实时计算 很难提供令用户信服的推荐解释 基于物品的协同过滤算法强调 把和你喜欢的物品相似的物品推荐给你基于物品的 CF 的原理和基于用户的 CF 类似，只是在计算邻居时采用物品本身，而不是从用户的角度。在京东、天猫上看到「购买了该商品的用户也经常购买的其他商品」，就是主要基于 ItemBasedCF。 过程： 基于用户对物品的偏好计算相似度，找到相似的物品； 根据物品的相似度和用户的历史行为预测当前用户还没有表示偏好的物品，计算得到一个排序的物品列表作为推荐。 因为物品直接的相似性相对比较固定，所以可以预先在线下计算好不同物品之间的相似度，把结果存在表中，当推荐时进行查表，计算用户可能的打分值。 优点和适用场景： 可以发现用户潜在的但自己尚未发现的兴趣爱好 有效的进行长尾挖掘 利用用户的历史行为给用户做推荐解释，使用户比较信服 适用于物品数明显小于用户数的场合，否则物品相似度矩阵计算代价很大 适合长尾物品丰富，用户个性化需求强的领域 缺点： 对新用户友好，对新物品不友好，因为物品相似度矩阵不需要很强的实时性 Item CF 和 User CF 是基于协同过滤推荐的两个最基本的算法，大家都觉得 Item CF 从性能和复杂度上比 User CF 更优，其中的一个主要原因就是对于一个在线网站，用户的数量往往大大超过物品的数量，同时物品的数据相对稳定，因此计算物品的相似度不但计算量较小，但这种情况只适应于提供商品的电子商务网站，对于新闻，博客或者微内容的推荐系统，情况往往是相反的，物品的数量是海量的，同时也是更新频繁的，所以单从复杂度的角度，这两个算法在不同的系统中各有优势，推荐引擎的设计者需要根据自己应用的特点选择更加合适的算法。 两个例子： 非社交网络：在非社交网络的网站中，内容内在的联系是很重要的推荐原则，它比基于相似用户的推荐原则更加有效。比如在购书网站上，当你看一本书的时候，推荐引擎会给你推荐相关的书籍，这个推荐的重要性远远超过了网站首页对该用户的综合推荐。可以看到，在这种情况下，Item CF 的推荐成为了引导用户浏览的重要手段。同时 Item CF 便于为推荐做出解释，在一个非社交网络的网站中，给某个用户推荐一本书，因为这本书和你以前看的某本书相似，用户可能就觉得合理而采纳了此推荐。 社交网络：在现今很流行的社交网络站点中，User CF 是一个更不错的选择，User CF 加上社会网络信息，可以增加用户对推荐解释的信服程度。 更多见[推荐算法]基于用户的协同过滤算法 项目算法采用的是基于物品的协同过滤算法，相似度算法用的是 cosine similarity。通过计算 similarity between a1 and all user download history 来推导 similarity between a1 and all other apps，前提是假定每个 user download history list 里的 app 是相互关联的。看下面的具体例子。 cosine similarity similarity between a3 and a5 a3’s top-5 related apps 实现首先读取 MongoDB 的数据，过程略。这里主要展示算法实现。cosine similarity123456789101112@classmethoddef cosine_similarity(cls, app_list1, app_list2): match_count = cls.__count_match(app_list1, app_list2) return float(match_count) / math.sqrt( len(app_list1) * len(app_list2))@classmethoddef __count_match(cls, list1, list2): count = 0 for element in list1: if element in list2: count += 1 return count top-5 related app_list112345678910111213141516171819202122def calculate_top_5(app, user_download_history): &apos;&apos;&apos; cosine_similarity between an App and user&apos;s history &apos;&apos;&apos; #create a dict to store each other app and its similarity to this app app_similarity = collections.defaultdict(float) #&#123;app_id: similarity&#125; for apps in user_download_history: #calculate the similarity similarity = Helper.cosine_similarity([app], apps) # accumluate similarity for other_app in apps: app_similarity[other_app] += similarity # There could be app without related apps (not in any download history) if not app in app_similarity: return #sort app_similarity dict by value and get the top 5 as recommendation app_similarity.pop(app) sorted_tups = sorted(app_similarity.items(), key=operator.itemgetter(1), reverse=True)#sort by similarity top_5_app = [sorted_tups[0][0], sorted_tups[1][0], sorted_tups[2][0], sorted_tups[3][0], sorted_tups[4][0]] #print(&quot;top_5_app for &quot; + str(app) + &quot;:\\t&quot; + str(top_5_app)) 最后要更新 MongoDB 中的数据。更新后的数据如下12&#123; &quot;_id&quot; : ObjectId(&quot;577cbfade677be6b09d8dc2c&quot;), &quot;score&quot; : &quot;8&quot;, &quot;title&quot; : &quot;果汁四溅&quot;, &quot;url&quot; : &quot;http://appstore.huawei.com:80/app/C10204319&quot;, &quot;app_id&quot; : &quot;C10204319&quot;, &quot;thumbnail_url&quot; : &quot;http://appimg.hicloud.com/hwmarket/files/application/icon144/f986a241d80d46fcb4fecc1e85121a60.png&quot;, &quot;intro&quot; : &quot;【果汁四溅】年度最“溅”的消除游戏！首发大奖10台iphone6溅到你手！ ★全球50多个国家APP商店推荐★ ★30个国家桌面游戏排名第一★ ★5000万玩家五星好评★ 游戏特色： 【七大新玩法，酷炫拽！叼咋天！】 【250关挑战极限！救救水果君】 【果汁爆溅，萌翻全场！】 首发&quot;, &quot;developer&quot; : &quot;深圳市唯变科技开发有限公司&quot;, &quot;top_5_app&quot; : [ &quot;C10053551&quot;, &quot;C10148546&quot;, &quot;C10141383&quot;, &quot;C10189589&quot;, &quot;C10026769&quot; ] &#125;&#123; &quot;_id&quot; : ObjectId(&quot;577cbfade677be6b09d8dc2d&quot;), &quot;score&quot; : &quot;9&quot;, &quot;title&quot; : &quot;泡泡龙亚特兰蒂斯&quot;, &quot;url&quot; : &quot;http://appstore.huawei.com:80/app/C10145675&quot;, &quot;app_id&quot; : &quot;C10145675&quot;, &quot;thumbnail_url&quot; : &quot;http://appimg.hicloud.com/hwmarket/files/application/icon144/cb3c6ce12b73424990921097fe20a7b1.png&quot;, &quot;intro&quot; : &quot;泡泡龙亚特兰蒂斯:一款令人着迷的泡泡龙游戏。在经典的游戏模式中增加了独有的BOSS战，每个场景都 有独特的守护者等待你的挑战。多种多样的奇趣道具供你使用。打BOSS，秀操作，耍道具让你爱不释手。欢乐之旅由一段美丽的故事带你进入。前所未有的体验，带给你神奇的亚特兰蒂斯之旅。&quot;, &quot;developer&quot; : &quot;深圳市灵游科技有限公司&quot;, &quot;top_5_app&quot; : [ &quot;C2217&quot;, &quot;C40224&quot;, &quot;C10196888&quot;, &quot;C10197446&quot;, &quot;C10047107&quot; ] &#125; 网站模块Skill javascript node.js meteor mongodb Performance 1k QPS (vs 10k QPS) 具体实现见 Meteor – App Recommender System","tags":"crawler"},{"title":"python-cgi + ajax 实现异步响应表单","url":"/2016/07/18/socket + python-cgi + ajax 实现异步响应表单/","text":"简单的界面用于个人 or 公司内部 demo。 cgiCGI 目前由NCSA维护，NCSA定义CGI如下：CGI(Common Gateway Interface),通用网关接口,它是一段程序,运行在服务器上如：HTTP服务器，提供同客户端HTML页面的接口。 架构 教程cgi 实在是…… 太！简！单！太！方！便了！不废话，上个教程。Python CGI编程 配置apache cgi 配置教程网上都有，上面的教程也有介绍，值得一提的是，我遵照了若干教程，然而并没能用 mac 自带的 apache 配置 cgi 成功，最后是用 xampp 配置好的，推测是原有的 xampp 对本机的 apache 有改动。 下面记录下 xampp 配置 cgi 过程。在 /Application/XAMPP/etc/httpd.conf 改123456&lt;Directory &quot;/Applications/XAMPP/xamppfiles/cgi-bin/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks MultiViews ExecCGI Order allow,deny Allow from all&lt;/Directory&gt; 在 /Applications/XAMPP/xamppfiles/apache2/conf/httpd.conf 改123456&lt;Directory &quot;/Applications/XAMPP/xamppfiles/apache2/htdocs&quot;&gt; Options Indexes FollowSymLinks MultiViews ExecCGI AllowOverride All Order allow,deny Allow from all&lt;/Directory&gt; 重启，把 cgi 代码放到 /Applications/XAMPP/xamppfiles/cgi-bin/ 目录下运行，如果无法运行，改权限 chmod 755 test.py 附测试代码1234567891011121314#!/usr/bin/python# -*- coding: UTF-8 -*-print &quot;Content-type:text/html&quot;print # 空行，告诉服务器结束头部print &apos;&lt;html&gt;&apos;print &apos;&lt;head&gt;&apos;print &apos;&lt;meta charset=&quot;utf-8&quot;&gt;&apos;print &apos;&lt;title&gt;Hello Word - 我的第一个 CGI 程序！&lt;/title&gt;&apos;print &apos;&lt;/head&gt;&apos;print &apos;&lt;body&gt;&apos;print &apos;&lt;h2&gt;Hello Word! 我是来自菜鸟教程的第一CGI程序&lt;/h2&gt;&apos;print &apos;&lt;/body&gt;&apos;print &apos;&lt;/html&gt;&apos; 浏览器打开 http://localhost/cgi-bin/test.py， 测试成功。 cgi 调试为了浏览器调试，在 cgi 文件中加上下面的代码。12import cgitbcgitb.enable() 这时，debug信息会显示在浏览器上面，方便调试。生产环境中出于安全的考虑，一般会关掉debug的功能。 ajax简介AJAX 全称 Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。它并非一种新的技术，而是以下几种原有技术的结合体。 使用 CSS 和 XHTML 来表示。 使用 DOM 模型来交互和动态显示。 使用 XMLHttpRequest 来和服务器进行异步通信。 使用 javascript 来绑定和调用。 通过 AJAX 异步技术，可以在客户端脚本与 web 服务器交互数据的过程中使用 XMLHttpRequest 对象来完成 HTTP 请求(Request)/应答(Response)模型： 不需要用户等待服务端响应。在异步派发 XMLHttpRequest 请求后控制权马上就被返回到浏览器。界面不会出现白板，在得到服务器响应之前还可以友好的给出一个加载提示。 不需要重新加载整个页面。为 XMLHttpRequest 注册一个回调函数，待服务器响应到达时，触发回调函数，并且传递所需的少量数据。“按需取数据”也降低了服务器的压力。 不需要使用隐藏或内嵌的框架。在 XHR 对象之前，模拟 Ajax 通信通常使用 hack 手段，如使用隐藏的或内嵌的框架(iframe标签)。 重要对象：XMLHttpRequestXMLHttpRequest 是一套可以在 Javascript、VbScript、Jscript 等脚本语言中通过http协议传送或接收 XML 及其他数据的一套API。 主要函数(客户端) open(method,url,async, bstrUser, bstrPassword)规定请求的类型、URL 以及是否异步处理请求。 setRequestHeader(name,value)自定义HTTP头部信息。需在open()方法之后和send()之前调用，才能成功发送请求头部信息。onreadystatchange, send(string)将请求发送到服务器。参数string仅用于POST请求；对于GET请求的参数写在url后面，所以string参数传递null。 简单实例封装123456789101112131415161718192021222324var myAjax = &#123; // XMLHttpRequest IE7+, Firefox, Chrome, Opera, Safari ； ActiveXObject IE6, IE5 xhr: window.XMLHttpRequest ? new XMLHttpRequest() : new ActiveXObject(&apos;Microsoft.XMLHTTP&apos;), get: function (url, callback) &#123; this.xhr.open(&apos;get&apos;, url); this.onreadystatechange(callback, this.xhr); this.xhr.send(null); &#125;, post: function (url, data, callback) &#123; this.xhr.open(&apos;post&apos;, url); this.xhr.setRequestHeader(&apos;Content-Type&apos;, &apos;application/x-www-form-urlencoded&apos;); this.onreadystatechange(callback, this.xhr); this.xhr.send(data); &#125;, onreadystatechange: function (func, _xhr) &#123; _xhr.onreadystatechange = function () &#123; if (_xhr.readyState == 4) &#123; if (_xhr.status == 200) &#123; func(_xhr.responseText); &#125; &#125; &#125; &#125;&#125; 使用123456789$(&apos;#btn_nowTime1&apos;).bind(&apos;click&apos;, null , function () &#123; myAjax.post(&apos;AjaxHandler.ashx&apos;, &apos;func=GetServerTime&apos; , function (data) &#123; if (data) alert(data); &#125; ); &#125;); socketSocket 是任何一种计算机网络通讯中最基础的内容。例如当你在浏览器地址栏中输入 www.oschina.net 时，你会打开一个套接字，然后连接到 www.oschina.net 并读取响应的页面然后然后显示出来。而其他一些聊天客户端如 gtalk 和 skype 也是类似。任何网络通讯都是通过 Socket 来完成的。下面简单介绍下 python 的 socket 编程。 server主要函数 s.bind(address)将 socket 绑定到地址, 在 AF_INET 下,以元组（host,port）的形式表示地址. s.listen(backlog)开始监听 TCP 传入连接。backlog 指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。 s.accept()接受TCP连接并返回（conn,address）,其中 conn 是新的 socket 对象，可以用来接收和发送数据。address是连接客户端的地址。 过程 创建 socket socket.socket(socket.AF_INET,socket.SOCK_STREAM) 绑定到本地IP与端口 s.bind() 开始监听连接 s.listen() 进入循环，不断接受客户端的连接请求 s.accept() 然后接收传来的数据，并发送给对方数据 # 接收数据 s.recv() # 发送数据 s.sendall() 传输完毕后，关闭socket s.close() client主要函数 s.connect(address)连接到 address 处的 socket。一般 address 的格式为元组（hostname,port），如果连接出错，返回 socket.error 错误。 s.connect_ex(adddress)功能与 connect(address) 相同，但是成功返回0，失败返回errno的值。 过程 创建 socket，连接远端地址 socket.socket(socket.AF_INET,socket.SOCK_STREAM) s.connect() 连接后发送数据和接收数据 s.sendall() s.recv() 传输完毕后，关闭 socket s.close() server, client 主要公共函数 s.recv(bufsize[,flag])接受 TCP socket 的数据。数据以字符串形式返回，bufsize 指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。 s.send(string[,flag])发送TCP数据。将string中的数据发送到连接的 socket 。返回值是要发送的字节数量，该数量可能小于 string 的字节大小。 s.sendall(string[,flag])完整发送TCP数据。将string中的数据发送到连接的 socket ，但在返回之前会尝试发送所有数据。成功返回 None，失败则抛出异常。 s.close()关闭 socket。 实例实现一个简单的 socket，用户输入问题，刷新页面响应。 server 完整代码1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/python# -*- coding: UTF-8 -*-import socketimport sysHOST = &apos;localhost&apos; # Symbolic name meaning all available interfacesPORT = 9000 # Arbitrary non-privileged port# create tcp sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)print &apos;Socket created&apos;try: s.bind((HOST, PORT))except socket.error , msg: print &apos;Bind failed. Error Code : &apos; + str(msg[0]) + &apos; Message &apos; + msg[1] sys.exit()print &apos;Socket bind complete&apos;s.listen(10)print &apos;Socket now listening&apos;while 1: #wait to accept a connection - blocking call conn, addr = s.accept() print &apos;Connected with &apos; + addr[0] + &apos;:&apos; + str(addr[1]) data = conn.recv(1024) reply = &apos;&#123;&quot;search&quot;:&#123;&quot;cost&quot;:0.01,&quot;data&quot;:[&#123;&quot;ask&quot;:&quot;在哪里&quot;,&quot;answer&quot;:[&quot;不是在这里&quot;,&quot;你在这里&quot;,&quot;好久不见&quot;],&quot;score&quot;:99&#125;]&#125;,&quot;model&quot;:&#123;&quot;cost&quot;:0.02,&quot;answer&quot;:&quot;在这里哈哈哈&quot;&#125;&#125;&apos; print reply if not data: break conn.sendall(reply)conn.close()s.close() client 完整代码client 响应表单mysocket.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#!/usr/bin/python# -*- coding: UTF-8 -*-import jsonimport socketimport cgitbimport cgicgitb.enable()form = cgi.FieldStorage()question = form.getvalue(&apos;question&apos;)sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)sock.connect((&apos;localhost&apos;, 9000))message = questiontry: # Set the whole string sock.sendall(message)except socket.error: # Send failed print &apos;Send failed&apos; sys.exit()# sock.send(data)result = json.loads(sock.recv(10240))# 以下代码处理 json 并显示表单search_cost = result[&apos;search&apos;][&apos;cost&apos;]answers = result[&apos;search&apos;][&apos;data&apos;][0][&apos;answer&apos;]ans = answers[0]search_score = result[&apos;search&apos;][&apos;data&apos;][0][&apos;score&apos;]rnnAns = result[&apos;model&apos;]print &quot;Content-type:text/html&quot;printprint &apos;&lt;html&gt;&apos;print &apos;&lt;head&gt;&apos;print &apos;&lt;meta charset=&quot;utf-8&quot;&gt;&apos;print &apos;&lt;title&gt;TEST&lt;/title&gt;&apos;print &apos;&lt;/head&gt;&apos;print &apos;&lt;body align=&quot;center&quot;&gt;&lt;div width=&quot;980&quot; align=&quot;center&quot;&gt;&apos;print &quot;&lt;h2&gt;Question: &quot; + question + &quot;&lt;/h2&gt;&quot;print &quot;&lt;hr &gt;&lt;h2&gt; Top 3&lt;/h2&gt;&quot;print &quot;Cost: &quot;print search_costprint &quot;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;print &quot;Score: &quot;print search_scoreprint &quot;&lt;br &gt;&quot;for i in range(1, len(answers) + 1): print &quot;&lt;p&gt;&quot; print i print &quot;:&amp;nbsp;&quot; print answers[i - 1].encode(&apos;utf8&apos;) print &quot;&lt;br&gt;&quot;print &quot;&lt;hr /&gt;&lt;h2&gt; RNN &amp;nbsp; Model &lt;/h2&gt;&quot;print &quot;Cost: &quot;print rnnAns[&apos;cost&apos;]print &quot;&lt;br&gt;&lt;p&gt;&quot;print rnnAns[&apos;answer&apos;].encode(&apos;utf8&apos;)print &quot;&lt;/p&gt;&quot;print &quot;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&quot;print &apos;&lt;/div&gt;&lt;/body&gt;&apos;print &apos;&lt;/html&gt;&apos; client 主页面index.html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt; &lt;style&gt; body &#123; font-family: &quot;arial&quot;; &#125; table, td, th &#123; border: 1px solid #ddd; &#125; th, td &#123; border-bottom: 1px solid #ddd; height: 50px; text-align: left; &#125; table &#123; border-collapse: collapse; width: 80%; &#125; &#125; &lt;/style&gt; &lt;title&gt;Simple Evaluation Check&lt;/title&gt; &lt;script language=&quot;Javascript&quot;&gt; function xmlhttpPost(strURL) &#123; var xmlHttpReq = false; var self = this; // Mozilla/Safari if (window.XMLHttpRequest) &#123; self.xmlHttpReq = new XMLHttpRequest(); &#125; // IE else if (window.ActiveXObject) &#123; self.xmlHttpReq = new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;); &#125; self.xmlHttpReq.open(&apos;POST&apos;, strURL, true); # 设置 content-type self.xmlHttpReq.setRequestHeader(&apos;Content-Type&apos;, &apos;application/x-www-form-urlencoded&apos;); self.xmlHttpReq.onreadystatechange = function() &#123; if (self.xmlHttpReq.readyState == 4) &#123; updatepage(self.xmlHttpReq.responseText); &#125; &#125; self.xmlHttpReq.send(getquerystring()); &#125; function getquerystring() &#123; var form = document.forms[&apos;f1&apos;]; var question = form.question.value; qstr = &apos;question=&apos; + question; // NOTE: no &apos;?&apos; before querystring return qstr; &#125; function updatepage(str) &#123; document.getElementById(&quot;result&quot;).innerHTML = str; &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;form name=&quot;f1&quot;&gt; &lt;p&gt;Question: &lt;input name=&quot;question&quot; type=&quot;text&quot;&gt; &lt;input value=&quot;Go&quot; type=&quot;button&quot; onclick=&apos;JavaScript:xmlhttpPost(&quot;cgi-bin/mysocket.py&quot;)&apos;&gt; &lt;/p&gt; &lt;div id=&quot;result&quot;&gt;&lt;/div&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 运行运行 server.py，浏览器输入 http://localhost/index.html 查看效果主页 异步响应 server 参考链接Python CGI编程Writing Your First Python CGI – Ajax Script触碰jQuery：AJAX异步详解","tags":"前端 cgi ajax socket"},{"title":"Tf-idf 总结笔记","url":"/2016/07/10/Tfidf总结笔记/","text":"简单的概念，强大的效用。附 sklearn 和 nltk 实现代码。 部分截图、概念描述来自 CMU 95 - 865 Text Analytics，上课的时候没有好好做笔记，到实习的时候发现，有些概念虽然很简单，但确实很实用，理解透彻才能发挥无穷效力。是在评估聚类算法的时候偶然想到的方法，确！实！很！有！用！ TF-IDF（term frequency–inverse document frequency），一种常用的加权技术，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。主要逻辑是：字词的重要性随著它在文件中出现的次数成正比增加，但同时会随著它在语料库中出现的频率成反比下降。 TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜寻引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。 预备知识Heap’s law 通常用于预测 vocabulary size，Zipf’s law 则用于描述 term frequency 的分布。 Heaps’ Law一张图解释。 Zipf’s Law齐普夫定律，本科信息计量学就学过，大致是说，在一个自然语言的语料库中，一个词的出现频数和这个词在这个语料中的排名（这个排名是基于出现次数的）成反比，频数和排名的乘积是常数。即 Rank Frequency = Constant (Constant = 0.1 N)，或者 P(tR) = 0.1/N。Zipf’s law 告诉我们以下几点 ‘A few terms are very common’，这些大部分是 stopwords。 ‘Most terms are very rare’，多数 term 只出现两三次，完全可以忽略。 very common 的，very rare 的在文本分析中都可以忽略，真正重要的是在中间的一部分 terms。 两幅图概括。 从 Zipf’s law 得到的一些数字是： 排名第一的词占全部词的 10% 排名前5的词占全部词的 23% 前100 的词占全部词的 52% 50% 的 term 只出现了一次 91% 的 term 出现的次数小于 10 应用合理使用 Zipf’s law，我们可以大大减少字典存储内存。另外， Zipf’s law 还可以为特定的任务制作特定的 stopwords list。 Example: “trading” and “prices” are frequent Wall Street Journal terms• They are candidate stopwords• They also are important terms for financial analysis• If your task is financial analysis, leave them in• If your task is analysis of technology products, maybe discard them Tf-idf 笔记逻辑Zipf’s law 给出了自然语言的统计性质，term frequence is highly skewed. 由此发展出了更能代表 term weight 的方法，tf - idf，用中文来表述没那么直观，且看英文解释。简单来讲就是说，如果某个词或短语在一篇文章中出现的频率 TF 高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。 公式 tf 通常会被正规化，以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否。） 意义 Reward words that better represent each document Reward words that discriminate among different documents Scale for document length 当然也有些情境下 tf 已经足够，并不需要 tfidf，如 文件都是同一长度 并不需要区分文件（也就不需要idf） 机器学习算法可以学习特征等 代码实现sklearn 方法首先看下要用到的两个类，CountVectorizer 和 TfidfTransformer。参数一目了然，之后对比与 nltk 结果差异时再做解释。CountVectorizer12345678&gt;&gt;&gt; vectorizer = CountVectorizer()&gt;&gt;&gt; vectorizerCountVectorizer(analyzer=u&apos;word&apos;, binary=False, decode_error=u&apos;strict&apos;, dtype=&lt;type &apos;numpy.int64&apos;&gt;, encoding=u&apos;utf-8&apos;, input=u&apos;content&apos;, lowercase=True, max_df=1.0, max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None, stop_words=None, strip_accents=None, token_pattern=u&apos;(?u)\\\\b\\\\w\\\\w+\\\\b&apos;, tokenizer=None, vocabulary=None) TfidfTransformer1234&gt;&gt;&gt; tfidfTransformer = TfidfTransformer()&gt;&gt;&gt; tfidfTransformerTfidfTransformer(norm=u&apos;l2&apos;, smooth_idf=True, sublinear_tf=False, use_idf=True) 计算 tfidf 代码123456789101112131415161718192021222324252627282930from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformercorpus = []doc1 = &quot;I love Chinese food&quot;doc2 = &quot;I love American spirits&quot;corpus.append(doc1)corpus.append(doc2)def calTfidf(corpus): # 该转换为词频矩阵 矩阵元素a[i][j] 表示j词在i类文本下的词频 vectorizer = CountVectorizer() # vectorizer = CountVectorizer(token_pattern=&apos;(?u)\\\\b\\\\w+\\\\b&apos;) # 统计每个词语的tf-idf权值 transformer = TfidfTransformer() # transformer = TfidfTransformer(norm=None) tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus)) tfidf_weight = tfidf.toarray() idf_weight = transformer.idf_ # idf np.log(float(n_samples) / df) + 1.0 word = vectorizer.get_feature_names() # 获取词袋模型中的所有词语 termWeights = dict() for i in range(len(tfidf_weight)): lwords = [(word[j], float(tfidf_weight[i][j]), float(idf_weight[j])) for j in range(len(word))] lwords = sorted(lwords, key=lambda m: -m[1]) termWeights[i] = lwords for key, items in termWeights.items(): print u&quot;-------第&quot;, key, u&quot;类文本的词语tf-idf权重------&quot; for item in items: print &apos;Word: &#123;&#125;\\tTfidf: &#123;&#125;\\tIdf: &#123;&#125;&apos;.format(item[0], item[1], item[2]) 输出 -------第 0 类文本的词语tf-idf权重------ Word: chinese Tfidf: 0.631667201738 Idf: 1.40546510811 Word: food Tfidf: 0.631667201738 Idf: 1.40546510811 Word: love Tfidf: 0.449436416524 Idf: 1.0 Word: american Tfidf: 0.0 Idf: 1.40546510811 Word: spirits Tfidf: 0.0 Idf: 1.40546510811 -------第 1 类文本的词语tf-idf权重------ Word: american Tfidf: 0.631667201738 Idf: 1.40546510811 Word: spirits Tfidf: 0.631667201738 Idf: 1.40546510811 Word: love Tfidf: 0.449436416524 Idf: 1.0 Word: chinese Tfidf: 0.0 Idf: 1.40546510811 Word: food Tfidf: 0.0 Idf: 1.40546510811 为什么少了个 I ？看 CountVectorizer 构造器有一个参数是 token_pattern，忽略了单个字母的 word。 token_pattern (default u'(?u)\\b\\w\\w+\\b'), regular expression identifying tokens–by default words that consist of a single character (e.g., ‘a’, ‘2’) are ignored, setting token_pattern to '(?u)\\b\\w+\\b' will include these tokens 改成 vectorizer = CountVectorizer(token_pattern=’(?u)\\b\\w+\\b’) 就会包括 I -------第 0 类文本的词语tf-idf权重------ Word: chinese Tfidf: 0.576152355165 Idf: 1.40546510811 Word: food Tfidf: 0.576152355165 Idf: 1.40546510811 Word: i Tfidf: 0.40993714596 Idf: 1.0 Word: love Tfidf: 0.40993714596 Idf: 1.0 Word: american Tfidf: 0.0 Idf: 1.40546510811 Word: spirits Tfidf: 0.0 Idf: 1.40546510811 -------第 1 类文本的词语tf-idf权重------ Word: american Tfidf: 0.576152355165 Idf: 1.40546510811 Word: spirits Tfidf: 0.576152355165 Idf: 1.40546510811 Word: i Tfidf: 0.40993714596 Idf: 1.0 Word: love Tfidf: 0.40993714596 Idf: 1.0 Word: chinese Tfidf: 0.0 Idf: 1.40546510811 Word: food Tfidf: 0.0 Idf: 1.40546510811 nltk 方法1234567891011121314151617181920212223242526272829303132333435363738from __future__ import division, unicode_literalsfrom textblob import TextBlob as tbimport mathcorpus = []doc1 = &quot;I love Chinese food&quot;doc2 = &quot;I love American spirits&quot;corpus.append(doc1)corpus.append(doc2)def tf(word, blob): return blob.words.count(word) / len(blob.words)def n_containing(word, bloblist): return sum(1 for blob in bloblist if word in blob.words)def idf(word, bloblist): return math.log(len(bloblist) / n_containing(word, bloblist)) + 1def tfidf(word, blob, bloblist): return tf(word, blob) * idf(word, bloblist)def calTfidf(corpus): bloblist = [tb(doc.strip(&apos;\\n&apos;)) for doc in corpus] for i, blob in enumerate(bloblist): tf_scores = &#123;word: tf(word, blob) for word in blob.words&#125; idf_scores = &#123;word: idf(word, bloblist) for word in blob.words&#125; tfidf_scores = &#123;word: tfidf(word, blob, bloblist) for word in blob.words&#125; sorted_words = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True) print &apos;u&quot;-------第&quot;, key, u&quot;类文本的词语tf-idf权重------&quot;&apos; for word, score in sorted_words[:50]: print (&quot;Word: &#123;&#125;\\t TF-IDF: &#123;&#125;\\t TF: &#123;&#125;\\t IDF: &#123;&#125;&quot;.format(word, round(score, 5), tf_scores[word], round(idf_scores[word], 5))) 输出 u\"-------第\", key, u\"类文本的词语tf-idf权重------\" Word: food TF-IDF: 0.42329 TF: 0.25 IDF: 1.69315 Word: Chinese TF-IDF: 0.42329 TF: 0.25 IDF: 1.69315 Word: I TF-IDF: 0.25 TF: 0.25 IDF: 1.0 Word: love TF-IDF: 0.25 TF: 0.25 IDF: 1.0 u\"-------第\", key, u\"类文本的词语tf-idf权重------\" Word: American TF-IDF: 0.42329 TF: 0.25 IDF: 1.69315 Word: spirits TF-IDF: 0.42329 TF: 0.25 IDF: 1.69315 Word: I TF-IDF: 0.25 TF: 0.25 IDF: 1.0 Word: love TF-IDF: 0.25 TF: 0.25 IDF: 1.0 比较发现 sklearn 和 nltk 两种方法计算的结果不同，研究一下发现是对 tf 的处理不同。 看 sklearn 的 TfidfTransformer，发现进行了正则化(L2)，norm=u’l2’。 而 nltk，我们用的是 Linear scaling 的方法。 为什么要进行这样的比较，实际是因为当时需要看 tf-idf, tf, idf 各自的情况，却发现 sklearn 得不到正确的 tf，于是才折腾的用了 nltk，实际上通过 nltk 自己写函数会更灵活，具体问题具体分析吧。 缺陷与不足TF-IDF 并不是万能的，它单纯地认为文本频数小的单词就越重要，文本频数大的单词就越无用，显然这并不是完全正确的。可能会出现的结果： 被忽略的高频词。高频词 != 无意义的词。引入 idf，初衷是抑制无意义的高频词（通常是 stopwords）的影响，如上文提到的 Wall Street Journal 例子，如果在金融分析的场景下，“trading” 和 “prices” 这类高频词本不该被忽略。 被强调的低频词。 这也是为什么我在计算了 tf-idf 的同时，还要观察 tf、idf 的值的原因。根据不同的场景，可能需要引入阈值，限制IDF值过大的词语导入。另外 tfidf 这种基于词袋的算法还有个与生俱来的硬伤 – 位置信息被忽略。","tags":"nlp"},{"title":"Meteor--App_Recommender_System","url":"/2016/07/07/Meteor-App-Recommender-System/","text":"Meteor 是一个构建在 Node.js 之上的平台，用来开发实时网页程序，这一篇用 Meteor 搭建 App_Recommender_System 的 front-end. 基础Meteor 的创新Meteor 的关键性创新在于 Rails 程序只跑在服务器上，而一个 Meteor App 还包括在客户端（浏览器）上运行的客户端组件。这就相当于书店的伙计不仅仅在书店里帮你找书，还跟你回家，每天晚上读给你听（这听起来怪怪的）。这种架构让 Meteor 变得数据库无处不在。简单说，Meteor 把你的数据拿出一部分子集复制到客户端。这样后两个主要结果：第一，服务器不再发送 HTML 代码到客户端，而是发送真实的原始数据，让客户端决定如何处理线传数据。第二，你可以不必等待服务器传回数据，而是立即访问甚至修改数据（延迟补偿 latency compensation）。 Meteor 特点Meteor 位于程序数据库和用户界面之间，保持二者之间的数据同步更新。除此之外，Meteor 还有以下特点： 纯数据对话。服务器与客户端初始化后只传输数据，由客户端决定如何渲染。 一种语言。前后端统一使用 JavaScript 进行开发。 无处不在的数据库。浏览器端使用与服务器端一致的 API 访问本地数据库。 延迟补偿。在客户端使用预取和数据模型模拟技术，提供接近零延迟的数据库连接体验。 全栈响应式。实时作为默认模式，从数据库到模版的所有层面上，都应当具备可用的事件驱动接口。 社区生态友好。Meteor 开放源代码并能与现有的开源工具和框架整合，而非取代它们 简单即生产力。让事情看起来简单的最佳方式就是让它真正变得简单，通过干净且具古典美的 API 来实现。 Meteor 结构一般来说需要新建四个子文件夹：/client，/server，/public 和 /lib。然后在 /client 文件夹中新建 main.html 和 main.js 文件。这些文件夹中有一些拥有特别的作用。 Meteor 文件规则 在 /server 文件夹中的代码只会在服务器端运行。 在 /client 文件夹中的代码只会在客户端运行。 其它代码则将同时运行于服务器端和客户端上。 请将所有的静态文件（字体，图片等）放置在 /public 文件夹中。 Meteor 加载文件顺序 在 /lib 文件夹中的文件将被优先载入。 所有以 main.* 命名的文件将在其他文件载入后载入。 其他文件以文件名的字母顺序载入。 Meteor 核心概念模板系统 SpacebarsSpacebar 就是简单的 HTML 加上三件事情：Inclusion （有时也称作 “partial”）、Expression 和 Block Helper。123- Inclusion ：通过 &#123;&#123;&gt; templateName&#125;&#125; 标记，简单直接地告诉 Meteor 这部分需要用相同名称的模板来取代- Expression ：比如 &#123;&#123;title&#125;&#125; 标记，它要么是调用当前对象的属性，要么就是对应到当前模板管理器中定义的 helper 方法，并返回其方法值。- Block Helper ：在模板中控制流程的特殊标签，如 &#123;&#123;#each&#125;&#125;…&#123;&#123;/each&#125;&#125; 或 &#123;&#123;#if&#125;&#125;…&#123;&#123;/if&#125;&#125; 。 模板的作用局限于显示或循环变量，而 helper 则扮演着一个相当重要的角色：把值分配给每个变量。 Spacebars 文档 collectionmeteor collection 是 MongoDB Collections 的扩展，在 server 下插入 collection 的数据将会在 MongoDB 自动更新。任何在 client 下 publish 的数据将会在客户端页面实时显示。 All collections are reactively updated on both the client and the server. If a new app were published to our store, and thousands of clients were connected, all of their app stores would update immediately without any extra work on our end! 服务器端在服务器，collection 有一个任务就是和 Mongo 数据库联络，读取任何数据变化。 在这种情况下，它可以比对标准的数据库。collection 还可以像 API 一样操作 Mongo 数据库。在服务器端的代码，你可以写像 Posts.insert() 或 Posts.update() 这样的 Mongo 命令，来对 Mongo 数据库中的 posts 集合进行操作。 客户端在客户端，collection 是一个安全拷贝来自于实时一致的数据子集。客户端的 collection 总是（通常）透明地实时更新数据子集。当你在客户端申明 Posts = new Mongo.Collection(‘posts’); 你实际上是创建了一个本地的，在浏览器缓存中的真实的 Mongo 集合。 当我们说客户端 collection 被”缓存”是指它保存了你数据的一个子集，而且对这些数据提供了十分快速的访问。 有一点我们必须要明白，因为这是 Meteor 工作的一个基础: 通常说来，客户端的集合的数据是你 Mongo 数据库的所有数据的一个子集（毕竟我们不会想把整个数据库的数据全传到客户端来）。 另外，那些数据是被存储在浏览器内存中的，也就是说访问这些数据几乎不需要时间，不像去服务器访问 Posts.find() 那样需要等待，因为数据事实上已经载入了。 客户端-服务器通讯实际情况是服务器端的 collection 被客户端的 collection 通知说有一个新 item，然后执行了一个任务把这个 item 放入 Mongo 数据库，进而送到所有连接着的客户端。在浏览器的控制台取出所有的 item 没什么用处。需要把这些数据显示在模板中，并把这个简单的 HTML 原型变成一个有用的实时 Web 应用。 发布（Publication）和订阅（Subscription）collection 通过发布（publications）和订阅（subscriptions）机制把数据实时同步上行或者下行到连接着的各个用户的浏览器或者Mongo数据库中。Meteor App 保证只发布你让这个当前用户看到的数据。autopublish 的目的是让 Meteor 应用有个简单的起步阶段，它简单地直接把服务器上的全部数据镜像到客户端，因此你就不用管发布和订阅了。然而在实际工程中，我们需要删除它。 meteor remove autopublish 发布一个 App 的数据库可能用上万条数据，其中一些还可能是私用和保密敏感数据。显而易见我们不能简单地把数据库镜像到客户端去，无论是安全原因还是扩展性原因。发布 就是告诉 Meteor 哪些数据子集是需要送到客户端。为达到这个目的，我们建立一个简单的 Publish() 函数，只发布没有打标记的帖子 // 在服务器端 Meteor.publish('posts', function() { return Posts.find({flagged: false}); }); 订阅订阅 就是让客户端来确定哪些子集是他们在某个特别时候特别需要的。 在客户端我们需要订阅这个发布。我们仅仅需要增加这样一行到 main.js 文件中 Meteor.subscribe('posts'); Meteor 程序在客户端能够具有可伸缩性：不去订阅全部数据，而是指选择你现在需要的数据去订阅。这样的话，你就可以避免消耗大量的客户端内存，无论服务器端的总数据量有多大。 DDP 基本上我们可以把发布/订阅模式想象成为一个漏斗，从服务器端（数据源）过滤数据传送到客户端（目标）。 这个漏斗的专属协议叫做 DDP（分布式数据协议 Distributed Data Protocol 的缩写）。如果想了解 DDP 的更多细节，可以通过看 Matt DeBergalis（Meteor 创始人之一）在 Real-time 大会上的讲演视频，或者来自 Chris Mather 的这个截屏视频，来学习关于这个概念更多的细节。 DDP distributed data protocol. the stateful websocket protocol.(under \"Publish and subscribe\", \"Methods\", and \"Server connections\") `ddp` can be configured to use a randomly generated subdomain for each long polling connection(Web browsers put a limit on the total number of HTTP connections that can be open to a particular domain at any one time, across all browser tabs.) 所谓 wire up(Mongo driver will automatically register with `ddp` to receive incoming data for `mycollection` and use it to keep `MyCollection` up to date.) 特性： database driver integration automatic latency compensation（client's screen update instantly when they make changes 不用 wait for server round trip. 和 full-stack db drivers to snapshot and restore records??） transparent reconnect authentication (authentication hooks work great with Meteor Account.) input sanitization（audit-argument-checks， match's check） tracker-aware（connection status, subscription readiness, currently logged-in user 都是 reactive variables） default connect（meteor tools 构建会自动set up server, 这样就可以直接 meteor.subscribe，而不用 myconn = DPP.connect(url), myconn.subscribe 了） connection lifecycle hooks (当connection建立或关闭时，实现用户在线统计功能) CRUD bilerplate and quickstart packages （The `insecure` package turns off `allow`/`deny` rule checking for the generic `create`, `update`, and `delete` methods. The `autopublish` package automatically subscribes every connected client to the full contents of every database collection.） Router假设有一个帖子列表页面，我们还希望可以通过固定链接访问到每个单独的帖子页面，URL 形式是 http://myapp.com/posts/xyz（这里的 xyz 是 MongoDB 的 _id 标识符），对于每个帖子来说是唯一的。这意味着我们需要某些路由来看看浏览器的地址栏里面的路径是什么，并相应地显示正确的内容。这就是 router 的作用。 添加 Iron Router 包meteor add iron:router 基本概念 路由规则（Route）：路由规则是路由的基本元素。它的工作就是当用户访问 App 的某个 URL 的时候，告诉 App 应该做什么，返回什么东西。 路径（Path）：路径是访问 App 的 URL。它可以是静态的（/terms_of_service）或者动态的（/posts/xyz），甚至还可以包含查询参数（- /search?keyword=meteor）。 目录（Segment）：路径的一部分，使用正斜杠（/）进行分隔。 Hooks：Hooks 是可以执行在路由之前，之后，甚至是路由正在进行的时候。一个典型的例子是，在显示一个页面之前检测用户是否拥有这个权限。 过滤器（Filter）：过滤器类似于 Hooks ，为一个或者多个路由规则定义的全局过滤器。 路由模板（Route Template）：每个路由规则指向的 Meteor 模板。如果你不指定，路由器将会默认去寻找一个具有相同名称的模板。 布局（Layout）：你可以想象成一个数码相框的布局。它们包含所有的 HTML 代码放置在当前的模板中，即使模板发生改变它们也不会变。 控制器（Controller）：有时候，你会发现很多你的模板都在重复使用一些参数。为了不重复你的代码，你可以让这些路由规则继承一个路由控制器（Routing Controller）去包含所有的路由逻辑。 路由：把 URL 映射到模板默认情况下，Iron Router 会为路由规则，指定相同名字的模板。而如果路径（path 参数）没有指定，它也会根据路由规则的名字，去指定同样名字的路径。 你可能想知道为什么我们需要在一开始去制定路由规则。这是因为 Iron Router 的部分功能需要使用路由规则去生成 App 的链接信息。其中最常见的一个是 的 Spacebars helper，它需要返回路由规则的 URL 路径。 除了指定静态的 / URL ，我们还可以使用 Spacebars helper。虽然它们的效果是一样的，不过这给了我们更多的灵活性，如果我们更改了路由规则的映射路径，helper 仍然可以输出正确的 URL 。 等待数据如果你要部署当前版本的 App（或启动起来去使用上面的链接），你会注意到在所有帖子完全出现之前，列表里面会空了一段时间。这是因为在第一次加载页面的时候，要等到 posts 订阅完成后，即从服务器抓取完帖子的数据，才能有帖子显示在页面上。 这应该要有一个更好的用户体验，比如提供一些视觉上的反馈让用户知道正在读取数据，这样用户才会去继续等待。Iron Router 给了我们一个简单的方法去实现它。我们把订阅放到 waitOn 的返回上。 Meteor 部署meteor deploy myapp.meteor.com 当然，你要把“myapp”替换成你想要的名称，最好是命名一个没有被使用的。如果你的名称已经被使用，Meteor 会提示你去输入密码。如果发生这样的情况，只需通过 ctrl+c 来取消当前操作，然后用另一个不同的名称再试一次。 如果顺利地部署成功了，几秒钟后你就能够在 http://myapp.meteor.com 上访问到你的应用了。 实例安装 meteorjs$ curl https://install.meteor.com/ | sh 创建项目 $ meteor create app_store $ cd App-Recommender-System/ $ meteor 浏览器打开 http://localhost:3000/，就可以看到 Meteor App 的状态。 第三方 packageAdd three packages: twbs:bootstrap - Twitter Bootstrap packaged for Meteor iron:router – A Meteor package that handles routing between pages barbatus:stars-rating – A small library to give us nice rating stars for the app store. meteor add iron:router twbs:bootstrap barbatus:stars-rating Remove two default packages: autopublish – a development package that publishes all of our MongoDB data to the client. Great for prototyping, insecure for production! insecure – The package name says it all. This package allows the user client to create, update, read and delete any data in our database. It’s another package meant to make development easier, but we won’t have a need for this in our project. meteor remove autopublish insecure serverCreate app collection新建 lib 文件夹，创建 apps.js 文件，添加如下代码 Apps = new Meteor.Collection('apps'); Put json files这里衔接上一个部分 crawler 的工作，将我们保存在 MongoDB 的数据导出来放在 server 文件夹下。 mongoexport -d appstore -c app_info -o ./app_info_new.json Populate app collectionserver 文件夹下新建 fixures.js 来 load data. // checks if app collection is empty so we don't call this code on every run if(Apps.find({}).count() < 1){ // read in json file using Npm filesystem package var fs = Npm.require('fs'); fs.readFile('../../../../../server/app_info.json', 'utf8', Meteor.bindEnvironment(function(err, data) { if (err) throw err; var appData = data.split(\"\\n\"); for (var i = 0; i < appData.length - 1; i++) { var rawAppData = JSON.parse(appData[i]); var app = {}; app.name = rawAppData.title; app.app_id = rawAppData.app_id; app.developer = rawAppData.developer; app.description = rawAppData.intro; app.avgRating = parseInt(rawAppData.score) / 2; app.iconUrl = rawAppData.thumbnail_url; app.recommendedApps = rawAppData.top_5_app; app.numberOfRecommendations = 0; // insert app into collection Apps.insert(app); } }, function(err){ throw err; })); } Publish app collectionserver 文件夹下新建 publications.js 文件 publish data1234567891011121314151617/** returns all apps in the collection, takes an options object that is used to pushsorting and filtering operations onto the server side, this publication will be usedin top charts list*/Meteor.publish(&apos;apps&apos;,function(options)&#123; return Apps.find(&#123;&#125;,options);&#125;);/** takes an appid as a parameter and returns just one app that matches the appid,this publication will be used by our app details page for a single app */Meteor.publish(&apos;singleApp&apos;,function(id)&#123; return Apps.find(&#123;_id:id&#125;);&#125;);/** this publication will be used to look up the recommended apps*/Meteor.publish(&apos;singleAppByAppId&apos;,function(appId)&#123; return Apps.find(&#123;app_id:appId&#125;);&#125;); client新建 index.html 文件在 client 目录下新建 index.html 文件。添加 head，meteor 的 Blaze template engine 会产生 body。123456&lt;head&gt; &lt;title&gt;App Store&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt; 添加 css 文件这里就不贴代码了 Tell iron:router where to rend templates在 layouts 里新建 master_layout.html 文件1234567891011&lt;template name=&quot;masterLayout&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-4 col-md-offset-4 col-sm-12 col-xs-12 mainContainer&quot;&gt; &#123;&#123;&gt; yield &#125;&#125; &lt;!-- tells iron:router where to render our view templates inside of this layout--&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt; topChart template新建 views 文件夹，新建 topChart.html 文件1234567891011&lt;!-- define a template named topChart --&gt;&lt;template name=&quot;topChart&quot;&gt; &lt;!-- utilize the bootstrap navbar class to give us the App Store top bar --&gt; &lt;nav class=&quot;navbar navbar-default&quot;&gt; &lt;div class=&quot;container-fluid&quot;&gt; &lt;div class=&quot;text-center&quot; id=&quot;navTitle&quot;&gt; &lt;strong&gt;Top Charts&lt;/strong&gt; &lt;/div&gt; &lt;/div&gt; &lt;/nav&gt;&lt;/template&gt; 为 topChart template 填充数据之前我们加了 “iron:router” 包，用这个包，我们可以提供一个得到 topChart template 的路径，为这个 template 设置数据在 lib 下新建 routing 文件夹，添加 router.js 文件12345678910111213141516171819202122Router.configure(&#123; // tell iron router to render our individual templates inside of our masterLayout template layoutTemplate: &quot;masterLayout&quot;&#125;);Router.route(&apos;/&apos;, &#123;// describe the route path, &apos;/&apos; - root path of our web app name: &apos;topChart&apos;,// the template this route will use waitOn: function() &#123; // iron router will hold off rendering our page until the waitOn function completes // returns a subscription to our “apps” publication // passes a set of options to the server, // tells the server to sort our apps based off of avgRating and app_id. And to only give us a max of 20 results. Meteor.subscribe(&apos;apps&apos;, &#123;sort: &#123;avgRating: -1, app_id: -1&#125;, limit: 50&#125;); &#125;, // The return value of the data function becomes the Blaze template’s “data context”. // returns an object with a single property “apps” that contains all the Apps returned via our subscription. data: function () &#123; return &#123; apps: Apps.find(&#123;&#125;, &#123;sort: &#123;avgRating: -1, app_id: -1&#125;, limit: 50&#125;) &#125;; &#125;&#125;); 更新 topChart.html 文件123456789&lt;ul class=&quot;list-group&quot;&gt; &lt;!-- use the built in SpaceBars &#123;&#123;#each&#125;&#125; to iterate through the “apps” property that we set inside our route’s ”data” function. Inside the &#123;&#123;#each&#125;&#125;&#123;&#123;/each&#125;&#125; block the data context changes from “apps” to be the app in scope for each iteration.--&gt; &#123;&#123;#each apps&#125;&#125; &lt;!-- call the “appPreview” template. Since it is inside the &#123;&#123;#each&#125;&#125; block it will be passed the data for each individual app as its context as we iterate through our parent data context. --&gt; &#123;&#123;&gt; appPreview this&#125;&#125; &#123;&#123;/each&#125;&#125;&lt;/ul&gt; appPreview templateviews 里添加 appPreview.html 文件1234567891011121314151617181920212223242526&lt;template name=&quot;appPreview&quot;&gt; &lt;!-- each app preview will be wrapped in an &lt;li&gt; element, as the topChart template will insert each app into a &lt;ul&gt;--&gt; &lt;li class=&quot;list-group-item&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-xs-1 appRank text-muted&quot;&gt; &#123;&#123;rank&#125;&#125; &lt;/div&gt; &lt;!-- set the img src to the iconUrl property that we scraped--&gt; &lt;div class=&quot;col-xs-3 appIconPreview&quot;&gt; &lt;img height=50 width=50 src=&quot;&#123;&#123;iconUrl&#125;&#125;&quot;/&gt; &lt;/div&gt; &lt;div class=&quot;col-xs-6 nameColumn&quot;&gt; &lt;a href=&quot;&#123;&#123;pathFor &apos;appPage&apos;&#125;&#125;&quot;&gt;&#123;&#123;name&#125;&#125;&lt;/a&gt;&lt;br/&gt; &lt;div style=&quot;display:flex&quot;&gt; &lt;!-- the stars-rating package with this template. pass apps avgRating property to the templates &quot;rating&quot; property so that it can color the correct # of stars--&gt; &#123;&#123;&gt; starsRating rating=avgRating class=&apos;mystar&apos; size=&apos;sm&apos;&#125;&#125; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col-xs-2 text-right getApp&quot;&gt; &lt;!-- pathFor is a built in helper that takes the name of the route and returns a correct path. --&gt; &lt;a href=&quot;&#123;&#123;pathFor &apos;appPage&apos;&#125;&#125;&quot; class=&quot;btn btn-primary&quot;&gt;+ Get&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/li&gt;&lt;/template&gt; appPage template和上面是同样的道理，在 views 里添加 appPage.html 文件，然后为 appPage template 填充数据，不同的是这里多了中间一步，通过遍历 recommendedApps，我们只能从数据库里得到 recommended app 的 appid, 然而并没有 data context，也就是说，我们还需要有一个 template helper 来设置 recommended apps 的 data context，所以需要新建一个 appPage.js 文件来完成这个工作。123456789101112131415161718192021// Template.&#123;&#123;templateName&#125;&#125;.helpers() takes a JSON object where the keys are the name of hte helper function// these functions can be called directly from a blaze templateTemplate.appPage.helpers(&#123; getSuggestedApp: function(appId) &#123; // use singleAppByAppId subscription, then use Apps.findOne() to retrieve the app object and return it to our Blaze // template, the pass the object to suggestedApp templates as the data context Meteor.subscribe(&apos;singleAppByAppId&apos;, appId); return Apps.findOne(&#123;app_id: appId&#125;); &#125;&#125;);// attach JQuerystyle event listeners on a template by passing a json object to Template.&#123;&#123;templateName&#125;&#125;.events().// the key here is the event type(click in this case) followed by the CSS selecter(#backLink in this case)// values are the functions to be executed on event click. here we are using a feature of iron router “history.back()” to// bring us back to the previous pageTemplate.appPage.events(&#123; &quot;click #backLink&quot; : function(evt) &#123; history.back(); &#125;&#125;); 之后再修改 routers.js 文件，加上1234567891011Router.route(&apos;/app/:_id&apos;, &#123;//’:’ tells Iron Router that this is a variable that will be bound to the _id parameter name: &apos;appPage&apos;, waitOn: function() &#123; // pass the app id passed in the url by using this.params._id Meteor.subscribe(&apos;singleApp&apos;, this.params._id); &#125;, data: function () &#123; // bind the app with the given id to the data context of template return Apps.findOne(this.params._id); &#125;&#125;); 运行效果 代码 参考链接DISCOVER METEOR","tags":"crawler meteor"},{"title":"项目实战--云计算Social Networking Timeline","url":"/2016/07/05/项目实战--云计算Social Networking Timeline/","text":"CMU 15619 Cloud Computing 的 individual project，项目全名是 Social Networking Timeline with Heterogeneous Back-ends，通过 MySQL/HBase/MongoDB 实现简化版 twitter 的后端。 Implementing Basic Login with MySQL on RDSAWS RDS 配置 MySQL 并导入 users.csv and userinfo.csv 数据集， 数据集： users.csv [UserID, Password] userinfo.csv [UserID, Name, Profile Image URL] 如果用户名密码正确，返回 user name and Profile Image Url，如果不正确，name 返回 “Unauthorized”，Profile Image URL 返回 “#”. Request: GET /task1?id=[UserID]&pwd=[Password] Response: returnRes({\"name\":\"my_name\", \"profile\":\"profile_image_url\"}) 效果： Storing Social Graph using HBase数据集： links.csv [Followee, Follower] 对 followers 进行排序。排序规则： 按姓名进行升序排序 按 Profile Image URL 进行升序排序 实现：从 HBase 中根据 userid 找出 followers，再从 MySQL 中根据 follower userid 找出 name 和 profile url 并进行排序。 这里的问题是 HBase 的表如何设计能最大化性能。可以采用的方式为：对数据集进行处理，按 followee 排序然后按 followers 排序，并进行合并，得到 [Followee, FollowerList]，followee 作为 rowkey。 Request: GET /task2?id=[UserID] Response: {\"followers\":[{\"name\":\"follower_name_1\", \"profile\":\"profile_image_url_1\"}, {\"name\":\"follower_name_2\", \"profile\":\"profile_image_url_2\"}, ...]} Build Homepage using MongoDB同样是对 HBase 表的设计。这里要求的是根据 userid 找到 followees，然后再找到 followees 的 posts。为了提高性能，可以做的是：对数据集进行处理，按 follower 排序然后按 followees 排序，并进行合并，得到 [Follower, FolloweeList] 数据集：posts.csv{ “pid”:xxx, // PostID “uid”:xxx, // UserID of poster “name”:”xxx”, // User name of poster “profile”:”xxx”, // Poster profile image URL “timestamp”:”YYYY-MM-DD HH:MM:SS”, // When post is posted “image”:”xxx”, // Post image “content”:”xxx”, // Post text content “comments”:[ // comments json array { “uid”:xxx, // UserID of commenter “name”:”xxx”, // User name of commenter “profile”:”xxx”, // Commenter profile image URL “timestamp”:”YYYY-MM-DD HH:MM:SS”, // When comment is made “content”:”xxx” // Comment text content }, { “uid”:xxx, ……. }, …… ]} Request: GET /task3?id=[UserID] Response: {\"posts\":[{post1_json}, {post2_json}, ...]} Put Everything Together显示 user 关注的人的最新 30 篇 posts排序规则：对 followers 进行排序。排序规则： 按姓名进行升序排序 按 Profile Image URL 进行升序排序 对最新 30 篇 posts 排序： 按 timestamp 升序排序 按 pid (PostID) 升序排序 不满 30 篇 posts 返回全部。 Sample Request: http://backend-public-dns:8080/MiniSite/task4?id=99 Sample Response:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 &quot;followers&quot;: [ &#123; &quot;name&quot;: &quot;Alastair Moock&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/61ed34b1f6bcd5498d888e3c2a1768.png&quot; &#125;, &#123; &quot;name&quot;: &quot;Amr Diab&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/507e08e097e49ffaa584b988748180.png&quot; &#125;, &#123; &quot;name&quot;: &quot;CJ Bolland&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/699bb8d37e61d66750e58fd1513637.png&quot; &#125;, ... (more followers ommitted) ], &quot;name&quot;: &quot;Accent&quot;, &quot;posts&quot;: [ &#123; &quot;content&quot;: &quot;Wow, just experienced Screamers (2006)&quot;, &quot;timestamp&quot;: &quot;2015-08-07 19:06:57&quot;, &quot;uid&quot;: 2587, &quot;_id&quot;: &#123; &quot;$oid&quot;: &quot;56b06bde2fa550d2061f30c2&quot; &#125;, &quot;name&quot;: &quot;Beggars Opera&quot;, &quot;image&quot;: &quot;http://cmucloudsocial.s3.amazonaws.com/posts/Screamers_2006_.png&quot;, &quot;pid&quot;: 156154, &quot;comments&quot;: [ &#123; &quot;uid&quot;: 34190, &quot;timestamp&quot;: &quot;2015-10-21 13:57:59&quot;, &quot;content&quot;: &quot;I have seen this movie on starz, I regret to say that I was not lucky enough to have watched it while the screening took place. This documentary follows the one and only System Of A Down, throughout several locations from LA to Europe, while diggin deep in history and showing the truth about the forgotten genocide. This movie includes interviews with experts and some of the survivors of the genocide. This sad story of human history also follows the massacre that took place in africa during 2004 while the whole world stood watching, idle in the face of massive death. To conclude this, several SOAD fans won&apos;t be dissapointed by the extensive repertoire of songs played throughout the film. I&apos;m glad I&apos;m finally getting the DVD after a long wait, I hope you feel the same way.&quot;, &quot;name&quot;: &quot;Youngster&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/6a75f0eea78b8cd2c0ae4da2f85f34.png&quot; &#125;, &#123; &quot;uid&quot;: 27184, &quot;timestamp&quot;: &quot;2015-10-21 21:36:12&quot;, &quot;content&quot;: &quot;Great movie for fans of System of a Down. Better yet, this is a great movie documenting genocide in general, and the Armenian genocide in particular. I highly recommend this movie. It is a must see. Share the movie with friends, family, and members of your local community. Everyone will thank you for it. Very eye-opening experience.&quot;, &quot;name&quot;: &quot;Shirobon&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/539869e8b863511771c3b0b5e13d94.png&quot; &#125;, ... (more comments omitted) ], &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/8f64d02d77cf734ddde87b7832ca76.png&quot; &#125;, &#123; &quot;content&quot;: &quot;Wow, just experienced The Tube (2004)&quot;, &quot;timestamp&quot;: &quot;2015-08-11 02:42:40&quot;, &quot;uid&quot;: 357, &quot;_id&quot;: &#123; &quot;$oid&quot;: &quot;56b06be12fa550d2061f706a&quot; &#125;, &quot;name&quot;: &quot;Agoria&quot;, &quot;image&quot;: &quot;http://cmucloudsocial.s3.amazonaws.com/posts/The_Tube_2004_.png&quot;, &quot;pid&quot;: 175927, &quot;comments&quot;: [ &#123; &quot;uid&quot;: 29700, &quot;timestamp&quot;: &quot;2015-09-15 10:20:44&quot;, &quot;content&quot;: &quot;A FORMER GOVERNMENT AGENT HOLDS A TRAIN HOSTAGE WITH A BOMB THAT&apos;LL BLOW UP IF THE TRAIN STOPS AND IT&apos;S UP TO A DETECTIVE TO STOP HIM AND FIND A WAY TO SAVE THE LIVES OF THE PASSENGERS. WHAT WE HAVE HERE IS BASICALLY ANOTHER IMITATION OF &apos;&apos;SPEED&apos;&apos;. THE DIALOGUE IS LAUGHABLE AND THE ACTION [WHICH THERE IS PLENTY OF] IS NOT REALLY THAT ENTERTAINING. THE ACTING IS ALSO PRETTY BAD, BUT THE MOVIE TENDS TO SHOW A FEW SIGNS OF LIFE IN THE LAST 30 MINUTES. IF YOU&apos;RE AN ACTION FAN [LIKE ME] AND YOU&apos;RE CURIOUS ABOUT THIS MOVIE, RENT IT. BUT DON&apos;T BUY IT. ON THIS DVD, YOU HAVE THE CHOICE OF WATCHING THIS MOVIE DUBBED IN EITHER ENGLISH OR FRENCH OR YOU CAN WATCH THIS MOVIE IN ITS ORIGINAL LANGUAGE, WHICH IS KOREAN.&quot;, &quot;name&quot;: &quot;Teimoso&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/a3a08f80ee44be2438293a04d2f9f2.png&quot; &#125;, &#123; &quot;uid&quot;: 31346, &quot;timestamp&quot;: &quot;2015-10-12 06:16:52&quot;, &quot;content&quot;: &quot;A Hollywood movie went out into the world, traveled to Korea, got assimilated and regurgitated, and now it returns to our shores as this. The studios know it and advertise it using reviews that cast it as the Korean version of Speed. It also &quot;borrows&quot; a score straight from Hans Zimmer&apos;s work for The Rock, and the main actor looks and acts like Chow Yun Fat light. It&apos;s discouraging to see Korean cinema paying homage to American action flicks when it has so many more interesting stories to tell. At least Woon-Hak Baek&apos;s first feature, Shiri, spoke in a unique voice and told a story personal to the Korean experience. This is a step backwards for him.On the other hand, this movie composite of so many action movies we&apos;ve seen before is fascinating in its skewed familiarity. It&apos;s not terrible; the production values are high, the acting occasionally thrilling, the one-liners sometimes amusing. It&apos;s no more or less diverting than the average Hollywood Die Hard knockoff. I think of it as top notch karaoke, like American Idol. In the proper context, it&apos;s impressive.In the grand scheme of things, though, it&apos;s depressing, especially when Korean directors like Chan-wook Park are producing such unique and energetic work.&quot;, &quot;name&quot;: &quot;The Veronicas&quot;, &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/1bd4dc1a4ca7a49daf53ca9a03735e.png&quot; &#125;, ... (more comments omitted) ], &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/329125b52f0db7d04ed8828b5eccac.png&quot; &#125;, ... (more posts ommitted) ], &quot;profile&quot;: &quot;https://cmucloudsocial.s3.amazonaws.com/profiles/8e8a1b156037ed1ecfba40b917084e.png&quot;&#125;) Basic Recommendation根据 userid 推荐 10 个 user。算法： 基于用户的协同过滤算法。Eg.assume A follows {B, C, D}.Followee B follows {C, E, A},followee C follows {F, G} andfollowee D follows {G, H}. 得分：{G: 2, E: 1, F: 1, H: 1} 排序规则： 按得分降序排序 按 user id 升序排序 少于 10 个用户返回全部。 Request: GET /task2?id=[UserID] Response: returnRes({\"recommendation\":[{name:, profile:},{name:, profile:},...,{name:, profile:]})","tags":"back-ends"},{"title":"爬虫总结--汇总贴","url":"/2016/06/27/爬虫总结--汇总贴/","text":"从 抓取 –&gt; 分析 –&gt; 存储 三个部分对之前5篇博客和代码进行重组。 抓取cloud scrapy博客 防止爬虫被 ban设置 user-agent 和 ip 代理来防止爬虫被 ban 的测试代码博客 模拟登录代码博客 scrapy-splash 爬取js交互式表格数据代码博客 同时运行多个爬虫代码 分布式爬虫博客代码 增量爬取利用 redis博客 处理验证码 更换ip地址 使用cookie登陆 验证码识别手段 分析不规则的 html代码博客 存储如何进行网页去重？将 url 抽象为关键特征相似度的计算。比如可以把站点抽象为一维特征，目录深度抽象为一维特征，一级目录、二级目录、尾部页面的名字也都可以抽象为一维特征。得到各个维度的特征，定义每个特征的重要程度，给出公式，把这个问题简化成一个机器学习的问题，只需要人为判断出一批url是否相似，用svm训练一下就可以达到机器判断的目的。博客 内容以什么形式存储？关系数据库 or NoSQL? (待补充) 代码快速通道百度贴吧百度知道网易新闻百度搜索、贴吧、知道分布式爬虫京东、苏宁FAQ","tags":"crawler"},{"title":"numpy－理解 keepdims=True","url":"/2016/06/26/numpy－理解keepdims=True/","text":"理解 numpy 中的 keepdims。实现 softmax 时遇到的坑。 官方文档文档对 numpy.sum 里 keepdims 的说明如下：1234numpy.sum(a, axis=None, dtype=None, out=None, keepdims=False)[source]keepdims : bool, optionalIf this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. 边做实验边来解释。 np.max(x)12345&gt;&gt;&gt; x=np.array([[1001, 1002], [3, 4]])&gt;&gt;&gt; x -= np.max(x)&gt;&gt;&gt; xarray([[ -1, 0], [-999, -998]]) np.max(x) 的结果一个数 1002, 矩阵的最大值。因此 x -= np.max(x) 的效果是减去矩阵 x 中所有元素最大值 np.max(x, axis=1)12345&gt;&gt;&gt; x=np.array([[1001, 1002], [3, 4]])&gt;&gt;&gt; x -= np.max(x, axis=1)&gt;&gt;&gt; xarray([[ -1, 998], [-999, 0]]) axis=1 代表以行为单位，因此 np.max(x, axis＝1) 求的是每行的最大值，然而注意它的结果默认是一个行向量，[1002, 4]如果是 axis=0，代表以列为单位，求每一列最大值，结果是 [1001, 1002]x -= np.max(x, axis=1) 在这里完全不 make sense，如果硬要解释的话，就是第 i 列减去 第 i 行的最大值，当然这就要求矩阵必须是方阵。（没有 broadcast）所以我们要做的实际就是把这个行向量转化为列向量，然后 broadcast correctly against the input array，这也就是 keepdims 的功能。 np.max(x, axis=1, keepdims=True) 减去每一行最大值的正确打开方式123456&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; x=np.array([[1001, 1002], [3, 4]])&gt;&gt;&gt; x -= np.max(x, axis=1, keepdims=True)&gt;&gt;&gt; xarray([[-1, 0], [-1, 0]])","tags":"python"},{"title":"论文笔记 - Distributed representations of sentences and documents","url":"/2016/06/22/句向量总结笔记（简洁版）/","text":"算法的 PV-DM 版本与 PV-DBOW 的核心理论，为了方便描述，这里的 paragraph 与句子同义。 原文： LE, Quoc V.; MIKOLOV, Tomas. Distributed representations of sentences and documents). arXiv preprint arXiv:1405.4053, 2014. 译文： Word2vec 句向量模型PV-DM与PV-DBOW原论文翻译 分布记忆模型(PV-DM)用神经网络训练词向量的逻辑是，让网络去预测单词(目标词/上下文)这样的任务，句向量也是一样，我们给定从句子里的一些上下文，让网络去预测下一个单词。在句（Paragraph）向量模型中，每一个句子都被映射成一个独立的向量，这个句向量作为矩阵 D 的一列；同时，每一个词也被映射成一个独立的向量，这个词向量作为矩阵 W 的一列。对这个句向量和这些词向量求平均或者首尾相连，用来预测文本中的下一个词。这里，我们选用首尾相连来组合这些矩阵。 严格的说，与 Word2vec 的公式相比，唯一的不同点在于这里从 W 和D 两个矩阵中构造 h。句子的标识（Token）被当做另外一个“词”看待。它扮演一个“Memory”的角色，用来记忆当前文本或文章主题中漏掉了什么。因此，这个模型被称为“句向量的分布记忆模型”(PV-DM: Distributed Memory Model of Paragraph Vectors)。 上下文是固定长度的，从句子的一个滑动窗口中取样。句向量被这这个句子产生的所有上下文共享，但不超越句子。但是词向量矩阵 W 是超越句子，全局共享的。比如说，”powerful”的词向量也对所有的句子有效。 通过随机梯度下降法来训练这些句向量和词向量，在此过程中通过反向传播获得梯度。在随机梯度下降的每一步，都可以从一个随机的句子中抽取一个定长的上下文，从网络中计算出梯度误差，然后更新模型的参数。 在预测阶段，需要执行一个“推断（inference）”步骤计算新句子的句向量。也是通过梯度上升来获取。在这个阶段，其余的模型参数、词向量矩阵 W 和 softmax 权重是固定的。 假设语料库中有 N 个句子，字典里有 M 个词汇；我们试图将每一个句子映射到 p 维空间，每一个词映射到 q 维空间，于是这个模型就有总共 N×p+M×q 个参数（包括softmax参数）。即使句子的数量会随着 N 的增大而增大，训练中的更新还是稀疏且高效。 经过训练，这些句向量就可以当做句子的特征使用。我们可以把这些特征直接用于传统的机器学习技术，比如逻辑回归、支持向量机或者 K-means 聚类。总而言之，这个算法有两个关键阶段： 通过训练获得词向量矩阵 W, softmax 权重 U, b 以及句向量 D； 第二个阶段是推断阶段，用于取得一个新句子（没有出现过）的句向量 D，通过增加更多的列在矩阵 D 里，并保持 W, U, b 不变的情况下在矩阵 D 上进行梯度下降。我们使用 D 通过一个基础的分类器给句子加上标签 句向量有两个显著的优点： 它的训练集是没有被标签的数据，因此它可以被用于一些训练样本标签不足的任务 句向量也解决了词袋模型的一些关键的弱点。第一，它继承了词向量的一个重要特性——词和词之间的语义。在语义里，“强有力”比起“巴黎”来说，和“强壮”更接近。第二，它考虑到了“词序（word order）”，n-gram 模型则需要设置一个较大的 n 才能做到。这一点很重要，因为模型保存了句子中大量的信息，包括词序。也就是说，我们的模型优于词袋 n-gram 模型，因为后者会表现出一个极高的维度，影响效率而且很难泛化 分布词袋模型(PV-DBOW)-无词序句向量上面的方法讨论了在一个文本窗口内，通过句向量和词向量的首尾相接来预测下一个词。另一种方法不把上下文中的词作为输入，而是强制这个模型在输出中从句子中随机抽取词汇来进行预测。实际上，其意义在于在每一个随机梯度下降的迭代中，我们抽取一个文本窗口，然后从这个文本窗口中抽取一个词，然后通过一个分类任务得到句向量。这项技术如图所示。我们把这个版本称为句向量的分布词袋(PV-DBOW): Distributed Bag of Words version of Paragraph Vector）。 句向量被训练出来，用来预测在一个小窗口中的词汇。 除了在概念上简单以外，这个模型只需要存储少量的数据。相比于上一个模型需要存储 softmax 权重和词向量，这个模型只需要存储 softmax 权重。同样的，这个模型也近似于 Skip-gram 模型。 PV-DM &amp; PV-DBOW 结合可以把每一个句向量当作两个向量的组合：一个通过 PV-DM 训练，另一个通过 PV-DBOW 训练。PV-DM 能够很好地执行多种任务，但是它结合 PV-DBOW 后，常常能够更加出色完成任务。 参考链接Word2vec 句向量模型PV-DM与PV-DBOW原论文翻译","tags":"word2vec deep-learning doc2vec 句向量"},{"title":"词向量总结笔记（简洁版）","url":"/2016/06/21/词向量总结笔记（简洁版）/","text":"综合各家博客整理的词向量总结笔记。 词向量模型one-hot Vectorone-hot vector最简单的编码方式：假设我们的词库总共有n个词，那我们开一个1*n的高维向量，而每个词都会在某个索引index下取到1，其余位置全部都取值为0。 问题这种词向量编码方式简单粗暴，我们将每一个词作为一个完全独立的个体来表达。遗憾的是，这种方式下，我们的词向量没办法给我们任何形式的词组相似性权衡。因为你开了一个极高维度的空间，然后每个词语都会占据一个维度，因此没有办法在空间中关联起来。 解决方案可以把词向量的维度降低一些，在这样一个子空间中，可能原本没有关联的词就关联起来了。 基于 SVD 的方法SVD这是一种构造词嵌入（即词向量）的方法，我们首先会遍历所有的文本数据集，然后统计词出现的次数，接着用一个矩阵 X 来表示所有的次数情况，紧接着对X进行奇异值分解得到一个 USVT 的分解。然后用 U 的行（rows）作为所有词表中词的词向量。对于矩阵 X ，有2种选择：全文或者窗口长度。 词-文档矩阵建立一个词组文档矩阵 X，具体是这么做的：遍历海量的文件，每次词组 i 出现在文件 j 中时，将 Xij 的值加1。不过大家可想而知，这会是个很大的矩阵R|V|×M，而且矩阵大小还和文档个数M有关系。所以咱们最好想办法处理和优化一下。word-document的共现矩阵最终会得到泛化的主题（例如体育类词汇会有相似的标记），这就是浅层语义分析(LSA, Latent Semantic Analysis) 基于窗口的共现矩阵 X把矩阵X记录的词频变成一个相关性矩阵，对 X 做奇异值分解，观察奇异值（矩阵的对角元素），并根据我们期待保留的百分比来进行截断（只保留前k个维度），把子矩阵 U1:|V|,1:k 视作我们的词嵌入矩阵。也就是说，对于词表中的每一个词，我们都用一个 k 维的向量来表达了。窗口长度容易捕获语法（POS）和语义信息 对共现矩阵X进行奇异值分解特征值分解与奇异值分解特征值分解只适用于方阵。当矩阵是高维的情况下，那么这个矩阵就是高维空间下的一个线性变换，一个矩阵乘以一个向量后得到的向量，其实就相当于将这个向量进行了线性变换。我们通过特征值分解得到的前N个特征向量，对应了这个矩阵最主要的N个变化方向。利用这前N个变化方向，可以近似这个矩阵（变换）。也就是 – 提取这个矩阵最重要的特征。总结一下，特征值分解可以得到特征值与特征向量，特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么，可以将每一个特征向量理解为一个线性的子空间，我们可以利用这些线性的子空间干很多的事情。奇异值分解是一个能适用于任意的矩阵的一种分解的方法，可以通过求特征值得到。 Python中简单的词向量SVD分解 问题 矩阵的维度会经常变化（新的词语经常会增加，语料库的大小也会随时变化）。 矩阵是非常稀疏的，因为大多数词并不同时出现。 矩阵的维度通常非常高（≈106×106），需要大量的存储 训练需要O(n2)的复杂度 对于新词或者新的文档很难及时更新 需要专门对矩阵X进行特殊处理，以应对词组频率的极度不平衡的状况 解决方案：直接学习低维度的词向量idea: 将最重要的信息存储在固定的，低维度的向量里：密集向量（dense vector)，维数通常是25-1000然而，如何降维？ 基于迭代的方法创建一个模型，它能够一步步迭代地进行学习，并最终得出每个单词基于其上下文的条件概率。 n-gram基本思想： 一个词出现的概率只与它前面固定数目的词相关。主要工作是在预料中统计各种词串出现的次数以及平滑化处理，概率值计算号之后就存储起来，下次需要计算一个句子的概率时，只需找到相关的概率参数，将它们连乘起来就好了。建立一个概率模型，它包含已知和未知参数。每增加一个训练样本，它就能从模型的输入、输出和期望输出（标签），多学到一点点未知参数的信息。在每次迭代过程中，这个模型都能够评估其误差，并按照一定的更新规则，惩罚那些导致误差的参数。(误差“反向传播”法)。 CBOW以 {“The”, “cat”, “over”, “the”, “puddle”} 为上下文，能够预测或产生它们中心的词语”jumped”。模型输入为 x(c)，模型输出为 y，y 就是中心词 ‘jumped’。对于每个词语 wi 学习了两个向量。 连续词袋模型（CBOW）中的各个记号： $W_i$：单词表 V 中的第 i 个单词, one-hot 向量 $v∈R^{n∗|V|}$：输入词矩阵 $v_i$：V的第i列，n 维 $W_i$ 的输入向量 $U∈R^{|V|∗n}$：输出词矩阵 $U_i$：U 的第 i 行，n 维 $W_i$ 的输出向量 把整个过程拆分成以下几步： 对于 m 个词长度的输入上下文，我们产生它们的 one-hot 向量 $(x^{c−m},⋯,x^{c−1},x^{c+1},⋯,x^{c+m})$，作为模型输入。 我们得到上下文的嵌入词向量 $(v_{c−m+1}=Vx^{c−m+1},⋯,v_{c+m}=Vx^{c+m})$ 将这些向量取平均 $\\widehat{v}=\\frac {V_{c−m} +V_{c−m+1} +⋯+V_{c+m}}{2m}$ 产生一个得分向量 $z=U\\widehat{v}$ 将得分向量转换成概率分布形式 $\\widehat{y}=softmax(z)$ 我们希望我们产生的概率分布 ,与真实概率分布 $\\widehat{y}$ 相匹配。而 y 刚好也就是我们期望的真实词语的one-hot向量。 怎样找到矩阵U、V？目标函数选交叉熵，用梯度下降法去更新每一个相关的词向量 $U_c$ 和 $V_j$. 当我们试图从已知概率学习一个新的概率时，最常见的是从信息论的角度寻找方法来评估两个概率分布的差距。其中广受好评又广泛应用的一个评估差异/损失的函数是交叉熵：$H(\\widehat{y},y) = -\\sum_{j=1}^{|V|}y_jlog(\\widehat{y}_j)$ 结合我们当下的例子，y 只是一个one-hot向量，于是上面的损失函数就可以简化为：$H(\\widehat{y},y) = -y_jlog(\\widehat{y}_j)$ 我们用 c 表示 y 这个 one-hot 向量取值为 1 的那个维度的下标。所以在我们预测为准确值的情况下 $\\widehat{y}_c=1$。于是损失为 −1 log(1) = 0。所以对于一个理想的预测值，因为预测得到的概率分布和真实概率分布完全一样，因此损失为0。相反,当我们的预测结果非常不理想， $\\widehat{y}_c=0.01$。计算得到的损失为−1 log(0.01) ≈ 4.605，损失非常大，原本这才是标准结果，可是你给了一个非常低的概率，因此会拿到一个非常大的loss。最终的优化函数为： Skip-Gram与上面提到的模型对应的另一种思路，是以中心的词语 ”jumped” 为输入，能够预测或产生它周围的词语 ”The”, “cat”, “over”, “the”, “puddle” 等。这里我们叫 ”jumped” 为上下文。我们把它叫做Skip-Gram 模型。 这个模型的建立与连续词袋模型（CBOW）非常相似，但本质上是交换了输入和输出的位置。我们令输入的 one-hot 向量（中心词）为 x（因为它只有一个），输出向量为 y(j)。U 和 V 的定义与连续词袋模型一样。看一下网络结构图： 举个例子，假设现在的数据集如下： the quick brown fox jumped over the lazy dog 这个数据集中包含了词语及其上下文信息。上下文信息(Context)是一个比较宽泛的概念，有多种不同的理解：例如，词语周边的句法结构，词语的左边部分的若干个词语信息，对应的右半部分等。这里，我们使用最原始和基本的定义，即认为词语左右相邻的若干个词汇是该词对应的上下文信息。例如，取左右的词窗口为1，下面是数据集中的(上下文信息，对应的词)的pairs： ([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox), ... Skip-Gram模型是通过输入的目标词来预测其对应的上下文信息，所以目标是通过[quick]来预测[the]和[brown]，通过[brown]来预测[quick]和[fox]… 将上面的pair转换为(inpUt, output)的形式如下： (quick, the), (quick, brown), (brown, quick), (brown, fox), ... 对应到上面部分，我们可以把 Skip-Gram 模型的运作方式拆分成以下几步： 生成 one-hot 输入向量 x。 得到上下文的嵌入词向量 $V_c$=$V_x$。 因为这里不需要取平均值的操作，所以直接是$\\widehat{v}=v_c$。 通过$U=UV_c$产生 2m 个得分向量 $U_{c−m},⋯,U_{c−1},U_{c+1},⋯,U_{c+m}$，如果上下文各取一个词，就是 $U_{c-1}$, $U_{c+1}$ 将得分向量转换成概率分布形式 $y=softmax(u)$。 我们希望我们产生的概率分布与真实概率分布 $y^{c−m},⋯,y^{c−1},,y^{c+1}⋯,y^{c+m}$ 相匹配，也就是我们真实输出结果的 one-hot 向量。 为模型设定一个目标/损失函数。不过不同的地方是我们这里需要引入朴素贝叶斯假设来将联合概率拆分成独立概率相乘。只要给出了中心词，所有的输出词是完全独立的。使用随机梯度下降算法(SGD)来进行最优化求解，并且使用mini-batch方法 (通常batch_size在16到512之间)。可以用随机梯度下降法去更新未知参数的梯度。对应的优化函数是 这里值得一提的是，skipgram 和 PMI 之间是有联系的，Levy and Goldberg(2014) 提到过，skip-gram 在矩阵成为 PMI 的一个 shifted version 时($WW^{‘T}=M^{PMI}-logk$)，得到最优解，也就是说， Skip-gram is implicitly factoring a shifted version of the PMI matrix into the two embedding matrices. 我们再次观察一下目标函数，注意到对整个单词表|V|求和的计算量是非常巨大的，任何一个对目标函数的更新和求值操作都会有O(|V|)的时间复杂度。我们需要一个思路去简化一下，我们想办法去求它的近似，可以参照负面采样（Negative Sampling） why skip-gram在NLP中，语料的选取是一个相当重要的问题。首先，语料必须充分。一方面词典的词量要足够大，另一方面尽可能地包含反映词语之间关系的句子，如“鱼在水中游”这种句式在语料中尽可能地多，模型才能学习到该句中的语义和语法关系，这和人类学习自然语言是一个道理，重复次数多了，也就会模型了。其次，语料必须准确。所选取的语料能够正确反映该语言的语义和语法关系。如中文的《人民日报》比较准确。但更多时候不是语料选取引发准确性问题，而是处理的方法。由于窗口大小的限制，这会导致超出窗口的词语与当前词之间的关系不能正确地反映到模型中，如果单纯扩大窗口大小会增加训练的复杂度。Skip-gram模型的提出很好解决了这些问题。 我们来看看 skip-gram 的定义。 Skip-gram 实际上的定义很简单，就是允许跳几个字的意思。依照原论文里的定义，这个句子： Insurgents killed in ongoing fighting. 在 bi-grams 的时候是拆成： { insurgents killed, killed in, in ongoing, ongoing fighting } 在 2-skip-bi-grams 的时候拆成： { insurgents killed, insurgents in, insurgents ongoing, killed in, killed ongoing, killed fighting, in ongoing, in fighting, ongoing fighting } 在 tri-grams 的时候是： { insurgents killed in, killed in ongoing, in ongoing fighting } 在 2-skip-tri-grams 的时候是： { insurgents killed in, insurgents killed ongoing, insurgents killed fighting, insurgentsin ongoing, insurgents in fighting, insurgents ongoing fighting, killed in ongoing, killed in fighting, killed ongoing fighting, in ongoing fighting } 这样就有办法在整篇文章都是用“台湾大学”的情况下以“台大”找到文章，解决一些“同义词”想要解决的问题。Skip-gram 一方面反映了句子的真实意思，另一方面还扩大了语料，2元词组由原来的4个扩展到了9个，3元词组由原来的3个扩展到了10个。 Word2VecWord2Vec 是一个典型的预测模型，用于高效地学习Word Embedding，实现的模型就是上面提到的两种：连续词袋模型(CBOW)和Skip-Gram模型。算法上这两个模型是相似的 CBOW 从输入的上下文信息来预测目标词 Skip-gram 模型则是相反的，从目标词来预测上下文信息一般而言，这种方式上的区别使得 CBOW 模型更适合应用在小规模的数据集上，能够对很多的分布式信息进行平滑处理；而 Skip-Gram 模型则比较适合用于大规模的数据集上。 另外一点是，embeddings 可以来捕捉关系！ 向量空间模型(Vector space models, VSMs)将词语表示为一个连续的词向量，并且语义接近的词语对应的词向量在空间上也是接近的。分布式假说理论： 该假说的思想是如果两个词的上下文(context)相同，那么这两个词所表达的语义也是一样的；换言之，两个词的语义是否相同或相似，取决于两个词的上下文内容，上下文相同表示两个词是可以等价替换的。 词向量生成方法主要分两大类： 计数法(count-based methods, e.g. Latent Semantic Analysis)在大型语料中统计词语及邻近的词的共现频率，然后将之为每个词都映射为一个稠密的向量表示； 预测法(predictive methods, e.g. neural probabilistic language models)。直接利用词语的邻近词信息来得到预测词的词向量（词向量通常作为模型的训练参数）。 词向量任务评价内部任务评价内部任务评价的特点如下： 一般是在一个特定的子任务中进行评测 计算很快 有助于理解相关的系统 在实际的NLP任务中表现好坏，可能需要外部关联实际应用 方法：词向量类比我们先输入一组不完整的类比 a:b::c:? 内部任务评价系统找出最大化余弦相似度的词向量理想情况下，我们想得到xb−xa=xd−xc(例如，王后–国王 = 女演员 – 男演员)。于是xb−xa+xc=xd, 所以我们只需要找出一个与xb−xa+xc的标准化内积（比如余弦相似度）取最大值的词向量就可以了。 类比语料示例： 首都城市1 : 国家1 : : 首都城市2 : 国家2 Beijing:China::Astana Kazakhstan Beijing:China::Asmara Eritrea ... 比较级 bad:worst::big biggest bad:worst::easy easiest ... 时态 dancing:danced::decreased decreased dancing:danced::falling fell ... 评测语料 方法：相关性评价另外一个评测词向量质量的简单方法是人为对两个词的相似度在一个固定区间内打分(比如说 0-10)，再跟对应向量的余弦相适度进行对比。评测语料 考虑参数 词向量的维度 资料库的大小 资料源/类型 上下文窗口的大小 上下文的对称性 一般而言， 精度和使用的模型高度相关，因为这些生成词向量的方法所依据的特性是完全不同的(如同时出现的次数，奇异向量等。) 文集量越大，精度越高，因为例子越多，生成的系统学习到的经验就更丰富。比如在完成词汇类比的例子中，系统如果之前没有接触测试词，就可能会生成错误的结果。 如果维度特别低或特别高，精度就会比较低。低维度词向量无法捕捉文集中不同词语的不同意义。这可以视为我们模型复杂度过低而导致的高偏差。比如 “king”, “queen”, “man”, “woman” 这几个词，我们需要至少2个维度像”gender” 如 “leadership” 来把它们编译成 2-字节 词向量。 过低的维度将无法捕捉四个词之间的语义差别，而过高的维度将捕捉到一些对泛化能力没有用的噪音– 即高方差的问题。 外部任务评价外部任务评价的特点如下： 在一个实际任务中进行评测 需要花很长的时间来计算精度 不太清楚是否是某个子系统或者其他子系统，又或是几个子系统互相作用引起的问题 如果替换原有的子系统后获得精度提升，则说明替换很可能是有效的 参考链接：斯坦福大学课程：深度学习与自然语言处理斯坦福大学深度学习与自然语言处理第二讲：词向量","tags":"nlp word2vec deep-learning 词向量"},{"title":"TensorFlow 实战 MINST","url":"/2016/06/20/TensorFlow实战-MNIST/","text":"工作中需要实现 CNN、RNN 模型，于是开始学习 TensorFlow。这是第一篇，MNIST的实战。官方文档讲的很详细，这里我不过是用我的思路整理一遍，方便日后的查阅。 TensorFlow 介绍综述TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 例如, 你可以将一小组图像集表示为一个四维浮点数数组, 这四个维度分别是 [batch, height, width, channels]. 一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是 tensorflow::Tensor 实例. 下载安装1sudo pip install —upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl 初步使用 使用图 (graph) 来表示计算任务. 在被称之为 会话 (Session) 的上下文 (context) 中执行图. 使用 tensor 表示数据. 通过 变量 (Variable) 维护状态. 使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 常量a = tf.constant([3.0, 3.0])# 变量，变量要进行初始化x = tf.Variable([1.0, 2.0])# 变量初始化init_op = tf.initialize_all_variables()# 矩阵乘法product = tf.matmul(matrix1, matrix2)# 减法sub = tf.sub(x, a)# 加法new_value = tf.add(state, one)# Fetch# 启动默认图sess = tf.Session()# 执行矩阵乘法。函数调用 &apos;run(product)&apos; 触发了图中三个 op (两个常量 op 和一个矩阵乘法 op) 的执行result = sess.run(product)# 任务完成, 关闭会话.sess.close()# Session 对象在使用完后需要关闭以释放资源. 除了显式调用 close 外, 也可以使用 &quot;with&quot; 代码块 来自动完成关闭动作.with tf.Session() as sess: result = sess.run([product]) print result# 取回多个 tensor:input1 = tf.constant(3.0)input2 = tf.constant(2.0)input3 = tf.constant(5.0)intermed = tf.add(input2, input3)mul = tf.mul(input1, intermed)with tf.Session() as sess: result = sess.run([mul, intermed]) print result# Feed#feed 使用一个 tensor 值临时替换一个操作的输出结果. 你可以提供 feed 数据作为 run() 调用的参数. feed 只在调用它的方法内有效, 方法结束, feed 就会消失. 最常见的用例是将某些特殊的操作指定为 &quot;feed&quot; 操作, 标记的方法是使用 tf.placeholder() 为这些操作创建占位符.input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.mul(input1, input2)with tf.Session() as sess: print sess.run([output], feed_dict=&#123;input1:[7.], input2:[2.]&#125;) 单层 SoftMax 神经网络模型加载 MNIST 数据60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。 每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。图片设为“xs”，标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 mnist.train.images ，训练数据集的标签是 mnist.train.labels。 每一张图片包含28X28个像素点。我们把这个数组展开成一个向量，长度是 28x28 = 784。 在 MNIST 训练数据集中，mnist.train.images 是一个形状为 [60000, 784] 的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。 相对应的 MNIST 数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。为了用于这个教程，我们使标签数据是”one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。因此， mnist.train.labels 是一个 [60000, 10] 的数字矩阵。 12import tensorflow.examples.tutorials.mnist.input_data as input_datamnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True) 运行 TensorFlow 的 InteractiveSessionTensorflow 依赖于一个高效的C++后端来进行计算。与后端的这个连接叫做session。一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。这里，我们使用更加方便的InteractiveSession类。通过它，你可以更加灵活地构建你的代码。它能让你在运行图的时候，插入一些计算图，这些计算图是由某些操作(operations)构成的。这对于工作在交互式环境中的人们来说非常便利，比如使用IPython。如果你没有使用InteractiveSession，那么你需要在启动session之前构建整个计算图，然后启动该计算图。12import tensorflow as tfsess = tf.InteractiveSession() 构建 Softmax 回归模型y = softmax(Wx + b) 1234567891011# x 是一个占位符placeholder，在TensorFlow运行计算时输入这个值。我们希望能够输入任意数量的MNIST图像，每一张图展平成784维的向量。我们用2维的浮点数张量来表示这些图，这个张量的形状是[None，784 ]。（这里的None表示此张量的第一个维度可以是任何长度的。）x = tf.placeholder(tf.float32, [None, 784])# 权重值W = tf.Variable(tf.zeros([784,10]))# 偏离值b = tf.Variable(tf.zeros([10]))# 类别预测 － softmax 模型。（激活函数，线性输出-&gt;概率分布）y = tf.nn.softmax(tf.matmul(x,W) + b) 我们在调用tf.Variable的时候传入初始值。在这个例子里，我们把 W 和 b 都初始化为零向量。W 是一个784x10的矩阵（因为我们有784个特征和10个输出值）。b 是一个10维的向量（因为我们有10个分类）。 构建代价函数指标交叉熵 代码12345# 正确值y_ = tf.placeholder(&quot;float&quot;, [None,10])# 损失函数cross_entropy = -tf.reduce_sum(y_*tf.log(y)) 注意，tf.reduce_sum把minibatch里的每张图片的交叉熵值都加起来了。我们计算的交叉熵是指整个minibatch的。 训练模型1train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) TensorFlow用梯度下降算法（gradient descent algorithm）以0.01的学习速率最小化交叉熵。梯度下降算法（gradient descent algorithm）是一个简单的学习过程，TensorFlow只需将每个变量一点点地往使成本不断降低的方向移动。 TensorFlow在这里实际上所做的是，它会在后台给计算图增加一系列新的计算操作单元用于实现反向传播算法和梯度下降算法。然后，它返回给你的只是一个单一的操作，当运行这个操作时，它用梯度下降算法训练你的模型，微调你的变量，不断减少成本。 返回的train_step操作对象，在运行时会使用梯度下降来更新参数。因此，整个模型的训练可以通过反复地运行train_step来完成。 训练1234567891011# 初始化变量init = tf.initialize_all_variables()# 在session里启动模型sess = tf.Session()sess.run(init)# 开始训练模型，这里我们让模型循环训练1000次！for i in range(1000): batch = mnist.train.next_batch(50) sess.run(train_step,feed_dict=&#123;x: batch[0], y_: batch[1]&#125;) 每一步迭代，我们都会随机加载50个训练样本，然后执行一次train_step，并通过feeddict将x 和 y张量占位符用训练训练数据替代。 使用一小部分的随机数据来进行训练被称为随机训练（stochastic training）- 在这里更确切的说是随机梯度下降训练。在理想情况下，我们希望用我们所有的数据来进行每一步的训练，因为这能给我们更好的训练结果，但显然这需要很大的计算开销。所以，每一次训练我们可以使用不同的数据子集，这样做既可以减少计算开销，又可以最大化地学习到数据集的总体特性。 评估模型找出预测正确的标签tf.argmax 给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签。tf.argmax(y,1)返回的是模型对于任一输入x预测到的标签值tf.argmax(y_,1) 代表正确的标签tf.equal 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)1correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) 这里返回一个布尔数组。为了计算我们分类的准确率，我们将布尔值转换为浮点数来代表对、错，然后取平均值。例如：[True, False, True, True]变为[1,0,1,1]，计算出平均值为0.75。1accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;)) 最后，我们可以计算出在测试数据上的准确率，大概是90.92%。1print sess.run(accuracy,feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;) 多层卷积网络模型CNN 对模式分类非常适合，最初是为识别二维形状而特殊设计的，这种二维形状对平移、比例缩放、倾斜或其他形式对变形有高度不变性。详见 卷积神经网络 CNN 笔记 TensorFlow 实现初始化权重和偏置项为了创建这个模型，我们需要创建大量的权重和偏置项。这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免 0 梯度。由于我们使用的是 ReLU 神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为 0 的问题（dead neurons）。为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。1234567def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial) 卷积和池化我们的卷积使用 1 步长（stride size），0 边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的 2x2 大小的模板做 max pooling。为了代码更简洁，我们把这部分抽象成一个函数。12345678# 卷积函数def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)# 池化函数def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;) 第一层卷积第一层卷积由一个卷积接一个 max pooling 完成。卷积在每个 5x5 的 patch 中算出 32 个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是 patch 的大小，接着是输入的通道数目，最后是输出的通道数目。 而对于每一个输出通道都有一个对应的偏置量。123456789W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])# 把 x 变成一个4d向量，其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是 rgb 彩色图，则为3)。x_image = tf.reshape(x, [-1,28,28,1])# 把 x_image 和权值向量进行卷积，加上偏置项，然后应用 ReLU 激活函数，最后进行 max pooling。h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1) 第二层卷积为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个 5x5 的 patch 会得到64个特征。12345W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2) 密集连接层(全连接层)经过第一次池化，图片尺寸减小到 14*14，经过第二次池化，图片尺寸减小到 7x7。我们加入一个有 1024 个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。12345W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) Dropout为了减少过拟合，我们在输出层之前加入 dropout。我们用一个 placeholder 来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用 dropout，在测试过程中关闭 dropout。 TensorFlow的tf.nn.dropout 操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。12keep_prob = tf.placeholder(&quot;float&quot;)h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) 输出层最后，我们添加一个softmax层，就像前面的单层softmax regression一样。1234W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2) 训练和评估模型使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码，只是我们会用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。最后的准确率是 99.2％12345678910111213141516cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))sess.run(tf.initialize_all_variables())for i in range(20000): batch = mnist.train.next_batch(50) if i % 100 == 0: train_accuracy = sess.run( accuracy, feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 1.0&#125;) print &quot;step %d, training accuracy %g&quot; % (i, train_accuracy) sess.run(train_step, feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)print &quot;test accuracy %g&quot; % sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;) 代码 参考链接: 中文文档github 项目地址http://blog.csdn.net/zouxy09/article/details/8781543http://blog.csdn.net/celerychen2009/article/details/8973218卷积神经网络(CNN)学习笔记 - LeNet5网络详解","tags":"tensorflow"},{"title":"爬虫总结(五)-- 其他技巧","url":"/2016/06/20/爬虫总结-五-其他技巧/","text":"补充前面没有提到的一些技巧。 模拟登录研究源码以 github 登录（https://github.com/login） 为例，查看html源码会发现表单里面有个隐藏的authenticity_token值，这个是需要先获取然后跟用户名和密码一起提交的。1234567891011121314151617181920212223242526&lt;div class=&quot;auth-form p-3&quot; id=&quot;login&quot;&gt; &lt;!-- &lt;/textarea&gt; --&gt;&lt;!-- &apos;&quot;` --&gt;&lt;form accept-charset=&quot;UTF-8&quot; action=&quot;/session&quot; data-form-nonce=&quot;b2e0b5f779ddbb5dbf93b903a82e5fc5204da96b&quot; method=&quot;post&quot;&gt;&lt;div style=&quot;margin:0;padding:0;display:inline&quot;&gt;&lt;input name=&quot;utf8&quot; type=&quot;hidden&quot; value=&quot;&amp;#x2713;&quot; /&gt;&lt;input name=&quot;authenticity_token&quot; type=&quot;hidden&quot; value=&quot;MDOLdxNeNMPn2sjrj51G+v/yMYpikLru8QWiLI170WRME4UBfvGItiAhzZWFujZVUSoT7SFygFcjE8pMfRcMHQ==&quot; /&gt;&lt;/div&gt; &lt;div class=&quot;auth-form-header&quot;&gt; &lt;h1&gt;Sign in to GitHub&lt;/h1&gt; &lt;/div&gt; &lt;div id=&quot;js-flash-container&quot;&gt;&lt;/div&gt; &lt;div class=&quot;auth-form-body mt-4&quot;&gt; &lt;label for=&quot;login_field&quot;&gt; Username or email address &lt;/label&gt; &lt;input autocapitalize=&quot;off&quot; autocorrect=&quot;off&quot; autofocus=&quot;autofocus&quot; class=&quot;form-control input-block&quot; id=&quot;login_field&quot; name=&quot;login&quot; tabindex=&quot;1&quot; type=&quot;text&quot; /&gt; &lt;label for=&quot;password&quot;&gt; Password &lt;a href=&quot;/password_reset&quot; class=&quot;label-link&quot;&gt;Forgot password?&lt;/a&gt; &lt;/label&gt; &lt;input class=&quot;form-control form-control input-block&quot; id=&quot;password&quot; name=&quot;password&quot; tabindex=&quot;2&quot; type=&quot;password&quot; /&gt; &lt;input class=&quot;btn btn-primary btn-block&quot; data-disable-with=&quot;Signing in…&quot; name=&quot;commit&quot; tabindex=&quot;3&quot; type=&quot;submit&quot; value=&quot;Sign in&quot; /&gt; &lt;/div&gt;&lt;/form&gt; 重写start_requests方法首先确保 cookie 打开 COOKIES_ENABLES = True 重写start_requests方法 # 重写了爬虫类的方法, 实现了自定义请求, 运行成功后会调用callback回调函数 def start_requests(self): return [Request(\"https://github.com/login\", meta={'cookiejar': 1}, callback=self.post_login)] # FormRequeset def post_login(self, response): # 先去拿隐藏的表单参数authenticity_token authenticity_token = response.xpath( '//input[@name=\"authenticity_token\"]/@value').extract_first() logging.info('authenticity_token=' + authenticity_token) pass start_requests方法指定了回调函数，用来获取隐藏表单值authenticity_token，同时我们还给Request指定了cookiejar的元数据，用来往回调函数传递cookie标识。 使用FormRequestScrapy为我们准备了FormRequest类专门用来进行Form表单提交的。 # FormRequeset def post_login(self, response): # 先去拿隐藏的表单参数authenticity_token authenticity_token = response.xpath( '//input[@name=\"authenticity_token\"]/@value').extract_first() logging.info('authenticity_token=' + authenticity_token) # FormRequeset.from_response是Scrapy提供的一个函数, 用于post表单 # 登陆成功后, 会调用after_login回调函数，如果url跟Request页面的一样就省略掉 return [FormRequest.from_response(response, url='https://github.com/session', meta={'cookiejar': response.meta['cookiejar']}, #headers=self.post_headers, formdata={ 'login': 'shuang0420', 'password': 'XXXXXXXXXXXXXXXXX', 'authenticity_token': authenticity_token }, callback=self.after_login, dont_filter=True )] FormRequest.from_response()方法让你指定提交的url，请求头还有form表单值，注意我们还通过meta传递了cookie标识。它同样有个回调函数，登录成功后调用。下面我们来实现它。注意这里我继续传递cookiejar，访问初始页面时带上cookie信息。 def after_login(self, response): # 登录之后，开始进入我要爬取的私信页面 for url in self.start_urls: logging.info('letter url=' + url) yield Request(url, meta={'cookiejar': response.meta['cookiejar']},callback=self.parse_page) 页面处理这个例子的主要任务是模拟登录，在登录 github 后爬取主页的 comments 内容。 代码123456789101112def parse_page(self, response): &quot;&quot;&quot;comments 内容&quot;&quot;&quot; logging.info(u&apos;--------------消息分割线-----------------&apos;) logging.info(response.url) replaceTags = re.compile(&apos;&lt;.*?&gt;&apos;) replaceLine = re.compile(&apos;\\r|\\n|\\t&apos;) message = response.xpath( &apos;//div[@class=&quot;details&quot;]/div[@class=&quot;message markdown-body&quot;]|div[@class=&quot;message markdown-body&quot;]/blockquote&apos;).extract() for m in message: m = replaceTags.sub(&quot;&quot;, m) m = replaceLine.sub(&quot;&quot;, m) print m 爬取结果 I like topn (or perhaps top_n) a little better, because it's not dependent on what the features represent (words, phrases, entities, characters...). … Note: as of now, the classes and methods are not well arranged, and there are a few mock classes (which will be removed) to help me with testing. O… Hello @gojomo thank you for replying fast.I have used save() to save the model and load_word2vec_format() to load the model. Thats where the probl… The unicode_errors='ignore' option should make it impossible for the exact same error to occur; perhaps you're getting some other very-similar error? (Nevermind, #758 added annoy.) It looks like the tests don't run on Travis, since Annoy is not installed there. Not sure how to fix the test failure in Python 2.6 either. Hello,Sorry for posting after even you have created the FAQ.I trained a model with tweets which had some undecodable unicode characters. When i t… dtto Misleading comment: there is no \"training\", the model is transferred from Mallet. These parameters only affect inference, model is unchanged. PEP8: Hanging indent of 4 spaces. @piskvorky I've addressed the comments. Could you please check? Thanks, that was quick :) @piskvorky , @tmylk , could you review? Added comment, made change in changelog. No, this was after that in 0.13.2. I noticed it because when I was testing the #768 solution, print_topics was failing. @tmylk how do you review these PRs before merging? There are too many errors, we cannot merge code so carelessly. Looks good to me... except still needs a comment explaining why the alias is there. And maybe a mention in the changelog, so we can deprecate the o… Yes, assign self.wordtopics = self.word_topics, with a big fat comment explaining why this alias is there. I don't understand how this version with storing unicode to binary files even worked. It means our unit tests must be faulty / incomplete. 代码 识别验证码验证码是一种非常有效的反爬虫机制，它能阻止大部分的暴力抓取，在电商类、投票类以及社交类等网站上应用广泛。如果破解验证码，成为了数据抓取工作者必须要面对的问题。下面介绍3种常用的方法。 更换ip地址在访问某些网站时，我们最初只是需要提供用户名密码就可以登陆的，比如说豆瓣网，如果我们要是频繁登陆访问，可能这时网站就会出现一个验证码图片，要求我们输入验证码才能登陆，这样在保证用户方便访问的同时，又防止了机器的恶意频繁访问。对于这种情况，我们可以使用代理服务器访问，只需要换个ip地址再次访问，验证码就不会出现了，当然，当验证码再次出现的时候，我们只能再更换ip地址。 使用cookie登陆如果采用cookie登陆，可以这样实现：首先需要手动登陆网站一次，获取服务器返回的cookie，这里就带有了用户的登陆信息，当然也可以采用获取的cookie登陆该网站的其他页面，而不用再次登陆。具体代码已经实现，详见ZhihuSpider。我们只需要在配置文件中提供用户名密码，及相应的cookie即可。对于不出现验证码的情况，爬虫会提交用户名密码实现post请求登陆，如果失败，才会使用事先提供的cookie信息。 需要说明的是，判断爬虫登陆与否，我们只需要看一下爬取的信息里面是否带有用户信息即可。在使用cookie登陆的时候，还需要不定期更新cookie，以保证爬取顺利进行。 验证码识别手段使用cookie登陆比较简单，但是有时效性问题。验证码识别是个很好的思路，然而识别的精度又限制了抓取的效率。 爬取js交互式表格数据这里，若使用Google Chrome分析”请求“对应的链接(方法：右键→审查元素→Network→清空，点击”加载更多“，出现对应的GET链接寻找Type为text/html的，点击，查看get参数或者复制Request URL)，循环过程。 启动 splash 容器 $ docker run -p 8050:8050 scrapinghub/splash 配置 scrapy-splash在你的 scrapy 工程的配置文件settings.py中添加 SPLASH_URL = 'http://192.168.59.103:8050' # 添加Splash中间件，还是在settings.py中通过DOWNLOADER_MIDDLEWARES指定，并且修改HttpCompressionMiddleware的优先级 DOWNLOADER_MIDDLEWARES = { 'scrapy_splash.SplashCookiesMiddleware': 723, 'scrapy_splash.SplashMiddleware': 725, 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810, } # 默认情况下，HttpProxyMiddleware的优先级是750，要把它放在Splash中间件后面 # 设置Splash自己的去重过滤器 DUPEFILTER_CLASS = 'scrapy_splash.SplashAwareDupeFilter' # 如果你使用Splash的Http缓存，那么还要指定一个自定义的缓存后台存储介质，scrapy-splash提供了一个scrapy.contrib.httpcache.FilesystemCacheStorage的子类 HTTPCACHE_STORAGE = 'scrapy_splash.SplashAwareFSCacheStorage' # 如果你要使用其他的缓存存储，那么需要继承这个类并且将所有的scrapy.util.request.request_fingerprint调用替换成scrapy_splash.splash_request_fingerprint 使用 scrapy-splashSplashRequest最简单的渲染请求的方式是使用scrapy_splash.SplashRequest，通常你应该选择使用这个12345678910111213yield SplashRequest(url, self.parse_result, args=&#123; # optional; parameters passed to Splash HTTP API &apos;wait&apos;: 0.5, # &apos;url&apos; is prefilled from request url # &apos;http_method&apos; is set to &apos;POST&apos; for POST requests # &apos;body&apos; is set to request body for POST requests &#125;, endpoint=&apos;render.json&apos;, # optional; default is render.html splash_url=&apos;&lt;url&gt;&apos;, # optional; overrides SPLASH_URL slot_policy=scrapy_splash.SlotPolicy.PER_DOMAIN, # optional) 另外，你还可以在普通的scrapy请求中传递splash请求meta关键字达到同样的效果12345678910111213141516171819202122yield scrapy.Request(url, self.parse_result, meta=&#123; &apos;splash&apos;: &#123; &apos;args&apos;: &#123; # set rendering arguments here &apos;html&apos;: 1, &apos;png&apos;: 1, # &apos;url&apos; is prefilled from request url # &apos;http_method&apos; is set to &apos;POST&apos; for POST requests # &apos;body&apos; is set to request body for POST requests &#125;, # optional parameters &apos;endpoint&apos;: &apos;render.json&apos;, # optional; default is render.json &apos;splash_url&apos;: &apos;&lt;url&gt;&apos;, # optional; overrides SPLASH_URL &apos;slot_policy&apos;: scrapy_splash.SlotPolicy.PER_DOMAIN, &apos;splash_headers&apos;: &#123;&#125;, # optional; a dict with headers sent to Splash &apos;dont_process_response&apos;: True, # optional, default is False &apos;dont_send_headers&apos;: True, # optional, default is False &apos;magic_response&apos;: False, # optional, default is True &#125;&#125;) Splash API说明，使用SplashRequest是一个非常便利的工具来填充request.meta[‘splash’]里的数据 meta[‘splash’][‘args’] 包含了发往Splash的参数。 meta[‘splash’][‘endpoint’] 指定了Splash所使用的endpoint，默认是render.html meta[‘splash’][‘splash_url’] 覆盖了settings.py文件中配置的Splash URL meta[‘splash’][‘splash_headers’] 运行你增加或修改发往Splash服务器的HTTP头部信息，注意这个不是修改发往远程web站点的HTTP头部 meta[‘splash’][‘dont_send_headers’] 如果你不想传递headers给Splash，将它设置成True meta[‘splash’][‘slot_policy’] 让你自定义Splash请求的同步设置 meta[‘splash’][‘dont_process_response’] 当你设置成True后，SplashMiddleware不会修改默认的scrapy.Response请求。默认是会返回SplashResponse子类响应比如SplashTextResponse meta[‘splash’][‘magic_response’] 默认为True，Splash会自动设置Response的一些属性，比如response.headers,response.body等如果你想通过Splash来提交Form请求，可以使用scrapy_splash.SplashFormRequest，它跟SplashRequest使用是一样的。 Responses对于不同的Splash请求，scrapy-splash返回不同的Response子类 SplashResponse 二进制响应，比如对/render.png的响应 SplashTextResponse 文本响应，比如对/render.html的响应 SplashJsonResponse JSON响应，比如对/render.json或使用Lua脚本的/execute的响应 如果你只想使用标准的Response对象，就设置meta[‘splash’][‘dont_process_response’]=True 所有这些Response会把response.url设置成原始请求URL(也就是你要渲染的页面URL)，而不是Splash endpoint的URL地址。实际地址通过response.real_url得到 实例爬取华为应用市场( http://appstore.huawei.com/more/all )的“下一页” url 链接。 查看网页源代码123456789101112131415161718&lt;script type=&quot;text/javascript&quot; src=&quot;http://app.vmall.com/js/core/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; var jsResource = new Array(); jsResource[&apos;cloud.page.count&apos;] = &quot;共&quot;; jsResource[&apos;cloud.page.numbers&apos;] = &quot;条记录&quot;; jsResource[&apos;cloud.page.last_page&apos;] = &quot;上一页&quot;; jsResource[&apos;cloud.page.next_page&apos;] = &quot;下一页&quot;; jsResource[&apos;cloud.page.pages&apos;] = &quot;页&quot;; jsResource[&apos;cloud.page.first&apos;] = &quot;首页&quot;; jsResource[&apos;cloud.page.last&apos;] = &quot;尾页&quot;; jsResource[&apos;cloud.downAppError&apos;]=&quot;您的请求正在处理中，请不要重复提交。&quot; jsResource[&apos;cloud.msg.ok&apos;]=&quot;确定&quot; jsResource[&apos;cloud.msg.message&apos;]=&quot;提示&quot; jsResource[&apos;cloud.detail.close&apos;]=&quot;关闭&quot;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://app.vmall.com/js/all/more.js?version=2.9.5.20150418&quot;&gt;&lt;/script&gt; 查看渲染后的代码启动 splash 容器，在浏览器打开 http://192.168.59.103:8050/ ， 输入网址进行 render，查看渲染后的代码。1&lt;div class=&quot;page-ctrl ctrl-app&quot; id=&quot;recommendListPage&quot;&gt;&lt;a href=&quot;http://appstore.huawei.com:80/more/all/1&quot;&gt;首页&lt;/a&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/1&quot;&gt;&lt;em class=&quot;arrow-grey-lt&quot;&gt;&amp;nbsp;&lt;/em&gt;上一页&lt;/a&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/1&quot;&gt;1&lt;/a&gt;&lt;span&gt;2&lt;/span&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/3&quot;&gt;3&lt;/a&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/4&quot;&gt;4&lt;/a&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/5&quot;&gt;5&lt;/a&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/3&quot;&gt;下一页&lt;em class=&quot;arrow-grey-rt&quot;&gt;&amp;nbsp;&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;http://appstore.huawei.com:80/more/all/41&quot;&gt;尾页&lt;/a&gt; spider 部分代码 def parse(self, response): page = Selector(response) hrefs = page.xpath('//h4[@class=\"title\"]/a/@href') if not hrefs: return for href in hrefs: url = href.extract() yield scrapy.Request(url, callback=self.parse_item) # find next page nextpage = page.xpath('//div[@class=\"page-ctrl ctrl-app\"]/a/em[@class=\"arrow-grey-rt\"]/../@href').extract_first() print nextpage yield scrapy.Request(nextpage,callback=self.parse,meta={ 'splash': { 'endpoint': 'render.html', 'args': {'wait': 0.5} } }) 完整代码 分析不规则的 html之前的几个部分解决的都是 下载 Web 页面 的问题，这里补充下获取网页后分析过程的一些技巧。以苏宁易购 help 页面为例。start_url 是 http://help.suning.com/faq/list.htm ， 爬取的是左边侧栏每个大类的每个小类下右边的问题页面，如“权益介绍”、“等级权益介绍”这些 FAQ 页面，如何到达这些页面就不再多说，关键是到达这些页面后怎么获得信息。 看一部分的网页源代码1234567891011121314151617181920212223242526272829&lt;div id=&quot;contentShow&quot;&gt; &lt;p class=&quot;MsoNormal&quot; style=&quot;background:white;text-align:left;&quot; align=&quot;left&quot;&gt; &lt;span style=&quot;font-size:9pt;font-family:宋体;color:black;&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class=&quot;MsoNormal&quot; style=&quot;background:white;&quot; align=&quot;left&quot;&gt; &lt;br /&gt;&lt;/p&gt;&lt;p class=&quot;MsoNormal&quot; style=&quot;background:white;&quot; align=&quot;left&quot;&gt; &lt;b&gt;一、权益类型&lt;/b&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;MsoNormal&quot; style=&quot;background:white;&quot; align=&quot;left&quot;&gt; 本次改版将上线&lt;span&gt;7&lt;/span&gt;个会员权益，涵盖价格优惠、资格抢先、服务优先等多个方面，会员等级越高，可享受到的会员权益越多。&lt;span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p class=&quot;MsoNormal&quot; style=&quot;background:white;&quot; align=&quot;left&quot;&gt; &lt;b&gt;二、具体详情：&lt;/b&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;MsoNormal&quot; style=&quot;background:white;&quot; align=&quot;left&quot;&gt; &lt;b&gt;1&lt;/b&gt;&lt;b&gt;、生日红包&lt;/b&gt;&lt;br /&gt;特权内容：&lt;span&gt;&lt;br /&gt;&lt;/span&gt;已验证手机号的&lt;span&gt;V2&lt;/span&gt;及以上等级的会员，在实名认证或完善生日资料后，可在生日周期间获得生日红包。&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;V2&lt;/span&gt;等级生日红包为&lt;span&gt;6&lt;/span&gt;元云券，&lt;span&gt;V3&lt;/span&gt;等级生日红包为&lt;span&gt;8&lt;/span&gt;元云券。（&lt;span&gt;2016&lt;/span&gt;年6月12日开始实施）&lt;span&gt;&lt;br /&gt;&lt;/span&gt;注意事项：&lt;span&gt;&lt;br /&gt;1&lt;/span&gt;）生日红包券为限品类云券，在生日周时自动发到会员账户，会员在成功收到生日红包券后会有短信提醒，并可登录“我的易购&lt;span&gt;-&lt;/span&gt;我的优惠券”【&lt;span&gt;&lt;a href=&quot;http://member.suning.com/emall/MyGiftTicket&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;点击查看&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;】，每个会员同一自然年内仅可获得一张生日红包券；&lt;span&gt;&lt;br /&gt;2&lt;/span&gt;）券使用规则：且限一次性使用、不找零、不兑现，不可以和云券叠加，可以和无敌券、易券叠加使用，不可使用自提；&lt;span&gt;&lt;br /&gt;3&lt;/span&gt;）券有效期：自券到账之日起&lt;span&gt;8&lt;/span&gt;日内有效；&lt;span&gt;&lt;br /&gt;4&lt;/span&gt;）券适用商品范围：仅限购买自营商品使用，也可以用于大聚惠、抢团购、手机专享价、名品特卖商品，但闪拍、秒杀、预售、海外购、虚拟商品、特殊类商品（一段奶粉等）及平台商户商品不可使用；&lt;span&gt;&lt;br /&gt;5&lt;/span&gt;）使用生日红包券的订单若发生退货，在有效期内券将返回至顾客账户，可再次使用；如用券订单退货时已超过券有效期，券将自动失效，不做延期；&lt;span&gt;&lt;/span&gt;&lt;/p&gt;...... 不难发现，有些文字分布在 div[@id=”contentShow”]/p div[@id=”contentShow”]/p/span div[@id=”contentShow”]/p/b 观察其他页面会发现还有些分布在 div[@id=”contentShow”]/h4 下或者 h3 下，有的甚至直接就在 div[@id=”contentShow”] 下。。怎么办？当然可以穷尽各种规则，也可以先把不需要的标签给去掉再 extract，这些我开始都傻傻的尝试过，结果总会忽略一些文字，后来在沮丧的看着 output 文件时福至心灵，直接取了 div[@id=”contentShow”] 再把所有的标签去掉不就行了？！ 上代码12345page = html.xpath(&apos;//div[@id=&quot;contentShow&quot;]&apos;).extract_first()replaceTags = re.compile(&apos;&lt;.*?&gt;&apos;)replaceLine = re.compile(&apos;\\r|\\n|\\t&apos;)page = replaceTags.sub(&quot;&quot;, page)page = re.sub(replaceLine, &quot;&quot;, page) 最后的结果非常干净1&#123;&quot;url&quot;: &quot;http://help.suning.com/page/id-26.htm&quot;, &quot;text&quot;: &quot; 一、账号注册目前注册个人用户仅支持：手机号方式进行注册。1、打开苏宁易购网站，点击页头“注册”，进入注册页面 2、进入注册页面，如果您是个人用户，可以用手机号进行注册；如果您是企业用户，可以点击“企业用户注册”，用单位名称进行注册，如果您有易购账号，可以点击“马上登录”3、填写注册信息，按照网页提示，填写手机号、验证码和密码 4、恭喜您，注册成功 &quot;, &quot;question&quot;: &quot;账户注册&quot;, &quot;title&quot;: &quot;易购注册登录&quot;&#125; 掌握这个技巧，处理类似问题就很简单啦，如再爬京东的 help 网页，稍微改下代码5分钟就能搞定。 代码 其他回头谈点背景知识,scrapy使用了twisted.一个异步网络框架.因此要留意潜在的阻塞情况.但注意到settings中有个参数是设置ItemPipeline的并行度.由此推测pipeline不会阻塞,pipeline可能是在线程池中执行的(未验证).Pipeline一般用于将抓取到的信息保存(写数据库,写文件),因此这里你就不用担心耗时操作会阻塞整个框架了,也就不用在Pipeline中将这个写操作实现为异步.除此之外框架的其他部分.都是异步的,简单说来就是,爬虫生成的请求交由调度器去下载,然后爬虫继续执行.调度器完成下载后会将响应交由爬虫解析.网上找到的参考例子,部分将js支持写到了DownloaderMiddleware中,scrapy官网的code snippet也是这样 .若这样实现,就阻塞了整个框架,爬虫的工作模式变成了,下载-解析-下载-解析,而不在是并行的下载.在对效率要求不高的小规模爬取中问题不大.更好的做法是将js支持写到scrapy的downloader里.网上有一个这样的实现(使用selenium+phantomjs).不过仅支持get请求.在适配一个webkit给scrapy的downloader时,有各种细节需要处理. 参考链接scrapy定制爬虫-爬取javascript内容Scrapy笔记（11）- 模拟登录网络爬虫-验证码登陆Scrapy笔记（12）- 抓取动态网站","tags":"crawler"},{"title":"爬虫总结(四)-- 分布式爬虫","url":"/2016/06/17/爬虫总结-四-分布式爬虫/","text":"分布式爬虫的演习。分布式爬虫问题其实也就是多台机器多个 spider 对 多个 url 的同时处理问题，怎样 schedule 这些 url，怎样汇总 spider 抓取的数据。最简单粗暴的方法就是将 url 进行分片，交给不同机器，最后对不同机器抓取的数据进行汇总。然而这样每个 spider 只能对自己处理的 url 去重，没办法全局的去重，另外性能也很难控制，可能有某台机器很早就跑完了，而别的机器还要跑很久。另一种思路就是把 url 存在某个地方，共享给所有的机器，总的调度器来分配请求，判断 spider 有没有闲置，闲置了就继续给它任务，直到所有的 url 都爬完，这种方法解决了去重问题（下面会具体讲到），也能提高性能，scrapy-redis 就实现了这样一个完整框架，总的来说，这更适合广度优先的爬取。 ScrapydScrapy 并没有提供内置的分布式抓取功能，不过有很多方法可以帮你实现。 如果你有很多个spider，最简单的方式就是启动多个 Scrapyd 实例，然后将spider分布到各个机器上面。 如果你想多个机器运行同一个spider，可以将url分片后交给每个机器上面的spider。比如你把URL分成3份 http://somedomain.com/urls-to-crawl/spider1/part1.list http://somedomain.com/urls-to-crawl/spider1/part2.list http://somedomain.com/urls-to-crawl/spider1/part3.list 然后运行3个 Scrapyd 实例，分别启动它们，并传递part参数 curl http://scrapy1.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=1 curl http://scrapy2.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 -d part=2 curl http://scrapy3.mycompany.com:6800/schedule.json -d project=myproject -d spider=spider1 Crawlera这个，花钱就可以轻易解决～ 直达 Scrapy-redisRedis 是高性能的 key-value 数据库。我们知道 MongoDB 将数据保存在了硬盘里，而 Redis 的神奇之处在于它将数据保存在了内存中，因此带来了更高的性能。 分布式原理scrapy-redis实现分布式，其实从原理上来说很简单，这里为描述方便，我们把自己的核心服务器称为 master，而把用于跑爬虫程序的机器称为 slave。 回顾 scrapy 框架，我们首先给定一些start_urls，spider 最先访问 start_urls 里面的 url，再根据我们的 parse 函数，对里面的元素、或者是其他的二级、三级页面进行抓取。而要实现分布式，只需要在这个starts_urls里面做文章就行了。进一步描述如下： master 产生 starts_urls，url 会被封装成 request 放到 redis 中的 spider:requests，总的 scheduler 会从这里分配 request，当这里的 request 分配完后，会继续分配 start_urls 里的 url。 slave 从 master 的 redis 中取出待抓取的 request，下载完网页之后就把网页的内容发送回 master 的 redis，key 是 spider:items。scrapy 可以通过 settings 来让 spider 爬取结束之后不自动关闭，而是不断的去询问队列里有没有新的 url，如果有新的 url，那么继续获取 url 并进行爬取，所以这一过程将不断循环。 master 里的 reids 还有一个 key 是 “spider:dupefilter” 用来存储抓取过的 url 的 fingerprint（使用哈希函数将url运算后的结果），防止重复抓取，只要 redis 不清空，就可以进行断点续爬。 对于已有的 scrapy 程序，对其扩展成分布式程序还是比较容易的。总的来说就是以下几步： 找一台高性能服务器，用于 redis 队列的维护以及数据的存储。 扩展 scrapy 程序，让其通过服务器的 redis 来获取 start_urls，并改写 pipeline 里数据存储部分，把存储地址改为服务器地址。 在服务器上写一些生成url的脚本，并定期执行。 关于 scheduler 到底是怎么进行调度的，需要看源码进行分析。 源码分析可能上面的描述还是不够清楚，干脆看一下源码吧，scrapy-redis 主要要一下几个文件。 零件分析 connection.py根据 settings 里的配置实例化 redis 连接，被 dupefilter 和 scheduler 调用。 dupefilter.py对 request 进行去重，使用了 redis 的 set。 queue.py三种 queue, SpiderQueue（FIFO), SpiderPriorityQueue，以及 SpiderStack(LIFI)。默认使用的是第二种。 pipelines.py分布式处理，将 item 存储在 redis 中。 scheduler.py取代 scrapy 自带的 scheduler,实现分布式调度，数据结构来自 queue。 spider.py定义 RedisSpider.py, 继承了 RedisMixin 和 CrawlSpider。 由上可知，scrapy-redis 实现的 爬虫分布式 和 item处理分布式 就是由模块 scheduler 和模块 pipelines 实现。上述其它模块作为为二者辅助的功能模块。 调度过程初始化spider 被初始化时，同时会初始化一个对应的 scheduler 对象，这个调度器对象通过读取 settings，配置好自己的调度容器 queue 和判重工具dupefilter。 判重 &amp; 进入调度池每当一个 spider 产出一个 request 的时候，scrapy 内核会把这个 request 递交给这个 spider 对应的 scheduler 对象进行调度，scheduler 对象通过访问 redis 对 request 进行判重，如果不重复就把他添加进 redis 中的调度池。 调度当调度条件满足时，scheduler 对象就从 redis 的调度池中取出一个 request 发送给spider，让 spider 爬取，若爬取过程中返回更多的url，那么继续进行直至所有的 request 完成。在这个过程中通过 connect signals.spider_idle 信号对 crawler 状态的监视，scheduler 对象发现 这个 spider 爬取了所有暂时可用 url，对应的 redis 的调度池空了，于是触发信号 spider_idle，spider收到这个信号之后，直接连接 redis 读取 strart_url池，拿去新的一批 url，返回新的 make_requests_from_url(url) 给引擎，进而交给调度器调度。 熟悉了原理其实可以自己来写 scheduler，自己定义调度优先级和顺序，👇 Redis 配置下载 Rediswget http://download.redis.io/releases/redis-3.2.1.tar.gz 下载 scrapy-redispip install scrapy-redis 安装 Redismake make test 修改配置文件安装完成后，redis 默认是不能被远程连接的，此时要修改配置文件 redis.conf，修改后，重启 redis 服务器 #bind 127.0.0.1 bind 0.0.0.0 任意目录下运行sudo cp redis.conf /etc/ 可能错误如果因为 gcc 而不能 make sudo apt-get build-dep gcc 如果遇到这个， make[1]: Entering directory `/opt/redis-2.6.14/src' CC adlist.o In file included from adlist.c:34: zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory zmalloc.h:55:2: error: #error \"Newer version of jemalloc required\" make[1]: *** [adlist.o] Error 1 make[1]: Leaving directory `/opt/redis-2.6.14/src' make: *** [all] Error 2 可以看这里 用这个命令 make MALLOC=libc 如果遇到这个 You need tcl 8.5 or newer in order to run the Redis test 安装 tcl sudo apt-get install tcl (redis 更多安装配置)[https://testerhome.com/topics/3887] Redis 常用命令运行 Redisredis-server redis.conf 进入命令行模式redis-cli 清空缓存flushdb 查看所有 key 127.0.0.1:6379> keys * 1) \"dmoz:items\" 2) \"dmoz:requests\" 3) \"dmoz:dupefilter\" 查看 list (item) 127.0.0.1:6379> LRANGE dmoz:items 0 3 1) \"{\\\"spider\\\": \\\"dmoz\\\", \\\"crawled\\\": \\\"2016-07-12 11:18:35\\\", \\\"link\\\": \\\"http://feeds.abcnews.com/abcnews/topstories\\\", \\\"name\\\": \\\"ABC News: Top Stories \\\", \\\"description\\\": \\\"Collection of news headlines.\\\"}\" 2) \"{\\\"spider\\\": \\\"dmoz\\\", \\\"crawled\\\": \\\"2016-07-12 11:18:35\\\", \\\"link\\\": \\\"http://abcnews.go.com/\\\", \\\"name\\\": \\\"ABCNews.com \\\", \\\"description\\\": \\\"Includes American and world news headlines, articles, chatrooms, message boards, news alerts, video and audio webcasts, shopping, and wireless news service. As well as ABC television show information and content.\\\"}\" 3) \"{\\\"spider\\\": \\\"dmoz\\\", \\\"crawled\\\": \\\"2016-07-12 11:18:35\\\", \\\"link\\\": \\\"http://www.alarabiya.net/\\\", \\\"name\\\": \\\"Al Arabiya News Channel \\\", \\\"description\\\": \\\"Arabic-language news network. Breaking news and features along with videos, photo galleries and In-Focus sections on major news topics. (Arabic, English, Persian, Urdu)\\\"}\" 4) \"{\\\"spider\\\": \\\"dmoz\\\", \\\"crawled\\\": \\\"2016-07-12 11:18:35\\\", \\\"link\\\": \\\"http://www.aljazeera.com/\\\", \\\"name\\\": \\\"Aljazeera \\\", \\\"description\\\": \\\"English version of the Arabic-language news network. Breaking news and features plus background material including profiles and global reactions.\\\"}\" 查看 set (dupefilter) 127.0.0.1:6379> SMEMBERS dmoz:dupefilter 1) \"28bf6cfa1409d6d2ad2852663a3751ae077a0b01\" 2) \"6af16713d5d423a2e91c87085f277a810c690cfa\" 3) \"c0ccfd767892b2bbb533a52c7cde55543aa4605b\" 4) \"0ca88e614179c791f258d89a820449c91940c4d4\" 5) \"546577e3457c55057c56985b71e6a142fe5a64e9\" 6) \"d2af0f8cf72e394dc46a720ee620fd7cdb0b6ad6\" 7) \"e0c1ab903b2a95f05bc8f5a5036b2f6f0b3fcbd0\" 8) \"bf1290602aa0fd2deb7f8b582f855535ca151990\" 9) \"c59f100b08e424352e6e368ff94d797c35fc5a4b\" 10) \"5acf897c445b3dbba5b371f811b74e26c52cd5c6\" 查看 sorted set (requests) 127.0.0.1:6379> ZRANGE dmoz:requests 0 3 1) \"\\x80\\x02}q\\x01(U\\x04bodyq\\x02U\\x00U\\t_encodingq\\x03U\\x05utf-8q\\x04U\\acookiesq\\x05}q\\x06U\\x04metaq\\a}q\\b(U\\x05depthq\\tK\\x01U\\tlink_textq\\nclxml.etree\\n_ElementStringResult\\nq\\x0bU\\tInvestingq\\x0c\\x85\\x81q\\r}q\\x0e(U\\a_parentq\\x0fNU\\x0cis_attributeq\\x10\\x89U\\battrnameq\\x11NU\\ais_textq\\x12\\x89U\\ais_tailq\\x13\\x89ubU\\x04ruleq\\x14K\\x00uU\\aheadersq\\x15}q\\x16U\\aRefererq\\x17]q\\x18U\\x14http://www.dmoz.org/q\\x19asU\\x03urlq\\x1aX'\\x00\\x00\\x00http://www.dmoz.org/Business/Investing/U\\x0bdont_filterq\\x1b\\x89U\\bpriorityq\\x1cK\\x00U\\bcallbackq\\x1dU\\x14_response_downloadedq\\x1eU\\x06methodq\\x1fU\\x03GETq U\\aerrbackq!Nu.\" 2) \"\\x80\\x02}q\\x01(U\\x04bodyq\\x02U\\x00U\\t_encodingq\\x03U\\x05utf-8q\\x04U\\acookiesq\\x05}q\\x06U\\x04metaq\\a}q\\b(U\\x05depthq\\tK\\x01U\\tlink_textq\\nclxml.etree\\n_ElementStringResult\\nq\\x0bU\\tLibrariesq\\x0c\\x85\\x81q\\r}q\\x0e(U\\a_parentq\\x0fNU\\x0cis_attributeq\\x10\\x89U\\battrnameq\\x11NU\\ais_textq\\x12\\x89U\\ais_tailq\\x13\\x89ubU\\x04ruleq\\x14K\\x00uU\\aheadersq\\x15}q\\x16U\\aRefererq\\x17]q\\x18U\\x14http://www.dmoz.org/q\\x19asU\\x03urlq\\x1aX(\\x00\\x00\\x00http://www.dmoz.org/Reference/Libraries/U\\x0bdont_filterq\\x1b\\x89U\\bpriorityq\\x1cK\\x00U\\bcallbackq\\x1dU\\x14_response_downloadedq\\x1eU\\x06methodq\\x1fU\\x03GETq U\\aerrbackq!Nu.\" 3) \"\\x80\\x02}q\\x01(U\\x04bodyq\\x02U\\x00U\\t_encodingq\\x03U\\x05utf-8q\\x04U\\acookiesq\\x05}q\\x06U\\x04metaq\\a}q\\b(U\\x05depthq\\tK\\x01U\\tlink_textq\\nclxml.etree\\n_ElementStringResult\\nq\\x0bU\\tTeen Lifeq\\x0c\\x85\\x81q\\r}q\\x0e(U\\a_parentq\\x0fNU\\x0cis_attributeq\\x10\\x89U\\battrnameq\\x11NU\\ais_textq\\x12\\x89U\\ais_tailq\\x13\\x89ubU\\x04ruleq\\x14K\\x00uU\\aheadersq\\x15}q\\x16U\\aRefererq\\x17]q\\x18U\\x14http://www.dmoz.org/q\\x19asU\\x03urlq\\x1aX-\\x00\\x00\\x00http://www.dmoz.org/Kids_and_Teens/Teen_Life/U\\x0bdont_filterq\\x1b\\x89U\\bpriorityq\\x1cK\\x00U\\bcallbackq\\x1dU\\x14_response_downloadedq\\x1eU\\x06methodq\\x1fU\\x03GETq U\\aerrbackq!Nu.\" 4) \"\\x80\\x02}q\\x01(U\\x04bodyq\\x02U\\x00U\\t_encodingq\\x03U\\x05utf-8q\\x04U\\acookiesq\\x05}q\\x06U\\x04metaq\\a}q\\b(U\\x05depthq\\tK\\x01U\\tlink_textq\\nclxml.etree\\n_ElementStringResult\\nq\\x0bU\\nBasketballq\\x0c\\x85\\x81q\\r}q\\x0e(U\\a_parentq\\x0fNU\\x0cis_attributeq\\x10\\x89U\\battrnameq\\x11NU\\ais_textq\\x12\\x89U\\ais_tailq\\x13\\x89ubU\\x04ruleq\\x14K\\x00uU\\aheadersq\\x15}q\\x16U\\aRefererq\\x17]q\\x18U\\x14http://www.dmoz.org/q\\x19asU\\x03urlq\\x1aX&\\x00\\x00\\x00http://www.dmoz.org/Sports/Basketball/U\\x0bdont_filterq\\x1b\\x89U\\bpriorityq\\x1cK\\x00U\\bcallbackq\\x1dU\\x14_response_downloadedq\\x1eU\\x06methodq\\x1fU\\x03GETq U\\aerrbackq!Nu.\" 查看 list (items) 长度127.0.0.1:6379&gt; LLEN Search:items(integer) 376 查看 sorted set (requests) 长度127.0.0.1:6379&gt; ZCARD Search:requests(integer) 1 查看 set (dupefilter) 长度127.0.0.1:6379&gt; SCARD Search:dupefilter(integer) 1 Redis 教程 scrapy_redis 配置从 github 上 下载 example，修改相应文件，items.py, settings.py, process_items.py 等。最重要的是改 settings.py 通用配置 SCHEDULER = \"scrapy_redis.scheduler.Scheduler\" DUPEFILTER_CLASS = \"scrapy_redis.dupefilter.RFPDupeFilter\" SCHEDULER_QUEUE_CLASS = \"scrapy_redis.queue.SpiderPriorityQueue\" SCHEDULER_PERSIST = True # ITEM_PIPELINES ITEM_PIPELINES = { 'scrapy_redis.pipelines.RedisPipeline': 400, } master 配置settings.py 中添加 # redis REDIS_HOST = '127.0.0.1' REDIS_PORT = 6379 slave 配置settings.py 中添加 # redis REDIS_URL = 'redis://host_ip:6379' spider 改写导入模块 from scrapy_redis.spiders import RedisSpider 继承 RedisSpider，并从 Redis 读取 url class Search(RedisCrawlSpider): name = \"Search\" redis_key = 'Search:start_urls' 运行爬虫在 master 上启动 Redis redis-server 启动 spider，任意顺序 scrapy crawl Search 可以看到 schedule 了多少 request $ scrapy crawl Search ... [Search] DEBUG: Resuming crawl (8712 requests scheduled) 导出数据写到数据库里很简单，在 process_items.py 里添加代码，指定数据库 ip，插入同一个数据库。这里我们的数据不用导出到 mongodb 等数据库，只用把它转化为文本文件即可。 redis-dump安装 redis-dump gem install redis-dump 导出 redis-dump -u 127.0.0.1:6379 > db.json 注意的是，它导出的是数据库里所有的 key-value，也就是说之后处理 items 的时候可能会有问题，item list 太大读取造成 memory error。 python 连接 redis很简单，导入模块，连接数据库，其他基本按照 redis 命令来。 import redis r = redis.Redis(host='106.75.136.128', port=6379) 如 for i in range(0, r.llen('Search:items'), 100): items = r.lrange('Search:items', start=0, end=100) 然后把文件写到文件里。 监控分布式系统还有一个问题，怎么监控 slave，知道哪台机器坏了，可以写个 socket 向 master 报告，或者用 email 告警。 其他每次执行重新爬取，应该将redis中存储的数据清空，否则影响爬取现象。 另外，request 和 url 是不同的，前者是由后者经由函数make_request_from_url实现，并且这个过程由spider完成。spider会返回（return、yield）request给scrapy引擎进而交割调度器。url也是在spider中定义或由spider获取的。 参考链接:使用scrapy,redis,mongodb实现的一个分布式网络爬虫scrapy-redis实现爬虫分布式爬取分析与实现定向爬虫：Scrapy 与 Redis 入门Scrapy笔记（7）- 内置服务基于Redis的三种分布式爬虫策略基于Python,scrapy,redis的分布式爬虫实现框架scrapy-redis源码分析Scrapy Redis源码 spider分析","tags":"crawler"},{"title":"讲座笔记 -- 腾讯应用宝","url":"/2016/06/15/讲座笔记 -- 腾讯应用宝/","text":"卓居超，2013年加入腾讯内部搜索部门，现负责腾讯应用宝搜索项目。近年来从事的科研工作集中在垂直领域的搜索、推荐技术研究。2015年代表腾讯公司在 WSDM 会议上做题为 “Semantic Matching in APP Search” 的主题报告，介绍腾讯应用宝语义搜索的技术实现。今天他在公司做了一场关于腾讯应用宝的分享，这是一篇讲座笔记。 应用宝 – 腾讯的安卓应用市场 搜索是重要入口（新应用的分发） app 快速的增长 一年增长几百万 二八原则 长尾大 0.1%的应用 80%的分发 指标 Downloads QV UV CTR (Click-Through-Rate) ROP (Rate-Of-Penetration) CTR(Click-Through-Rate): 网络广告（图片广告/文字广告/关键词广告/排名广告/视频广告等）的点击到达率，即该广告的点击量（严格的来说，可以是到达目标页面的数量）除以广告的浏览量（PV- Page View）。 语义计算策略数据特征 数据量少 审核通过的应用数量只有数十万 文本信息少 附带文本信息少 这就意味着能建索引的量少 –&gt; 所以要将信息泛化 应对策略搜索＋推荐用 词、主题、标签 来描述语义 (query –&gt; term + topic + tag –&gt; app) 数据补充爬取全网资源 游戏站点、用户评价 知识库：百度百科、百度知道 其他应用商店 搜索引擎 解析 应用宝用户行为 容易出现的问题是噪音会很大，所以需要机器学习的方法进一步的过滤 过程就是 页面抓取 –&gt; 内容抓取 –&gt; 知识挖掘 –&gt; 标签 + 句法模板 + 标签集合 + 标签关联 –&gt; 标签关联净化 –&gt; 标签索引 数据挖掘利用用户行为来指导排序 点击下载因子。赋予大的权重（增强鲁棒性） entropy因子。entropy可以表示用户query的集中程度，，点击散，entropy高，区分精准query和模糊query 主题模型LDA 聚类，对 topic 进行人工标注，把 app 映射到 topicLDA 在业界用法比较多。然而它最大的特点是需要大量的语料，语料少效果就不好。所以需要补充大量文本数据。 标签挖掘 元搜方式挖掘 tag （通过搜app） 根据用户行为、画像挖掘 tag对用户进行分群 地区／年龄／职业／性别等 生成代表用户属性的标签给app 元搜，上大学的时候还学过来着，居然听讲座的时候没想起来😳 元搜索引擎又称多搜索引擎，通过一个统一的用户界面帮助用户在多个搜索引擎中选择和利用合适的（甚至是同时利用若干个）搜索引擎来实现检索操作，是对分布于网络的多种检索工具的全局控制机制。（搜索引擎分类：全文搜索引擎、目录索引、元搜索引擎） 数据清洗方法：机器学习模型计算 confidence levelhuman editor + web data + qa (lda) user group tags –&gt; GBDT mode GBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。 app 语义画像语义描述体系分多个维度 机器学习（LTR）挑战：多来源检索结果不可比（类别／tag）利器：lambdaMART 排序模型（GBRT的变种） LTR - Learning to rank：学习排序用机器学习的方法进行排序，可用于相关性排序、推荐引擎等系统中。Learning to rank or machine-learned ranking (MLR) is a type of supervised or semi-supervised machine learning problem in which the goal is to automatically construct a ranking model from training data. 应用宝搜索商业化分发升级应用+应用分发 –&gt; 内容服务分发 意图识别优化：什么时候出应用，什么时候出音乐，热度 多来源混排：机器学习＋运营系统优化异构排序，促进分发效率（应用、音乐等怎么混排） 多场景引导：在热词、直达区（搜索补充呈现）、联想词等场景引导用户，培养内容搜索习惯 应用搜索广告技术核心 app 画像基于标签、主题、类别的 app 细粒度商业词 动态混排根据 query 动态选择广告槽位 利用相似应用打tag（confidence level –&gt; filter） 机器学习的本质已知数据 先验知识（专家系统） 未知数据的特征 –&gt; 求未知数据的优化分布通用技术难点：空间搜索 函数泛化 实际工作： 模型10% 其他90% 数据从哪来 特征如何抽取 领域先验知识 大量噪音？维数灾难？L0,L1,L2正则化 剪枝琐碎的准备工作很重要 L0正则化的值是模型参数中非零参数的个数。L1正则化表示各个参数绝对值之和。L2正则化标识各个参数的平方的和的开方值。 大公司 vs 小公司大公司搜索 推荐 广告 都能接触到，可以和牛人接触流程化 冗余 很多团队想做一件事 小公司 方向更对不被商业价值束缚 不被同伴利益束缚 不被自己经验束缚 跑的更快不被用户束缚 不被流程束缚 不被一般道德束缚 复利效应应用宝光是去噪就做了一年。每天积累一点 –&gt; 复利效应 –&gt; 无法超越腾讯去做搜索，做不过百度，为什么？技术团队不强？no！因为百度做了几十年的搜索，每天进步一点，复利效应无法超越。我们要找到可以产生复利效应的点。算法是数学专家的事，我们可以做的是应用方面的复利效应，比如说聊天机器人。","tags":"腾讯"},{"title":"爬虫总结(三)-- cloud scrapy","url":"/2016/06/15/爬虫总结-三-scrapinghub/","text":"发现了一个比较好玩的东西，scrapinghub，试着玩了一下 cloud scrapy，因为就它是免费的。。最大优点是可以将爬虫可视化。这里就简单记录一下它怎么用。 注册账号 &amp; 新建 scrapy cloud project在scrapyinghub 官网 注册账号登录后 create project，在新建的项目下，查看 Code &amp; Deploys，找到 API key 和 Project ID Deploy your project$ pip install shub login 并输入 API key $ shub login Enter your API key from https://dash.scrapinghub.com/account/apikey API key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Validating API key... API key is OK, you are logged in now. deploy 并输入 Project ID $ shub deploy ProjectID Packing version ed6b3b8-master Deploying to Scrapy Cloud project \"76180\" {\"status\": \"ok\", \"project\": 76180, \"version\": \"ed6b3b8-master\", \"spiders\": 1} Run your spiders at: https://dash.scrapinghub.com/p/76180/ Schedule your spider在自己的项目面板下选择 run spider 开启爬虫，也可以通过命令行开启。 shub schedule Zhidao Spider Zhidao scheduled, job ID: 76153/2/2 Watch the log on the command line: shub log -f 2/2 or print items as they are being scraped: shub items -f 2/2 or watch it running in Scrapinghub's web interface: https://dash.scrapinghub.com/p/76153/job/2/3 看最新的 log 和 itemsJOBID格式：2/2， 2/1 … shub log JOBID shub items JOBID 或者 Dashboard 查看结果 通过 Dashbord 还可以实时监控 crawler job 的情况，发出的请求数，抓取的 item 数，log 和 error 信息，执行的时间等，都一目了然。 Save itemscurl -u APIkey: http://storage.scrapinghub.com/items/76153/2/2 > items.json 分布式爬虫cloud scrapy 也提供了分布式爬虫的选择，当然是付费的。 Crawlera强悍的 Crawlera 提供了防止 ban 的机制，通过 ip、user-agent、cookie 等设置，防止爬虫被禁，详见 billing 完整代码 参考链接:http://doc.scrapinghub.com/scrapy-cloud.html#deploying-a-scrapy-spider","tags":"crawler"},{"title":"爬虫总结(二)-- scrapy","url":"/2016/06/12/爬虫总结-二-scrapy/","text":"用现成的框架的好处就是不用担心 cookie、retry、频率限制、多线程的事。这一篇把上一篇的实例用 scrapy 框架重新实现一遍。主要步骤就是新建项目 (Project) –&gt; 定义目标（Items）–&gt; 制作爬虫（Spider）–&gt; 存储结果（Pipeline） Scrapy 概述 Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试 Scrapy 架构Scrapy 使用了 Twisted异步网络库来处理网络通讯。整体架构大致如下 绿线是数据流向，首先从初始 URL 开始，Scheduler 会将其交给 Downloader 进行下载，下载之后会交给 Spider 进行分析，Spider 分析出来的结果有两种：一种是需要进一步抓取的链接，例如之前分析的“下一页”的链接，这些东西会被传回 Scheduler ；另一种是需要保存的数据，它们则被送到 Item Pipeline 那里，那是对数据进行后期处理（详细分析、过滤、存储等）的地方。另外，在数据流动的通道里还可以安装各种中间件，进行必要的处理。 Scrapy 组件 引擎(Scrapy): 用来处理整个系统的数据流处理, 触发事务(框架核心) 调度器(Scheduler): 用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL（抓取网页的网址或者说是链接）的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址 下载器(Downloader): 用于下载网页内容, 并将网页内容返回给蜘蛛(Scrapy下载器是建立在twisted这个高效的异步模型上的) 爬虫(Spiders): 爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面 项目管道(Pipeline): 负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据。 下载器中间件(Downloader Middlewares): 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。 爬虫中间件(Spider Middlewares): 介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。 调度中间件(Scheduler Middewares): 介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。 Scrapy 运行流程 引擎从调度器中取出一个链接(URL)用于接下来的抓取 引擎把URL封装成一个请求(Request)传给下载器，下载器把资源下载下来，并封装成应答包(Response) 爬虫解析Response 若是解析出实体（Item）,则交给实体管道进行进一步的处理;若是解析出的是链接（URL）,则把URL交给Scheduler等待抓取 默认情况下，Scrapy使用 LIFO 队列来存储等待的请求。简单的说，就是 深度优先顺序 。如果想要 广度优先顺序 进行爬取，需要进行设定。 Scrapy 存在的问题爬虫是一个很依赖于网络io的应用，单机的处理能力有限，很快就变成瓶颈。而scrapy并不是一个分布式的设计，在需要大规模爬取的情况下就很成问题。当然可以通过修改Request队列来实现分布式爬取，而且工作量也不算特别大。 scrapy的并行度不高。力图在爬虫里做一些计算性的操作就会影响抓取的速率。这主要是python里的线程机制造成的，因为Python使用了GIL(和Ruby一样)，多线程并不会带来太多速度上的提升(除非用Python的C扩展实现自己的模块，这样绕过了GIL)。Summary:Use Python threads if you need to run IO operations in parallel. Do not if you need to run computations in parallel. scrapy的内存消耗很快。可能是出于性能方面的考虑，pending requests并不是序列化存储在硬盘中，而是放在内存中的(毕竟IO很费时)，而且所有Request都放在内存中。你抓取到 百万网页的时候，考虑到单个网页时产生很多链接的，pending request很可能就近千万了，加上脚本语言里的对象本来就有额外成本，再考虑到GC不会立即释放内存，内存占用就相当可观了。归根到底，这两个问题是根植于语言之中的。 Scrapy 实例新建项目 (Project) scrapy startproject news_scrapy 输入以上命令之后，就会看见命令行运行的目录下多了一个名为 news_scrapy 的目录，目录的结构如下： |---- news_scrapy | |---- news_scrapy | |---- __init__.py | |---- items.py #用来存储爬下来的数据结构（字典形式） | |---- pipelines.py #用来对爬出来的item进行后续处理，如存入数据库等 | |---- settings.py #爬虫配置文件 | |---- spiders #此目录用来存放创建的新爬虫文件（爬虫主体） | |---- __init__.py | |---- scrapy.cfg #项目配置文件 定义目标（Items）Items是装载抓取的数据的容器，工作方式像 python 里面的字典，但它提供更多的保护，比如对未定义的字段填充以防止拼写错误通过创建scrapy.Item类, 并且定义类型为 scrapy.Field 的类属性来声明一个Item，通过将需要的item模型化，来控制站点数据。编辑 items.py # -*- coding: utf-8 -*- import scrapy class NewsScrapyItem(scrapy.Item): # define the fields for your item here like: category = scrapy.Field() url = scrapy.Field() secondary_title = scrapy.Field() secondary_url = scrapy.Field() #text = Field() 制作爬虫（Spider）Spider 定义了用于下载的URL列表、跟踪链接的方案、解析网页内容的方式，以此来提取items。要建立一个Spider，你必须用scrapy.spider.BaseSpider创建一个子类，并确定三个强制的属性： name：爬虫的识别名称，必须是唯一的，在不同的爬虫中你必须定义不同的名字。 start_urls：爬取的URL列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。 parse()：解析的方法，调用的时候传入从每一个URL传回的Response对象作为唯一参数，负责解析并匹配抓取的数据(解析为item)，跟踪更多的URL。 在 spiders 目录下新建 Wynews.py，代码如下。利用 yield Request(url=item[‘url’],meta={‘item_1’: item},callback=self.second_parse) 来进行第二层爬取。 class WynewsSpider(BaseSpider): name = \"Wynews\" start_urls = ['http://news.163.com/rank/'] def parse(self,response): html = HtmlXPathSelector(response) page = html.xpath('//div[@class=\"subNav\"]/a') for i in page: item = dict() item['category'] = i.xpath('text()').extract_first() item['url'] = i.xpath('@href').extract_first() print item['category'],item['url'] yield Request(url=item['url'],meta={'item_1': item},callback=self.second_parse) def second_parse(self,response): item_1= response.meta['item_1'] html = HtmlXPathSelector(response) #print 'response ',response page = html.xpath('//tr/td/a') #print 'page ',page items = [] for i in page: item = DidiScrapyItem() item['category'] = item_1['category'].encode('utf8') item['url'] = item_1['url'].encode('utf8') item['secondary_title'] = i.xpath('text()').extract_first().encode('utf8') item['secondary_url'] = i.xpath('@href').extract_first().encode('utf8') #print i.xpath('text()').extract(),i.xpath('@href').extract() items.append(item) return items 存储结果（Pipeline）Item pipeline 的主要责任是负责处理 spider 抽取的 Item，主要任务是清理、验证和存储数据。当页面被 spider 解析后，将被发送到 pipeline，每个 pipeline 的组件都是由一个简单的方法组成的Python类。pipeline 获取Item，执行相应的方法，并确定是否需要在 pipeline中继续执行下一步或是直接丢弃掉不处理。 执行过程 清理HTML数据 验证解析到的数据（检查Item是否包含必要的字段） 检查是否是重复数据（如果重复就删除） 将解析到的数据存储到 数据库/文件 中 主要方法 process_item(item, spider)每一个item管道组件都会调用该方法，并且必须返回一个item对象实例或raise DropItem异常。被丢掉的item将不会在管道组件进行执行 open_spider(spider)当spider执行的时候将调用该方法 close_spider(spider)当spider关闭的时候将调用该方法 编写自己的 Pipeline编辑 pipelines.py。把抓取的 items 保存到 json 文件中。 import json class NewsScrapyPipeline(object): def __init__(self): self.file = open('items.json', 'w') def process_item(self, item, spider): line = json.dumps(dict(item),ensure_ascii=False) + \"\\n\" self.file.write(line) return item 另外，如果不考虑编码（没有中文），可以在运行爬虫的时候直接通过下面的命令导出结果。 dump到JSON文件: scrapy crawl myspider -o items.json dump到CSV文件: scrapy crawl myspider -o items.csv dump到XML文件: scrapy crawl myspider -o items.xml 激活Item Pipeline组件在settings.py文件中，往ITEM_PIPELINES中添加项目管道的类名，激活项目管道组件 ITEM_PIPELINES = { 'news_scrapy.pipelines.NewsScrapyPipeline': 300, } 开启爬虫 (Crawl)scrapy crawl Wynews 完整代码 可能出现的问题 (Problem)打开 items.json 文件，中文可能会出现文件乱码问题 [{\"category\": \"\\u93c2\\u4f34\\u6908\", \"url\": \"http://news.163.com/special/0001386F/rank_news.html\", \"secondary_title\": \"\\u934b\\u950b\\u9422\\u5cf0\\u30b3\\u95c3\\u8e6d\\u7b09\\u9473\\u6ec8\\u69fb\\u951b\\u5c7e\\u5d0f\\u6fc2\\u7a3f\\u5dfb\\u9359\\u53c9\\u7c2e\\u6769\\u6ec4\\u7966\\u95c0\", \"secondary_url\": \"http://caozhi.news.163.com/16/0615/09/BPJG6SB60001544E.html\"}, 这一行代码就能解决。 line = json.dumps(dict(item),ensure_ascii=False) + \"\\n\" 结果 {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"A股闯关MSCI再度失败 索罗斯们押注对冲胜出\", \"secondary_url\": \"http://money.163.com/16/0615/06/BPJ4T69300253B0H.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"湖北副省长担心房价下跌：泡沫若破裂后果很严重\", \"secondary_url\": \"http://money.163.com/16/0615/08/BPJBM36U00252G50.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"马云:假货质量超过正品 打假很复杂\", \"secondary_url\": \"http://money.163.com/16/0615/08/BPJAIOVI00253G87.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"A股闯关未成功 纳入MSCI新兴市场指数被延迟\", \"secondary_url\": \"http://money.163.com/16/0615/07/BPJ7260D00252G50.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"马云称许多假货比真品好 网友:怪不得淘宝假货多\", \"secondary_url\": \"http://money.163.com/16/0615/08/BPJC437N002526O3.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"贪官示意家人低价买地 拆迁后获赔近亿元\", \"secondary_url\": \"http://money.163.com/16/0615/08/BPJAT58400252G50.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"又是毒胶囊:浙江查获1亿多粒毒胶囊 6人被捕\", \"secondary_url\": \"http://money.163.com/16/0615/07/BPJ8NMRG00253B0H.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"还不起了？委内瑞拉寻求宽限1年偿还中国贷款\", \"secondary_url\": \"http://money.163.com/16/0615/07/BPJ9IH3400252C1E.html\"} {\"category\": \"财经\", \"url\": \"http://money.163.com/special/002526BH/rank.html\", \"secondary_title\": \"A股频现清仓式减持 上半年十大减持王曝光\", \"secondary_url\": \"http://money.163.com/16/0615/07/BPJ7Q9BC00254IU4.html\"} {\"category\": \"汽车\", \"url\": \"http://news.163.com/special/0001386F/rank_auto.html\", \"secondary_title\": \"《装X购车指南》 30-50万都能买到啥车？\", \"secondary_url\": \"http://auto.163.com/16/0615/07/BPJ6U1J900084TUP.html\"} {\"category\": \"汽车\", \"url\": \"http://news.163.com/special/0001386F/rank_auto.html\", \"secondary_title\": \"看挡杆还以为是A8L 新款哈弗H9内饰曝光\", \"secondary_url\": \"http://auto.163.com/16/0615/00/BPIGTP4B00084TUO.html\"} {\"category\": \"汽车\", \"url\": \"http://news.163.com/special/0001386F/rank_auto.html\", \"secondary_title\": \"前脸/尾灯有变 新款捷达搭1.5L油耗更低\", \"secondary_url\": \"http://auto.163.com/16/0615/00/BPIGMEHE00084TUO.html\"} {\"category\": \"汽车\", \"url\": \"http://news.163.com/special/0001386F/rank_auto.html\", \"secondary_title\": \"主打车型不超10万良心价 远景SUV将8月上市\", \"secondary_url\": \"http://auto.163.com/16/0615/00/BPIHR2A500084TUO.html\"} {\"category\": \"汽车\", \"url\": \"http://news.163.com/special/0001386F/rank_auto.html\", \"secondary_title\": \"Macan并不是我真姓 众泰SR8搭2.0T/D\", \"secondary_url\": \"http://auto.163.com/16/0613/00/BPDBPB0J00084TUO.html\"} {\"category\": \"汽车\", \"url\": \"http://news.163.com/special/0001386F/rank_auto.html\", \"secondary_title\": \"上海福特翼搏优惠1.5万元\", \"secondary_url\": \"http://auto.163.com/16/0615/00/BPIHH8FF000857M6.html\"} 添加命令行参数第一种方法，在命令行用crawl控制spider爬取的时候，加上-a选项，如 scrapy crawl WangyiSpider -a category=打车 然后在 spider 的构造函数里加上带入的参数12345678910import scrapyclass WangyiSpider(BaseSpider): name = &quot;Wangyi&quot; def __init__(self, category=None, *args, **kwargs): super(WangyiSpider, self).__init__(*args, **kwargs) self.base_url = &apos;http://news.yodao.com/&apos; self.start_urls = [&apos;http://news.yodao.com/search?q=&apos; + category] 代码通过关键词爬取网易新闻－代码 运行多个爬虫默认情况当你每次执行scrapy crawl命令时会创建一个新的进程。但我们可以使用核心API在同一个进程中同时运行多个spider，如下，在 settings.py 的同级目录下编辑 run.py，导入编写的 spider 类如 JingdongSpider, SuningSpider。12345678910111213141516171819202122232425262728import scrapyfrom twisted.internet import reactorfrom scrapy.crawler import CrawlerRunnerfrom scrapy.utils.log import configure_loggingfrom scrapy.spiders import Spiderfrom scrapy.selector import HtmlXPathSelectorfrom items import FaqscrapyItemfrom scrapy.http import Requestfrom scrapy.selector import Selectorfrom scrapy.utils.project import get_project_settingsfrom spiders.FAQ_jingdong import JingdongSpiderfrom spiders.FAQ_suning import SuningSpiderimport reif __name__ == &apos;__main__&apos;: settings = get_project_settings() configure_logging(settings) runner = CrawlerRunner(settings) runner.crawl(JingdongSpider) runner.crawl(SuningSpider) d = runner.join() d.addBoth(lambda _: reactor.stop()) # blocks process so always keep as the last statement reactor.run() 然而不幸的是同一进程内运行多个 spider 可能会出现数据丢失问题，影响进一步的数据使用。如下：123&#123;&quot;url&quot;: &quot;http://help.jd.com/user/issue/231-213.html&quot;, &quot;text&quot;: &quot;订单已提交成功，如何付款？付款方式分为以下几种：（注：先款订单请您在订单提交后24小时内完成支付，否则订单会自动取消）1.货到付款：选择货到付款，在订单送达时您可选择现金、POS机刷卡、支票方式支付货款或通过京东APP手机客户端【扫一扫】功能扫描包裹单上的订单条形码方式用手机来完成订单的支付（扫码支付）；在订单未妥投之前您还可以进入“我的订单”在线支付货款。注意：货到付款的订单，如果一个ID帐号在一个月内有过1次以上或一年内有过3次以上，无理由不接收我司配送的商品，我司将在相应的ID帐户里按每单扣除500个京豆做为运费；时间计算方法为：成功提交订单后向前推算30天为一个月，成功提交订单后向前推算365天为一年，不以自然月和自然年计算。2.在线支付：选择在线支付，请您进入“我的订单”，点击“付款”，按提示进行操作；目前在线支付支持京东白条、余额、银行卡、网银+、微信、银联在线、网银钱包、信用卡等方式进行支付，可根据您的使用喜好进行选择。3.分期付款：目前不支持信用卡分期付款。4.公司转账：提交订单后选择线下公司转账会生成15位汇款识别码，请您按照提示到银行操作转账，然后进入“我的订单”填写付款确认；5.邮局汇款：订单提交成功后，请您按照提示到邮局操作汇款，然后进入“我的订单”填写付款确认。&quot;, &quot;question&quot;: &quot;订单已提交成功，如何付款？&quot;, &quot;title&quot;: &quot;支付流程&quot;&#125;�系统停机维护期间。（二） 电信设备出现故障不能进行数据传输的。（三） 由于黑客攻击、网络供应商技术调整或故障、网站升级、银行方面的问题等原因而造成的易付宝服务中断或延迟。（四） 因台风、地震、海啸、洪水、停电、战争、恐怖袭击等不可抗力之因素，造成易付宝系统障碍不能执行业务的。 第十三条 关于本协议条款和其他协议、告示或其他有关您使用本服务的通知，易付宝将以电子形式或纸张形式通知您，包括但不限于依据您向易付宝提供的电子邮件地址发送电子邮件的方式、依据投资者提供的联系地址寄送挂号信的方式、易付宝或合作伙伴网站公告、或发送手机短信、系统内通知和电话通知等方式。 第十四条 易付宝有权根据需要不时地修改本协议或制定、修改各类规则，但是，对于减少您权益或加重您义务的新增、变更或修改，易付宝将在生效日前提前至少7个日历日进行公示，如您不同意相关新增、变更或修改，您可以选择在公示期内终止本协议并停止使用本服务。如果相关新增、变更或修改生效后，您继续使用本服务则表示您接受修订后的权利义务条款。 第十五条 因本协议引起的或与本协议有关的争议，均适用中华人民共和国法律。 第十六条 因本协议引起的或与本协议有关的争议，易付宝与用户协商解决。协商不成的，任何一方均有权向被告住所地人民法院提起诉讼。 第十七条 本协议作为《易付宝余额理财服务协议》的有效补充，本协议未约定的内容，双方需按照《易付宝余额理财服务协议》相关约定。 &quot;, &quot;question&quot;: &quot;零钱宝定期转出服务协议&quot;, &quot;title&quot;: &quot;苏宁理财&quot;&#125;l&quot;: &quot;http://help.suning.com/page/id-536.htm&quot;, &quot;text&quot;: &quot; 代码 Scrapy 调优提高并发能力增加并发并发是指同时处理的request的数量。其有全局限制和局部(每个网站)的限制。Scrapy 默认的全局并发限制(16)对同时爬取大量网站的情况并不适用，因此需要增加这个值。 增加多少取决于爬虫能占用多少CPU。 一般开始可以设置为 100 。不过最好的方式是做一些测试，获得 Scrapy 进程占取CPU与并发数的关系。选择一个能使CPU占用率在80%-90%的并发数比较恰当。 # 增加全局并发数 CONCURRENT_REQUESTS = 100 mac 下调试，运行程序后通过 top 监控，p 按 cpu 排序。观察发现，在 CONCURRENT_REQUESTS = 32 时，cpu 占用最多到 50% 左右，调整到 CONCURRENT_REQUESTS = 100，cpu 占用 90% 上下。 查看本机 cpu 信息，用 sysctl machdep.cpu 命令，如下，可以看到我的机子是双核、4线程的。 # cpu 信息 $ sysctl machdep.cpu .......... machdep.cpu.core_count: 2 machdep.cpu.thread_count: 4 machdep.cpu.tsc_ccc.numerator: 0 machdep.cpu.tsc_ccc.denominator: 0 降低log级别为了减少CPU使用率(及记录log存储的要求), 当调试程序完毕后，可以不使用 DEBUG log级别。 # 设置Log级别: LOG_LEVEL = 'INFO' 禁止cookies禁止cookies能减少CPU使用率及Scrapy爬虫在内存中记录的踪迹，提高性能。 # 禁止cookies: COOKIES_ENABLED = False 禁止重试对失败的HTTP请求进行重试会减慢爬取的效率，尤其是当站点响应很慢(甚至失败)时， 访问这样的站点会造成超时并重试多次。这是不必要的，同时也占用了爬虫爬取其他站点的能力。 # 禁止重试: RETRY_ENABLED = False 减小下载超时对一个非常慢的连接进行爬取(一般对通用爬虫来说并不重要)， 减小下载超时能让卡住的连接能被快速的放弃并解放处理其他站点的能力。 # 减小下载超时: DOWNLOAD_TIMEOUT = 15 # 可能会引发的错误 TimeoutError: User timeout caused connection failure: Getting http://homea.people.com.cn/n1/2016/0628/c69176-28504657.html took longer than 15.0 seconds.. 通过如上配置，我的爬虫每分钟响应的request是之前的4倍，然而值得注意的是，这些设置并不是在所有场景都适用，需要通过具体场景试验，具体问题具体分析。 避免被禁止(ban)有些网站实现了特定的机制，以一定规则来避免被爬虫爬取。下面是些处理这些站点的建议(tips): 使用user agent池，轮流选择之一来作为user agent。池中包含常见的浏览器的user agent(google一下一大堆) 禁止cookies(参考 COOKIES_ENABLED)，有些站点会使用cookies来发现爬虫的轨迹。 设置下载延迟(2或更高)。参考 DOWNLOAD_DELAY 设置。 如果可行，使用 Google cache 来爬取数据，而不是直接访问站点。 使用IP池。例如免费的 Tor项目 或付费服务(ProxyMesh)。 使用高度分布式的下载器(downloader)来绕过禁止(ban)，就只需要专注分析处理页面。这样的例子有: Crawlera 如果仍然无法避免被ban，考虑商业支持. 实例 首先要有的是 user agent池 和 IP池。user agent池如下，添加在 settings.py 中。 USER_AGENTS = [ \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\", \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)\", \"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\", \"Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)\", \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)\", \"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)\", \"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)\", \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)\", \"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6\", \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1\", \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0\", \"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5\", \"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6\", \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20\", \"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52\", ] IP池 获取方式有多种，这里抓取的是西刺免费代理IP的 IP，注意实时更新问题，否则很容易失败。将抓取的 IP 以 http://host1:port 的格式存储于 list.txt 文本中。在 settings.py 里添加 PROXY_LIST = ‘/path/to/proxy/list.txt’。 有了 user agent池 和 IP池，接下来需要编写中间件，如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import reimport randomimport base64from scrapy import logclass RandomProxy(object): def __init__(self, settings): self.proxy_list = settings.get(&apos;PROXY_LIST&apos;) fin = open(self.proxy_list) self.proxies = &#123;&#125; for line in fin.readlines(): parts = re.match(&apos;(\\w+://)(\\w+:\\w+@)?(.+)&apos;, line) if not parts: continue # Cut trailing @ if parts.group(2): user_pass = parts.group(2)[:-1] else: user_pass = &apos;&apos; self.proxies[parts.group(1) + parts.group(3)] = user_pass fin.close() @classmethod def from_crawler(cls, crawler): return cls(crawler.settings) def process_request(self, request, spider): # Don&apos;t overwrite with a random one (server-side state for IP) if &apos;proxy&apos; in request.meta: return proxy_address = random.choice(self.proxies.keys()) proxy_user_pass = self.proxies[proxy_address] request.meta[&apos;proxy&apos;] = proxy_address if proxy_user_pass: basic_auth = &apos;Basic &apos; + base64.encodestring(proxy_user_pass) request.headers[&apos;Proxy-Authorization&apos;] = basic_auth print &quot;**************ProxyMiddleware have pass************&quot; + proxy[&apos;ip_port&apos;] def process_exception(self, request, exception, spider): proxy = request.meta[&apos;proxy&apos;] log.msg(&apos;Removing failed proxy &lt;%s&gt;, %d proxies left&apos; % ( proxy, len(self.proxies))) try: del self.proxies[proxy] except ValueError: passclass RandomUserAgent(object): &quot;&quot;&quot;Randomly rotate user agents based on a list of predefined ones&quot;&quot;&quot; def __init__(self, agents): self.agents = agents @classmethod def from_crawler(cls, crawler): return cls(crawler.settings.getlist(&apos;USER_AGENTS&apos;)) def process_request(self, request, spider): print &quot;**************************&quot; + random.choice(self.agents) request.headers.setdefault(&apos;User-Agent&apos;, random.choice(self.agents)) 改写 spider，check 某个元素，确保 proxy 能够返回 target page。 if not pageUrls: yield Request(url=response.url, dont_filter=True) 配置 settings.py # Retry many times since proxies often fail RETRY_TIMES = 10 # Retry on most error codes since proxies fail for different reasons RETRY_HTTP_CODES = [500, 503, 504, 400, 403, 404, 408] # Configure a delay for requests for the same website (default: 0) DOWNLOAD_DELAY=3 # Disable cookies (enabled by default) COOKIES_ENABLED=False # Enable downloader middlewares DOWNLOADER_MIDDLEWARES = { 'scrapy.contrib.downloadermiddleware.retry.RetryMiddleware': 90, # Fix path to this module 'blogCrawler.middlewares.RandomProxy': 100, 'blogCrawler.middlewares.RandomUserAgent': 1, 'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware': 110, } 这是一份简单的测试代码 其他调优来自 使用scrapy进行大规模抓取 如果想要爬取的质量更高，尽量使用宽度优先的策略，在配置里设置 SCHEDULER_ORDER = ‘BFO’ 修改单爬虫的最大并行请求数 CONCURRENT_REQUESTS_PER_SPIDER 修改twisted的线程池大小，默认值是10。参考Using Threads in Twisted，在scrapy/core/manage.py爬虫启动前加上 reactor.suggestThreadPoolSize(poolsize) 可以开启dns cache来提高性能。在配置里面加上 EXTENSIONS={’scrapy.contrib.resolver.CachingResolver’: 0,} 如果自己实现duplicate filter的话注意要保证它是一直可用的，dupfilter里的异常是不会出现在日志文件中的，好像外面做了try-expect处理 去重与增量抓取去重Scrapy支持通过RFPDupeFilter来完成页面的去重（防止重复抓取）。RFPDupeFilter实际是根据request_fingerprint实现过滤的，实现如下：1234567891011121314151617def request_fingerprint(request, include_headers=None):if include_headers: include_headers = tuple([h.lower() for h in sorted(include_headers)])cache = _fingerprint_cache.setdefault(request, &#123;&#125;)if include_headers not in cache: fp = hashlib.sha1() fp.update(request.method) fp.update(canonicalize_url(request.url)) fp.update(request.body or &apos;&apos;) if include_headers: for hdr in include_headers: if hdr in request.headers: fp.update(hdr) for v in request.headers.getlist(hdr): fp.update(v) cache[include_headers] = fp.hexdigest()return cache[include_headers] 我们可以看到，去重指纹是sha1(method + url + body + header)，所以，实际能够去掉重复的比例并不大。 如果我们需要自己提取去重的finger，需要自己实现Filter，并配置上它。 例如下面这个Filter只根据url去重：1234567891011from scrapy.dupefilter import RFPDupeFilterclass SeenURLFilter(RFPDupeFilter): &quot;&quot;&quot;A dupe filter that considers the URL&quot;&quot;&quot; def __init__(self, path=None): self.urls_seen = set() RFPDupeFilter.__init__(self, path) def request_seen(self, request): if request.url in self.urls_seen: return True else: self.urls_seen.add(request.url) 要在 settings 添加配置。DUPEFILTER_CLASS =’scraper.custom_filters.SeenURLFilter’ 增量爬取可以看这篇汇总贴 其实如果根据 url 判断的话有很多种方案，如下面这种（比起上面汇总贴的其他方案来说算是复杂的）。 增量抓取。一个针对多个网站的爬虫很难一次性把所有网页爬取下来，并且网页也处于不断更新的状态中，爬取是一个动态的过程，爬虫支持增量的抓取是很必要的。大概的流程就是关闭爬虫时保存duplicate filter的数据，保存当前的request队列，爬虫启动时导入duplicate filter，并且用上次request队列的数据作为start url。这里还涉及scrapy一个称得上bug的问题，一旦抓取队列里url过多，关闭scrapy需要很久，有时候要花费几天的时间。我们hack了scrapy的代码，在接收到关闭命令后，保存duplicate filter数据和当前的request队列和已抓取的url列表，然后调用twisted的reactor.stop()强制退出。当前的request队列可以通过scrapy.core.scheduler的pending_requests成员得到。 然而，如果使所有网站的动态过滤，比如是不是多了一个新回复，在url上的变化并不能体现出来，搜索引擎采用的是一系列的算法，判断某一个页面的更新时机。这个时候只能尝试用网页在进入下一级页面的时候都类似于最后更新时间、最后活动时间的参数进行判断了。 有机会会去尝试。 参考资料scrapy 文档向scrapy中的spider传递参数的几种方法使用scrapy进行大规模抓取Scrapy笔记（10）- 动态配置爬虫","tags":"crawler"},{"title":"爬虫总结(一)-- 爬虫基础 & python实现","url":"/2016/06/11/爬虫总结（一）/","text":"爬虫在平时也经常用，但一直没有系统的总结过，其实它涉及了许多的知识点。这一系列会理一遍这些知识点，不求详尽，只希望以点带面构建一个爬虫的知识框架。这一篇是概念性解释以及入门级爬虫介绍（以爬取网易新闻为例）。 爬虫基础什么是爬虫爬虫说白了其实就是获取资源的程序。制作爬虫的总体分三步：爬－取－存。首先要获取整个网页的所有内容，然后再取出其中对你有用的部分，最后再保存有用的部分。 爬虫类型 网络爬虫网络爬虫，是一种按照一定的规则，自动的 抓取万维网信息的程序或者脚本。网络爬虫是搜索引擎系统中十分重要的组成部分，爬取的网页信息用于建立索引从而为搜索引擎提供支持，它决定着整个引擎系统的内容是否丰富，信息是否即时，其性能的优劣直接影响着搜索引擎的效果。 传统爬虫从一个或若干初始网页的URL开始，获得初始网页的URL，在抓取网页过程中，不断从当前页面上抽取新的URL放入队列，直到满足系统的一定停止条件。 工作原理 根据一定的网页分析算法过滤与主题无关的链接，保留有用链接并将其放入等待抓取的URL队列 根据一定的搜索策略从队列中选择下一步要抓取的网页URL，重复上述过程，直到达到指定条件才结束爬取 对所有抓取的网页进行一定的分析、过滤，并建立索引，以便之后的查询和检索。 爬取策略广度优先完成当前层次的搜索后才进行下一层次的搜索。一般的使用策略，一般通过队列来实现。 最佳优先会有评估算法，凡是被算法评估为有用的网页，先来爬取。 深度优先实际应用很少。可能会导致trapped问题。通过栈来实现。 URL（ Uniform Resource Locator: 统一资源定位符）互联网上资源均有其唯一的地址，由三部分组成。 模式/协议 文件所在IP地址及端口号 主机上的资源位置 例子：http://www.example.com/index.html Web Server／Socket如何建立连接和传输数据的web server 的工作过程其实和打电话的过程差不多（买电话–&gt;注册号码–&gt;监听–&gt;排队接听–&gt;读写–&gt;关闭），经典的三步握手（有人在吗？我在呢，你呢？我也在）在排队接听时进行。下面一张图足以解释一切。 Crawler端需要一个socket接口，向服务器端发起connect请求，完成连接后就可以和服务器交流了，操作完毕会关闭socket接口。服务器端更复杂一点，也需要一个socket接口，并且这个socket接口需要绑定一个地址（bind()），这就相当于有一个固定的电话号码，这样其他人拨打这个号码就可以找到这个服务器。绑定之后服务器的socket就开始监听（listen()）有没有用户请求，如果有，就接收请求（accept()），和用户建立连接，然后就可以交流。 HTML DOM DOM 将 HTML 文档表达为树结构 定义了访问和操作 HTML 文档的标准 Cookie 由服务器端生成，发送给 User-Agent(一般是浏览器)，浏览器会将 Cookie 的 key/value 保存到某个目录下的文本文件哪，下次访问同一网站时就发送该 Cookie 给服务器。 HTTP GET 直接以链接形式访问，链接中包含了所有的参数 PUT 把提交的数据放到 HTTP 包的包体中 eg. import urllib import urllib2 url='http://www.zhihu.com/#signin' user_agent='MOZILLA/5.0' values={'username':'252618408@qq.com','password':'xxx'} headers={'User-Agent':user_agent} data=urllib.urlencode(values) # urlencode 是 urllib 独有的方法 request=urllib2.Request(url,data,headers) # write a letter response=urllib2.urlopen(request) # send the letter and get the reply page=response.read() # read the reply urllib 仅可以接受 URL，这意味着你不可以伪装你的 User Agent 字符串等，但 urllib 提供了 urlencode 方法用来GET查询字符串等产生，而 urllib2 没有。因此 urllib, urllib2经常一起使用。 Headers 设置 User-Agent: 部分服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求 Content-Type: 使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析 application/xml: 在 XMl RPC, 如 RESTful/SOAP 调用时使用 application/json: 在 JSON RPC 调用时使用 application/x-www-form-urlencoded: 浏览器提交 Web 表单时使用 爬虫难点爬虫的两部分，一是下载 Web 页面，有许多问题需要考虑。如何最大程度地利用本地带宽,如何调度针对不同站点的 Web 请求以减轻对方服务器的负担等。一个高性能的 Web Crawler 系统里，DNS 查询也会成为急需优化的瓶颈，另外，还有一些“行规”需要遵循（例如robots.txt）。而获取了网页之后的分析过程也是非常复杂的，Internet 上的东西千奇百怪，各种错误百出的 HTML 页面都有，要想全部分析清楚几乎是不可能的事；另外，随着 AJAX 的流行，如何获取由 Javascript 动态生成的内容成了一大难题；除此之外，Internet 上还有有各种有意或无意出现的 Spider Trap ，如果盲目的跟踪超链接的话，就会陷入 Trap 中万劫不复了，例如这个网站，据说是之前 Google 宣称 Internet 上的 Unique URL 数目已经达到了 1 trillion 个，因此这个人 is proud to announce the second trillion 。 最简单的爬虫requests 库 import requests url = \"http://shuang0420.github.io/\" r = requests.get(url) urllib2 库1234567891011import urllib2# request source fileurl = &quot;http://shuang0420.github.io/&quot;request = urllib2.Request(url) # write a letterresponse = urllib2.urlopen(request) # send the letter and get the replypage = response.read() # read the reply# save source filewebFile = open(&apos;webPage.html&apos;, &apos;wb&apos;)webFile.write(page)webFile.close() 这是一个简单的爬虫，打开 webPage.html 是这样的显示，没有css. 实例：爬取网易新闻爬取网易新闻 [代码示例]– 使用 urllib2 的 requests包来爬取页面– 使用正则表达式和 bs4 分析一级页面,使用 Xpath 来分析二级页面– 将得到的标题和链接,保存为本地文件 分析初始页面我们的初始页面是 http://news.163.com/rank 查看源代码 我们想要的是分类标题和URL，需要解析 DOM 文档树,这里使用了 BeautifulSoup 里的方法。123456789101112def Nav_Info(myPage): # 二级导航的标题和页面 pageInfo = re.findall(r&apos;&lt;div class=&quot;subNav&quot;&gt;.*?&lt;div class=&quot;area areabg1&quot;&gt;&apos;, myPage, re.S)[ 0].replace(&apos;&lt;div class=&quot;subNav&quot;&gt;&apos;, &apos;&apos;).replace(&apos;&lt;div class=&quot;area areabg1&quot;&gt;&apos;, &apos;&apos;) soup = BeautifulSoup(pageInfo, &quot;lxml&quot;) tags = soup(&apos;a&apos;) topics = [] for tag in tags: # 只要 科技、财经、体育 的新闻 # if (tag.string==&apos;科技&apos; or tag.string==&apos;财经&apos; or tag.string==&apos;体育&apos;): topics.append((tag.string, tag.get(&apos;href&apos;, None))) return topics 然而，Beautiful Soup对文档的解析速度不会比它所依赖的解析器更快,如果对计算时间要求很高或者计算机的时间比程序员的时间更值钱,那么就应该直接使用 lxml。换句话说,还有提高Beautiful Soup效率的办法,使用lxml作为解析器。Beautiful Soup用lxml做解析器比用html5lib或Python内置解析器速度快很多。bs4 的默认解析器是 html.parser，使用lxml的代码如下： BeautifulSoup(markup, \"lxml\") 分析二级页面 查看源代码 我们要爬取的是之间的新闻标题和链接，同样需要解析文档树，可以通过以下代码实现，这里用了 lxml 解析器，效率更高。123456def News_Info(newPage): # xpath 使用路径表达式来选取文档中的节点或节点集 dom = etree.HTML(newPage) news_titles = dom.xpath(&apos;//tr/td/a/text()&apos;) news_urls = dom.xpath(&apos;//tr/td/a/@href&apos;) return zip(news_titles, news_urls) 完整代码 潜在问题 我们的任务是爬取1万个网页，按上面这个程序，耗费时间长，我们可以考虑开启多个线程(池)去一起爬取，或者用分布式架构去并发的爬取网页。 种子URL和后续解析到的URL都放在一个列表里，我们应该设计一个更合理的数据结构来存放这些待爬取的URL才是，比如队列或者优先队列。 对各个网站的url，我们一视同仁，事实上，我们应当区别对待。大站好站优先原则应当予以考虑。 每次发起请求，我们都是根据url发起请求，而这个过程中会牵涉到DNS解析，将url转换成ip地址。一个网站通常由成千上万的URL，因此，我们可以考虑将这些网站域名的IP地址进行缓存，避免每次都发起DNS请求，费时费力。 解析到网页中的urls后，我们没有做任何去重处理，全部放入待爬取的列表中。事实上，可能有很多链接是重复的，我们做了很多重复劳动。 爬虫被封禁问题 优化方案 并行爬取问题 关于并行爬取，首先我们想到的是多线程或者线程池方式，一个爬虫程序内部开启多个线程。同一台机器开启多个爬虫程序，这样，我们就有N多爬取线程在同时工作，大大提高了效率。 当然，如果我们要爬取的任务特别多，一台机器、一个网点肯定是不够的，我们必须考虑分布式爬虫。分布式架构，考虑的问题有很多，我们需要一个scheduler来分配任务并排序，各个爬虫之间还需要通信合作，共同完成任务，不要重复爬取相同的网页。分配任务时我们还需要考虑负载均衡以做到公平。（可以通过Hash，比如根据网站域名进行hash） 负载均衡分派完任务之后，千万不要以为万事大吉了，万一哪台机器挂了呢？原先指派给挂掉的哪台机器的任务指派给谁？又或者哪天要增加几台机器，任务有该如何进行重新分配呢？所以我们还要 task table 来纪录状态。 待爬取网页队列如何对待待抓取队列，跟操作系统如何调度进程是类似的场景。不同网站，重要程度不同，因此，可以设计一个优先级队列来存放待爬起的网页链接。如此一来，每次抓取时，我们都优先爬取重要的网页。当然，你也可以效仿操作系统的进程调度策略之多级反馈队列调度算法。 DNS缓存为了避免每次都发起DNS查询，我们可以将DNS进行缓存。DNS缓存当然是设计一个hash表来存储已有的域名及其IP。 网页去重说到网页去重，第一个想到的是垃圾邮件过滤。垃圾邮件过滤一个经典的解决方案是Bloom Filter（布隆过滤器）。布隆过滤器原理简单来说就是：建立一个大的位数组，然后用多个Hash函数对同一个url进行hash得到多个数字，然后将位数组中这些数字对应的位置为1。下次再来一个url时，同样是用多个Hash函数进行hash，得到多个数字，我们只需要判断位数组中这些数字对应的为是全为1，如果全为1，那么说明这个url已经出现过。如此，便完成了url去重的问题。当然，这种方法会有误差，只要误差在我们的容忍范围之类，比如1万个网页，我只爬取到了9999个，并不会有太大的实际影响。一种很不错的方法来自url相似度计算，简单介绍下。考虑到url本身的结构，对其相似度的计算就可以抽象为对其关键特征相似度的计算。比如可以把站点抽象为一维特征，目录深度抽象为一维特征，一级目录、二级目录、尾部页面的名字也都可以抽象为一维特征。比如下面两个url:url1: http://www.spongeliu.com/go/happy/1234.htmlurl2: http://www.spongeliu.com/snoopy/tree/abcd.html 特征： 站点特征：如果两个url站点一样，则特征取值1，否则取值0； 目录深度特征：特征取值分别是两个url的目录深度是否一致； 一级目录特征：在这维特征的取值上，可以采用多种方法，比如如果一级目录名字相同则特征取1，否则取0；或者根据目录名字的编辑距离算出一个特征值；或者根据目录名字的pattern，如是否数字、是否字母、是否字母数字穿插等。这取决于具体需求，这里示例仅仅根据目录名是否相同取1和0； 尾页面特征：这维特征的取值同一级目录，可以判断后缀是否相同、是否数字页、是否机器生成的随机字符串或者根据编辑长度来取值，具体也依赖于需求。这里示例仅仅判断最后一级目录的特征是否一致（比如是否都由数字组成、是否都有字母组成等）。 这样，对于这两个url就获得了4个维度的特征，分别是：1 1 0 0 。有了这两个特征组合，就可以根据具体需求判断是否相似了。我们定义一下每个特征的重要程度，给出一个公式： similarity = feather1 * x1 + feather2*x2 + feather3*x3 + feather4*x4 其中x表示对应特征的重要程度，比如我认为站点和目录都不重要，最后尾页面的特征才是最重要的，那么x1,x2,x3都可以取值为0，x4取值为1，这样根据similarity就能得出是否相似了。或者认为站点的重要性占10%，目录深度占50%，尾页面的特征占40%，那么系数分别取值为0.1\\0.5\\0\\0.4即可。 其实这样找出需要的特征，可以把这个问题简化成一个机器学习的问题，只需要人为判断出一批url是否相似，用svm训练一下就可以达到机器判断的目的。除了上面这种两个url相似度的判断，也可以将每一条url都抽象成一组特征，然后计算出一个url的得分，设置一个分数差的阈值，就可以达到从一大堆url中找出相似的url的目的。 数据存储的问题数据存储同样是个很有技术含量的问题。用关系数据库存取还是用NoSQL，抑或是自己设计特定的文件格式进行存储，都大有文章可做。 进程间通信分布式爬虫，就必然离不开进程间的通信。我们可以以规定的数据格式进行数据交互，完成进程间通信。 反爬虫机制问题针对反爬虫机制，我们可以通过轮换IP地址、轮换Cookie、修改用户代理(User Agent)、限制速度、避免重复性爬行模式等方法解决。 参考链接: 网络爬虫基本原理(一)http://www.chinahadoop.cn/course/596/learn#lesson/11986https://www.bittiger.io/blog/post/5pDTFcDwkmCvvmKyshttps://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html","tags":"crawler"},{"title":"gensim-doc2vec实战","url":"/2016/06/01/gensim-doc2vec实战/","text":"gensim的doc2vec找不到多少资料，根据官方api探索性的做了些尝试。本文介绍了利用gensim的doc2vec来训练模型，infer新文档向量，infer相似度等方法，有一些不成熟的地方，后期会继续改进。 导入模块 # -*- coding: utf-8 -*- import sys reload(sys) sys.setdefaultencoding('utf8') import gensim, logging import os import jieba # logging information logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) 读取文件 # get input file, text format f = open('trainingdata.txt','r') input = f.readlines() count = len(input) print count 文件预处理，分词等 # read file and separate words alldocs=[] # for the sake of check, can be removed count=0 # for the sake of check, can be removed for line in input: line=line.strip('\\n') seg_list = jieba.cut(line) output.write(' '.join(seg_list) + '\\n') alldocs.append(gensim.models.doc2vec.TaggedDocument(seg_list,count)) # for the sake of check, can be removed count+=1 # for the sake of check, can be removed 模型选择gensim Doc2Vec 提供了 DM 和 DBOW 两个模型。gensim 的说明文档建议多次训练数据集并调整学习速率或在每次训练中打乱输入信息的顺序以求获得最佳效果。 # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size Doc2Vec(sentences,dm=1, dm_concat=1, size=100, window=2, hs=0, min_count=2, workers=cores) # PV-DBOW Doc2Vec(sentences,dm=0, size=100, hs=0, min_count=2, workers=cores) # PV-DM w/average Doc2Vec(sentences,dm=1, dm_mean=1, size=100, window=2, hs=0, min_count=2, workers=cores) 训练并保存模型 # train and save the model sentences= gensim.models.doc2vec.TaggedLineDocument('output.seq') model = gensim.models.Doc2Vec(sentences,size=100, window=3) model.train(sentences) model.save('all_model.txt') 保存文档向量 # save vectors out=open(\"all_vector.txt\",\"wb\") for num in range(0,count): docvec =model.docvecs[num] out.write(docvec) #print num #print docvec out.close() 检验 计算训练文档中的文档相似度 # test, calculate the similarity # 注意 docid 是从0开始计数的 # 计算与训练集中第一篇文档最相似的文档 sims = model.docvecs.most_similar(0) print sims # get similarity between doc1 and doc2 in the training data sims = model.docvecs.similarity(1,2) print sims infer向量，比较相似度下面的代码用于检验模型正确性，随机挑一篇trained dataset中的文档，用模型重新infer，再计算与trained dataset中文档相似度，如果模型良好，相似度第一位应该就是挑出的文档。 # check ############################################################################# # A good check is to re-infer a vector for a document already in the model. # # if the model is well-trained, # # the nearest doc should (usually) be the same document. # ############################################################################# print 'examing' doc_id = np.random.randint(model.docvecs.count) # pick random doc; re-run cell for more examples print('for doc %d...' % doc_id) inferred_docvec = model.infer_vector(alldocs[doc_id].words) print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3))) 遇到的问题👇两个错误还在探索中，根据官方指南是可以运行的，然而我遇到了错误并没能解决。第一段错误代码，关于train the model alldocs=[] count=0 for line in input: #print line line=line.strip('\\n') seg_list = jieba.cut(line) #output.write(line) output.write(' '.join(seg_list) + '\\n') alldocs.append(gensim.models.doc2vec.TaggedDocument(seg_list,count)) count+=1 model = Doc2Vec(alldocs,size=100, window=2, min_count=5, workers=4) model.train(alldocs) 报错信息 Traceback (most recent call last): File \"d2vTestv5.py\", line 59, in model = Doc2Vec(alldocs[0],size=100, window=2, min_count=5, workers=4) File \"/usr/local/lib/python2.7/site-packages/gensim/models/doc2vec.py\", line 596, in __init__ self.build_vocab(documents, trim_rule=trim_rule) File \"/usr/local/lib/python2.7/site-packages/gensim/models/word2vec.py\", line 508, in build_vocab self.scan_vocab(sentences, trim_rule=trim_rule) # initial survey File \"/usr/local/lib/python2.7/site-packages/gensim/models/doc2vec.py\", line 639, in scan_vocab document_length = len(document.words) AttributeError: 'generator' object has no attribute 'words' 第二段错误代码，关于infer doc_words1=['验证','失败','验证码','未','收到'] doc_words2=['今天','奖励','有','哪些','呢'] # get infered vector invec1 = model.infer_vector(doc_words1, alpha=0.1, min_alpha=0.0001, steps=5) invec2 = model.infer_vector(doc_words2, alpha=0.1, min_alpha=0.0001, steps=5) print invec1 print invec2 # get similarity # the output docid is supposed to be 0 sims = model.docvecs.most_similar([invec1]) print sims # according to official guide, the following codes are supposed to be fine, but it fails to run sims= model.docvecs.similarity(invec1,invec2) print model.similarity(['今天','有','啥','奖励'],['今天','奖励','有','哪些','呢']) 最后两行代码报错，错误信息 raceback (most recent call last): File \"d2vTestv5.py\", line 110, in sims= model.docvecs.similarity(invec1,invec2) File \"/usr/local/lib/python2.7/site-packages/gensim/models/doc2vec.py\", line 484, in similarity return dot(matutils.unitvec(self[d1]), matutils.unitvec(self[d2])) File \"/usr/local/lib/python2.7/site-packages/gensim/models/doc2vec.py\", line 341, in __getitem__ return vstack([self[i] for i in index]) File \"/usr/local/lib/python2.7/site-packages/gensim/models/doc2vec.py\", line 341, in __getitem__ return vstack([self[i] for i in index]) TypeError: 'numpy.float32' object is not iterable 更多代码 回顾这里我们尝试了很多种方法作比较研究。 纯 log 模型 纯 百科 模型 百科模型 + log 再训练模型 log 词库 + 百科模型 + log 再训练模型 (用到了 reset_weights 方法) 综合来讲，log 词库，百科数据训练模型，log 再训练的方法效果会更好些，然而增加百科数据并不会大幅提升效果。 对纯 log 模型而言，win=5，4的结果差不多，都要比 win=2 好很多。 log 模型对相近词的把握不是很好，前两个词非常准确，但是之后的词就没有多少代表性了，主要是因为词库里有大量噪音，加上百科数据训练，词的权重进行调整，会更偏向百科里的词，有人会有疑问，为什么 log 的词库百科训练会出现那么多百科的词，那是因为 log 里有新闻/百科的文本，包含了这些词，是谁这么无聊…… 有效的语料库和干净的文本数据是模型分析的保证。有效的语料库和干净的文本数据是模型分析的保证。有效的语料库和干净的文本数据是模型分析的保证。重要的事情说三遍！ eg. 与“奖励”最相近的词 # 纯 log 模型 奖 0.866039454937 奖金 0.838458776474 礼 0.698936760426 截止 0.662528753281 % 0.639326810837 周期 0.61717569828 1.8 0.609462141991 抽奖 0.581079006195 责 0.580395340919 消息 0.57931292057 # log 词库，百科训练模型 嘉奖 0.607903599739 奖赏 0.607445776463 报酬 0.59623169899 声望 0.580911517143 阴谋 0.557106971741 表扬 0.54744797945 奖品 0.543839931488 惩罚 0.540722668171 弱点 0.535359799862 俸禄 0.532780826092 # log 词库，百科训练模型，log 再训练 奖 0.86665225029 奖金 0.828586399555 补贴 0.731625974178 补助 0.640836119652 回事 0.638447761536 补偿 0.63090801239 账 0.630112946033 帐 0.605027675629 区别 0.58495759964 原因 0.584367990494 参考链接https://radimrehurek.com/gensim/models/doc2vec.htmlhttps://github.com/piskvorky/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynbhttp://blog.csdn.net/raycchou/article/details/50971599","tags":"gensim doc2vec"},{"title":"gensim - word2vec实战","url":"/2016/05/30/gensim-word2vec实战/","text":"介绍如何利用 gensim 库建立简单的 word2vec 模型。 # -*- coding: utf-8 -*- import gensim from gensim.corpora import WikiCorpus from gensim.models import Word2Vec from gensim.models.word2vec import LineSentence import os import logging import jieba import re import multiprocessing import sys reload(sys) sys.setdefaultencoding('utf-8') # logging information logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s') logging.root.setLevel(level=logging.INFO) # get input file, text format inp = sys.argv[1] input = open(inp, 'r') output = open('output.seq', 'w') if len(sys.argv) < 2: print(globals()['__doc__'] % locals()) sys.exit(1) # read file and separate words for line in input.readlines(): line=line.strip('\\n') seg_list = jieba.cut(line) output.write(' '.join(seg_list) + '\\n') output.close() output= open('output.seq', 'r') # initialize the model # size = the dimensionality of the feature vectors # window = the maximum distance between the current and predicted word within a sentence # min_count = ignore all words with total frequency lower than this. model = Word2Vec(LineSentence(output), size=100, window=3, min_count=5,workers=multiprocessing.cpu_count()) # save model model.save('output.model') model.save_word2vec_format('output.vector', binary=False) # test model=gensim.models.Word2Vec.load('output.model') x = model.most_similar([u'奖励']) for i in x: print \"Word: {}\\t Similarity: {}\".format(i[0], i[1]) 更多代码","tags":"gensim word2vec"},{"title":"word2vec详解之六 -- 若干源码细节","url":"/2016/05/29/word2vec详解之六-若干源码细节/","text":"word2vec 是 Google 于 2013 年开源推出的一个用于获取 word vector 的工具包，它简单、高效，因此引起了很多人的关注。由于 word2vec 的作者 Tomas Mikolov 在两篇相关的论文 [3,4] 中并没有谈及太多算法细节，因而在一定程度上增加了这个工具包的神秘感。一些按捺不住的人于是选择了通过解剖源代码的方式来一窥究竟，出于好奇，我也成为了他们中的一员。读完代码后，觉得收获颇多，整理成文，给有需要的朋友参考。 作者: peghoty出处: http://blog.csdn.net/itplus/article/details/37969979欢迎转载/分享, 但请务必声明文章出处.","tags":"word2vec"},{"title":"word2vec详解之五 -- 基于 Negative Sampling 的模型","url":"/2016/05/29/word2vec详解之五-基于-Negative-Sampling-的模型/","text":"word2vec 是 Google 于 2013 年开源推出的一个用于获取 word vector 的工具包，它简单、高效，因此引起了很多人的关注。由于 word2vec 的作者 Tomas Mikolov 在两篇相关的论文 [3,4] 中并没有谈及太多算法细节，因而在一定程度上增加了这个工具包的神秘感。一些按捺不住的人于是选择了通过解剖源代码的方式来一窥究竟，出于好奇，我也成为了他们中的一员。读完代码后，觉得收获颇多，整理成文，给有需要的朋友参考。 作者: peghoty出处: http://blog.csdn.net/itplus/article/details/37969979欢迎转载/分享, 但请务必声明文章出处.","tags":"word2vec"},{"title":"word2vec详解之四 -- 基于Hierarchical Softmax 的模型","url":"/2016/05/29/word2vec详解之四-基于Hierarchical-Softmax-的模型/","text":"word2vec 是 Google 于 2013 年开源推出的一个用于获取 word vector 的工具包，它简单、高效，因此引起了很多人的关注。由于 word2vec 的作者 Tomas Mikolov 在两篇相关的论文 [3,4] 中并没有谈及太多算法细节，因而在一定程度上增加了这个工具包的神秘感。一些按捺不住的人于是选择了通过解剖源代码的方式来一窥究竟，出于好奇，我也成为了他们中的一员。读完代码后，觉得收获颇多，整理成文，给有需要的朋友参考。 作者: peghoty出处: http://blog.csdn.net/itplus/article/details/37969979欢迎转载/分享, 但请务必声明文章出处.","tags":"word2vec"},{"title":"word2vec详解之三 -- 背景知识","url":"/2016/05/29/word2vec详解之三-背景知识/","text":"word2vec 是 Google 于 2013 年开源推出的一个用于获取 word vector 的工具包，它简单、高效，因此引起了很多人的关注。由于 word2vec 的作者 Tomas Mikolov 在两篇相关的论文 [3,4] 中并没有谈及太多算法细节，因而在一定程度上增加了这个工具包的神秘感。一些按捺不住的人于是选择了通过解剖源代码的方式来一窥究竟，出于好奇，我也成为了他们中的一员。读完代码后，觉得收获颇多，整理成文，给有需要的朋友参考。 作者: peghoty出处: http://blog.csdn.net/itplus/article/details/37969979欢迎转载/分享, 但请务必声明文章出处.","tags":"word2vec"},{"title":"word2vec详解之二 -- 预备知识","url":"/2016/05/29/word2vec详解之二-预备知识/","text":"word2vec 是 Google 于 2013 年开源推出的一个用于获取 word vector 的工具包，它简单、高效，因此引起了很多人的关注。由于 word2vec 的作者 Tomas Mikolov 在两篇相关的论文 [3,4] 中并没有谈及太多算法细节，因而在一定程度上增加了这个工具包的神秘感。一些按捺不住的人于是选择了通过解剖源代码的方式来一窥究竟，出于好奇，我也成为了他们中的一员。读完代码后，觉得收获颇多，整理成文，给有需要的朋友参考。 作者: peghoty出处: http://blog.csdn.net/itplus/article/details/37969979欢迎转载/分享, 但请务必声明文章出处.","tags":"word2vec"},{"title":"word2vec详解之一 -- 目录和前言","url":"/2016/05/28/word2vec详解之一-目录和前言/","text":"word2vec 是 Google 于 2013 年开源推出的一个用于获取 word vector 的工具包，它简单、高效，因此引起了很多人的关注。由于 word2vec 的作者 Tomas Mikolov 在两篇相关的论文 [3,4] 中并没有谈及太多算法细节，因而在一定程度上增加了这个工具包的神秘感。一些按捺不住的人于是选择了通过解剖源代码的方式来一窥究竟，出于好奇，我也成为了他们中的一员。读完代码后，觉得收获颇多，整理成文，给有需要的朋友参考。 作者: peghoty出处: http://blog.csdn.net/itplus/article/details/37969979欢迎转载/分享, 但请务必声明文章出处.","tags":"word2vec"},{"title":"PHP连接数据库js可视化数据","url":"/2016/05/26/PHP连接数据库js可视化数据/","text":"","tags":""},{"title":"短句归一化--LSI模型","url":"/2016/05/25/短问题归一化-LSI模型/","text":"LSI 理解LSI(Latent Semantic Indexing)，中文意译是潜在语义索引，即通过海量文献找出词汇之间的关系。基本理念是当两个词或一组词大量出现在一个文档中时，这些词之间就是语义相关的。 潜在语义索引是一种用奇异值分解方法获得在文本中术语和概念之间关系的索引和获取方法。该方法的主要依据是在相同文章中的词语一般有类似的含义。该方法可以可以从一篇文章中提取术语关系，从而建立起主要概念内容。 降维过程将文档库表示成VSM模型的词-文档矩阵Am×n(词-文档矩阵那就是词作为行，文档作为列，这是矩阵先行后列的表示决定的，当然如果表示成文档-词矩阵的话，后面的计算就要用该矩阵的转置了),其中m表示文档库中包含的所有不同的词的个(行数是不同词的个数)，即行向量表示一个词在不同文档出现的次数，n 表示文档库中的文档数(列数是不同文档的个数)，即列向量表示的是不同的文档.A表示为A = [α ij ],在此矩阵中 ,α ij为非负值 , 表示第 i 个词在第j 个文档中出现的频度。显然，A是稀疏矩阵(这是VSM和文档决定的)。 利用奇异值分解SVD(Singular Value Decomposition)求A的只有K个正交因子的降秩矩阵，该过程就是降维的过程。SVD的重要作用是把词和文档映射到同一个语义空间中，将词和文档表示为K个因子的形式。显然，这会丢失信息，但主要的信息却被保留了。为什么该过程可以降维呢？因为该过程解决了同义和多义现象。可以看出，K的取值对整个分类结果的影响很大。因为，K过小，则丢失信息就越多；K过大，信息虽然多，但可能有冗余且计算消耗大。K的选择也是值得研究的，不过一般取值为100-300，不绝对。 适用性对于 LSI/PLSI 来说，聚类的意义不在于文档，而在于单词。所以对于聚类的一种变型用法是，当 k 设的足够大时，LSI/PLSI 能够给出落在不同子空间的单词序列，基本上这些单词之间拥有较为紧密的语义联系。其实这种用法本质上还是在利用降维做单词相关度计算。 特征降维LSI 本质上是把每个特征映射到了一个更低维的子空间（sub space)，所以用来做降维可以说是天造地设。TFIDF是另一个通用的降维方法，通过一个简单的公式（两个整数相乘）得到不同单词的重要程度，并取前k个最重要的单词，而丢弃其它单词，只有信息的丢失，并没有信息的改变。从执行效率上 TFIDF 远远高于 LSI，不过从效果上（至少在学术界）LSI 要优于TFIDF。不过必须提醒的是，无论是上述哪一种降维方法，都会造成信息的偏差，进而影响后续分类/聚类的准确率。 降维是希望以可接受的效果损失下，大大提高运行效率和节省内存空间。然而能不降维的时候还是不要降维（比如你只有几千篇文档要处理，那样真的没有必要降维）。 单词相关度计算LSI 的结果通过简单变换就能得到不同单词之间的相关度( 0 ~ 1 之间的一个实数），相关度非常高的单词往往拥有相同的含义。不过不要被“潜在语义”的名称所迷惑，所谓的潜在语义只不过是统计意义上的相似，如果想得到同义词还是使用同义词词典靠谱。LSI 得到的近义词的特点是它们不一定是同义词（甚至词性都可能不同），但它们往往出现在同类情景下（比如“魔兽” 和 “dota”)。不过事实上直接使用LSI做单词相关度计算的并不多，一方面在于现在有一些灰常好用的同义词词典，另外相对无监督的学习大家还是更信任有监督的学习（分类）得到的结果。 聚类直接用 LSI 聚类的情景还没有见过，但使用该系列算法的后续变种 PLSI, LDA 进行聚类的的确有一些。其中LDA聚类还有些道理（因为它本身就假设了潜在topic的联合概率分布），用 LSI 进行聚类其实并不合适。本质上 LSI 在找特征子空间，而聚类方法要找的是实例分组。 LSI 虽然能得到看起来貌似是聚类的结果，但其意义不见得是聚类所想得到的。一个明显的例子就是，对于分布不平均的样本集（比如新闻类的文章有1000篇，而文学类的文章只有10篇）， LSI/PLSI 得到的往往是相对平均的结果(A类500篇，B类600篇)，这种情况下根本无法得到好的聚类结果。相对传统聚类方法k-means， LSI 系列算法不仅存在信息的偏差（丢失和改变），而且不能处理分布不均的样本集。 实验说明用了python的gensim包现有的数据是438条标准问题以及3300条人工问题（可以转化为438条标准问题），现在需要对人工问题做一个归一化。这里采用LSI模型进行建模实验，步骤如下。 导入包 # -*- coding: utf-8 -*- from gensim import corpora, models, similarities import logging import jieba import jieba.posseg as pseg # 防止乱码 import sys reload(sys) sys.setdefaultencoding('utf-8') # 打印log信息 logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) 文本预处理 # 标准FAQ，一行对应一条问句 f = open('FAQuniq.txt', 'r') # 对问句进行分词 texts = [[word for word in jieba.cut(document, cut_all = False)] for document in f] # 抽取一个bag-of-words，将文档的token映射为id dictionary = corpora.Dictionary(texts) # 保存词典 dictionary.save('LSI.dict') # 产生文档向量，将用字符串表示的文档转换为用id和词频表示的文档向量 corpus = [dictionary.doc2bow(text) for text in texts] # 基于这些“训练文档”计算一个TF-IDF模型 tfidf = models.TfidfModel(corpus) # 转化文档向量，将用词频表示的文档向量表示为一个用tf-idf值表示的文档向量 corpus_tfidf = tfidf[corpus] # 训练LSI模型 即将训练文档向量组成的矩阵SVD分解，并做一个秩为2的近似SVD分解 lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=100) # 保存模型 lsi.save('LSI.pkl') lsi.print_topics(20) 初始化验证performance的文件checkFile的每行格式为： 原始问题的docid：对应的标准问题的topicid 把它存到checkDict这个dictionary中，key是docid，value是topicid。 checkDict=dict() def getCheckId(): fcheck=open('checkFile.txt') for line in fcheck: line=line.strip('\\n') if (len(line)==0): continue docid=line.split(\":\")[0] topicid=line.split(\":\")[1] checkDict[int(docid)]=int(topicid) getCheckId() 归一化／计算文档相似度 # 建索引 index = similarities.MatrixSimilarity(lsi[corpus]) # 初始化分数 score1=0 score2=0 score3=0 # 读取文件，文件的每行格式为一个原始问句 f2=open('ORIFAQ3330.txt','r') # count的作用是和checkFile的docid，即checkDict的key对应 count=1 for query in f2: # 获取该原始问句本应对应的正确标准问句 if (not checkDict.has_key(count)): count+=1 continue checkId=checkDict[count] # 将问句向量化 query_bow = dictionary.doc2bow(jieba.cut(query, cut_all = False)) # 再用之前训练好的LSI模型将其映射到二维的topic空间： query_lsi = lsi[query_bow] # 计算其和index中doc的余弦相似度了： sims = index[query_lsi] sort_sims = sorted(enumerate(sims), key=lambda item: -item[1]) # 找出最相关的三篇文档，计算这三篇文档是否包括标准问句，如果文档就是标准问句，对应的分数加1 if (checkId==sort_sims[0][0]): score1+=1 elif (checkId==sort_sims[1][0]): score2+=1 elif (checkId==sort_sims[2][0]): score3+=1 count+=1 打印分数 print \"Score1: \".format(score1*1.0/count) print \"Score2: \".format(score2*1.0/count) print \"Score3: \".format(score3*1.0/count) 结论其实这里的结果非常差，原因是文档（每一条问句）太短，只有十几个字，另外文档数太少，LSI降维牺牲了准确率，下一个实验LDA的准确率相比会高很多。另外，本次实验所用的样本分布并不均匀，“未收到奖励”类似问题出现的频率比“软件无声音”类似问题出现的频率要高很多。重申：LSI/PLSI 得到的往往是相对平均的结果(A类500篇，B类600篇)，这种情况下根本无法得到好的聚类结果。相对传统聚类方法k-means， LSI 系列算法不仅存在信息的偏差（丢失和改变），而且不能处理分布不均的样本集。 LSI 缺陷常用的VSM文本表示模型中有两个主要的缺陷： 该模型假设所有特征词条之间是相互独立、互不影响的（朴素贝叶斯也是这个思想），即该模型还是基于“词袋”模型（应该说所有利用VSM模型没有进行潜在语义分析的算法都是基于“词袋”假设）。 没有进行特征降维，特征维数可能会很高，向量空间可能很大，对存储和计算资源要求会比较高。 LSI的基本思想是文本中的词与词之间不是孤立的，存在着某种潜在的语义关系，通过对样本数据的统计分析，让机器自动挖掘出这些潜在的语义关系，并把这些关系表示成计算机可以”理解”的模型。它可以消除词匹配过程中的同义和多义现象。它可以将传统的VSM降秩到一个低维的语义空间中，在该语义空间中计算文档的相似度等。总的说来，LSI就是利用词的语义关系对VSM模型进行降维，并提高分类的效果。 参考链接http://www.zwbk.org/MyLemmaShow.aspx?lid=257113http://www.52nlp.cn/%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%96%87%E6%A1%A3%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%BA%8C","tags":"machine-learning lda topic-modeling cluster"},{"title":"在c里调用python","url":"/2016/05/22/在c里调用python/","text":"这一个例子是c调用了python的函数，函数返回值是list，包含了100个float值。 #include #include #include void test1(){ Py_Initialize();//初始化python char *test = \"奖励\"; PyObject * pModule = NULL; PyObject * pModule1 = NULL; PyObject * pFunc = NULL; PyObject * pArg = NULL; PyObject * result; pModule = PyImport_ImportModule(\"inferSingleDocVec\");//引入模块 pFunc = PyObject_GetAttrString(pModule, \"getDocVec\");//直接获取模块中的函数 pArg= Py_BuildValue(\"(s)\", test); result = PyEval_CallObject(pFunc, pArg); //调用直接获得的函数，并传递参数；这里得到的是一个list for (int i = 0; i < PyList_Size(result); i++) { printf(\"%f\\t\", PyFloat_AsDouble(PyList_GetItem(result, (Py_ssize_t)i)));//打印每一个元素 } //下面代码适用于返回值为字符串的情况 //char* s=NULL; //PyArg_Parse(result, \"s\", &s); //for (int i=0;s[i]!='\\0';i++){ // printf(\"%c\",s[i]); // } Py_Finalize(); //释放python // return; } int main(int argc, char* argv[]) { test1(); return 0; } 编译运行 $ gcc -I/usr/local/lib/python2.7.11 -o inferDocVec inferDocVec.c -lpython2.7 $ ./inferDocVec 调用的inferSingleDocVec文件 #!/usr/bin/python # -*- coding: utf-8 -*- ### for infer import sys reload(sys) sys.setdefaultencoding('utf8') import gensim, logging from gensim.models import Doc2Vec import os import jieba import multiprocessing import numpy as np import base64 logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) def getDocVec(doc_words): docwords=[word for word in jieba.cut(doc_words, cut_all = False)] model = Doc2Vec.load('all_model_v2.txt') invec = model.infer_vector(docwords, alpha=0.1, min_alpha=0.0001, steps=5) return (list)(invec) 关于如何将python文件转为模块，详见之前的一篇博文python 将自己写的py文件作为模块导入 参考链接 https://www.daniweb.com/programming/software-development/threads/237529/what-does-pyarg_parse-do-in-detail http://stackoverflow.com/questions/5079570/writing-a-python-c-extension-how-to-correctly-load-a-pylistobject","tags":"python c"},{"title":"AP聚类","url":"/2016/05/19/AP聚类/","text":"AP算法的具体工作过程如下：先计算N个点之间的相似度值，将值放在S矩阵中，再选取P值(一般取S的中值)。设置一个最大迭代次数(文中设默认值为1000)，迭代过程开始后，计算每一次的R值和A值，根据R(k,k)+A(k,k)值来判断是否为聚类中心(文中指定当(R(k,k)+A(k,k))＞0时认为是一个聚类中心)，当迭代次数超过最大值( 即maxits值)或者当聚类中心连续多少次迭代不发生改变( 即convits值)时终止计算(文中设定连续50次迭代过程不发生改变是终止计算)。 Affinity Propagation (AP) 聚类是最近在Science杂志上提出的一种新的聚类算法。它根据N个数据点之间的相似度进行聚类,这些相似度可以是对称的,即两个数据点互相之间的相似度一样(如欧氏距离);也可以是不对称的,即两个数据点互相之间的相似度不等。这些相似度组成N×N的相似度矩阵S(其中N为有N个数据点)。AP算法不需要事先指定聚类数目,相反它将所有的数据点都作为潜在的聚类中心,称之为exemplar。以S矩阵的对角线上的数值s(k, k)作为k点能否成为聚类中心的评判标准,这意味着该值越大,这个点成为聚类中心的可能性也就越大,这个值又称作参考度p (preference)。在这里介绍几个文中常出现的名词：exemplar：指的是聚类中心。similarity：数据点i和点j的相似度记为S(i，j)。是指点j作为点i的聚类中心的相似度。一般使用欧氏距离来计算，如－|| ||。文中，所有点与点的相似度值全部取为负值。因为我们可以看到，相似度值越大说明点与点的距离越近，便于后面的比较计算。preference：数据点i的参考度称为P(i)或S(i,i)。是指点i作为聚类中心的参考度。一般取S相似度值的中值。Responsibility:R(i,k)用来描述点k适合作为数据点i的聚类中心的程度。Availability:A(i,k)用来描述点i选择点k作为其聚类中心的适合程度。 Script output:Estimated number of clusters: 3Homogeneity: 0.872Completeness: 0.872V-measure: 0.872Adjusted Rand Index: 0.912Adjusted Mutual Information: 0.871Silhouette Coefficient: 0.753 Python source code: plot_affinity_propagation.pyprint(doc) from sklearn.cluster import AffinityPropagationfrom sklearn import metricsfrom sklearn.datasets.samples_generator import make_blobs ############################################################################## Generate sample datacenters = [[1, 1], [-1, -1], [1, -1]]X, labels_true = make_blobs(n_samples=300, centers=centers, cluster_std=0.5, random_state=0) ############################################################################## Compute Affinity Propagationaf = AffinityPropagation(preference=-50).fit(X)cluster_centers_indices = af.cluster_centersindiceslabels = af.labels_ nclusters = len(cluster_centers_indices) print(‘Estimated number of clusters: %d’ % nclusters)print(“Homogeneity: %0.3f” % metrics.homogeneity_score(labels_true, labels))print(“Completeness: %0.3f” % metrics.completeness_score(labels_true, labels))print(“V-measure: %0.3f” % metrics.v_measure_score(labels_true, labels))print(“Adjusted Rand Index: %0.3f” % metrics.adjusted_rand_score(labels_true, labels))print(“Adjusted Mutual Information: %0.3f” % metrics.adjusted_mutual_info_score(labels_true, labels))print(“Silhouette Coefficient: %0.3f” % metrics.silhouette_score(X, labels, metric=’sqeuclidean’)) ############################################################################## Plot resultimport matplotlib.pyplot as pltfrom itertools import cycle plt.close(‘all’)plt.figure(1)plt.clf() colors = cycle(‘bgrcmykbgrcmykbgrcmykbgrcmyk’)for k, col in zip(range(nclusters), colors): class_members = labels == k cluster_center = X[cluster_centers_indices[k]] plt.plot(X[class_members, 0], X[class_members, 1], col + ‘.’) plt.plot(cluster_center[0], cluster_center[1], ‘o’, markerfacecolor=col, markeredgecolor=’k’, markersize=14) for x in X[class_members]: plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col) plt.title(‘Estimated number of clusters: %d’ % nclusters)plt.show() 参考链接http://scikit-learn.org/stable/modules/clustering.htmlhttp://blog.csdn.net/u010695420/article/details/42239465 聚类算法Affinity Propagation(AP) Affinity Propagation聚类算法简称AP，是一个在07年发表在Science上面比较新的算法。 AP算法的基本思想是将全部样本看作网络的节点，然后通过网络中各条边的消息传递计算出各样本的聚类中心。聚类过程中，共有两种消息在各节点间传递，分别是吸引度( responsibility)和归属度(availability) 。AP算法通过迭代过程不断更新每一个点的吸引度和归属度值，直到产生m个高质量的Exemplar（类似于质心），同时将其余的数据点分配到相应的聚类中。 在AP算法中有一些特殊名词： Exemplar：指的是聚类中心，K-Means中的质心。Similarity：数据点i和点j的相似度记为s(i, j)，是指点j作为点i的聚类中心的相似度。一般使用欧氏距离来计算，一般点与点的相似度值全部取为负值；因此，相似度值越大说明点与点的距离越近，便于后面的比较计算。Preference：数据点i的参考度称为p(i)或s(i,i)，是指点i作为聚类中心的参考度。一般取s相似度值的中值。Responsibility：r(i,k)用来描述点k适合作为数据点i的聚类中心的程度。Availability：a(i,k)用来描述点i选择点k作为其聚类中心的适合程度。Damping factor(阻尼系数)：主要是起收敛作用的。在实际计算应用中，最重要的两个参数（也是需要手动指定）是Preference和Damping factor。前者定了聚类数量的多少，值越大聚类数量越多；后者控制算法收敛效果。 AP聚类算法与经典的K-Means聚类算法相比，具有很多独特之处： 无需指定聚类“数量”参数。AP聚类不需要指定K（经典的K-Means）或者是其他描述聚类个数（SOM中的网络结构和规模）的参数，这使得先验经验成为应用的非必需条件，人群应用范围增加。明确的质心（聚类中心点）。样本中的所有数据点都可能成为AP算法中的质心，叫做Examplar，而不是由多个数据点求平均而得到的聚类中心（如K-Means）。对距离矩阵的对称性没要求。AP通过输入相似度矩阵来启动算法，因此允许数据呈非对称，数据适用范围非常大。初始值不敏感。多次执行AP聚类算法，得到的结果是完全一样的，即不需要进行随机选取初值步骤（还是对比K-Means的随机初始值）。算法复杂度较高，为O(NNlogN)，而K-Means只是O(N*K)的复杂度。因此当N比较大时(N&gt;3000)，AP聚类算法往往需要算很久。若以误差平方和来衡量算法间的优劣，AP聚类比其他方法的误差平方和都要低。（无论k-center clustering重复多少次，都达不到AP那么低的误差平方和）AP算法相对K-Means鲁棒性强且准确度较高，但没有任何一个算法是完美的，AP聚类算法也不例外： AP聚类应用中需要手动指定Preference和Damping factor，这其实是原有的聚类“数量”控制的变体。算法较慢。由于AP算法复杂度较高，运行时间相对K-Means长，这会使得尤其在海量数据下运行时耗费的时间很多。以下使用Python的机器学习库SKlearn应用AP（AffinityPropagation）算法进行案例演示。 案例中，我们会先对AP算法和K-Means聚类算法的运行时间做下对比，分别选取100,500,1000样本量下进行两种算法的聚类时间对比；然后，使用AP算法做聚类分析。 AP和K-Means运行时间对比 #coding:utf-8 import numpy as npimport matplotlib.pyplot as pltimport timefrom sklearn.cluster import KMeans,AffinityPropagationfrom sklearn.datasets.samples_generator import make_blobs 生成测试数据np.random.seed(0)centers = [[1, 1], [-1, -1], [1, -1]]kmeans_time = []ap_time = []for n in [100,500,1000]: X, labels_true = make_blobs(n_samples=n, centers=centers, cluster_std=0.7) # 计算K-Means算法时间 k_means = KMeans(init=&apos;k-means++&apos;, n_clusters=3, n_init=10) t0 = time.time() k_means.fit(X) kmeans_time.append([n,(time.time() - t0)]) # 计算AP算法时间 ap = AffinityPropagation() t0 = time.time() ap.fit(X) ap_time.append([n,(time.time() - t0)]) print (‘K-Means time’,kmeans_time[:10])print (‘AP time’,ap_time[:10]) 图形展示km_mat = np.array(kmeans_time)ap_mat = np.array(ap_time)plt.figure()plt.bar(np.arange(3), km_mat[:,1], width = 0.3, color = ‘b’, label = ‘K-Means’, log = ‘True’)plt.bar(np.arange(3)+0.3, ap_mat[:,1], width = 0.3, color = ‘g’, label = ‘AffinityPropagation’, log = ‘True’)plt.xlabel(‘Sample Number’)plt.ylabel(‘Computing time’)plt.title(‘K-Means and AffinityPropagation computing time ‘)plt.legend(loc=’upper center’)plt.show() 运算结果如下：bars11 (‘K-Means time’, [[100, 0.029999971389770508], [500, 0.029999971389770508], [1000, 0.0410001277923584]])(‘AP time’, [[100, 0.03000020980834961], [500, 1.8999998569488525], [1000, 16.31499981880188]]) 图中为了更好的展示数据对比，已经对时间进行log处理，但可以从输出结果直接读取真实数据运算时间。由结果可以看到：当样本量为100时，AP的速度要大于K_Means；当数据增加到500甚至1000时，AP算法的运算时间要大大超过K-Means算法；甚至当我试图运算更大的数据量（100000）时，直接内存错误而被迫中止。 AP聚类示例 #coding:utf-8 from sklearn.cluster import AffinityPropagationfrom sklearn import metricsfrom sklearn.datasets.samples_generator import make_blobsimport numpy as np 生成测试数据centers = [[1, 1], [-1, -1], [1, -1]]X, labels_true = make_blobs(n_samples=300, centers=centers, cluster_std=0.5, random_state=0) AP模型拟合af = AffinityPropagation(preference=-50).fit(X)cluster_centers_indices = af.cluster_centersindiceslabels = af.labels_new_X = np.column_stack((X, labels)) nclusters = len(cluster_centers_indices) print(‘Estimated number of clusters: %d’ % nclusters)print(“Homogeneity: %0.3f” % metrics.homogeneity_score(labels_true, labels))print(“Completeness: %0.3f” % metrics.completeness_score(labels_true, labels))print(“V-measure: %0.3f” % metrics.v_measure_score(labels_true, labels))print(“Adjusted Rand Index: %0.3f” % metrics.adjusted_rand_score(labels_true, labels))print(“Adjusted Mutual Information: %0.3f” % metrics.adjusted_mutual_info_score(labels_true, labels))print(“Silhouette Coefficient: %0.3f” % metrics.silhouette_score(X, labels, metric=’sqeuclidean’))print(‘Top 10 sapmles:’,new_X[:10]) 图形展示import matplotlib.pyplot as pltfrom itertools import cycle plt.close(‘all’)plt.figure(1)plt.clf() colors = cycle(‘bgrcmykbgrcmykbgrcmykbgrcmyk’)for k, col in zip(range(nclusters), colors): class_members = labels == k cluster_center = X[cluster_centers_indices[k]] plt.plot(X[class_members, 0], X[class_members, 1], col + ‘.’) plt.plot(cluster_center[0], cluster_center[1], ‘o’, markerfacecolor=col, markeredgecolor=’k’, markersize=14) for x in X[class_members]: plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col) plt.title(‘Estimated number of clusters: %d’ % nclusters)plt.show() 运行结果：ap_clustering1111 Estimated number of clusters: 3Homogeneity: 0.872Completeness: 0.872V-measure: 0.872Adjusted Rand Index: 0.912Adjusted Mutual Information: 0.871Silhouette Coefficient: 0.753(‘Top 10 sapmles:’, array([[ 1.47504421, 0.9243214 , 0. ], [-0.02204385, -0.80495334, 1. ], [-1.17671587, -1.80823709, 2. ], [ 0.77223375, 1.00873958, 0. ], [ 1.23283122, 0.23187816, 0. ], [-0.92174673, -0.88390948, 2. ], [ 1.65956844, -1.44120941, 1. ], [ 0.33389417, -1.98431234, 1. ], [-1.27143074, -0.79197498, 2. ], [ 1.33614738, 1.20373092, 0. ]])) AffinityPropagation可配置的参数包括：（重点是damping和preference） class sklearn.cluster.AffinityPropagation(damping=0.5, max_iter=200, convergence_iter=15, copy=True, preference=None, affinity=’euclidean’, verbose=False) AP算法的应用场景： 图像、文本、生物信息学、人脸识别、基因发现、搜索最优航线、 码书设计以及实物图像识别等领域。 尾巴 综合来看，由于AP算法不适用均值做质心计算规则，因此对于离群点和异常值不敏感；同时其初始值不敏感的特性也能保持模型的较好鲁棒性。这两个突出特征使得它可以作为K-Means算法的一个有效补充，但在大数据量下的耗时过长，这导致它的适用范围只能是少量数据；虽然通过调整damping（收敛规则）可以在一定程度上提升运行速度（damping值调小），但由于算法本身的局限性决定了这也只是杯水车薪。聚类算法Affinity Propagation(AP)","tags":""},{"title":"LDA 以及 Gensim 实现","url":"/2016/05/18/Gensim-and-LDA-Training-and-Prediction/","text":"用 Gensim 实现 LDA，相比 JGibbLDA 的使用 Gensim 略为麻烦，然而感觉更清晰易懂，也就更灵活。 LDA 介绍LDA 是一种典型的词袋模型，即一篇文档是由一组词构成，词与词之间没有顺序以及先后的关系。一篇文档可以包含多个主题，文档中每一个词都由其中的一个主题生成。 需要理解的概念有： 一个函数：gamma 函数 两个分布：beta分布、Dirichlet分布 一个模型：LDA（文档-主题，主题-词语） 一个采样：Gibbs采样 核心公式：1p(w|d) = p(w|t)*p(t|d) 文档的生成过程 从狄利克雷分布中取样生成文档 i 的主题分布 $\\theta_i$ 从主题的多项式分布中取样生成文档i第 j 个词的主题 $z_{i,j}$ 从狄利克雷分布中取样生成主题对应的词语分布 $\\varnothing_{z_{i,j}}$ 从词语的多项式分布 $\\varnothing_{z_{i,j}}$ 中采样最终生成词语 $w_{i,j}$ 怎么选择 topic 个数 最小化 topic 的相似度 perplexity Python gensim 实现 # install the related python packages >>> pip install numpy >>> pip install scipy >>> pip install gensim >>> pip install jieba from gensim import corpora, models, similarities import logging import jieba # configuration logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # load data from file f = open('newfile.txt', 'r') documents = f.readlines() ＃ tokenize texts = [[word for word in jieba.cut(document, cut_all = False)] for document in documents] # load id->word mapping (the dictionary) dictionary = corpora.Dictionary(texts) # word must appear >10 times, and no more than 40% documents dictionary.filter_extremes(no_below=40, no_above=0.1) # save dictionary dictionary.save('dict_v1.dict') # load corpus corpus = [dictionary.doc2bow(text) for text in texts] # initialize a model tfidf = models.TfidfModel(corpus) # use the model to transform vectors, apply a transformation to a whole corpus corpus_tfidf = tfidf[corpus] # extract 100 LDA topics, using 1 pass and updating once every 1 chunk (10,000 documents), using 500 iterations lda = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=100, iterations=500) # save model to files lda.save('mylda_v1.pkl') # print topics composition, and their scores, for the first document. You will see that only few topics are represented; the others have a nil score. for index, score in sorted(lda[corpus_tfidf[0]], key=lambda tup: -1*tup[1]): print \"Score: {}\\t Topic: {}\".format(score, lda.print_topic(index, 10)) # print the most contributing words for 100 randomly selected topics lda.print_topics(100) # load model and dictionary model = models.LdaModel.load('mylda_v1.pkl') dictionary = corpora.Dictionary.load('dict_v1.dict') # predict unseen data query = \"未收到奖励\" query_bow = dictionary.doc2bow(jieba.cut(query, cut_all = False)) for index, score in sorted(model[query_bow], key=lambda tup: -1*tup[1]): print \"Score: {}\\t Topic: {}\".format(score, model.print_topic(index, 20)) # if you want to predict many lines of data in a file, do the followings f = open('newfile.txt', 'r') documents = f.readlines() texts = [[word for word in jieba.cut(document, cut_all = False)] for document in documents] corpus = [dictionary.doc2bow(text) for text in texts] # only print the topic with the highest score for c in corpus: flag = True for index, score in sorted(model[c], key=lambda tup: -1*tup[1]): if flag: print \"Score: {}\\t Topic: {}\".format(score, model.print_topic(index, 20)) TipsIf you occur encoding problems, you can try the following code add it at the beginning of your python file # -*- coding: utf-8 -*- # also, do the followings import sys reload(sys) sys.setdefaultencoding('utf-8') # the following code may lead to encoding problem when there're Chinese characters model.show_topics(-1, 5) # use this instead model.print_topics(-1, 5) You can see step-by-step output by the following references. References: https://radimrehurek.com/gensim/tut2.html official guide (en) http://blog.csdn.net/questionfish/article/details/46725475 official guide (ch) https://radimrehurek.com/gensim/wiki.html#latent-dirichlet-allocation","tags":"machine-learning"},{"title":"Gensim-用Python做主题模型","url":"/2016/05/18/Gensim-用Python做主题模型/","text":"gensim 介绍gemsim是一个免费python库，能够从文档中有效地自动抽取语义主题。gensim中的算法包括：LSA(Latent Semantic Analysis), LDA(Latent Dirichlet Allocation), RP (Random Projections), 通过在一个训练文档语料库中，检查词汇统计联合出现模式, 可以用来发掘文档语义结构，这些算法属于非监督学习，可以处理原始的，非结构化的文本（”plain text”）。 gensim 特性 内存独立- 对于训练语料来说，没必要在任何时间将整个语料都驻留在RAM中 有效实现了许多流行的向量空间算法－包括tf-idf，分布式LSA, 分布式LDA 以及 RP；并且很容易添加新算法 对流行的数据格式进行了IO封装和转换 在其语义表达中，可以相似查询 gensim的创建的目的是，由于缺乏简单的（java很复杂）实现主题建模的可扩展软件框架. gensim 设计原则 简单的接口，学习曲线低。对于原型实现很方便 根据输入的语料的size来说，内存各自独立；基于流的算法操作，一次访问一个文档. gensim 核心概念gensim的整个package会涉及三个概念：corpus, vector, model. 语库(corpus)文档集合，用于自动推出文档结构，以及它们的主题等，也可称作训练语料。 向量(vector) 在向量空间模型(VSM)中，每个文档被表示成一个特征数组。例如，一个单一特征可以被表示成一个问答对(question-answer pair): [1].在文档中单词”splonge”出现的次数？ 0个[2].文档中包含了多少句子？ 2个[3].文档中使用了多少字体? 5种这里的问题可以表示成整型id (比如：1,2,3等), 因此，上面的文档可以表示成：(1, 0.0), (2, 2.0), (3, 5.0). 如果我们事先知道所有的问题，我们可以显式地写成这样：(0.0, 2.0, 5.0). 这个answer序列可以认为是一个多维矩阵（3维）. 对于实际目的，只有question对应的answer是一个实数. 对于每个文档来说，answer是类似的. 因而，对于两个向量来说（分别表示两个文档），我们希望可以下类似的结论：“如果两个向量中的实数是相似的，那么，原始的文档也可以认为是相似的”。当然，这样的结论依赖于我们如何去选取我们的question。 稀疏矩阵(Sparse vector) 通常，大多数answer的值都是0.0. 为了节省空间，我们需要从文档表示中忽略它们，只需要写：(2, 2.0), (3, 5.0) 即可(注意：这里忽略了(1, 0.0)). 由于所有的问题集事先都知道，那么在稀疏矩阵的文档表示中所有缺失的特性可以认为都是0.0. gensim的特别之处在于，它没有限定任何特定的语料格式；语料可以是任何格式，当迭代时，通过稀疏矩阵来完成即可。例如，集合 ([(2, 2.0), (3, 5.0)], ([0, -1.0], [3, -1.0])) 是一个包含两个文档的语料，每个都有两个非零的 pair。 模型(model) 对于我们来说，一个模型就是一个变换(transformation)，将一种文档表示转换成另一种。初始和目标表示都是向量－－它们只在question和answer之间有区别。这个变换可以通过训练的语料进行自动学习，无需人工监督，最终的文档表示将更加紧凑和有用；相似的文档具有相似的表示。 演示代码演示代码 参考链接 http://d0evi1.github.io/gensim/","tags":"machine-learning lda gensim topic-modeling cluster"},{"title":"JGibbLDA实战","url":"/2016/05/16/JGibbLDA实战/","text":"尝试了下JGibbLDA，发现按官方教程用以下命令直接运行jar包会出现错误。 错误命令： java -mx512M -cp bin:lib/args4j-2.0.6.jar jgibblda.LDA -est -alpha 0.5 -beta 0.1 -ntopics 100 -niters 1000 -savestep 100 -twords 20 -dfile models/casestudy/newdocs.dat 错误信息： 手动配置于是尝试导入eclipse运行手动配置，成功，过程如下。 下载JGibbLDA的jar包并解压；网址：http://jgibblda.sourceforge.net/#Griffiths04 导入eclipse，确保jar包在目录中 找到LDACmdOption.java文件， 修改部分代码 @Option(name=\"-dir\", usage=\"Specify directory\") public String dir = \"models/casestudy-en\"; @Option(name=\"-dfile\", usage=\"Specify data file\") public String dfile = \"models/casestudy-en/newdocs.dat\"; 值得注意的是，dfile的格式必须是👇这个样子： [M] [document1] [document2] ... [documentM] 第一行[M]是documents的总数，之后的每一行是一个document，每个document是一个word list，或者说是bag of words。 [document i] = [word i1] [word i2] ... [word iNi] 各参数含义：-est 从训练语料中评估出LDA模型-alpha LDA模型中的alpha数值，默认为50/K(K是主题数目)-beta LDA模型中的beta数值，默认是0.1-ntopics 主题数目，默认值是100-niters GIbbs采样的迭代数目，默认值为2000-savestep 指定开始保存LDA模型的迭代次数-dir 训练语料目录-dfile 训练语料文件名称 修改项目的Run Configurations，在Java Application中选择LDA，点击(x)=Arguments，输入 -est -alpha 0.2 -beta 0.1 -ntopics 100 -niters 1000 -savestep 100 -twords 100 -dir Users\\x\\MyEclipse1\\JGibbLDA-v.1.0\\models\\casestudy-en -dfile \"newdocs.dat\" 若利用已训练的LDA模型预测，输入以下参数： -inf -dir Users\\x\\MyEclipse1\\JGibbLDA-v.1.0\\models\\casestudy-en -dfile \"test.txt\" 注意，进行预测时，当前目录下必须包含已有的LDA训练输出文件，包括model-final.others、model-final.phi、model-final.tassign、model-final.theta、model-final.twords、wordmap.txt文件，如果运行报错，尝试修改LDACmdOption.java的modelName，确保和文件名的modelname部分一致。@Option(name=”-model”, usage=”Specify the model name”) public String modelName = “model-final”; 如果出现java heap limited的问题，在VM arguments下添加 -Xms1g -Xmx1g -Xmn512m Run输出文件主要有：.others 文件存储LDA模型参数，如alpha、beta等。.phi 每个topic内对doc的分布情况。文件存储词语-主题分布，每一行是一个主题，列内容为词语。.theta 每个doc内对应上面的n个topic的分布情况。文件主题文档分布，每一行是一个文档，列内容是主题概率。.tassign 文件是训练预料中单词的主题指定（归属），每一行是一个语料文档。.twords n个topic，以及每个topic下面包含的具体的字词wordmap.txt 词-id映射其中根据采样迭代次数来指定，如model-00800，最后一次采样名称命名为model-final。 参考链接：http://www.ithao123.cn/content-4208214.htmlhttp://jgibblda.sourceforge.net/","tags":"machine-learning lda topic-modeling cluster"},{"title":"让百度、google收录博客","url":"/2016/05/13/让百度、google收录博客/","text":"github 封了百度爬虫，因此百度索引不到我们在 github 上搭的博客（想知道自己的博客是否被索引可以这样查询，在搜索引擎中输入：site: 博客域名）解决github屏蔽百度爬虫的思路就是“迁出”我们的博客，让百度爬虫不直接访问github就行了。建议看这篇文章先进行尝试，若不行，尝试本文所用方法。 百度收录让百度收录的第一问题是解决封禁，方案是迁出博客，让百度爬虫不直接访问 github. 注册域名在godaddy注册并申请一个域名。55元／年。 域名备案？no!以下情况需要备案 在国内申请的域名，如万网等服务商 凡是在中国大陆境内购买服务器的用户需备案，即你的网站空间在国内。 但是！如果申请自国外服务商，如 Godaddy ，网站内容托管在国外服务商，如github或者买的国外的虚拟主机，那么你不需要备案！！这也就意味着，如果你想搭建个博客站点，还不想捣鼓这麻烦的备案流程，那么你唯一的做法就是，在国外服务商申请域名+购买国外的空间（或者使用国外免费的空间如github托管静态站点） 将博客托管至Coding平台注册Coding账户并建立项目去Coding 官网注册，并新建一个和账户名相同的账户。 设置ssh在Coding的个人主页的账户中，进入SSH公钥，添加你的公钥。（在本机 .ssh 目录下找到 id_rsa.pub，复制里面的内容在SSH-RSA公钥内容中即可。） 输入 ssh -T git@git.coding.net 进行测试，如果显示如下则SSH配置成功： Hello ...! You've conected to Coding.net by SSH successfully! 修改网站配置文件在你的 blog 根目录下的配置文件_config.yml，找到deploy的设置处，改为如下： deploy: type: git repo: github: git@github.com:XXXXXXXXXXXXXXXXXXXXXXXXXXXX coding: git@git.coding.net:XXXXXXXXXXXXXXXXXXXXXXXXX,master 注意要改成你的项目地址。 ### 将网站文件部署至Coding 在你的 github page 根目录下运行 hexo g -d 成功之后，进入你的Coding对应的项目中应该能看到网站文件。 配置Coding的Page服务进入你在Coding上的项目，点击左侧的代码可以看到Coding Pages服务。输入分支为master，点击开启服务。在自定义域名处填上你的网站域名。如图&lt;–&gt; 配置DNS在Godaddy注册商域名修改DNS地址。登录godaddy 按 dnspod 要求更改 nameserver。 在dnspod进行网站的 dns 设置。将国内线路设置为CNAME的 pages.coding.me。之后就可以打开自己的域名啦～ github 也可以绑定域名。在本地网站根目录下的source文件夹下，新建一个文件名为CNAME的文件（无后缀名），填写你所绑定的域名地址，如 www.shuang0420.com，然后 generate &amp; deploy，就成功绑定域名啦。 如图 让百度收录用 百度站长工具 的抓取诊断功能看是能进行抓取。百度输入 site:www.shuang0420.com 检验。 google 收录google 收录就比较简单。 添加站点并验证用自己的google帐号登陆 Webmaster Central，添加站点并验证。 将验证文件放到 source 文件下，在站点配置文件中加入 skip_render: googled6054e120f1a1419.html 产生 sitemap使用插件 hexo-generator-sitemap 能生成站点地图, 方法如下 $ npm install hexo-generator-sitemap --save 然后在 Hexo 根目录下的 config.yml 里配置一下 sitemap: path: sitemap.xml path 表示 Sitemap 的路径. 默认为 sitemap.xml. 然后重新生成 hexo g 添加 sitemap用 google 站长工具，在 抓取——站点地图 中就能看到 添加/测试站点地图，添加 sitemap.xml 即可。 参考链接如何将博客托管至Coding及相应的DNS设置","tags":"hexo"},{"title":"gollum/-github上搭建个人wiki","url":"/2016/05/13/gollum:-github上搭建个人wiki/","text":"博客凸显创作，维基则是整理的好工具，很多入门级别、复用别人的操作，如配置环境等，更适合发布在个人维基上，本文就以gollum+github搭建个人wiki做个示范。 开通Wiki登陆Github，找到你所开通的Github项目的Settings栏目，开通Wikis，如果只希望别人可读不可写，勾选：Restrict edits to Collaborators only。如下图所示： git clone 相应维基的git地址 git clone git@github.com:Shuang0420/Shuang0420.github.io.wiki.git wiki 如果你之前没有设置git密钥，可以参照以下步骤先做配置，如果已经设置，请忽略。 查看是否已经有了ssh密钥：cd ~/.ssh如果没有密钥则不会有此文件夹，有则备份删除 生成密钥，得到两个文件：id_rsa 和 id_rsa.pub ssh-keygen -t rsa -C “haiyan.xu.vip@gmail.com” 添加密钥到ssh：ssh-add id_rsa 在github上settings中添加ssh密钥，即“id_rsa.pub”里的公钥。 测试：ssh git@github.com 配置个人wiki 在wiki目录下，安装bundler gem install bundler 如果安装没有问题，可以跳过以下错误解决。 ERROR: Could not find a valid gem 'bundler' (>= 0), here is why: Unable to download data from https://rubygems.org/ - Errno::EPIPE: Broken pipe - SSL_connect (https://rubygems.org/latest_specs.4.8.gz) 解决： gem source -a http://rubygems.org/ gem install bundler 然而还是有错误： Fetching: bundler-1.12.5.gem (100%)^[[A ERROR: While executing gem ... (Gem::FilePermissionError) You don't have write permissions for the /Library/Ruby/Gems/2.0.0 directory. 因为没有sudo： sudo gem install bundler 新建Gemfile文件，内容如下： source \"http://rubygems.org\" gem 'redcarpet' gem \"grit\", '~> 2.5.0', git: 'https://github.com/gitlabhq/grit.git', ref: '42297cdcee16284d2e4eff23d41377f52fc28b9d' gem 'gollum', git: 'https://github.com/gollum/gollum.git' 运行： # 安装项目依赖的所有gem包;此命令会尝试更新系统中已存在的gem包 bundle install 时间有点久，耐心等待。 然而最后出现error, An error occurred while installing charlock_holmes (0.7.3), and Bundler cannot continue. Make sure that `gem install charlock_holmes -v '0.7.3'` succeeds before bundling. 好。那就按要求安装。 sudo gem install charlock_holmes -v '0.7.3' 好。继续按要求安装。 brew install icu4c 再重来 sudo gem install charlock_holmes -v '0.7.3' bundle install 因为没有安装bundle gem install bundle 安装后再次尝试运行 bundle install error Could not reach host index.rubygems.org. Check your network connection and try again. 出现这种错误可以尝试把Gemfile里的https改成http（互相转化进行尝试） bundle install 终于成功！ 已安装成功gollum等。然后运行： gollum 走到这一步了本人还是遇到了万恶的失败。 看着已经安装好了 Installing nokogiri 1.6.7.2 with native extensions Installing rack-protection 1.5.3 Installing gollum-grit_adapter 1.0.1 Installing sanitize 2.1.0 Installing sinatra 1.4.7 Installing gollum-lib 4.2.0 Using gollum 4.0.1 from https://github.com/gollum/gollum.git (at master@5a5e56a) Bundle complete! 3 Gemfile dependencies, 24 gems now installed. Use `bundle show [gemname]` to see where a bundled gem is installed. 然而实际并没有 $ gollum -bash: gollum: command not found 大写的忧伤。最后通过直接安装gollum解决。 sudo gem install gollum gollum 终于可以在本地启动成功维基。打开网址：http://0.0.0.0:4567/，可以直接在浏览器中编辑。 如果发现不能如下错误，请尝试更新ruby。 更新ruby步骤 安装 RVM RVM:Ruby Version Manager,Ruby版本管理器，包括Ruby的版本管理和Gem库管理(gemset) curl -L get.rvm.io | bash -s stable source ~/.bashrc source ~/.bash_profile 测试是否安装正常 rvm -v 用RVM升级Ruby #查看当前ruby版本 ruby -v #列出已知的ruby版本 rvm list known #安装ruby 2.3.0 rvm install 2.3.0 安装完成之后ruby -v查看是否安装成功。 重新安装完毕后回到第3步。 github同步在wiki目录下面，进行git库操作，提交本地对维基内容的修改。一切将自动保存在你的Github上的个人博客网站的wiki目录下面。 cd ~/wiki git add . git commit -am\"first commit\" git push","tags":"wiki"},{"title":"Hexo 主题配置","url":"/2016/05/12/Github-Pages-Hexo主题配置/","text":"终于搭建完自己的博客站点啦，好有成就感✌️分享一些本站使用的 NexT 主题配置技巧。 添加“标签”页面在终端窗口下，定位到 Hexo 站点目录下，新建一个页面，命名为 tags ： $ cd your-hexo-site $ hexo new page tags 注意：如果有启用 多说 或者 Disqus 评论，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false，如： title: 标签 date: 2014-12-22 12:39:04 type: \"tags\" comments: false 在菜单中添加链接。编辑 主题配置文件 ， 添加 tags 到 menu 中，如下: menu: home: / archives: /archives tags: /tags 添加“分类”页面在终端窗口下，定位到 Hexo 站点目录下，新建一个页面，命名为 categories ： $ cd your-hexo-site $ hexo new page categories 注意：如果有启用 多说 或者 Disqus 评论，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false，如： title: 分类 date: 2014-12-22 12:39:04 type: \"categories\" comments: false 在菜单中添加链接。编辑 主题配置文件 ， 添加 categories 到 menu 中，如下: menu: home: / archives: /archives categories : /categories 添加其它菜单页面与添加分类、标签页面步骤相同，但还需要加一步，在主题文件夹下的 languages 文件夹中找到你使用的语言文件，打开后，在 menu 下新增刚刚添加的页面。否则在主页中显示的新页面是 Menu.xxx 形式而不是 xxx。 评论系统感觉 DISUQS 比 多说 的设置简单一些。在 https://disqus.com/ 按要求注册，完成后在 admin/settings/general/ 下找到 Shortname。编辑 站点配置文件， 添加 disqus_shortname 字段，设置如下： disqus_shortname: your-disqus-shortname 设置 RSS安装 hexo-generator-feed，在站点的根目录下执行以下命令： $ npm install hexo-generator-feed --save 更改 主题配置文件，设定 rss 字段的值，留空表示使用 Hexo 生成的 Feed 链接。 访问量统计编辑 主题配置文件 中的 busuanzi_count 的配置项。当enable: true时，代表开启全局开关。若site_uv、site_pv、page_pv的值均为false时，不蒜子仅作记录而不会在页面上显示。 搜索服务常用的是 local search 和 swiftype，local search，配置简单，但是个人试验可以搜内容，但无法跳转页面，swiftype 没有这种问题。Local search安装 hexo-generator-search，在站点的根目录下执行以下命令： $ npm install hexo-generator-search --save 编辑 站点配置文件，新增以下内容到任意位置： search: path: search.xml field: post Swiftype 前往 Swiftype 注册页面，注册一个新账户。 注册完成后，创建一个新的搜索引擎(create a search engine)，并按照提示完成创建步骤。 搜索引擎创建完成后，在菜单中选择 Integrate -&gt; Install Search 开启搜索定制，按照步骤完成定制。最后一步记得点击 Active 按钮。 返回定制引擎的第二个步骤 INSTALL CODE，复制出你的 swiftype_key,也就是下面的”xxxxxxxxx”部分。 12345678&lt;script type=&quot;text/javascript&quot;&gt; (function(w,d,t,u,n,s,e)&#123;w[&apos;SwiftypeObject&apos;]=n;w[n]=w[n]||function()&#123; (w[n].q=w[n].q||[]).push(arguments);&#125;;s=d.createElement(t); e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e); &#125;)(window,document,&apos;script&apos;,&apos;//s.swiftypecdn.com/install/v2/st.js&apos;,&apos;_st&apos;); _st(&apos;install&apos;,&apos;xxxxxxxxx&apos;,&apos;2.0.0&apos;);&lt;/script&gt; 编辑 站点配置文件， 新增字段 swiftype_key，值设置成第四步中赋值出来的 key # Swiftype Search Key swiftype_key: xxxxxxxxx 开启打赏功能只需要在 主题配置文件 中填入 微信 和 支付宝 收款二维码图片地址 即可开启该功能。 reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！ wechatpay: /path/to/wechat-reward-image alipay: /path/to/alipay-reward-image 设置阅读全文在首页显示一篇文章的部分内容，并提供一个链接跳转到全文页面是一个常见的需求。 NexT 提供三种方式来控制文章在首页的显示方式。 也就是说，在首页显示文章的摘录并显示 阅读全文 按钮，可以通过以下方法： 在文章中使用 手动进行截断，这是 Hexo 提供的方式，推荐使用。在文章的 front-matter 中添加 description，并提供文章摘录自动形成摘要，在 主题配置文件 中添加： auto_excerpt: enable: true length: 150 默认截取的长度为 150 字符，可以根据需要自行设定 MathJax只讲一种简单的方法 － 插件。安装 $ npm install hexo-math --save 在 Hexo 文件夹中执行： $ hexo math install 在 config.yml 文件中添加： plugins: hexo-math 对于不含特殊符号的公式，可以直接使用 MathJax 的 inline math 表达式. 如果含有特殊符号，则需要人肉 escape，如 \\ 之类的特殊符号在 LaTex 表达式中出现频率很高，这样就很麻烦，使用 tag 能够省不少事。 具体用法见 Hexo MathJax插件.MathJax用法总结 插入本地图片 更改站点配置文件 config.yml post_asset_folder: true 在hexo 目录中执行 npm install https://github.com/CodeFalling/hexo-asset-image --save 新建博客，在 post 中会生成一个和博客名相同的文件夹和一个 .md 文件 hexo new \"newblog\" 把图片放入文件夹，在 .md 文件中使用 1&#123;% imgurl Github-Pages-Hexo%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE/newblog/pict.jpg ful-image alt:newblog/pict.jpg %&#125; 整理自 NexT 使用文档","tags":"hexo"},{"title":"Github Pages+Hexo搭建个人博客","url":"/2016/05/12/Github-Pages-Hexo搭建个人博客/","text":"一直想有个美美的博客，CSDN实在无法满足。看了一些大神的 github 博客，非常艳羡，自己学着搭了个，看在它这么好看的份上，我也会坚持写写写！ 为什么用Github Pages + HexoGithub Page优点 轻量级的博客系统，没有麻烦的配置 使用标记语言，比如Markdown 无需自己搭建服务器 根据Github的限制，对应的每个站有300MB空间 可以绑定自己的域名 Github Page有两种page模式，User/Organization Pages（个人或公司站点）和Project Pages（项目站点）。这里我们用的是user/Organization Pages，要求使用自己的用户名，每个用户名下面只能建立一个，资源命名必须符合这样的规则username/username.github.com，主干上内容被用来构建和发布页面 Hexo优点 用于搭建博客网站框架，可以简单实现优美的博客网站; 在本地端搭建，就可脱机查阅; 架构不依托于其他门户网站，不再担心门户网站倒闭，不担心博文丢失或难以导出; 博文为markdown格式，通用，容易上手，便于快速书写; 可部署在github上； 创造者来自中国台湾，所以几乎所有模板都关注到了中文的兼容性，很适合使用汉语的码农。 搭建步骤新建github repository在github上新建repository，name为username.github.io。 Hexo安装先安装git和node.js brew install git brew install node 验证是否安装成功 node -v npm -v 安装Hexo npm install -g hexo #-g表示全局安装, npm默认为当前项目安装 Hexo部署新建文件夹并打开，在文件夹内操作。 hexo init #新建博客目录 hexo g #根据当前目录下文件生成静态网页 hexo s #启动服务器 现在就可以到浏览器输入localhost:4000查看啦。 简单介绍一下文件目录 public：执行hexo generate命令，输出的静态网页内容目录 scaffolds：layout模板文件目录，其中的md文件可以添加编辑 scripts：扩展脚本目录，这里可以自定义一些javascript脚本 source：文章源码目录，该目录下的markdown和html文件均会被hexo处理。该页面对应repo的根目录，404文件、favicon.ico文件，CNAME文件等都应该放这里，该目录下可新建页面目录。 drafts：草稿文章 posts：发布文章themes：主题文件目录 config.yml：全局配置文件，大多数的设置都在这里 package.json：应用程序数据，指明hexo的版本等信息，类似于一般软件中的 关于 按钮 Hexo复制主题 hexo clean hexo g hexo s git clone https://github.com/cnfeat/cnfeat.git themes/jacman 启用主题修改Hexo目录下的config.yml配置文件中的theme属性，将其设置为jacman。 theme: jacman #或你的主题名，注意冒号后有一个空格 注意：Hexo有两个config.yml文件，一个在根目录，一个在theme下，此时修改的是在根目录下的。 更新主题 cd themes/jacman git pull 注意：为避免出错，请先备份你的_config.yml 文件后再升级 Hexo本地调试 hexo g #生成 hexo s #启动本地服务，进行文章预览调试 hexo d -g #或者直接作用组合命令 浏览器输入localhost:4000，即可查看搭建效果。每次变更config.yml 文件或者上传文件都可以先用此命令调试。 Hexo部署到githubnpm install hexo-deployer-git --save 在 Hexo 文件夹下找到 config.yml 文件, 找到其中的 deploy 标签，改成下图所示形式，并保存。注意：冒号后面要加上一个空格，否则会报错 deploy: type: git repo: https://github.com/Shuang0420/Shuang0420.github.io.git 运行如下命令： hexo clean hexo generate hexo deploy 发博文 hexo new \"postname\" #然后在posts目录下的postname.md文件中编辑博客 hexo clean hexo generate # (若要本地预览就先执行 hexo server) hexo deploy 快捷命令 hexo g == hexo generate hexo d == hexo deploy hexo s == hexo server hexo n == hexo new # 还能组合使用，如： hexo d -g 参考链接： http://mozhenhau.com/2015/03/05/%E5%9C%A8Mac%E9%80%9A%E8%BF%87Hexo%E5%9C%A8github%E4%B8%8A%E5%BB%BA%E7%AB%8B%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/ http://evakasch.github.io/2016/05/04/hexo-setup/","tags":"hexo"},{"title":"让进程在后台可靠运行的几种方法","url":"/2016/04/22/让进程在后台可靠运行的几种方法/","text":"当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。 nohup只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。同时可在结尾加上”&amp;”来将命令同时放入后台运行，也可用”&gt;filename 2&gt;&amp;1”来更改缺省的重定向文件名。 $ nohup ping www.ibm.com & [1] 6982 $ nohup: appending output to `nohup.out' $ ps -ef |grep www.ibm.com 501 6982 5823 0 4:23下午 ttys000 0:00.03 ping www.ibm.com 501 7120 5823 0 4:26下午 ttys000 0:00.01 grep www.ibm.com setsidnohup 能通过忽略 HUP 信号来使我们的进程避免中途被中断，换个角度思考，如果我们的进程不属于接受 HUP 信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。 $ setsid ping www.ibm.com $ ps -ef |grep www.ibm.com root 31094 1 0 07:28 ? 00:00:00 ping www.ibm.com root 31102 29217 0 07:29 pts/4 00:00:00 grep www.ibm.com 值得注意的是，上例中我们的进程 ID(PID)为31094，而它的父 ID（PPID）为1（即为 init 进程 ID），并不是当前终端的进程 ID。请将此例与nohup 例中的父 ID 做比较。 disown如果未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？ 用disown -h jobspec来使某个作业忽略HUP信号。 用disown -ah 来使所有的作业都忽略HUP信号。 用disown -rh 来使正在运行的作业忽略HUP信号。 需要注意的是，当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了”&amp;”来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用 CTRL-z（按住Ctrl键的同时按住z键）了！CTRL-z 的用途就是将当前进程挂起（Suspend），然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行。需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。 disown 示例1（如果提交命令时已经用“&amp;”将命令放入后台运行，则可以直接使用“disown”） $ cp -r testLargeFile largeFile & [1] 4825 $ jobs [1]+ Running cp -i -r testLargeFile largeFile & $ disown -h %1 $ ps -ef |grep largeFile root 4825 968 1 09:46 pts/4 00:00:00 cp -i -r testLargeFile largeFile root 4853 968 0 09:46 pts/4 00:00:00 grep largeFile $ logout disown 示例2（如果提交命令时未使用“&amp;”将命令放入后台运行，可使用 CTRL-z 和“bg”将其放入后台，再使用“disown”） $ cp -r testLargeFile largeFile2 [1]+ Stopped cp -i -r testLargeFile largeFile2 $ bg %1 [1]+ cp -i -r testLargeFile largeFile2 & $ jobs [1]+ Running cp -i -r testLargeFile largeFile2 & $ disown -h %1 $ ps -ef |grep largeFile2 root 5790 5577 1 10:04 pts/3 00:00:00 cp -i -r testLargeFile largeFile2 root 5824 5577 0 10:05 pts/3 00:00:00 grep largeFile2 screen如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。使用 screen 很方便，有以下几个常用选项： 用screen -dmS session name来建立一个处于断开模式下的会话（并指定其会话名）。 用screen -list 来列出所有会话。 用screen -r session name来重新连接指定会话。 用快捷键CTRL-a d 来暂时断开当前会话。 screen 示例 $ screen -dmS Urumchi $ screen -list There is a screen on: 12842.Urumchi (Detached) 1 Socket in /tmp/screens/S-root. $ screen -r Urumchi 当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。 未使用 screen 时新进程的进程树 $ ping www.google.com & [1] 9499 $ pstree -H 9499 init─┬─Xvnc ├─acpid ├─atd ├─2*[sendmail] ├─sshd─┬─sshd───bash───pstree │ └─sshd───bash───ping 我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。 使用了 screen 后新进程的进程树 $screen -r Urumchi $ ping www.ibm.com & [1] 9488 $ pstree -H 9488 init─┬─Xvnc ├─acpid ├─atd ├─screen───bash───ping ├─2*[sendmail] 而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。 参考链接http://www.ibm.com/developerworks/cn/linux/l-cn-nohup/","tags":"python c"},{"title":"python-jieba-分词----官方文档截取","url":"/2016/04/01/python-jieba-分词----官方文档截取/","text":"jieba“结巴”中文分词：做最好的 Python 中文分词组件 特点 支持三种分词模式： 精确模式，试图将句子最精确地切开，适合文本分析； 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义； 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。 支持繁体分词 支持自定义词典 安装说明代码对 Python 2/3 均兼容 全自动安装：easy_install jieba 或者 pip install jieba / pip3 install jieba 半自动安装：先下载 http://pypi.python.org/pypi/jieba/ ，解压后运行 python setup.py install 手动安装：将 jieba 目录放置于当前目录或者 site-packages 目录 通过 import jieba 来引用 算法 基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG) 采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合 对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法 主要功能分词jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用 jieba.lcut 以及 jieba.lcut_for_search 直接返回 listjieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。 代码示例 # encoding=utf-8 import jieba seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True) print(\"Full Mode: \" + \"/ \".join(seg_list)) # 全模式 seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False) print(\"Default Mode: \" + \"/ \".join(seg_list)) # 精确模式 seg_list = jieba.cut(\"他来到了网易杭研大厦\") # 默认是精确模式 print(\", \".join(seg_list)) seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\") # 搜索引擎模式 print(\", \".join(seg_list)) 输出: 【全模式】: 我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学 【精确模式】: 我/ 来到/ 北京/ 清华大学 【新词识别】：他, 来到, 了, 网易, 杭研, 大厦 (此处，“杭研”并没有在词典中，但是也被Viterbi算法识别出来了) 【搜索引擎模式】： 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造 添加自定义词典载入词典 开发者可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然 jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率用法： jieba.load_userdict(file_name) # file_name 为文件类对象或自定义词典的路径 词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。词频省略时使用自动计算的能保证分出该词的词频。 例如： 创新办 3 i云计算 5凱特琳 nz台中更改分词器（默认为 jieba.dt）的 tmp_dir 和 cache_file 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。 范例： 自定义词典：https://github.com/fxsjy/jieba/blob/master/test/userdict.txt 用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_userdict.py 之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 / 加载自定义词库后： 李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 / 调整词典 使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。 注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。 代码示例： >>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False))) 如果/放到/post/中将/出错/。 >>> jieba.suggest_freq(('中', '将'), True) 494 >>> print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False))) 如果/放到/post/中/将/出错/。 >>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False))) 「/台/中/」/正确/应该/不会/被/切开 >>> jieba.suggest_freq('台中', True) 69 >>> print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False))) 「/台中/」/正确/应该/不会/被/切开 \"通过用户自定义词典来增强歧义纠错能力\" --- https://github.com/fxsjy/jieba/issues/14 关键词提取基于 TF-IDF 算法的关键词抽取 import jieba.analyse jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=()) sentence 为待提取的文本topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20withWeight 为是否一并返回关键词权重值，默认值为 FalseallowPOS 仅包括指定词性的词，默认值为空，即不筛选jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 实例，idf_path 为 IDF 频率文件 代码示例 （关键词提取） https://github.com/fxsjy/jieba/blob/master/test/extract_tags.py 关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径 用法： jieba.analyse.set_idf_path(file_name) # file_name为自定义语料库的路径 自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/idf.txt.big用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_idfpath.py 关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径 用法： jieba.analyse.set_stop_words(file_name) # file_name为自定义语料库的路径 自定义语料库示例：https://github.com/fxsjy/jieba/blob/master/extra_dict/stop_words.txt用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_stop_words.py 关键词一并返回关键词权重值示例 用法示例：https://github.com/fxsjy/jieba/blob/master/test/extract_tags_with_weight.py 基于 TextRank 算法的关键词抽取 jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) #直接使用，接口相同，注意默认过滤词性。 jieba.analyse.TextRank() #新建自定义 TextRank 实例 算法论文： TextRank: Bringing Order into Texts 基本思想: 将待抽取关键词的文本进行分词 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图 计算图中节点的PageRank，注意是无向带权图 使用示例: 见 test/demo.py 词性标注jieba.posseg.POSTokenizer(tokenizer=None) 新建自定义分词器，tokenizer 参数可指定内部使用的 jieba.Tokenizer 分词器。jieba.posseg.dt 为默认词性标注分词器。标注句子分词后每个词的词性，采用和 ictclas 兼容的标记法。用法示例 >>> import jieba.posseg as pseg >>> words = pseg.cut(\"我爱北京天安门\") >>> for word, flag in words: ... print('%s %s' % (word, flag)) ... 我 r 爱 v 北京 ns 天安门 ns 并行分词原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows用法： jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数 jieba.disable_parallel() # 关闭并行分词模式 例子：https://github.com/fxsjy/jieba/blob/master/test/parallel/test_file.py 实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。 注意：并行分词仅支持默认分词器 jieba.dt 和 jieba.posseg.dt。 Tokenize：返回词语在原文的起止位置注意，输入参数只接受 unicode # 默认模式 result = jieba.tokenize(u'永和服装饰品有限公司') for tk in result: print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2])) word 永和 start: 0 end:2 word 服装 start: 2 end:4 word 饰品 start: 4 end:6 word 有限公司 start: 6 end:10 # 搜索模式 result = jieba.tokenize(u'永和服装饰品有限公司', mode='search') for tk in result: print(\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2])) word 永和 start: 0 end:2 word 服装 start: 2 end:4 word 饰品 start: 4 end:6 word 有限 start: 6 end:8 word 公司 start: 8 end:10 word 有限公司 start: 6 end:10 ChineseAnalyzer for Whoosh 搜索引擎引用： from jieba.analyse import ChineseAnalyzer用法示例：https://github.com/fxsjy/jieba/blob/master/test/test_whoosh.py 命令行分词使用示例： python -m jieba news.txt > cut_result.txt 命令行选项（翻译）： 使用: python -m jieba [options] filename 如果没有指定文件名，则使用标准输入。–help 选项输出： $> python -m jieba --help Jieba command line interface. positional arguments: filename input file optional arguments: -h, --help show this help message and exit -d [DELIM], --delimiter [DELIM] use DELIM instead of ' / ' for word delimiter; or a space if it is used without DELIM -p [DELIM], --pos [DELIM] enable POS tagging; if DELIM is specified, use DELIM instead of '\\_' for POS delimiter -D DICT, --dict DICT use DICT as dictionary -u USER_DICT, --user-dict USER_DICT use USER_DICT together with the default dictionary or DICT (if specified) -a, --cut-all full pattern cutting (ignored with POS tagging) -n, --no-hmm don't use the Hidden Markov Model -q, --quiet don't print loading messages to stderr -V, --version show program's version number and exit If no filename specified, use STDIN instead. 延迟加载机制jieba 采用延迟加载，import jieba 和 jieba.Tokenizer() 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始 jieba，也可以手动初始化。 import jiebajieba.initialize() # 手动初始化（可选）在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径: jieba.set_dictionary(‘data/dict.txt.big’)例子： https://github.com/fxsjy/jieba/blob/master/test/test_change_dictpath.py 其他词典占用内存较小的词典文件 https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.small 支持繁体分词更好的词典文件 https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big 下载你所需要的词典，然后覆盖 jieba/dict.txt 即可；或者用 jieba.set_dictionary(‘data/dict.txt.big’) 其他语言实现结巴分词 Java 版本 作者：piaolingxue 地址：https://github.com/huaban/jieba-analysis 结巴分词 C++ 版本 作者：yanyiwu 地址：https://github.com/yanyiwu/cppjieba 结巴分词 Node.js 版本 作者：yanyiwu 地址：https://github.com/yanyiwu/nodejieba 结巴分词 Erlang 版本 作者：falood 地址：https://github.com/falood/exjieba 结巴分词 R 版本 作者：qinwf 地址：https://github.com/qinwf/jiebaR 结巴分词 iOS 版本 作者：yanyiwu 地址：https://github.com/yanyiwu/iosjieba 结巴分词 PHP 版本 作者：fukuball 地址：https://github.com/fukuball/jieba-php 结巴分词 .NET(C#) 版本 作者：anderscui 地址：https://github.com/anderscui/jieba.NET/ 系统集成 Solr: https://github.com/sing1ee/jieba-solr分词速度 1.5 MB / Second in Full Mode400 KB / Second in Default Mode测试环境: Intel(R) Core(TM) i7-2600 CPU @ 3.4GHz；《围城》.txt 常见问题 模型的数据是如何生成的？ 详见： https://github.com/fxsjy/jieba/issues/7 “台中”总是被切成“台 中”？（以及类似情况） P(台中) ＜ P(台)×P(中)，“台中”词频不够导致其成词概率较低 解决方法：强制调高词频 jieba.add_word(‘台中’) 或者 jieba.suggest_freq(‘台中’, True) “今天天气 不错”应该被切成“今天 天气 不错”？（以及类似情况） 解决方法：强制调低词频 jieba.suggest_freq((‘今天’, ‘天气’), True) 或者直接删除该词 jieba.del_word(‘今天天气’) 切出了词典中没有的词语，效果不理想？ 解决方法：关闭新词发现 jieba.cut(‘丰田太省了’, HMM=False) jieba.cut(‘我们中出了一个叛徒’, HMM=False) 更多问题请点击：https://github.com/fxsjy/jieba/issues?sort=updated&amp;state=closed 修订历史 https://github.com/fxsjy/jieba/blob/master/Changelog 参考链接https://github.com/fxsjy/jieba","tags":"gensim 分词"},{"title":"linux-python转码问题","url":"/2016/03/22/linux-python转码问题/","text":"之前用的一直是utf-8编码，几乎不会出现乱码问题。奈何公司的分词软件支持的输入和输出编码都是gbk，因此必须进行转码，一个非常痛苦的过程，如实记录下遇到的问题，供以后参考 标准utf8输出 #!/usr/bin/python # -*- coding: utf8 -*- #################### deal with base64 file ################### import gensim, logging from gensim.models import Doc2Vec import os import multiprocessing import numpy as np import base64 import codecs import g_url_text_pb2 import re import sys reload(sys) sys.setdefaultencoding('utf8') logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) def newFile(): global count fw = open('baike_url_part_000.chinese','w') with open('baike_url_part_000.result') as f: for line in f: base64Test = base64.b64decode(line) model=g_url_text_pb2.TextInfo() model.ParseFromString(base64Test) doc = model.title.decode('gbk', 'ignore')+' '+(model.content.decode('gbk', 'ignore')) doc = \"\".join(doc.split())#处理/r/t/n等 fw.write(\"\".join(doc)+\"\\n\") newFile() 转gbk输出先不管那些奇怪的^@^F等字符，转成gbk编码写入文件，加个encode就行啦 doc = doc.encode('gbk','ignore') doc = \"\".join(doc.split()) fw.write(\"\".join(doc)+\"\\n\") 打开一看，纳尼，怎么变成了这样！这是什么鬼！ 冷静……查看一下编码格式 file baike_url_part_000.chinese 然而……只显示了data……好忧伤…… baike_url_part_000.chinese: data 再看一下？好吧……binary。。 file -i baike_url_part_000.chinese baike_url_part_000.chinese: application/octet-stream; charset=binary iconv 文件编码转换iconv [选项…] [文件…] 输入/输出格式规范：-f, –from-code=名称 原始文本编码-t, –to-code=名称 输出编码 信息：-l, –list 列举所有已知的字符集 输出控制：-c 从输出中忽略无效的字符-o, –output=FILE 输出文件-s, –silent 关闭警告–verbose 打印进度信息 # utf 转 gbk iconv -c -f utf-8 -t gb2312 file 傻瓜命令行工具enca好了，这时候就要用神器啦！傻瓜命令行工具enca – 不但能智能识别文件的编码，而且还支持成批转换！心动了吗？心动不如行动！来！安装！so easy~ sudo apt-get install enca 常用的命令格式如下 #检查文件的编码 #enca -L 当前语言 -x 目标编码 文件名 enca -L zh_CN file #将文件编码转换为\"UTF-8\"编码 enca -L zh_CN -x UTF-8 file #如果不想覆盖原文件 enca -L zh_CN -x UTF-8 < file1 > file2 #把当前目录下的所有文件都转成utf-8 enca -L zh_CN -x utf-8 * 这里我们这么用👇 $ enca -L zh_CN baike_url_part_000.chinese Simplified Chinese National Standard; GB2312 locale发现是GB2312,说明不是代码的问题。但是为什么显示出来是乱码呢？那只是因为显示的时候使用的字符编码方式和实际内容的字符编码不一致，所以解决方式当然就是双方都用同一种编码方式喽。简单的命令就可以实现啦 export LC_ALL= 关于locale，强烈推荐看看Locale 详解，然后搞明白以下三个环境变量的优先级：LCALL&gt;LC*&gt;LANG。locale相关的各个环境变量的作用参见这里。 处理^@^F^A等特殊字符虽然可以显示了，但中间还有许多不能识别的字符 看一下这些字符的ascii对照表 然后一键替换，下面是将^@替换为空格的例子 sed -i \"s/[\\x00]/ /g\" baike_url_part_000.chinese 然而不可见字符这么多，总不能一个个替换吧！在python中直接用正则做替换，在split前加上一行代码 doc = re.sub(r'[\\x00-\\x0F]+',' ', doc) doc = \"\".join(doc.split()) fw.write(\"\".join(doc)+\"\\n\") 顺便提一下，在python中，字符串前加r代表此字符串为原样显示，不转义。就像字符串’\\n’转义是换行，若其前加上字母r,即r’\\n’，则不进行转义，结果将原样显示’\\n’。 这样，才算真正解决了这里的乱码问题。","tags":"python shell 编码"},{"title":"","url":"/mp/阅读理解和问题生成PR稿.html","text":"我们生成的问题： 1234contexts 100 推荐答案金星是距离地球最近的行星,(近地点)平均距离约4150万千米answer 100 金星ref 100 距 离 地 球 最 近 的 行 星 是pred 100 距 离 地 球 最 近 的 行 星 是 什 么 ? 训练集中已有的问题是： 123距离地球最近的恒星是什么？距离地球最近的行星是：距离地球最近的行星是？ 1234contexts 2687 推荐答案《水浒传》中七十二地煞之一:地文星圣手书生萧让籍贯:济州绰号:圣手书生星号:地文星梁山职务:掌管梁山行文和调兵遣将之事,是梁山的文职将领擅长:善写当时苏、黄、米、蔡四种字体绝活:摘星圣手宋江被捉到江州,吴用献计让戴宗请圣手书生萧让和善刻金石印记的玉臂匠金大坚到梁山伪造蔡京的文书,以救宋江answer 2687 萧 让ref 2687 圣 手 书 生 是 谁 ？pred 2687 谁 被 称 为 “ 圣 手 书 生 ” ? 1在“水浒传”中，谁有“圣手书生”之称？ 1234contexts 91 推荐答案最早的校园歌曲是在日本出现的answer 91 日本ref 91 校 园 歌 曲 最 早 出 现 在pred 91 校 园 歌 曲 最 早 出 现 在 哪 个 国 家 ? 1234世界最早的校园歌曲出现在最早的校园歌曲出现在哪里校园歌曲《童年》的词曲作者是：校园歌曲最早出现在:","tags":""},{"title":"","url":"/mp/2018CCF-GAIR.html","text":"孙茂松（清华大学） 强调的一个概念是中文的自然语言处理需要加入专家知识。主要介绍的工作是词表学习： 嵌入字信息的词表学习词的向量出现歧义时，可加入字的向量，相当于平滑作用，在这个刻度上没有这种信息，就进行回退因为词向量对高频词是没问题的，取相近词 K 近邻，猪肉/鸡肉语义是相似的，但对低频词/新词像马肉/龙肉，语义相关性就不高了所以在做 word vector 的时候，除了词信息，把字信息也算进来，当词向量不起作用的时候，字向量也能发挥功效，这在实践中还是经常会用到的技巧，不过这里还提到了一些其他 trick Position-based character embeddings 区分字在词中出现的位置，也就是用 char+pos 来表示字，idea 是通常一个字可能出现在词的开始、中间、尾部（用 $c^B$, $c^M$, $c^E$ 表示），却分别代表不同的含义，如车道、人行道和道法、道经中的道就不是一个含义； Cluster-based character embeddings，对每个字的所有 occurrence 进行聚类，然后对每个类建一个 embedding 参考论文：Joint Learning of Character and Word Embeddings 嵌入中文资源，基于知网的词表学习 作用大概是消歧，利用 hownet 解决中文词语的多义性，类比 wordnet 用来加强英语的多义性学习一样 当然 HowNet 和 WordNet 的构造还是有很大不同的。HowNet 对十几万汉语常用词进行了描述，描述用的三要素分别是 sememe，sense 和 word，比如 apple 包含了两个 sense，sense1 是水果，sense2 是电脑，对每个 sense，sememe 可以描述其对应的属性，这些属性会通过相对复杂的层级结构来对目标 sense 进行说明。 ​ 在基于 hownet 的词表学习里，sememe 是最小的语义单元，数量有限，大概只有两千个。每个单词可能对应多个 sense，将每个 sense 对应的 sememe 看成是一个集合，相似的 sense 会包含相同的 sememe。训练模型基于经典的 skip-gram，考虑上下文的同时，也考虑了词的 sememe 信息以及 sememe 与 sense 之间的关系，提供了三种融合方法，SSA/SAC/SAT，SSA 对每个 target word 取它对应所有 sememe embeddings 的平均值，SAC 对 context words 进行消歧来更好的学习目标单词，也就是用 sememe embedding 来表示 context，target word embedding 可以看做是为 context word embedding 选择最合适的 sense 和 sememe 的一个 attention 机制，而 SAT 则通过学习 context word 的原 embedding 和 target word 的 sememe embedding，把 context words 看做是 target word 不同 sense 上的 attention。 这样，sememe, sense, word 之间能够互相打通。在对低频词和新词问题上，由于多了词与词之间共享的 sememe embeddings，即低频词能够被解码成 sememe 并通过其他词得到良好的训练，因此相比于传统 WRL 模型能有更好的表现。 参考论文：Improved Word Representation Learning with Sememes 最后还介绍了清华出品的古诗系统，提到了与情感结合、与知识图谱结合等方法来增强作诗系统； 赵军（中科院自动化所） 主要讲的还是关系抽取中的远程监督（Distant Supervision）问题。远程监督基本假设是“两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系”，这样的假设太强，带来的最大问题就是噪声很多，一个解决方案是引入多示例学习，假定至少有一个句子表示了这种关系而不是每个句子都表示这种关系，把最有可能的句子标注出来，以提高性能。介绍的 paper 是 Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks，EMNLP 2015 挺有名的一篇文章，提出了用分段卷积神经网络 PCNN 来自动学习特征，以及加入 multi-instance learning 来解决远程监督引起的噪声问题。主要 idea 是在池化层通过两个实体的位置把句子分成三个部分，分别池化，再把三个部分的向量结合起来，做整个句子的向量化表示。 后面还讲了开放域更复杂的事件抽取，触发词问题，通过从一堆要素中定位核心要素，用核心要素到句子当中找到触发词，将触发词和前面的要素关联到一起，再回标，就可以在文本当中找到更多数据。 秦兵（哈工大）情感学习是自然语言处理的未来。 哈尔滨工业大学秦兵教授：「给定一个情感，可以让生成的文本带有这种情感，或者偏向这种情感。」，清华大学孙茂松教授紧接着讲解，「作诗将来要和知识图谱结合」，来到知识图谱领域，中科院赵军教授正是国内知识图谱和问答系统方面的知名专家，赵军教授还曾指导学生获得 2014 年 COLING 会议最佳论文奖。 哈尔滨工业大学秦兵教授：「给定一个情感，可以让生成的文本带有这种情感，或者偏向这种情感。」，清华大学孙茂松教授紧接着讲解，「作诗将来要和知识图谱结合」，来到知识图谱领域，中科院赵军教授正是国内知识图谱和问答系统方面的知名专家，赵军教授还曾指导学生获得 2014 年 COLING 会议最佳论文奖。 在 7 月 1 日上午的 NLP 专场上，腾讯知文算法负责人钟黎为大家带来了题为《从 0 到 1 打造下一代智能对话引擎》的主题演讲。 作为腾讯知文算法负责人，钟黎与大家分享了他们在智能对话系统上的研究经验。 他表示，在业界打造通用智能问答平台通常需要解决如下三种问答类型：一是任务驱动型，二是信息获取型，三是通用闲聊型。 他重点描述了第二种类型，即如何让问答系统解决用户的信息获取类问题。围绕这一类型，他讲解了智能问答系统的基础架构，以及非监督学习和监督学习在这里所起的作用。 此后，他阐述了目前业界较为通用的快速召回方案：第一种，基于词汇计数（Lexical term counting）的方法；第二种，基于语言模型的方法；第三种，基于向量化的方法。 在演讲的最后，他谈到知文团队在建设业界问答系统的一些心得体会。 第一，要重视 Baseline。 第二，尽早建立起整个流程的 pipeline。 第三，没有免费午餐定理，不存在万能算法。 第四，领域相关的数据准备、数据清洗非常重要。 以下为钟黎的演讲内容，雷锋网做了不改变原意的编辑整理。 大家好，我是腾讯知文的负责人钟黎，今天很荣幸站在这里跟大家分享我们团队在过去一年里打造智能问答的一些心得。前面几位老师从学术角度讲了自然语言处理技术最新的发展，我会更多地讲到如何打造一个业界可用的智能问答平台。 首先对我们团队做一个简短介绍，我们团队成立时间不长，到现在不足一年，成员来自五湖四海。我们研究的重点是自然语言的智能交互，围绕着这一研究重点的内涵和外延，我们在问答、对话、搜索这些领域都做了一些探索和尝试，也在 AAAI、IJCAI、SIGIR、EMNLP 等学术会议上发表了多篇论文。我们和腾讯金融云的同事一起打造了金融行业的智能客服解决方案，和腾讯视频云的同事一起打造了通用行业的小微智能客服解决方案，另外我们研发和支持了腾讯云内容理解产品。 下面这张图是微软周明老师的一张图，也是我非常赞同的一种分类。我们在业界打造通用智能问答平台的时候要解决如下几种问答类型： 第一种类型，任务驱动型。这种类型通常是用户希望去完成一些任务，比如查天气、查汇率等。 第二种类型，解决用户信息获取类的问题。这种类型也是我们这次分享的重点，我们将主要在这点展开。这也是目前业界落地最多的一种问答系统类型。 第三种类型，通用闲聊型。比如微软的小冰、苹果的 Siri 都支持通用闲聊，通用闲聊的加入会使对话系统更富于人性化，也可以加入个性化信息、用户画像信息，包括前面教授们提到的情感信息。 今天我将重点分享第二种问答类型，即如何让问答系统解决用户的信息获取类问题。这可以看作是一种问答，在问答领域可以将数据分为三种类型： 第一种，基于标准的、结构化的知识，比如说 FAQ 和 KG。FAQ 是常见问题解答，KG 是组织好的知识图谱，这两种都是比较结构化的数据类型。 第二种，数据以非结构化的形式存在，比如说表格、文档。 第三种，多模态、跨媒体问答，比如说 VQA，或可能存在视频、音频问答的语料库。 接下来讲我们在结构化的 FAQ 上怎么打造智能问答系统。 下图右边所示是一个非常通用的框架，这个框架跟搜索引擎的框架非常类似，主要包括如下模块： 首先是问题处理模块，这一模块的工作包括查询、问询改写，错词纠正，同义词替换。第二步是召回，即在 FAQ 里召回文档，最主要的目标是召回要快，召回率要很高，准确性可以比较低，可以召回不那么相关的信息。之后，我们会做一个匹配。 这跟搜索有什么区别？搜索会得到搜索结果列表，有很多的评价方式，比如说基于列表的评价，然后再用一些指标来评价搜索结果的好坏。问答的要求更高，有时候是没有列表显示出来，只有一句话或者只有一个答案，我们要追求 top1 的准确率，对匹配的要求会更高一些。 这里提到两种方式，非监督学习和监督学习，大家可以用非监督学习快速召回，但监督信号的加入可以较大提升匹配的准确性。 讲一讲比较流行或者在业界我们用得比较多的快速召回的方案。 第一种，基于词汇计数（Lexical term counting）的方法。大家都很熟悉这类方法，它基于字面匹配，好处在于很简单，对长尾的词有很好的鲁棒性，只要在标准问里有出现过，做匹配的时候一定可以召回。但是它的缺点很明显，它基于符号，没有语义层面的理解，所以很难处理字面不同语义相近的表述。 第二种，基于语言模型，主要思想是用概率的方法来判断知识库里面的 FAQ 和用户问询在哪一种在概率上更为接近。它的实战表现更好一些，但是它对语言模型参数的优化非常敏感，所以要做很多平滑实验。 第三种，基于向量化的方法。我把用户的问询投射到这样的向量空间里去，把知识库的 FAQ 也投射到这样的向量空间里去，在向量空间里用距离的方法去做度量。目前存在很多种投射方案，比如基于矩阵的分解，可以把向量拿出来，还可以基于一些其他方法做向量化，向量空间算距离的时候也有很多种方法，比如用平均求和来算这两个点之间的距离。 WMD 是 2015 年的工作，它用了一些更加新的方法来算这种距离，这样的方法比简单的平均化求距离要更好一些。但存在一个问题，这种方法对多义性的解决不太好。 后面先讲 TF-IDF，这个想法非常直观。TF 表示这个词在当前文档的频繁程度，IDF 表示这个词的性质。如果 IDF 非常高，说明这个词是一个比较独特的词，如果比较低，说明在很多文档中普遍出现，是一个比较泛的词。我们可以对它进行求乘积，得到 TF-IDF 的分数。 语言模型的基本思想是用概率分布的方式去描述句子。语言模型在很多地方都有广泛应用，比如说在机器翻译、拼写纠错中，它可以判断哪种可能性更高。在我们自己的召回里，我们基于文档或者标准 FAQ 来生成当前用户 Query 的概率大小，进而判断得分，这是语言模型用在 IR 上的基本思想。 要解决的问题和遇到的困难是，很可能用户 Query 中的词并没有在 FAQ 里出现，所以我们要做如下的平滑——如果该词出现了要怎样，如果没有出现要怎样。 不同平滑的方法对应不同的语言模型。从实践角度来看，TF-IDF 和语言模型比较，语言模型有比较大的提升，可以看到图右几项比较里有五项取得显著提升。 刚才提到词移距离的方法，这个方法就是 WMD，基于加权平均的方法比较简单，这里主要讲一下 WMD。我们投射的每个词都要算距离，需要找到与这个词最像的那个词，而不是简单地把这个词和所有词加权平均以后才会扩散。 看这个例子，对于「奥巴马」这个词来说，跟奥巴马最相近的词是总统，把这个词算出来，求的应该是最小的距离。这有点像旅行的问题，我有一些货品要从这边移到那边，总是要找出每次移动的最小距离，把这些距离加起来。 从下图可以看到 WMD 的效果，在几个评测里，它的错误率相对来说比较低，比其他方法低了将近十几、二十个百分点。它的实际效果确实不错，但是算法复杂度比较高，因为需要全部做两两比较来计算，所以耗时会长一点。我们一个很大的要求是快，对 WMD 有一些扩展研究，有兴趣的同学可以继续关注后面的一些工作。 刚才讲的是快速召回，接下来一个很关键的点是做深度匹配。现在有很多深度匹配的方式，最多的是监督匹配，在这当中有两类比较多的方法，一类是 Siamese 网络，一类是基于交互矩阵的网络。 像 CNN 的 ARC-1 就是 Siamese 网络典型的例子，Siamese 网络比较直观，它的想法很简单，把两个输入用同样的编码器做一个表达，把表达做出来以后，可以用一个模块来做相似度的计算，它的特点是共享网络结构和参数。右边是具体的实现，可以用 CNN 实现 Encoder。 基于交互矩阵的网络的不同之处在于，除了最终表达相关性度量时，中间某些词可能会有更强的交互，特别是在文档很长的时候。这一类型的网络和 Siamese 网络相比，在两个问句很短的时候打成平手，但是如果问题很长，包含了很多的内容，里面有一些关键信息，这一网络就会有更好的表现，当我们做好表达以后，会看这个表达里面每一个小的词组之间交互的情况。 下图是用的比较好的一个网络，左边是刚才提到的结构，右边加入了交互。左边非常简单，Question 和 Answer 进入以后得到了表达的矩阵，然后再得到向量，最后求出得分，这是非常直观的流程。在 Attentive Pooling 网络里，会把交互放在求向量之前，想要在交互矩阵中得到行的取值和列的取值，就要得到它们重新的表达，再用最后的表达求扩散的分数。对于长文档，特别是如果 FAQ 很长，基于交互矩阵的网络会带来更多信息。 刚才讲的是结构化文档构建的情况。在实际场景下，结构化的数据很少，因为结构化意味着人力的投入，意味着很多人要去做数据标注、做知识库的构建。目前非结构化的数据更多一些，这也是我们团队研究的重点，也是我们认为非常有前景的方向，即如何在非结构化文档里寻找信息和答案。 非常相似的一个领域是机器阅读理解，它有如下几个类型： 完形填空。在文章里挖几个实体词，用模型算法把实体词填上。 多项选择。读了这篇文章以后我会有问题，接下来会有几个答案，我会从里面选择所对应的答案。 答案匹配。通常给定一个问题，这个问题在原文中有出现，找到原文中哪些内容可以回答这个问题。 下图右边是比较典型的答案匹配的例子，这是斯坦福比较著名的 SQuAD 比赛。SQuAD 现在已经出了 2.0，在 1.0 的时候，所有的问题答案都在原文中出现过，所以很多学者觉得这并不是特别符合实际，所以现在升级到 2.0 版本。我们现在研究的场景还是基于答案是原文中有的，类似政府的一些文书、材料、文件，可以在里面找到答案。 实际上我们离真正做阅读理解还存在差异，我们在业界做阅读理解时，首先要做召回，因为不知道哪篇文章里包含了问题的答案。这里先要快速去做检索，做完检索才到下一个部分——文档阅读理解模块。文档阅读理解并不是这两年才发展起来的，很多年前就有相关工作了，以前是基于传统特征，比如说基于三元组的关系抽取的方法，现在更多想用一些深度模型的方法来做阅读理解。 下面是一般的 Doc Reader 框架。这几年阅读理解框架非常火，也有很多相关工作。下图右所示是谷歌最近得分最高的一个单模型 QANet，可以看到，首先会有一些 Encoder，把用户的问题都读取进来，它的核心在 Attention，可以设置很多 Attention 机制，比如基于字、基于短语，或基于时刻、步长的 Attention。Attention 是一个很大的舞台，可以尝试很多方法。当拿到问题和文档交互的内容信息，送到 Decoder 部分，来生成文档在文章中的位置。所以这是一个分类问题，即这个词是不是这个档案的开头，另外是找结尾，看这个词是不是档案的结尾。这是一个比较通用的框架。 最后谈谈我们在业界的一些心得。 首先，要重视 Baseline，这一点非常重要。不要把 Baseline 搞得太复杂，因为要通过 Baseline 理解数据和问题。 第二，尽快地构建 pipeline。我们的 pipeline 是一整套系统，包括数据处理、模型训练、模型加载、模型预测、模型评价，特别要注意评价指标和整个流程的打通，只有建立 pipeline 才有迭代的基础，如果没有 pipeline，就没办法迭代，没办法评价模型，也没办法更新框架。 第三，没有免费的午餐，没有倚天屠龙刀，不存在一种可以解决所有问题的算法，算法一定有其适用的数据和场景。有了基准和评价标准，我们才可以尝试更多模型，才能知道模型在哪种条件下更加合适，做到扬长避短。 最后，要有领域相关的数据。领域相关的数据不只是指训练数据，也包括该领域的专家经验和知识，与该领域相关的框架和模型。就我们的经验来讲，领域数据的优化，比如清洗领域数据，或者构建领域词典、词表，这些方法带来的提升比较显著，甚至比模型带来的提升更加显著，所以要重视领域数据的工作。 18年7月1日上午自然语言处理专场中腾讯知文算法负责人钟黎就NLP、NLU、dialogue等面临的问题，做了其“从0到1打造下一代智能问答引擎”的报告。 钟黎 ：腾讯知文算法负责人，高级研究员，目前负责知文智能问答、智能搜索、知识图谱、内容理解等技术研发和产品落地。他拥有丰富的大规模机器学习应用经验，曾参与研发类人机器人NAO、Watson智能会议助理等产品，并主导了腾讯SNG海量社交网络话题发现和大规模语义分析平台的研发工作。（引自雷锋网的描述） 因包含的信息量较大，在此与大家分享一下当时印象比较深的点，以及小编现场拍摄的资料。 腾讯知文智能对话引擎的架构图如下。分为三层，由下而上依次为：general conversation是基础会话，主要包括用户闲聊、情感联系和用户个人信息等；information &amp; answers是本次会议主要讨论分享的模块，包括智能搜索、单轮会话（single-turn mostly）和所需的会话模型；第三层是任务导向型的对话，包括词槽填充、多轮会话和对话管理（Dialog Management，DM）。 腾讯知文智能对话引擎架构 由于支持的问答来源不同，故而问答引擎中包含了涉及的问答来源的问答引擎。首先是communityQA，用来解决FAQ（常见问题问答集）的query；KBQA是基于知识库的问答，需要提前构建好知识库（比如，三元组的）；TableQA是基于结构化数据的问答，从表中查询问题和答案；passageQA是基于非结构化文本的问答，里面涉及到文本分析、知识抽取、自然语言处理、自然语言理解的功能，试图从文本/文档中获取query的答案；VQA是基于视频/图像的问答，答案来源于视频或图像。 支持的不同数据源的QA 一-基于结构化的FAQ的问答引擎流程 由两条技术路线来解决，一种是无监督学习，基于快速检索；另一种是有监督的学习，基于深度匹配。 结构化FAQ问答引擎流程 1.1 无监督的快速检索方法 采用了三个层次的方法来实现快速检索的方法。 首先用了基础的TFIDF提取query的关键词，用BM25来计算query和FAQ库中问题的相似度。这是典型的词汇统计的方法，该方法可以对rare word比较鲁棒，但同时也存在词汇匹配缺失的问题。 其次，采用了language model（简写LM）的方法，主要使用的是Jelinek-Mercer平滑法和Dirichlet平滑法，对于上面的词汇匹配问题表现良好，但是也存在平滑敏感的问题。 最后一层使用Embedding，采用了LSA/word2vec和腾讯知文自己提出的Weighted Sum/WMD方法，以此来表示语义层面的近似，但是也同样引发了歧义问题。 无监督的快速检索方法 基于TF-IDF的词统计 LM计算Query与Document匹配流程 LM与tf-idf对于平滑效果的准确率对比 word2vec embedding计算相似举例 Embedding distance错误率 1.2 监督的深度匹配方法 智能问答引擎的第二种方法是深度匹配的监督学习方法或者称其为监督的深度匹配方法。采用了两条思路，一条是基于Siamese networks神经网络架构，这是一种相似性度量方法，内部采用深度语义匹配模型（DSMM，Deep Structured Semantic Model），该方法在检索场景下使用点击数据来训练语义层次的匹配。另一条思路是Interaction-based networks，同时对问题和答案进行特征加权的Attention方案。 深度匹配的监督学习方法 Siamese networks：通过搜索引擎里 Query 和 Title 的海量的点击曝光日志，用 DNN 把 Query 和 Title 表达为低纬语义向量，并通过 cosine 距离来计算两个语义向量的距离，最终训练出语义相似度模型。该模型既可以用来预测两个句子的语义相似度，又可以获得某句子的低纬语义向量表达。 基于DSSM的Siamese networks 基于Attention机制的Interaction-based networks attentive Pooling Networks 二-基于非结构化文档的智能问答引擎 非结构化文档的智能问答离不开机器阅读理解，而机器阅读理解目前常见的无外乎： （1）cloze-style类似完形填空的； （2）multiple-choice类似多项选择的； （3）answer-matching类似文档中答案匹配的。 像PPT中给出的示例，询问某类“实体”，答案来源是一段文本，分析问句，从文本段落中找到答案。 机器阅读理解的类型 以下两张PPT给出了如何结合query从文档中获取答案的流程，及采用end-end的方式解码文档理解文档。这个在会议上未理解清楚，后续还需要查找腾讯知文开放的相关论文或文档来理解。 从文档中获取query答案的流程 三-总结 下面是钟黎研究员在智能问答引擎过程中总结的几点注意事项： 1、Baseline needs more love 哈，个人通俗理解，是说在做智能问答/对话的过程中不要总想着用高大上的算法，也要考虑关键词、词袋等一些基础方法，也许这些方法很简单但是可以解决很多看似困难的问题。请多给这些基础功能一些爱~~ 2、Starting from pipelines 因为智能问答/对话涉及的模块或策略比较多，根据产品规划或者应用落地，会不断的丰富其功能及提升其准确率，为了方便扩展，在问答系统开发的初期就一定要考虑好怎样合理设计pipeline。其实这个问题在小编工作过程中也碰到了~~ 3、No free lunch theorem 字面意思“没有免费的午餐”，个人理解的是指对话语料整理收集方面，还是需要做一些基础工作滴~ 4、Domain-specific data is the key 领域的专有数据是关键，因为对话的场景还是要解决实际业务问题的，所以不管是在问答数据准备上还是在模型训练上，最好都要丰富一部分业务专有数据。 以上，便是小编在此次会议中的收获，当然因为时间和小编脑容量有限，可能有些点没有提到或者提到的点未必准确，还请各位童鞋批评指正，共同探讨进步！在此，也非常感谢CCF-GAIR大会提供的学习交流机会！","tags":""},{"title":"aboutme","url":"/aboutme/index.html","text":"About Me就叫我阿衡吧。90后，曾居无锡、上海、广州、阿德莱德、匹兹堡，现居深圳，热爱所有居住过的城市，但也不希望未来拘泥于这小小一方天地。本科毕业于中山大学，研究生就读于卡耐基梅隆大学。曾是一枚典型的文科生，因为怀着改变世界（make a difference to the world）的期许而学代码（不要笑，梦想总是要有的）。不是天才也不是大牛，但相信有志者事竟成，不断学习摸索中，做着喜欢做的事，希望有一天我的成果能影响更多的人。 对文字的热爱历史悠久，大抵是从小学一篇大白兔开始 o(╯□╰)o，后来和很多少年人一样，有过很长一段为赋新词强说愁的岁月，直到大学来到广州，加入金字塔学社，感受到那些厚重的文笔产生的难以描述却又震荡人心的力量，感觉到过去的自己确实过于浅薄，过去的文字也过于轻飘，于是歇了笔，偶尔写写随笔，做做札记。 开始写博客是因为偶然间接触到小土刀的博客，发现是校友，对 CMU 这样高压环境下还能坚持输出博客的人&amp;行为着实佩服，于是开始入了技术博客的坑，最初的愿景很简单，只是整理一些零散的课程笔记，希望能记录下在 CMU 的一些成果，受众是自己，最多到同学，没想到不知不觉坚持了一年，甚至渐渐有了些小粉丝，看到自己的文章能够帮助到大家，由衷感动。 对 NLP 的热爱始自追一科技的实习，个人原因放弃了 offer，现就职于顺丰科技，主要做深度学习在自然语言处理方面的应用，具体有聊天机器人、知识图谱等。技术背景或者是兴趣点有： 自然语言处理（搜索引擎/QA系统/聊天机器人/知识图谱） 机器学习 / 深度学习 / 数据挖掘 云计算（Hadoop/Spark） 网站建设 IoT 热爱奶茶，标准吃货，生活简单，喜欢健身。通过博客认识了很多朋友，不会放弃写作。学习的路道阻且长，希望和大家共同进步。","tags":""},{"title":"tags","url":"/tags/index.html","text":"","tags":""},{"title":"","url":"/Linear Regression - Databricks.html","text":"Linear Regression - Databricks window.settings = {\"enableSshKeyUI\":false,\"defaultInteractivePricePerDBU\":0.4,\"enableOnDemandClusterType\":true,\"enableAutoCompleteAsYouType\":[],\"devTierName\":\"Community Edition\",\"enableJobsPrefetching\":true,\"workspaceFeaturedLinks\":[{\"linkURI\":\"https://docs.databricks.com/index.html\",\"displayName\":\"Documentation\",\"icon\":\"question\"},{\"linkURI\":\"https://docs.databricks.com/release-notes/product/index.html\",\"displayName\":\"Release Notes\",\"icon\":\"code\"},{\"linkURI\":\"https://docs.databricks.com/spark/latest/training/index.html\",\"displayName\":\"Training & Tutorials\",\"icon\":\"graduation-cap\"}],\"enableClearStateFeature\":false,\"dbcForumURL\":\"http://forums.databricks.com/\",\"enableProtoClusterInfoDeltaPublisher\":true,\"maxCustomTags\":45,\"enableInstanceProfilesUIInJobs\":true,\"nodeInfo\":{\"node_types\":[{\"support_ssh\":false,\"spark_heap_memory\":4800,\"instance_type_id\":\"r3.2xlarge\",\"spark_core_oversubscription_factor\":8.0,\"node_type_id\":\"dev-tier-node\",\"description\":\"Community Optimized\",\"support_cluster_tags\":false,\"container_memory_mb\":6000,\"node_instance_type\":{\"instance_type_id\":\"r3.2xlarge\",\"provider\":\"AWS\",\"compute_units\":26.0,\"number_of_ips\":15,\"local_disks\":1,\"reserved_compute_units\":3.64,\"memory_mb\":62464,\"num_cores\":8,\"reserved_memory_mb\":4800},\"memory_mb\":6144,\"is_hidden\":false,\"category\":\"Community Edition\",\"num_cores\":0.88,\"support_ebs_volumes\":false,\"is_deprecated\":false}],\"default_node_type_id\":\"dev-tier-node\"},\"enableClusterAcls\":true,\"notebookRevisionVisibilityHorizon\":999999,\"enableTableHandler\":true,\"maxEbsVolumesPerInstance\":10,\"isAdmin\":true,\"deltaProcessingBatchSize\":1000,\"enableLargeResultDownload\":true,\"zoneInfos\":[{\"id\":\"us-west-2c\",\"isDefault\":true},{\"id\":\"us-west-2b\",\"isDefault\":false},{\"id\":\"us-west-2a\",\"isDefault\":false}],\"enableCustomSpotPricingUIByTier\":false,\"enableEBSVolumesUIForJobs\":true,\"enablePublishNotebooks\":true,\"enableMaxConcurrentRuns\":true,\"enableJobAclsConfig\":false,\"enableFullTextSearch\":false,\"enableElasticSparkUI\":false,\"enableNewClustersCreate\":true,\"clusters\":true,\"allowRunOnPendingClusters\":true,\"fileStoreBase\":\"FileStore\",\"enableSshKeyUIInJobs\":true,\"enableDetachAndAttachSubMenu\":false,\"configurableSparkOptionsSpec\":[{\"keyPattern\":\"spark\\\\.kryo(\\\\.[^\\\\.]+)+\",\"valuePattern\":\".*\",\"keyPatternDisplay\":\"spark.kryo.*\",\"valuePatternDisplay\":\"*\",\"description\":\"Configuration options for Kryo serialization\"},{\"keyPattern\":\"spark\\\\.io\\\\.compression\\\\.codec\",\"valuePattern\":\"(lzf|snappy|org\\\\.apache\\\\.spark\\\\.io\\\\.LZFCompressionCodec|org\\\\.apache\\\\.spark\\\\.io\\\\.SnappyCompressionCodec)\",\"keyPatternDisplay\":\"spark.io.compression.codec\",\"valuePatternDisplay\":\"snappy|lzf\",\"description\":\"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs.\"},{\"keyPattern\":\"spark\\\\.serializer\",\"valuePattern\":\"(org\\\\.apache\\\\.spark\\\\.serializer\\\\.JavaSerializer|org\\\\.apache\\\\.spark\\\\.serializer\\\\.KryoSerializer)\",\"keyPatternDisplay\":\"spark.serializer\",\"valuePatternDisplay\":\"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer\",\"description\":\"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form.\"},{\"keyPattern\":\"spark\\\\.rdd\\\\.compress\",\"valuePattern\":\"(true|false)\",\"keyPatternDisplay\":\"spark.rdd.compress\",\"valuePatternDisplay\":\"true|false\",\"description\":\"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time.\"},{\"keyPattern\":\"spark\\\\.speculation\",\"valuePattern\":\"(true|false)\",\"keyPatternDisplay\":\"spark.speculation\",\"valuePatternDisplay\":\"true|false\",\"description\":\"Whether to use speculation (recommended off for streaming)\"},{\"keyPattern\":\"spark\\\\.es(\\\\.[^\\\\.]+)+\",\"valuePattern\":\".*\",\"keyPatternDisplay\":\"spark.es.*\",\"valuePatternDisplay\":\"*\",\"description\":\"Configuration options for ElasticSearch\"},{\"keyPattern\":\"es(\\\\.([^\\\\.]+))+\",\"valuePattern\":\".*\",\"keyPatternDisplay\":\"es.*\",\"valuePatternDisplay\":\"*\",\"description\":\"Configuration options for ElasticSearch\"},{\"keyPattern\":\"spark\\\\.(storage|shuffle)\\\\.memoryFraction\",\"valuePattern\":\"0?\\\\.0*([1-9])([0-9])*\",\"keyPatternDisplay\":\"spark.(storage|shuffle).memoryFraction\",\"valuePatternDisplay\":\"(0.0,1.0)\",\"description\":\"Fraction of Java heap to use for Spark's shuffle or storage\"},{\"keyPattern\":\"spark\\\\.streaming\\\\.backpressure\\\\.enabled\",\"valuePattern\":\"(true|false)\",\"keyPatternDisplay\":\"spark.streaming.backpressure.enabled\",\"valuePatternDisplay\":\"true|false\",\"description\":\"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set.\"},{\"keyPattern\":\"spark\\\\.streaming\\\\.receiver\\\\.maxRate\",\"valuePattern\":\"^([0-9]{1,})$\",\"keyPatternDisplay\":\"spark.streaming.receiver.maxRate\",\"valuePatternDisplay\":\"numeric\",\"description\":\"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details.\"},{\"keyPattern\":\"spark\\\\.streaming\\\\.kafka\\\\.maxRatePerPartition\",\"valuePattern\":\"^([0-9]{1,})$\",\"keyPatternDisplay\":\"spark.streaming.kafka.maxRatePerPartition\",\"valuePatternDisplay\":\"numeric\",\"description\":\"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details.\"},{\"keyPattern\":\"spark\\\\.streaming\\\\.kafka\\\\.maxRetries\",\"valuePattern\":\"^([0-9]{1,})$\",\"keyPatternDisplay\":\"spark.streaming.kafka.maxRetries\",\"valuePatternDisplay\":\"numeric\",\"description\":\"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3.\"},{\"keyPattern\":\"spark\\\\.streaming\\\\.ui\\\\.retainedBatches\",\"valuePattern\":\"^([0-9]{1,})$\",\"keyPatternDisplay\":\"spark.streaming.ui.retainedBatches\",\"valuePatternDisplay\":\"numeric\",\"description\":\"How many batches the Spark Streaming UI and status APIs remember before garbage collecting.\"}],\"enableReactNotebookComments\":true,\"enableAdminPasswordReset\":false,\"enableResetPassword\":true,\"maxClusterTagValueLength\":255,\"enableJobsSparkUpgrade\":true,\"enableNotebookCommandNumbers\":true,\"sparkVersions\":[{\"key\":\"1.6.3-db2-hadoop2-scala2.10\",\"displayName\":\"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)\",\"packageLabel\":\"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.x-ubuntu15.10\",\"displayName\":\"Spark 1.6.x (Hadoop 1)\",\"packageLabel\":\"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":false},{\"key\":\"1.4.x-ubuntu15.10\",\"displayName\":\"Spark 1.4.1 (Hadoop 1)\",\"packageLabel\":\"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.2.x-scala2.11\",\"displayName\":\"Spark Master Branch (Experimental, Scala 2.11)\",\"packageLabel\":\"spark-image-b2166ecda59b5d648306cc8a0923aa3a3bf4f25ea0d47bb42449010086f1f910\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.1.0-db2-scala2.11\",\"displayName\":\"Spark 2.1.0-db2 (Scala 2.11)\",\"packageLabel\":\"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.0.0-ubuntu15.10-scala2.10\",\"displayName\":\"Spark 2.0.0 (Scala 2.10)\",\"packageLabel\":\"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.2-db3-scala2.10\",\"displayName\":\"Spark 2.0.2-db3 (Scala 2.10)\",\"packageLabel\":\"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.1.0-db1-scala2.11\",\"displayName\":\"Spark 2.1.0-db1 (Scala 2.11)\",\"packageLabel\":\"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.1.1-db4-scala2.11\",\"displayName\":\"Spark 2.1.1-db4 RC4 (Scala 2.11)\",\"packageLabel\":\"spark-image-a44721b88b7cb3adbd583dc391c856090f1d08f5e5702025343eef7b11fcf11d\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":false},{\"key\":\"2.1.0-db2-scala2.10\",\"displayName\":\"Spark 2.1.0-db2 (Scala 2.10)\",\"packageLabel\":\"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.x-ubuntu15.10-hadoop1\",\"displayName\":\"Spark 1.6.x (Hadoop 1)\",\"packageLabel\":\"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":false},{\"key\":\"2.0.2-db4-scala2.11\",\"displayName\":\"Spark 2.0.2-db4 (Scala 2.11)\",\"packageLabel\":\"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.1-ubuntu15.10-hadoop1\",\"displayName\":\"Spark 1.6.1 (Hadoop 1)\",\"packageLabel\":\"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.x-gpu-scala2.11\",\"displayName\":\"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)\",\"packageLabel\":\"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.2-ubuntu15.10-hadoop1\",\"displayName\":\"Spark 1.6.2 (Hadoop 1)\",\"packageLabel\":\"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"1.6.3-db1-hadoop2-scala2.10\",\"displayName\":\"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)\",\"packageLabel\":\"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.3-db2-hadoop1-scala2.10\",\"displayName\":\"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)\",\"packageLabel\":\"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.2-ubuntu15.10-hadoop2\",\"displayName\":\"Spark 1.6.2 (Hadoop 2)\",\"packageLabel\":\"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"1.6.1-ubuntu15.10-hadoop2\",\"displayName\":\"Spark 1.6.1 (Hadoop 2)\",\"packageLabel\":\"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.2-db2-scala2.10\",\"displayName\":\"Spark 2.0.2-db2 (Scala 2.10)\",\"packageLabel\":\"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.x-ubuntu15.10-scala2.11\",\"displayName\":\"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)\",\"packageLabel\":\"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.x-scala2.10\",\"displayName\":\"Spark 2.0 (Auto-updating, Scala 2.10)\",\"packageLabel\":\"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.1.1-db4-scala2.10\",\"displayName\":\"Spark 2.1.1-db4 RC4 (Scala 2.10)\",\"packageLabel\":\"spark-image-00d828cd393fda30b92d472cf0f5e13ff9ba2af84382e69abd37934ff71be0e6\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":false},{\"key\":\"2.0.2-db1-scala2.11\",\"displayName\":\"Spark 2.0.2-db1 (Scala 2.11)\",\"packageLabel\":\"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.2-db4-scala2.10\",\"displayName\":\"Spark 2.0.2-db4 (Scala 2.10)\",\"packageLabel\":\"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.5.x-ubuntu15.10\",\"displayName\":\"Spark 1.5.2 (Hadoop 1)\",\"packageLabel\":\"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.0.x-scala2.11\",\"displayName\":\"Spark 2.0 (Auto-updating, Scala 2.11)\",\"packageLabel\":\"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.1.x-scala2.10\",\"displayName\":\"Spark 2.1 (Auto-updating, Scala 2.10)\",\"packageLabel\":\"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.1.0-db3-scala2.10\",\"displayName\":\"Spark 2.1.0-db3 (Scala 2.10)\",\"packageLabel\":\"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.0.2-db2-scala2.11\",\"displayName\":\"Spark 2.0.2-db2 (Scala 2.11)\",\"packageLabel\":\"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"1.3.x-ubuntu15.10\",\"displayName\":\"Spark 1.3.0 (Hadoop 1)\",\"packageLabel\":\"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.0.1-db1-scala2.11\",\"displayName\":\"Spark 2.0.1-db1 (Scala 2.11)\",\"packageLabel\":\"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.2-db3-scala2.11\",\"displayName\":\"Spark 2.0.2-db3 (Scala 2.11)\",\"packageLabel\":\"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"1.6.3-db1-hadoop1-scala2.10\",\"displayName\":\"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)\",\"packageLabel\":\"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.0.2-db1-scala2.10\",\"displayName\":\"Spark 2.0.2-db1 (Scala 2.10)\",\"packageLabel\":\"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.x-ubuntu15.10\",\"displayName\":\"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)\",\"packageLabel\":\"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.0.1-db1-scala2.10\",\"displayName\":\"Spark 2.0.1-db1 (Scala 2.10)\",\"packageLabel\":\"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.1.x-scala2.11\",\"displayName\":\"Spark 2.1 (Auto-updating, Scala 2.11)\",\"packageLabel\":\"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},{\"key\":\"2.1.0-db1-scala2.10\",\"displayName\":\"Spark 2.1.0-db1 (Scala 2.10)\",\"packageLabel\":\"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"1.6.0-ubuntu15.10\",\"displayName\":\"Spark 1.6.0 (Hadoop 1)\",\"packageLabel\":\"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"1.6.x-ubuntu15.10-hadoop2\",\"displayName\":\"Spark 1.6.x (Hadoop 2)\",\"packageLabel\":\"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":false},{\"key\":\"2.0.0-ubuntu15.10-scala2.11\",\"displayName\":\"Spark 2.0.0 (Scala 2.11)\",\"packageLabel\":\"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909\",\"upgradable\":true,\"deprecated\":true,\"customerVisible\":false},{\"key\":\"2.1.0-db3-scala2.11\",\"displayName\":\"Spark 2.1.0-db3 (Scala 2.11)\",\"packageLabel\":\"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true}],\"enableRestrictedClusterCreation\":true,\"enableFeedback\":true,\"enableClusterAutoScaling\":false,\"enableUserVisibleDefaultTags\":true,\"defaultNumWorkers\":0,\"serverContinuationTimeoutMillis\":10000,\"driverStderrFilePrefix\":\"stderr\",\"enableNotebookRefresh\":false,\"accountsOwnerUrl\":\"https://accounts.cloud.databricks.com/registration.html#login\",\"driverStdoutFilePrefix\":\"stdout\",\"defaultNodeTypeToPricingUnitsMap\":{\"r3.2xlarge\":2,\"class-node\":1,\"m4.2xlarge\":0.5,\"r4.xlarge\":1,\"m4.4xlarge\":0.5,\"r4.16xlarge\":8,\"p2.8xlarge\":16,\"m4.10xlarge\":0.5,\"r3.8xlarge\":8,\"r4.4xlarge\":4,\"dev-tier-node\":1,\"c3.8xlarge\":4,\"r3.4xlarge\":4,\"i2.4xlarge\":6,\"m4.xlarge\":0.5,\"r4.8xlarge\":8,\"r4.large\":0.5,\"development-node\":1,\"i2.2xlarge\":3,\"g2.8xlarge\":6,\"memory-optimized\":1,\"m4.large\":0.5,\"p2.16xlarge\":24,\"c3.2xlarge\":1,\"c4.2xlarge\":1,\"i2.xlarge\":1.5,\"compute-optimized\":1,\"c4.4xlarge\":2,\"c3.4xlarge\":2,\"g2.2xlarge\":1.5,\"p2.xlarge\":2,\"m4.16xlarge\":0.5,\"c4.8xlarge\":4,\"r3.xlarge\":1,\"r4.2xlarge\":2,\"i2.8xlarge\":12},\"enableSparkDocsSearch\":true,\"sparkHistoryServerEnabled\":true,\"enableEBSVolumesUI\":false,\"sanitizeMarkdownHtml\":true,\"enableIPythonImportExport\":true,\"enableClusterTagsUIForJobs\":true,\"enableClusterTagsUI\":false,\"enableNotebookHistoryDiffing\":true,\"branch\":\"2.43\",\"accountsLimit\":3,\"enableSparkEnvironmentVariables\":true,\"enableX509Authentication\":false,\"enableNotebookGitBranching\":true,\"local\":false,\"enableClusterAutoScalingForJobs\":false,\"enableStrongPassword\":false,\"displayDefaultContainerMemoryGB\":6,\"enableNotebookCommandMode\":true,\"disableS3TableImport\":false,\"deploymentMode\":\"production\",\"useSpotForWorkers\":true,\"enableUserInviteWorkflow\":true,\"enableStaticNotebooks\":true,\"enableCssTransitions\":true,\"minClusterTagKeyLength\":1,\"showHomepageFeaturedLinks\":true,\"pricingURL\":\"https://databricks.com/product/pricing\",\"enableClusterAclsConfig\":false,\"useTempS3UrlForTableUpload\":false,\"notifyLastLogin\":false,\"enableSshKeyUIByTier\":false,\"defaultAutomatedPricePerDBU\":0.2,\"enableNotebookGitVersioning\":true,\"files\":\"files/\",\"feedbackEmail\":\"feedback@databricks.com\",\"enableDriverLogsUI\":true,\"enableWorkspaceAclsConfig\":false,\"dropzoneMaxFileSize\":2047,\"enableNewClustersList\":false,\"enableNewDashboardViews\":true,\"driverLog4jFilePrefix\":\"log4j\",\"enableSingleSignOn\":true,\"enableMavenLibraries\":true,\"displayRowLimit\":1000,\"deltaProcessingAsyncEnabled\":true,\"enableSparkEnvironmentVariablesUI\":false,\"defaultSparkVersion\":{\"key\":\"2.1.x-scala2.10\",\"displayName\":\"Spark 2.1 (Auto-updating, Scala 2.10)\",\"packageLabel\":\"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626\",\"upgradable\":true,\"deprecated\":false,\"customerVisible\":true},\"enableCustomSpotPricing\":false,\"enableMountAclsConfig\":false,\"useDevTierHomePage\":true,\"enableClusterClone\":true,\"enableNotebookLineNumbers\":true,\"enablePublishHub\":false,\"notebookHubUrl\":\"http://hub.dev.databricks.com/\",\"showSqlEndpoints\":false,\"enableClusterAclsByTier\":false,\"databricksDocsBaseUrl\":\"https://docs.databricks.com/\",\"cloud\":\"AWS\",\"disallowAddingAdmins\":true,\"enableSparkConfUI\":true,\"featureTier\":\"DEVELOPER_BASIC_TIER\",\"mavenCentralSearchEndpoint\":\"http://search.maven.org/solrsearch/select\",\"enableOrgSwitcherUI\":true,\"clustersLimit\":1,\"enableJdbcImport\":true,\"logfiles\":\"logfiles/\",\"enableWebappSharding\":true,\"enableClusterDeltaUpdates\":true,\"enableSingleSignOnLogin\":false,\"ebsVolumeSizeLimitGB\":{\"GENERAL_PURPOSE_SSD\":[100,4096],\"THROUGHPUT_OPTIMIZED_HDD\":[500,4096]},\"enableMountAcls\":false,\"requireEmailUserName\":true,\"dbcFeedbackURL\":\"mailto:feedback@databricks.com\",\"enableMountAclService\":true,\"enableWorkspaceAcls\":false,\"maxClusterTagKeyLength\":127,\"gitHash\":\"f02f6a43e613f2d87429ffc62e757066894de04f\",\"showWorkspaceFeaturedLinks\":true,\"signupUrl\":\"https://databricks.com/try-databricks\",\"allowFeedbackForumAccess\":true,\"enableImportFromUrl\":true,\"enableMiniClusters\":true,\"enableNewTableUI\":true,\"enableDebugUI\":false,\"enableStreamingMetricsDashboard\":true,\"allowNonAdminUsers\":true,\"enableSingleSignOnByTier\":false,\"enableJobsRetryOnTimeout\":true,\"useStandardTierUpgradeTooltips\":true,\"staticNotebookResourceUrl\":\"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/\",\"enableSpotClusterType\":true,\"enableSparkPackages\":true,\"dynamicSparkVersions\":true,\"enableClusterTagsUIByTier\":false,\"enableNotebookHistoryUI\":true,\"enableClusterLoggingUI\":true,\"enableDatabaseDropdownInTableUI\":false,\"showDebugCounters\":false,\"enableInstanceProfilesUI\":false,\"enableFolderHtmlExport\":true,\"homepageFeaturedLinks\":[{\"linkURI\":\"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html\",\"displayName\":\"Introduction to Apache Spark on Databricks\",\"icon\":\"img/home/Python_icon.svg\"},{\"linkURI\":\"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html\",\"displayName\":\"Databricks for Data Scientists\",\"icon\":\"img/home/Scala_icon.svg\"},{\"linkURI\":\"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html\",\"displayName\":\"Introduction to Structured Streaming\",\"icon\":\"img/home/Python_icon.svg\"}],\"enableClusterStart\":false,\"enableEBSVolumesUIByTier\":false,\"upgradeURL\":\"https://accounts.cloud.databricks.com/registration.html#login\",\"notebookLoadingBackground\":\"#fff\",\"sshContainerForwardedPort\":2200,\"enableServerAutoComplete\":true,\"enableStaticHtmlImport\":true,\"enableInstanceProfilesByTier\":false,\"defaultMemoryPerContainerMB\":6000,\"enablePresenceUI\":true,\"accounts\":true,\"useOnDemandClustersByDefault\":true,\"useFramedStaticNotebooks\":false,\"enableNewProgressReportUI\":true,\"defaultCoresPerContainer\":4,\"showTerminationReason\":true,\"enableNewClustersGet\":true,\"showPricePerDBU\":false,\"showSqlProxyUI\":true}; var __DATABRICKS_NOTEBOOK_MODEL = {\"version\":\"NotebookV1\",\"origId\":1555922344233013,\"name\":\"Linear Regression - Databricks\",\"language\":\"python\",\"commands\":[{\"version\":\"CommandV1\",\"origId\":1555922344233015,\"guid\":\"475d47b5-aa38-4ed3-bfb1-05295eb5d986\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":0.0,\"command\":\"%md # **Linear Regression Lab**\\n#### This lab covers a common supervised learning pipeline, using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Our goal is to train a linear regression model to predict the release year of a song given a set of audio features.\\n#### ** This lab will cover: **\\n* *Part 1 (6 Points):* Read and parse the initial dataset\\n * *Visualization 1 (5 Points):* Features\\n * *Visualization 2 (5 Points):* Shifting labels\\n\\n* *Part 2 (6 Points):* Create and evaluate a baseline model\\n * *Visualization 3 (5 Points):* Predicted vs. actual\\n\\n* *Part 3 (15 Points):* Train least squares linear regression (via gradient descent) and evaluate a linear regression model\\n * *Visualization 4 (5 Points):* Training error\\n\\n* *Part 4 (15 Points):* Train Train least squares linear regression with L2 regularization (via gradient descent) and evaluate a linear regression model\\n * *Visualization 5 (5 Points):* Training error\\n\\n* *Part 5 (15 Points):* Train using SparkML and tune hyperparameters via grid search\\n * *Visualization 6 (5 Points):* Best model's predictions\\n * *Visualization 7 (5 Points):* Hyperparameter heat map\\n\\n* *Part 6 (8 Points):* Add interactions between features\\n \\n#### Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874689,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"9f74e90e-fa6b-4d59-ae47-a78d2aa80210\"},{\"version\":\"CommandV1\",\"origId\":1555922344233016,\"guid\":\"6bff22c1-bb0e-4e42-8250-1e2ab45edee0\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":1.0,\"command\":\"%md ### ** Part 0: Setup your DataBricks CE Spark cluster and attach this assignment notebook to it **\\n\\nStep I: Visit the web interface of DataBricks Community Edition at https://community.cloud.databricks.com/.\\n\\nStep II: Start a DataBricks Community Edition cluster by selecting \\\"New Cluster\\\" from the homepage.\\n\\nStep III: Give your cluster a name and click on \\\"Create Cluster\\\". This creates a single node cluster with 6GB memory for your account.\\n\\nStep IV: Go back to homepage, and choose \\\"Import Notebook.\\\" Upload this IPython assignment notebook by following the prompts and open the notebook. Rename the notebook from \\\"hw2_linear_reg_student.ipynb\\\" to \\\"andrewid_hw2_linear_reg_student.ipynb\\\" where \\\"andrewid\\\" is your actual Andrew ID.\\n\\nStep V: By default, the notebook is not attached to a Spark cluster and will show \\\"Detached\\\" as its status at the top of the notebook in the browser. Click on the \\\"Detached\\\" status and attach it to your cluster. It should now show the message as \\\"Attached (cluster name)\\\"\\n\\nStep VI: You can now import pyspark into the notebook. Also, attaching to the DataBricks Community Edition cluster automatically provides the SparkContext variable \\\"sc\\\" to the Python code in your notebook. Use it to create RDDs and write further Spark code.\\n\\nThese instructions are detailed with screenshots in slides 10-16 of the setup recitation available at https://www.andrew.cmu.edu/user/amaurya/docs/95869/hadoop-spark-setup-recitation.pdf \\n\\nThe dataset required for this assignment is available on the DataBricks CE Spark cluster and the command to create an RDD from it is included in section (1a). Alternatively, the dataset can be found at https://www.andrew.cmu.edu/user/amaurya/docs/95869/millionsong.txt\\n\\n#### Submission Instructions:\\n\\nYou will submit both a zipped file on Blackboard and a hard copy at the beginning of the class by the deadline date.\\n\\nPlease complete the assignment, execute all cells in the completed notebook, and make sure all results show up. Export the contents of the notebook by choosing \\\"File > Export > HTML\\\" and saving the resulting file as \\\"andrewid_hw2_linear_reg_student.html\\\" Place the two files \\\"andrewid_hw2_linear_reg_student.ipynb\\\" and \\\"andrewid_hw2_linear_reg_student.html\\\" in a folder, zip the folder to a zipped file named \\\"andrewid_hw2.zip\\\" and submit it to Blackboard by the deadline. In addition, print the HTML file and submit the hard copy at the beginning of the class on the date of the submission.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874711,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"e1da1638-f592-45c1-b86b-a9e7be685c3e\"},{\"version\":\"CommandV1\",\"origId\":1555922344233017,\"guid\":\"867ccbd1-f4dc-4cd9-aca3-3ba42357844e\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":2.0,\"command\":\"%md ### ** Part 1: Read and parse the initial dataset **\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874735,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"b5340357-8b87-42b1-871a-a42de2a84227\"},{\"version\":\"CommandV1\",\"origId\":1555922344233018,\"guid\":\"32955bbd-d158-4a8b-a264-ae6f2a66512b\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":3.0,\"command\":\"%md #### ** (1a) Load and check the data **\\n#### The raw data is currently stored in text file. We will start by storing this raw data in as an RDD, with each element of the RDD representing a data point as a comma-delimited string. Each string starts with the label (a year) followed by numerical audio features. Use the [count method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.count) to check how many data points we have. Then use the [take method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.take) to create and print out a list of the first 5 data points in their initial string format.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874748,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"cdf8837d-2907-4e61-ae05-edd62b1dff5b\"},{\"version\":\"CommandV1\",\"origId\":1555922344233019,\"guid\":\"9ab8e559-1b13-4ed4-8bba-671cc1e7ab4a\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":4.0,\"command\":\"import os\\nimport sys\\nimport os.path\\nimport pyspark\\n\\nnumPartitions = 2\\nrawData = sc.textFile('databricks-datasets/cs190/data-001/millionsong.txt', numPartitions)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390905717,\"submitTime\":1492390874761,\"finishTime\":1492390906137,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"2ef9daf6-2f8d-4f5c-abf4-323e4f2c5e65\"},{\"version\":\"CommandV1\",\"origId\":1555922344233020,\"guid\":\"765b26c4-4b31-4fa0-837f-9ae75bc7d652\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":5.0,\"command\":\"# TODO: Replace with appropriate code\\nnumPoints = rawData.count()\\nprint numPoints\\nsamplePoints = rawData.take(5)\\nprint samplePoints\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"6724\\n[u&apos;2001.0,0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817&apos;, u&apos;2001.0,0.854411946129,0.604124786151,0.593634078776,0.495885413963,0.266307830936,0.261472105188,0.506387076327,0.464453565511,0.665798573683,0.542968988766,0.58044428577,0.445219373624&apos;, u&apos;2001.0,0.908982970575,0.632063159227,0.557428975183,0.498263761394,0.276396052336,0.312809861625,0.448530069406,0.448674249968,0.649791323916,0.489868662682,0.591908113534,0.4500023818&apos;, u&apos;2001.0,0.842525219898,0.561826888508,0.508715259692,0.443531142139,0.296733836002,0.250213568176,0.488540873206,0.360508747659,0.575435243185,0.361005878554,0.678378718617,0.409036786173&apos;, u&apos;2001.0,0.909303285534,0.653607720915,0.585580794716,0.473250503005,0.251417011835,0.326976795524,0.40432273022,0.371154511756,0.629401917965,0.482243251755,0.566901413923,0.463373691946&apos;]\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390906287,\"submitTime\":1492390874768,\"finishTime\":1492390907702,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"a465f57f-6214-4a20-919e-f43a7c999c74\"},{\"version\":\"CommandV1\",\"origId\":1555922344233021,\"guid\":\"a8b9a870-1420-48e0-98e0-a722a0db67b4\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":6.0,\"command\":\"%md #### ** (1b) Using `LabeledPoint` **\\n#### In MLlib, labeled training instances are stored using the [LabeledPoint](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) object. Write the parsePoint function that takes as input a raw data point, parses it using Python's [unicode.split](https://docs.python.org/2/library/string.html#string.split) method, and returns a `LabeledPoint`. Use this function to parse samplePoints (from the previous question). Then print out the features and label for the first training point, using the `LabeledPoint.features` and `LabeledPoint.label` attributes. Finally, calculate the number features for this dataset.\\n#### Note that `split()` can be called directly on a `unicode` or `str` object. For example, `u'split,me'.split(',')` returns `[u'split', u'me']`.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874776,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"71876212-dbdc-43f8-94ff-6ac944a5946d\"},{\"version\":\"CommandV1\",\"origId\":1555922344233022,\"guid\":\"6f9800e0-56b5-48c9-9780-05a7b2ef3bc9\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":7.0,\"command\":\"import numpy as np\\nfrom pyspark.mllib.regression import LabeledPoint\\n\\n\\n# Here is a sample raw data point:\\n# '2001.0,0.884,0.610,0.600,0.474,0.247,0.357,0.344,0.33,0.600,0.425,0.60,0.419'\\n# In this raw data point, 2001.0 is the label, and the remaining values are features\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390907717,\"submitTime\":1492390874815,\"finishTime\":1492390907790,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4a9d14bc-8853-438f-81d9-a0a02c8f78d8\"},{\"version\":\"CommandV1\",\"origId\":1555922344233023,\"guid\":\"effa0940-ebd5-4c08-8b7c-cb85e585de23\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":8.0,\"command\":\"# TODO: Replace with appropriate code\\ndef parsePoint(line):\\n \\\"\\\"\\\"Converts a comma separated unicode string into a `LabeledPoint`.\\n\\n Args:\\n line (unicode): Comma separated unicode string where the first element is the label and the\\n remaining elements are features.\\n\\n Returns:\\n LabeledPoint: The line is converted into a `LabeledPoint`, which consists of a label and\\n features.\\n \\\"\\\"\\\"\\n parts = line.split(',')\\n return LabeledPoint(parts[0], parts[1:])\\n \\n\\nparsedSamplePoints = [parsePoint(point) for point in samplePoints]\\nfirstPointFeatures = parsedSamplePoints[0].features\\nfirstPointLabel = parsedSamplePoints[0].label\\nprint firstPointFeatures, firstPointLabel\\n\\nd = len(firstPointFeatures)\\nprint d\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"[0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817] 2001.0\\n12\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"NameError: global name &apos;LabeledPoint&apos; is not defined\",\"error\":null,\"workflows\":[],\"startTime\":1492390907799,\"submitTime\":1492390874825,\"finishTime\":1492390907840,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"65d4bd6a-3c56-4dc2-8a1b-cebdc79ea2ab\"},{\"version\":\"CommandV1\",\"origId\":1555922344233024,\"guid\":\"780d13d6-3f67-4722-b61e-5823eca65157\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":9.0,\"command\":\"%md #### **Visualization 1: Features**\\n#### First we will load and setup the visualization library. Then we will look at the raw features for 50 data points by generating a heatmap that visualizes each feature on a grey-scale and shows the variation of each feature across the 50 sample data points. The features are all between 0 and 1, with values closer to 1 represented via darker shades of grey.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874836,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ab835a91-8683-4ccf-abdb-314758bd0765\"},{\"version\":\"CommandV1\",\"origId\":1555922344233025,\"guid\":\"0fbbcdb2-bc4b-420c-94b8-5cbc99fe5e45\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":10.0,\"command\":\"import matplotlib.pyplot as plt\\nimport matplotlib.cm as cm\\n\\nsampleMorePoints = rawData.take(50)\\n# You can uncomment the line below to see randomly selected features. These will be randomly\\n# selected each time you run the cell. Note that you should run this cell with the line commented\\n# out when answering the lab quiz questions.\\n# sampleMorePoints = rawData.takeSample(False, 50)\\n\\nparsedSampleMorePoints = map(parsePoint, sampleMorePoints)\\ndataValues = map(lambda lp: lp.features.toArray(), parsedSampleMorePoints)\\n\\ndef preparePlot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\\n gridWidth=1.0):\\n \\\"\\\"\\\"Template for generating the plot layout.\\\"\\\"\\\"\\n plt.close()\\n fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\\n ax.axes.tick_params(labelcolor='#999999', labelsize='10')\\n for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\\n axis.set_ticks_position('none')\\n axis.set_ticks(ticks)\\n axis.label.set_color('#999999')\\n if hideLabels: axis.set_ticklabels([])\\n plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\\n map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\\n return fig, ax\\n\\n# generate layout and plot\\nfig, ax = preparePlot(np.arange(.5, 11, 1), np.arange(.5, 49, 1), figsize=(8,7), hideLabels=True,\\n gridColor='#eeeeee', gridWidth=1.1)\\nimage = plt.imshow(dataValues,interpolation='nearest', aspect='auto', cmap=cm.Greys)\\nfor x, y, s in zip(np.arange(-.125, 12, 1), np.repeat(-.75, 12), [str(x) for x in range(12)]):\\n plt.text(x, y, s, color='#999999', size='10')\\nplt.text(4.7, -3, 'Feature', color='#999999', size='11'), ax.set_ylabel('Observation')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390907852,\"submitTime\":1492390874852,\"finishTime\":1492390911028,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"1b5b93c3-428e-4977-bddc-da70b0f9f3f4\"},{\"version\":\"CommandV1\",\"origId\":1555922344233026,\"guid\":\"46931cf2-f8bc-44ef-8586-88dddb7939c9\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":11.0,\"command\":\"%md #### **(1c) Find the range **\\n#### Now let's examine the labels to find the range of song years. To do this, first parse each element of the `rawData` RDD, and then find the smallest and largest labels.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874863,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"eadce945-f20b-49a3-a68f-3388c4532bca\"},{\"version\":\"CommandV1\",\"origId\":1555922344233027,\"guid\":\"53502d27-db04-4ec4-9b36-2bae3cce01fa\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":12.0,\"command\":\"# TODO: Replace with appropriate code\\nparsedDataInit = rawData.map(lambda x: LabeledPoint(x.split(',')[0],x.split(',')[1:]))\\nonlyLabels = parsedDataInit.map(lambda x: int(float(x.label)))\\nminYear = sorted(onlyLabels.collect())[0]\\nmaxYear = sorted(onlyLabels.collect(), reverse=True)[0]\\nprint maxYear, minYear\\n\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"2011 1922\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"AttributeError: &apos;list&apos; object has no attribute &apos;take&apos;\",\"error\":null,\"workflows\":[],\"startTime\":1492390911055,\"submitTime\":1492390874876,\"finishTime\":1492390911634,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"c4def835-894c-4996-b848-6b4537660cfe\"},{\"version\":\"CommandV1\",\"origId\":1555922344233028,\"guid\":\"16acab46-f367-4b23-8a2e-be5fd17bb4a5\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":13.0,\"command\":\"%md #### **(1d) Shift labels **\\n#### As we just saw, the labels are years in the 1900s and 2000s. In learning problems, it is often natural to shift labels such that they start from zero. Starting with `parsedDataInit`, create a new RDD consisting of `LabeledPoint` objects in which the labels are shifted such that smallest label equals zero.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874884,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"94a3295a-5f62-400a-a889-448c1d99ffcc\"},{\"version\":\"CommandV1\",\"origId\":1555922344233029,\"guid\":\"0c4d9c90-8d5d-4675-9709-8315a7686216\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":14.0,\"command\":\"# TODO: Replace with appropriate code\\nparsedData = parsedDataInit.map(lambda x: LabeledPoint(int(float(x.label)-1922),x.features))\\n\\n# Should be a LabeledPoint\\nprint type(parsedData.take(1)[0])\\n# View the first point\\nprint '\\\\n{0}'.format(parsedData.take(1))\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"&lt;class &apos;pyspark.mllib.regression.LabeledPoint&apos;&gt;\\n\\n[LabeledPoint(79.0, [0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817])]\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3837.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3837.0 (TID 8412, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\",\"error\":null,\"workflows\":[],\"startTime\":1492390911642,\"submitTime\":1492390874908,\"finishTime\":1492390912015,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"2a057e9f-61fe-4b11-9187-419c52015708\"},{\"version\":\"CommandV1\",\"origId\":1555922344233030,\"guid\":\"39f75909-d9fd-46a6-9b26-54c4d9133a62\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":15.0,\"command\":\"%md #### ** Visualization 2: Shifting labels **\\n#### We will look at the labels before and after shifting them. Both scatter plots below visualize tuples storing i) a label value and ii) the number of training points with this label. The first scatter plot uses the initial labels, while the second one uses the shifted labels. Note that the two plots look the same except for the labels on the x-axis.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874916,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"b4346676-c58a-46b9-b7b1-32bb71425176\"},{\"version\":\"CommandV1\",\"origId\":1555922344233031,\"guid\":\"005c3230-a458-4269-b0d9-c9e40e002465\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":16.0,\"command\":\"# get data for plot\\noldData = (parsedDataInit\\n .map(lambda lp: (lp.label, 1))\\n .reduceByKey(lambda x, y: x + y)\\n .collect())\\nx, y = zip(*oldData)\\n\\n# generate layout and plot data\\nfig, ax = preparePlot(np.arange(1920, 2050, 20), np.arange(0, 150, 20))\\nplt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\\nax.set_xlabel('Year'), ax.set_ylabel('Count')\\ndisplay(fig)\\n\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3833.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3833.0 (TID 8407, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\",\"error\":null,\"workflows\":[],\"startTime\":1492390912025,\"submitTime\":1492390874944,\"finishTime\":1492390913414,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"7ba93c25-d252-4309-9652-58d5d591f899\"},{\"version\":\"CommandV1\",\"origId\":1555922344233032,\"guid\":\"5c711785-2d90-4733-9e91-b4fb72640378\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":17.0,\"command\":\"# get data for plot\\nnewData = (parsedData\\n .map(lambda lp: (lp.label, 1))\\n .reduceByKey(lambda x, y: x + y)\\n .collect())\\nx, y = zip(*newData)\\n\\n# generate layout and plot data\\nfig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\\nplt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\\nax.set_xlabel('Year (shifted)'), ax.set_ylabel('Count')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390913425,\"submitTime\":1492390874952,\"finishTime\":1492390914205,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"a130e977-c668-4df2-b308-f0e74386106f\"},{\"version\":\"CommandV1\",\"origId\":1555922344233033,\"guid\":\"5b28f784-b6d1-4485-b607-e6ea332c1b1f\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":18.0,\"command\":\"%md #### ** (1e) Training, validation, and test sets **\\n#### We're almost done parsing our dataset, and our final task involves split it into training, validation and test sets. Use the [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) with the specified weights and seed to create RDDs storing each of these datasets. Next, cache each of these RDDs, as we will be accessing them multiple times in the remainder of this lab. Finally, compute the size of each dataset and verify that the sum of their sizes equals the value computed in Part (1a).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874960,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4b8857f4-dd44-4532-8ab7-156d2c0aae39\"},{\"version\":\"CommandV1\",\"origId\":1555922344233034,\"guid\":\"41e5c467-130b-4171-b5bc-2dd53b0ec0eb\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":19.0,\"command\":\"# TODO: Replace with appropriate code\\nweights = [.8, .1, .1]\\nseed = 42\\nparsedTrainData, parsedValData, parsedTestData = parsedData.randomSplit(weights, seed)\\nparsedTrainData.cache()\\nparsedValData.cache()\\nparsedTestData.cache()\\nnTrain = parsedTrainData.count()\\nnVal = parsedValData.count()\\nnTest = parsedTestData.count()\\n\\nprint nTrain, nVal, nTest, nTrain + nVal + nTest\\nprint parsedData.count()\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"5371 682 671 6724\\n6724\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390914213,\"submitTime\":1492390874973,\"finishTime\":1492390915322,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"760a0a67-a1ac-481a-bd6f-db708504cfd7\"},{\"version\":\"CommandV1\",\"origId\":1555922344233035,\"guid\":\"c2a0c8b4-9135-49bc-96e0-048c13c93c50\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":20.0,\"command\":\"%md ### ** Part 2: Create and evaluate a baseline model **\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874981,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4c3cd2de-f1e7-42a2-9461-bbc3629b04c6\"},{\"version\":\"CommandV1\",\"origId\":1555922344233036,\"guid\":\"b736acdd-03a9-4ad8-94f3-9514fab27823\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":21.0,\"command\":\"%md #### **(2a) Average label **\\n#### A very simple yet natural baseline model is one where we always make the same prediction independent of the given data point, using the average label in the training set as the constant prediction value. Compute this value, which is the average (shifted) song year for the training set. Use an appropriate method in the [RDD API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390874994,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"2cc96b12-4128-4238-924d-21ec3b7c5903\"},{\"version\":\"CommandV1\",\"origId\":1555922344233037,\"guid\":\"69bfcdf4-8fd4-4723-b14f-814cf246f17c\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":22.0,\"command\":\"# TODO: Replace with appropriate code\\naverageTrainYear = (parsedTrainData.map(lambda x: x.label).mean())\\nprint averageTrainYear\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"53.9316700801\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390915331,\"submitTime\":1492390875168,\"finishTime\":1492390915503,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"e9b9c0c2-da97-423e-91d6-0e2d5def6181\"},{\"version\":\"CommandV1\",\"origId\":1555922344233038,\"guid\":\"62fdc029-9675-48ac-9bc4-86fa864faf08\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":23.0,\"command\":\"%md #### **(2b) Root mean squared error **\\n#### We naturally would like to see how well this naive baseline performs. We will use root mean squared error ([RMSE](http://en.wikipedia.org/wiki/Root-mean-square_deviation)) for evaluation purposes. Implement a function to compute RMSE given an RDD of (label, prediction) tuples, and test out this function on an example.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875176,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4d85c7d1-d657-4d28-948c-33b1f4cb79a1\"},{\"version\":\"CommandV1\",\"origId\":1555922344233039,\"guid\":\"270d7a5a-7657-4f67-8cec-1d588bc94f4b\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":24.0,\"command\":\"# TODO: Replace with appropriate code\\nimport math\\ndef squaredError(label, prediction):\\n \\\"\\\"\\\"Calculates the the squared error for a single prediction.\\n\\n Args:\\n label (float): The correct value for this observation.\\n prediction (float): The predicted value for this observation.\\n\\n Returns:\\n float: The difference between the `label` and `prediction` squared.\\n \\\"\\\"\\\"\\n return (prediction - label)**2\\n\\ndef calcRMSE(labelsAndPreds):\\n \\\"\\\"\\\"Calculates the root mean squared error for an `RDD` of (label, prediction) tuples.\\n\\n Args:\\n labelsAndPred (RDD of (float, float)): An `RDD` consisting of (label, prediction) tuples.\\n\\n Returns:\\n float: The square root of the mean of the squared errors.\\n \\\"\\\"\\\"\\n return math.sqrt(labelsAndPreds.map(lambda x: squaredError(x[0],x[1])).sum()/labelsAndPreds.count())\\n\\nlabelsAndPreds = sc.parallelize([(3., 1.), (1., 2.), (2., 2.)])\\n# RMSE = sqrt[((3-1)^2 + (1-2)^2 + (2-2)^2) / 3] = 1.291\\nexampleRMSE = calcRMSE(labelsAndPreds)\\nprint exampleRMSE\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"1.29099444874\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"NameError: global name &apos;math&apos; is not defined\",\"error\":null,\"workflows\":[],\"startTime\":1492390915512,\"submitTime\":1492390875190,\"finishTime\":1492390915789,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"d1fa89ad-9e4f-45ae-9383-e94031a8ea7e\"},{\"version\":\"CommandV1\",\"origId\":1555922344233040,\"guid\":\"9b5466d4-eded-4f98-977b-10bfe0df612e\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":25.0,\"command\":\"%md #### **(2c) Training, validation and test RMSE **\\n#### Now let's calculate the training, validation and test RMSE of our baseline model. To do this, first create RDDs of (label, prediction) tuples for each dataset, and then call calcRMSE. Note that each RMSE can be interpreted as the average prediction error for the given dataset (in terms of number of years).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875198,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"7b530f5d-d4e6-4fe3-a1d1-b7480e86cf56\"},{\"version\":\"CommandV1\",\"origId\":1555922344233041,\"guid\":\"7d0c34c4-5a8b-49a5-8214-1ffa54db432b\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":26.0,\"command\":\"# TODO: Replace with appropriate code\\nlabelsAndPredsTrain = parsedTrainData.map(lambda x: (x.label,averageTrainYear))\\nrmseTrainBase = calcRMSE(labelsAndPredsTrain)\\n\\nlabelsAndPredsVal = parsedValData.map(lambda x: (x.label,averageTrainYear))\\nrmseValBase = calcRMSE(labelsAndPredsVal)\\n\\nlabelsAndPredsTest = parsedTestData.map(lambda x: (x.label,averageTrainYear))\\nrmseTestBase = calcRMSE(labelsAndPredsTest)\\n\\nprint 'Baseline Train RMSE = {0:.3f}'.format(rmseTrainBase)\\nprint 'Baseline Validation RMSE = {0:.3f}'.format(rmseValBase)\\nprint 'Baseline Test RMSE = {0:.3f}'.format(rmseTestBase)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"Baseline Train RMSE = 21.306\\nBaseline Validation RMSE = 21.586\\nBaseline Test RMSE = 22.137\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390915799,\"submitTime\":1492390875214,\"finishTime\":1492390916376,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"417670be-6ee8-4ee1-968d-4936f5dd601f\"},{\"version\":\"CommandV1\",\"origId\":1555922344233042,\"guid\":\"b82db6f1-dd95-42b7-b7a2-4c5f63fc34b0\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":27.0,\"command\":\"%md #### ** Visualization 3: Predicted vs. actual **\\n#### We will visualize predictions on the validation dataset. The scatter plots below visualize tuples storing i) the predicted value and ii) true label. The first scatter plot represents the ideal situation where the predicted value exactly equals the true label, while the second plot uses the baseline predictor (i.e., `averageTrainYear`) for all predicted values. Further note that the points in the scatter plots are color-coded, ranging from light yellow when the true and predicted values are equal to bright red when they drastically differ.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875222,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ca958be9-c2a0-4529-8b03-3ffa24ec5f01\"},{\"version\":\"CommandV1\",\"origId\":1555922344233043,\"guid\":\"e108ecb7-a0a1-45b1-a97f-43fdad9aa6d9\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":28.0,\"command\":\"from matplotlib.colors import ListedColormap, Normalize\\nfrom matplotlib.cm import get_cmap\\ncmap = get_cmap('YlOrRd')\\nnorm = Normalize()\\n\\nactual = np.asarray(parsedValData\\n .map(lambda lp: lp.label)\\n .collect())\\nerror = np.asarray(parsedValData\\n .map(lambda lp: (lp.label, lp.label))\\n .map(lambda (l, p): squaredError(l, p))\\n .collect())\\nclrs = cmap(np.asarray(norm(error)))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(0, 100, 20), np.arange(0, 100, 20))\\nplt.scatter(actual, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.5)\\nax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390916383,\"submitTime\":1492390875255,\"finishTime\":1492390917233,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"8790195e-9d8c-4d6c-a9fe-11932151b660\"},{\"version\":\"CommandV1\",\"origId\":1555922344233044,\"guid\":\"d2ae11ac-5c0f-4a95-bbb8-6f1690ba0a7e\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":29.0,\"command\":\"predictions = np.asarray(parsedValData\\n .map(lambda lp: averageTrainYear)\\n .collect())\\nerror = np.asarray(parsedValData\\n .map(lambda lp: (lp.label, averageTrainYear))\\n .map(lambda (l, p): squaredError(l, p))\\n .collect())\\nnorm = Normalize()\\nclrs = cmap(np.asarray(norm(error)))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(53.0, 55.0, 0.5), np.arange(0, 100, 20))\\nax.set_xlim(53, 55)\\nplt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.3)\\nax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390917239,\"submitTime\":1492390875263,\"finishTime\":1492390917971,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"51877464-fd54-4ad4-ada6-4ea24dcde1ef\"},{\"version\":\"CommandV1\",\"origId\":1555922344233045,\"guid\":\"d8589dda-d037-4e1a-99ad-4e52acaa0d0c\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":30.0,\"command\":\"%md ### ** Part 3: Train Least Squares Linear Regression (via gradient descent) and evaluate a linear regression model **\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875270,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"92162183-e96c-4c76-b7dd-ce886800acf8\"},{\"version\":\"CommandV1\",\"origId\":1555922344233046,\"guid\":\"240d441f-bfa0-4c18-8159-be71d2a06041\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":31.0,\"command\":\"%md #### ** (3a) Gradient summand **\\n#### Now let's see if we can do better via linear regression, training a model via gradient descent (we'll omit the intercept for now). Recall that the gradient descent update for linear regression is: $$ \\\\scriptsize \\\\mathbf{w}_{i+1} = \\\\mathbf{w}_i - \\\\alpha_i \\\\sum_j (\\\\mathbf{w}_i^\\\\top\\\\mathbf{x}_j - y_j) \\\\mathbf{x}_j \\\\,.$$ where i is the iteration number of the gradient descent algorithm, and j identifies the observation.\\n#### First, implement a function that computes the summand for this update, i.e., the summand equals $$ (\\\\mathbf{w}^\\\\top \\\\mathbf{x} - y) \\\\mathbf{x} \\\\, ,$$ and test out this function on two examples. Use the `DenseVector` [dot](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.DenseVector.dot) method.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875286,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"de8c3b54-fb57-48e8-a8f7-cf2d2ab37b2f\"},{\"version\":\"CommandV1\",\"origId\":1555922344233047,\"guid\":\"76007047-bbf9-4267-bced-8ad5e6418dc7\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":32.0,\"command\":\"from pyspark.mllib.linalg import DenseVector\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390917985,\"submitTime\":1492390875299,\"finishTime\":1492390918024,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"1b48a08d-dbc7-49c6-820e-60fdb90ec972\"},{\"version\":\"CommandV1\",\"origId\":1555922344233048,\"guid\":\"bccf7044-a65a-4dcc-a4c8-6b7217218fa3\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":33.0,\"command\":\"# TODO: Replace with appropriate code\\ndef gradientSummand(weights, lp):\\n \\\"\\\"\\\"Calculates the gradient summand for a given weight and `LabeledPoint`.\\n\\n Note:\\n `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\\n within this function. For example, they both implement the `dot` method.\\n\\n Args:\\n weights (DenseVector): An array of model weights (betas).\\n lp (LabeledPoint): The `LabeledPoint` for a single observation.\\n\\n Returns:\\n DenseVector: An array of values the same length as `weights`. The gradient summand.\\n \\\"\\\"\\\"\\n return (weights.T.dot(lp.features) - lp.label) * lp.features\\n\\nexampleW = DenseVector([1, 1, 1])\\nexampleLP = LabeledPoint(2.0, [3, 1, 4])\\n# gradientSummand = (dot([1 1 1], [3 1 4]) - 2) * [3 1 4] = (8 - 2) * [3 1 4] = [18 6 24]\\nsummandOne = gradientSummand(exampleW, exampleLP)\\nprint summandOne\\n\\nexampleW = DenseVector([.24, 1.2, -1.4])\\nexampleLP = LabeledPoint(3.0, [-1.4, 4.2, 2.1])\\nsummandTwo = gradientSummand(exampleW, exampleLP)\\nprint summandTwo\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"[18.0,6.0,24.0]\\n[1.7304,-5.1912,-2.5956]\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"NameError: name &apos;DenseVector&apos; is not defined\",\"error\":null,\"workflows\":[],\"startTime\":1492390918032,\"submitTime\":1492390875307,\"finishTime\":1492390918106,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"091d1a14-0e8c-4255-ac48-a3c539d00040\"},{\"version\":\"CommandV1\",\"origId\":1555922344233049,\"guid\":\"1f228f4c-7b89-416d-bc08-ca22beccbb99\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":34.0,\"command\":\"%md #### ** (3b) Use weights to make predictions **\\n#### Next, implement a `getLabeledPredictions` function that takes in weights and an observation's `LabeledPoint` and returns a (label, prediction) tuple. Note that we can predict by computing the dot product between weights and an observation's features.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875314,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"d01a1875-ff44-4bd3-b600-796aef7eff9c\"},{\"version\":\"CommandV1\",\"origId\":1555922344233050,\"guid\":\"f6d30c1c-76eb-488a-aed0-4c24598745d7\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":35.0,\"command\":\"# TODO: Replace with appropriate code\\ndef getLabeledPrediction(weights, observation):\\n \\\"\\\"\\\"Calculates predictions and returns a (label, prediction) tuple.\\n\\n Note:\\n The labels should remain unchanged as we'll use this information to calculate prediction\\n error later.\\n\\n Args:\\n weights (np.ndarray): An array with one weight for each features in `trainData`.\\n observation (LabeledPoint): A `LabeledPoint` that contain the correct label and the\\n features for the data point.\\n\\n Returns:\\n tuple: A (label, prediction) tuple.\\n \\\"\\\"\\\"\\n return (observation.label, observation.features.dot(weights))\\n\\nweights = np.array([1.0, 1.5])\\npredictionExample = sc.parallelize([LabeledPoint(2, np.array([1.0, .5])),\\n LabeledPoint(1.5, np.array([.5, .5]))])\\nlabelsAndPredsExample = predictionExample.map(lambda lp: getLabeledPrediction(weights, lp))\\nprint labelsAndPredsExample.collect()\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"[(2.0, 1.75), (1.5, 1.25)]\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"SyntaxError: invalid syntax\",\"error\":null,\"workflows\":[],\"startTime\":1492390918113,\"submitTime\":1492390875328,\"finishTime\":1492390918285,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"0ed312f3-0867-4469-a319-df5dad68d3a3\"},{\"version\":\"CommandV1\",\"origId\":1555922344233051,\"guid\":\"e223714a-1c82-4c29-87c1-ce2aeb0c2bc5\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":36.0,\"command\":\"%md #### ** (3c) Gradient descent **\\n#### Next, implement a gradient descent function for linear regression and test out this function on an example.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875336,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4ac291a2-de7a-4e6a-9645-baaeec808a71\"},{\"version\":\"CommandV1\",\"origId\":1555922344233052,\"guid\":\"997cd743-5677-450e-8ce5-2f9327febc94\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":37.0,\"command\":\"# TODO: Replace with appropriate code\\ndef linregGradientDescent(trainData, numIters):\\n \\\"\\\"\\\"Calculates the weights and error for a linear regression model trained with gradient descent.\\n\\n Note:\\n `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\\n within this function. For example, they both implement the `dot` method.\\n\\n Args:\\n trainData (RDD of LabeledPoint): The labeled data for use in training the model.\\n numIters (int): The number of iterations of gradient descent to perform.\\n\\n Returns:\\n (np.ndarray, np.ndarray): A tuple of (weights, training errors). Weights will be the\\n final weights (one weight per feature) for the model, and training errors will contain\\n an error (RMSE) for each iteration of the algorithm.\\n \\\"\\\"\\\"\\n # The length of the training data\\n n = trainData.count()\\n # The number of features in the training data\\n d = len(trainData.take(1)[0].features)\\n w = np.zeros(d)\\n alpha = 1.0\\n # We will compute and store the training error after each iteration\\n errorTrain = np.zeros(numIters)\\n for i in range(numIters):\\n # Use getLabeledPrediction from (3b) with trainData to obtain an RDD of (label, prediction)\\n # tuples. Note that the weights all equal 0 for the first iteration, so the predictions will\\n # have large errors to start.\\n labelsAndPredsTrain = trainData.map(lambda lp: getLabeledPrediction(w, lp))\\n errorTrain[i] = calcRMSE(labelsAndPredsTrain)\\n\\n # Calculate the `gradient`. Make use of the `gradientSummand` function you wrote in (3a).\\n # Note that `gradient` sould be a `DenseVector` of length `d`.\\n gradient = trainData.map(lambda lp: gradientSummand(w, lp)).sum()\\n\\n # Update the weights\\n alpha_i = alpha / (n * np.sqrt(i+1))\\n w -= alpha_i * gradient\\n return w, errorTrain\\n\\n# create a toy dataset with n = 10, d = 3, and then run 5 iterations of gradient descent\\n# note: the resulting model will not be useful; the goal here is to verify that\\n# linregGradientDescent is working properly\\nexampleN = 10\\nexampleD = 3\\nexampleData = (sc\\n .parallelize(parsedTrainData.take(exampleN))\\n .map(lambda lp: LabeledPoint(lp.label, lp.features[0:exampleD])))\\nprint exampleData.take(2)\\nexampleNumIters = 5\\nexampleWeights, exampleErrorTrain = linregGradientDescent(exampleData, exampleNumIters)\\nprint exampleWeights\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"[LabeledPoint(79.0, [0.884123733793,0.610454259079,0.600498416968]), LabeledPoint(79.0, [0.854411946129,0.604124786151,0.593634078776])]\\n[ 48.88110449 36.01144093 30.25350092]\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390918293,\"submitTime\":1492390875365,\"finishTime\":1492390919908,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"d4cb893e-95d4-48a3-a698-3b05bde1e354\"},{\"version\":\"CommandV1\",\"origId\":1555922344233053,\"guid\":\"f47da6ef-ad41-45e6-8498-273a8f2f6e69\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":38.0,\"command\":\"%md #### ** (3d) Train the model **\\n#### Now let's train a linear regression model on all of our training data and evaluate its accuracy on the validation set. Note that the test set will not be used here. If we evaluated the model on the test set, we would bias our final results.\\n#### We've already done much of the required work: we computed the number of features in Part (1b); we created the training and validation datasets and computed their sizes in Part (1e); and, we wrote a function to compute RMSE in Part (2b).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875374,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"eb7ae588-7f8c-49be-a030-ed701db3ef25\"},{\"version\":\"CommandV1\",\"origId\":1555922344233054,\"guid\":\"dd597aff-8992-4a3d-a033-a4dd30e4a256\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":39.0,\"command\":\"# TODO: Replace with appropriate code\\nnumIters = 50\\nweightsLR0, errorTrainLR0 = linregGradientDescent(parsedTrainData,numIters)\\n\\nlabelsAndPreds = parsedValData.map(lambda lp: getLabeledPrediction(weightsLR0, lp))\\nrmseValLR0 = calcRMSE(labelsAndPreds)\\n\\nprint 'Validation RMSE:\\\\n\\\\tBaseline = {0:.3f}\\\\n\\\\tLR0 = {1:.3f}'.format(rmseValBase,\\n rmseValLR0)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"Validation RMSE:\\n\\tBaseline = 21.586\\n\\tLR0 = 19.192\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390919915,\"submitTime\":1492390875392,\"finishTime\":1492390932205,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"64ddde7f-2dc8-44b5-9710-c94cc3470f62\"},{\"version\":\"CommandV1\",\"origId\":1555922344233055,\"guid\":\"eacb5569-910d-4685-ba39-0bc2f6e8fbde\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":40.0,\"command\":\"%md #### ** Visualization 4: Training error **\\n#### We will look at the log of the training error as a function of iteration. The first scatter plot visualizes the logarithm of the training error for all 50 iterations. The second plot shows the training error itself, focusing on the final 44 iterations.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875401,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"580bb4a5-acf9-4482-b0df-1e2ac4cc2cfd\"},{\"version\":\"CommandV1\",\"origId\":1555922344233056,\"guid\":\"009a84b8-9247-4985-85da-504aa30b9b4e\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":41.0,\"command\":\"norm = Normalize()\\nclrs = cmap(np.asarray(norm(np.log(errorTrainLR0))))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(0, 60, 10), np.arange(2, 6, 1))\\nax.set_ylim(2, 6)\\nplt.scatter(range(0, numIters), np.log(errorTrainLR0), s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\\nax.set_xlabel('Iteration'), ax.set_ylabel(r'$\\\\log_e(errorTrainLR0)$')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390932213,\"submitTime\":1492390875414,\"finishTime\":1492390933140,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":true,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ebf89f89-9245-44f6-80d7-97e2531ffe7d\"},{\"version\":\"CommandV1\",\"origId\":1555922344233057,\"guid\":\"cf495fe2-7909-4444-8fad-f5271b9477f4\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":42.0,\"command\":\"norm = Normalize()\\nclrs = cmap(np.asarray(norm(errorTrainLR0[6:])))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(0, 60, 10), np.arange(17, 22, 1))\\nax.set_ylim(17.8, 21.2)\\nplt.scatter(range(0, numIters-6), errorTrainLR0[6:], s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\\nax.set_xticklabels(map(str, range(6, 66, 10)))\\nax.set_xlabel('Iteration'), ax.set_ylabel(r'Training Error')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390933146,\"submitTime\":1492390875422,\"finishTime\":1492390933679,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":true,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"80b3c472-0d76-405f-af0e-c968bb08200b\"},{\"version\":\"CommandV1\",\"origId\":1555922344233058,\"guid\":\"7ff2e0ff-2412-4a72-8c90-c23b47c59890\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":43.0,\"command\":\"%md ### ** Part 4: Train Least Squares Linear Regression with L2 regularization (via gradient descent) and evaluate a linear regression model **\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875430,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"6e89579a-a1fc-4962-b2da-d0943c3458cf\"},{\"version\":\"CommandV1\",\"origId\":1555922344233059,\"guid\":\"8c30d4c1-5794-4d00-afbc-742eadb977da\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":44.0,\"command\":\"%md #### ** (4a) Gradient summand **\\n#### Recall that the gradient descent update for linear regression with L2 regularization is: $$ \\\\scriptsize \\\\mathbf{w}_{i+1} = \\\\mathbf{w}_i - \\\\alpha_i \\\\left( \\\\sum_j (\\\\mathbf{w}_i^\\\\top\\\\mathbf{x}_j - y_j) \\\\mathbf{x}_j + \\\\eta \\\\mathbf{w}_i \\\\right) \\\\,.$$ where i is the iteration number of the gradient descent algorithm, and j identifies the observation.\\n#### We have already implemented the function gradientSummand that computes the summand for this update, i.e., $$ (\\\\mathbf{w}^\\\\top \\\\mathbf{x} - y) \\\\mathbf{x} \\\\,$$\\n#### We have also already implemented the `getLabeledPredictions` function that takes in weights and an observation's `LabeledPoint` and returns a (label, prediction) tuple.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875443,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"80ebc8ce-c049-4493-8424-e6cc3c774522\"},{\"version\":\"CommandV1\",\"origId\":1555922344233060,\"guid\":\"e11db638-0452-41d1-abf3-0ef11a6c2655\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":45.0,\"command\":\"%md #### ** (4b) Gradient descent with L2 regularization **\\n#### Next, implement a gradient descent function for linear regression with L2 regularization and test out this function on an example.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875456,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ca606295-d904-43cd-aa2f-7222a8e4c2b8\"},{\"version\":\"CommandV1\",\"origId\":1555922344233061,\"guid\":\"96dde286-04db-49da-a8ce-351e4b37cd83\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":46.0,\"command\":\"# TODO: Replace with appropriate code\\ndef linregGradientDescentWithL2Regularization(trainData, numIters):\\n \\\"\\\"\\\"Calculates the weights and error for a linear regression model with L2 regularization trained with gradient descent.\\n\\n Note:\\n `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\\n within this function. For example, they both implement the `dot` method.\\n\\n Args:\\n trainData (RDD of LabeledPoint): The labeled data for use in training the model.\\n numIters (int): The number of iterations of gradient descent to perform.\\n\\n Returns:\\n (np.ndarray, np.ndarray): A tuple of (weights, training errors). Weights will be the\\n final weights (one weight per feature) for the model, and training errors will contain\\n an error (RMSE) for each iteration of the algorithm.\\n \\\"\\\"\\\"\\n # The length of the training data\\n n = trainData.count()\\n # The number of features in the training data\\n d = len(trainData.take(1)[0].features)\\n w = np.zeros(d)\\n alpha = 1.0 # step\\n eta = 1e-1 # regParam\\n regType = 'l2' # regType\\n # We will compute and store the training error after each iteration\\n errorTrain = np.zeros(numIters)\\n for i in range(numIters):\\n # Use getLabeledPrediction from (3b) with trainData to obtain an RDD of (label, prediction)\\n # tuples. Note that the weights all equal 0 for the first iteration, so the predictions will\\n # have large errors to start.\\n labelsAndPredsTrain = trainData.map(lambda lp: getLabeledPrediction(w, lp))\\n errorTrain[i] = calcRMSE(labelsAndPredsTrain)\\n\\n # Calculate the `gradient`. Make use of the `gradientSummand` function you wrote in (3a).\\n # Be sure to properly account for the regularization term in the update.\\n # Note that `gradient` sould be a `DenseVector` of length `d`.\\n gradient = trainData.map(lambda lp: gradientSummand(w, lp)).sum() + eta * w\\n\\n\\n # Update the weights\\n alpha_i = alpha / (n * np.sqrt(i+1))\\n w -= alpha_i * gradient\\n return w, errorTrain\\n\\n# create a toy dataset with n = 10, d = 3, and then run 5 iterations of gradient descent\\n# note: the resulting model will not be useful; the goal here is to verify that\\n# linregGradientDescent is working properly\\nexampleN = 10\\nexampleD = 3\\nexampleData = (sc\\n .parallelize(parsedTrainData.take(exampleN))\\n .map(lambda lp: LabeledPoint(lp.label, lp.features[0:exampleD])))\\nprint exampleData.take(2)\\nexampleNumIters = 5\\nexampleWeights, exampleErrorTrain = linregGradientDescentWithL2Regularization(exampleData, exampleNumIters)\\nprint exampleWeights\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"[LabeledPoint(79.0, [0.884123733793,0.610454259079,0.600498416968]), LabeledPoint(79.0, [0.854411946129,0.604124786151,0.593634078776])]\\n[ 48.52247518 35.74064704 30.03664683]\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390933685,\"submitTime\":1492390875477,\"finishTime\":1492390935201,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":true,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"e739218a-1fb3-4556-881c-ffa198f91db9\"},{\"version\":\"CommandV1\",\"origId\":1555922344233062,\"guid\":\"1c3088e6-82fa-4bd3-9edb-7a52eb41a1cb\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":47.0,\"command\":\"%md #### ** (4c) Train the model **\\n#### Now let's train a regularized linear regression model on all of our training data and evaluate its accuracy on the validation set. Note that the test set will not be used here. If we evaluated the model on the test set, we would bias our final results.\\n#### We've already done much of the required work: we computed the number of features in Part (1b); we created the training and validation datasets and computed their sizes in Part (1e); and, we wrote a function to compute RMSE in Part (2b).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875485,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ee8d6f63-b833-4d50-b6fe-f56df7f49d6c\"},{\"version\":\"CommandV1\",\"origId\":1555922344233063,\"guid\":\"2dd6970c-d105-4ebc-a426-6b87c425ca29\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":48.0,\"command\":\"# TODO: Replace with appropriate code\\nnumIters = 50\\nweightsRegularizedLR, errorTrainRegularizedLR = linregGradientDescentWithL2Regularization(parsedTrainData,numIters)\\n\\nlabelsAndPreds = parsedValData.map(lambda lp: getLabeledPrediction(weightsRegularizedLR, lp))\\nrmseValRegularizedLR = calcRMSE(labelsAndPreds)\\n\\nprint 'Validation RMSE:\\\\n\\\\tBaseline = {0:.3f}\\\\n\\\\tLR0 = {1:.3f}'.format(rmseValBase,\\n rmseValRegularizedLR)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"Validation RMSE:\\n\\tBaseline = 21.586\\n\\tLR0 = 19.192\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390935208,\"submitTime\":1492390875502,\"finishTime\":1492390946971,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":true,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"5a9f2752-8fcf-470d-a955-c7640693f43f\"},{\"version\":\"CommandV1\",\"origId\":1555922344233064,\"guid\":\"f6a1dad9-b9fa-42a3-bd99-a2bb54ddad13\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":49.0,\"command\":\"%md #### ** Visualization 5: Training error **\\n#### We will look at the log of the training error as a function of iteration. The first scatter plot visualizes the logarithm of the training error for all 50 iterations. The second plot shows the training error itself, focusing on the final 44 iterations.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875510,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"1ee60abc-4095-4eaf-95a2-13e9866375e7\"},{\"version\":\"CommandV1\",\"origId\":1555922344233065,\"guid\":\"b81b5916-905c-4a48-b06b-b8702bc1c620\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":50.0,\"command\":\"norm = Normalize()\\nclrs = cmap(np.asarray(norm(np.log(errorTrainRegularizedLR))))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(0, 60, 10), np.arange(2, 6, 1))\\nax.set_ylim(2, 6)\\nplt.scatter(range(0, numIters), np.log(errorTrainRegularizedLR), s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\\nax.set_xlabel('Iteration'), ax.set_ylabel(r'$\\\\log_e(errorTrainRegularizedLR)$')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390946977,\"submitTime\":1492390875530,\"finishTime\":1492390947572,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"f8a2e931-4384-4a75-a06a-558f85237b9e\"},{\"version\":\"CommandV1\",\"origId\":1555922344233066,\"guid\":\"567a0174-6e63-4a22-b427-623a5242495c\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":51.0,\"command\":\"norm = Normalize()\\nclrs = cmap(np.asarray(norm(errorTrainRegularizedLR[6:])))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(0, 60, 10), np.arange(17, 22, 1))\\nax.set_ylim(17.8, 21.2)\\nplt.scatter(range(0, numIters-6), errorTrainRegularizedLR[6:], s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\\nax.set_xticklabels(map(str, range(6, 66, 10)))\\nax.set_xlabel('Iteration'), ax.set_ylabel(r'Training Error (L2 Regularization)')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390947577,\"submitTime\":1492390875538,\"finishTime\":1492390948229,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"816a983c-a7ec-41de-9f8b-cebd855b1c49\"},{\"version\":\"CommandV1\",\"origId\":1555922344233067,\"guid\":\"b4b4f00e-45b7-460e-ad00-7b9b3d0f45ee\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":52.0,\"command\":\"%md ### ** Part 5: Train using MLlib and perform grid search **\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875546,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"11be796d-66ee-4db7-a325-2d81bfd6064c\"},{\"version\":\"CommandV1\",\"origId\":1555922344233068,\"guid\":\"23a9d522-5ff9-4045-8064-45626040858a\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":53.0,\"command\":\"%md #### **(5a) `LinearRegressionWithSGD` **\\n#### We're already doing better than the baseline model, but let's see if we can do better by adding an intercept, using regularization (which we briefly explored earlier), and (based on the previous visualization) training for more iterations. MLlib's [LinearRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionWithSGD) essentially implements the same algorithm that we implemented in Part (3b), albeit more efficiently and with various additional functionality, such as stochastic gradient approximation, including an intercept in the model and also allowing L1 or L2 regularization. First use LinearRegressionWithSGD to train a model with L2 regularization and with an intercept. This method returns a [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel). Next, use the model's [weights](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.weights) and [intercept](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.intercept) attributes to print out the model's parameters.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875565,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"06f6e709-97e3-4b90-94f4-6453631f65c1\"},{\"version\":\"CommandV1\",\"origId\":1555922344233069,\"guid\":\"23e52128-fc7c-42ae-8ba9-d59103fd284f\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":54.0,\"command\":\"from pyspark.mllib.regression import LinearRegressionWithSGD\\n# Values to use when training the linear regression model\\nnumIters = 500 # iterations\\nalpha = 1.0 # step\\nminiBatchFrac = 1.0 # miniBatchFraction\\nreg = 1e-1 # regParam\\nregType = 'l2' # regType\\nuseIntercept = True # intercept\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":1492390948234,\"submitTime\":1492390875586,\"finishTime\":1492390948307,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"5944bf49-e762-4833-a30d-6629a5e322b0\"},{\"version\":\"CommandV1\",\"origId\":1555922344233070,\"guid\":\"afd1e315-ff8c-4383-8de1-751491e8a5d3\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":55.0,\"command\":\"# TODO: Replace with appropriate code\\nfirstModel = LinearRegressionWithSGD.train(parsedTrainData, iterations=numIters, miniBatchFraction=miniBatchFrac, regParam=reg, regType=regType, intercept=useIntercept)\\n\\n# weightsLR1 stores the model weights; interceptLR1 stores the model intercept\\nweightsLR1 = firstModel.weights\\ninterceptLR1 = firstModel.intercept\\nprint weightsLR1, interceptLR1\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"/databricks/spark/python/pyspark/mllib/regression.py:281: UserWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.\\n warnings.warn(&quot;Deprecated in 2.0.0. Use ml.regression.LinearRegression.&quot;)\\n[15.9789216525,13.923582484,0.781551054803,6.09257051566,3.91814791179,-2.30347707767,10.3002026917,3.04565129011,7.23175674717,4.65796458476,7.98875075855,3.1782463856] 13.3763009811\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"NameError: name &apos;LinearRegressionWithSGD&apos; is not defined\",\"error\":null,\"workflows\":[],\"startTime\":1492390948311,\"submitTime\":1492390875594,\"finishTime\":1492390950731,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"e4d0dda2-0f3c-4128-9ac2-7838c5474b4d\"},{\"version\":\"CommandV1\",\"origId\":1555922344233071,\"guid\":\"f3923643-a484-4527-87ef-49edbd0e25e9\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":56.0,\"command\":\"%md #### **(5b) Predict**\\n#### Now use the [LinearRegressionModel.predict()](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LinearRegressionModel.predict) method to make a prediction on a sample point. Pass the `features` from a `LabeledPoint` into the `predict()` method.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875602,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"f13a78b2-10f6-4c48-b1d3-2f42f81daada\"},{\"version\":\"CommandV1\",\"origId\":1555922344233072,\"guid\":\"005addfc-1656-4d98-8d04-495b4c2e844d\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":57.0,\"command\":\"# TODO: Replace with appropriate code\\nsamplePoint = parsedTrainData.take(1)[0]\\nsamplePrediction = firstModel.predict(samplePoint.features)\\nprint samplePrediction\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"56.5823796609\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"AttributeError: &apos;LabeledPoint&apos; object has no attribute &apos;map&apos;\",\"error\":null,\"workflows\":[],\"startTime\":1492390950739,\"submitTime\":1492390875628,\"finishTime\":1492390950811,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ef496a17-7b25-4a8c-843a-8d5d09f2f14f\"},{\"version\":\"CommandV1\",\"origId\":1555922344233074,\"guid\":\"1b466f11-edef-4fb6-ba47-46a8aa3c3adc\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":59.0,\"command\":\"%md #### ** (5c) Evaluate RMSE **\\n#### Next evaluate the accuracy of this model on the validation set. Use the `predict()` method to create a `labelsAndPreds` RDD, and then use the `calcRMSE()` function from Part (2b).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875636,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"e9337a9b-a5fa-432b-a4cc-c196182a846c\"},{\"version\":\"CommandV1\",\"origId\":1555922344233075,\"guid\":\"f0dcfa09-b15b-4ba9-9b14-4415167602e5\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":60.0,\"command\":\"# TODO: Replace with appropriate code\\nlabelsAndPreds = parsedValData.map(lambda lp: (lp.label, firstModel.predict(lp.features)))\\nrmseValLR1 = calcRMSE(labelsAndPreds)\\n\\nprint ('Validation RMSE:\\\\n\\\\tBaseline = {0:.3f}\\\\n\\\\tLR0 = {1:.3f}' +\\n '\\\\n\\\\tLR1 = {2:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"Validation RMSE:\\n\\tBaseline = 21.586\\n\\tLR0 = 19.192\\n\\tLR1 = 19.873\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390950816,\"submitTime\":1492390875649,\"finishTime\":1492390950988,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"5c28cb80-edbd-48bc-ba11-2d284d37e6a1\"},{\"version\":\"CommandV1\",\"origId\":1555922344233076,\"guid\":\"0af6a05f-fbd2-4792-8913-68e5a07ec023\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":61.0,\"command\":\"%md #### ** (5d) Grid search **\\n#### We're already outperforming the baseline on the validation set by almost 2 years on average, but let's see if we can do better. Perform grid search to find a good regularization parameter. Try `regParam` values `1e-10`, `1e-5`, and `1`.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875657,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4144223c-2888-4d66-b1ba-72d5d3b60aaf\"},{\"version\":\"CommandV1\",\"origId\":1555922344233077,\"guid\":\"8a63324f-2028-437a-9d59-1e3d30fe2eb7\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":62.0,\"command\":\"# TODO: Replace with appropriate code\\nbestRMSE = rmseValLR1\\nbestRegParam = reg\\nbestModel = firstModel\\n\\nnumIters = 500\\nalpha = 1.0\\nminiBatchFrac = 1.0\\nfor reg in [1e-10, 1e-5, 1]:\\n model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\\n miniBatchFrac, regParam=reg,\\n regType='l2', intercept=True)\\n labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\\n rmseValGrid = calcRMSE(labelsAndPreds)\\n print rmseValGrid\\n\\n if rmseValGrid < bestRMSE:\\n bestRMSE = rmseValGrid\\n bestRegParam = reg\\n bestModel = model\\nrmseValLRGrid = bestRMSE\\n\\nprint ('Validation RMSE:\\\\n\\\\tBaseline = {0:.3f}\\\\n\\\\tLR0 = {1:.3f}\\\\n\\\\tLR1 = {2:.3f}\\\\n' +\\n '\\\\tLRGrid = {3:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1, rmseValLRGrid)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"17.4831362704\\n17.4834818658\\n23.8000672935\\nValidation RMSE:\\n\\tBaseline = 21.586\\n\\tLR0 = 19.192\\n\\tLR1 = 19.873\\n\\tLRGrid = 17.483\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390950994,\"submitTime\":1492390875675,\"finishTime\":1492390960367,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ec4406d1-3f53-4969-b9f2-663e2d9bb975\"},{\"version\":\"CommandV1\",\"origId\":1555922344233078,\"guid\":\"15d1a113-1cf8-408f-bc69-d9e7e71a6ada\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":63.0,\"command\":\"%md #### ** Visualization 6: Best model's predictions**\\n#### Next, we create a visualization similar to 'Visualization 3: Predicted vs. actual' from Part 3 using the predictions from the best model from Part (5d) on the validation dataset. Specifically, we create a color-coded scatter plot visualizing tuples storing i) the predicted value from this model and ii) true label.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875683,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"99b0057c-bfdf-45d7-8f77-938ce79fdd01\"},{\"version\":\"CommandV1\",\"origId\":1555922344233079,\"guid\":\"420a605c-a2fc-4bed-807d-13687abc4035\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":64.0,\"command\":\"predictions = np.asarray(parsedValData\\n .map(lambda lp: bestModel.predict(lp.features))\\n .collect())\\nactual = np.asarray(parsedValData\\n .map(lambda lp: lp.label)\\n .collect())\\nerror = np.asarray(parsedValData\\n .map(lambda lp: (lp.label, bestModel.predict(lp.features)))\\n .map(lambda (l, p): squaredError(l, p))\\n .collect())\\n\\nnorm = Normalize()\\nclrs = cmap(np.asarray(norm(error)))[:,0:3]\\n\\nfig, ax = preparePlot(np.arange(0, 120, 20), np.arange(0, 120, 20))\\nax.set_xlim(15, 82), ax.set_ylim(-5, 105)\\nplt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=.5)\\nax.set_xlabel('Predicted'), ax.set_ylabel(r'Actual')\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390960374,\"submitTime\":1492390875708,\"finishTime\":1492390961191,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"8fedd3e0-3288-461a-83f6-42f20790befe\"},{\"version\":\"CommandV1\",\"origId\":1555922344233080,\"guid\":\"6b8fe710-f2f3-464d-afbd-a5ec5023d915\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":65.0,\"command\":\"%md #### ** (5e) Vary alpha and the number of iterations **\\n#### In the previous grid search, we set `alpha = 1` for all experiments. Now let's see what happens when we vary `alpha`. Specifically, try `1e-5` and `10` as values for `alpha` and also try training models for 500 iterations (as before) but also for 5 iterations. Evaluate all models on the validation set. Note that if we set `alpha` too small the gradient descent will require a huge number of steps to converge to the solution, and if we use too large of an `alpha` it can cause numerical problems, like you'll see below for `alpha = 10`.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875716,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"ed39975f-4b10-4277-8a62-4e89861775c5\"},{\"version\":\"CommandV1\",\"origId\":1555922344233081,\"guid\":\"92f20afa-bdb4-4658-b93c-2400a23744c8\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":66.0,\"command\":\"# TODO: Replace with appropriate code\\nreg = bestRegParam\\nmodelRMSEs = []\\n\\nfor alpha in [1e-5, 10, 1]:\\n for numIters in [500, 5]:\\n model = LinearRegressionWithSGD.train(parsedTrainData, numIters, alpha,\\n miniBatchFrac, regParam=reg,\\n regType='l2', intercept=True)\\n labelsAndPreds = parsedValData.map(lambda lp: (lp.label, model.predict(lp.features)))\\n rmseVal = calcRMSE(labelsAndPreds)\\n print 'alpha = {0:.0e}, numIters = {1}, RMSE = {2:.3f}'.format(alpha, numIters, rmseVal)\\n modelRMSEs.append(rmseVal)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"alpha = 1e-05, numIters = 500, RMSE = 56.973\\nalpha = 1e-05, numIters = 5, RMSE = 56.973\\nalpha = 1e+01, numIters = 500, RMSE = 33110728225678993724249071515084334709948166884960756405762586052582656490821782231141326865198981397833205889386753818624.000\\nalpha = 1e+01, numIters = 5, RMSE = 355124752.221\\nalpha = 1e+00, numIters = 500, RMSE = 17.483\\nalpha = 1e+00, numIters = 5, RMSE = 246.080\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390961196,\"submitTime\":1492390875741,\"finishTime\":1492390974726,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"f0241858-cdd6-48c6-8afd-0d5c7e6d1fd3\"},{\"version\":\"CommandV1\",\"origId\":1555922344233082,\"guid\":\"361908bc-790a-45ad-ab94-a36afcf9d354\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":67.0,\"command\":\"%md #### **Visualization 7: Hyperparameter heat map **\\n#### Next, we perform a visualization of hyperparameter search using a larger set of hyperparameters (with precomputed results). Specifically, we create a heat map where the brighter colors correspond to lower RMSE values. The first plot has a large area with brighter colors. In order to differentiate within the bright region, we generate a second plot corresponding to the hyperparameters found within that region.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875749,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"d685ad00-45aa-4ca6-9c68-08bcf56fa9ee\"},{\"version\":\"CommandV1\",\"origId\":1555922344233083,\"guid\":\"19fc968d-5a95-4265-bcaa-744b28ddb04f\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":68.0,\"command\":\"from matplotlib.colors import LinearSegmentedColormap\\n\\n# Saved parameters and results, to save the time required to run 36 models\\nnumItersParams = [10, 50, 100, 250, 500, 1000]\\nregParams = [1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1]\\nrmseVal = np.array([[ 20.36769649, 20.36770128, 20.36818057, 20.41795354, 21.09778437, 301.54258421],\\n [ 19.04948826, 19.0495 , 19.05067418, 19.16517726, 19.97967727, 23.80077467],\\n [ 18.40149024, 18.40150998, 18.40348326, 18.59457491, 19.82155716, 23.80077467],\\n [ 17.5609346 , 17.56096749, 17.56425511, 17.88442127, 19.71577117, 23.80077467],\\n [ 17.0171705 , 17.01721288, 17.02145207, 17.44510574, 19.69124734, 23.80077467],\\n [ 16.58074813, 16.58079874, 16.58586512, 17.11466904, 19.6860931 , 23.80077467]])\\n\\nnumRows, numCols = len(numItersParams), len(regParams)\\nrmseVal = np.array(rmseVal)\\nrmseVal.shape = (numRows, numCols)\\n\\nfig, ax = preparePlot(np.arange(0, numCols, 1), np.arange(0, numRows, 1), figsize=(8, 7), hideLabels=True,\\n gridWidth=0.)\\nax.set_xticklabels(regParams), ax.set_yticklabels(numItersParams)\\nax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Number of Iterations')\\n\\ncolors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\\nimage = plt.imshow(rmseVal,interpolation='nearest', aspect='auto',\\n cmap = colors)\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390974735,\"submitTime\":1492390875762,\"finishTime\":1492390975502,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"71c52f84-4297-49c4-a651-6a4ed9d08914\"},{\"version\":\"CommandV1\",\"origId\":1555922344233084,\"guid\":\"a7bb92cb-3d9c-4584-8afe-40f1f394bb51\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":69.0,\"command\":\"# Zoom into the bottom left\\nnumItersParamsZoom, regParamsZoom = numItersParams[-3:], regParams[:4]\\nrmseValZoom = rmseVal[-3:, :4]\\n\\nnumRows, numCols = len(numItersParamsZoom), len(regParamsZoom)\\n\\nfig, ax = preparePlot(np.arange(0, numCols, 1), np.arange(0, numRows, 1), figsize=(8, 7), hideLabels=True,\\n gridWidth=0.)\\nax.set_xticklabels(regParamsZoom), ax.set_yticklabels(numItersParamsZoom)\\nax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Number of Iterations')\\n\\ncolors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\\nimage = plt.imshow(rmseValZoom,interpolation='nearest', aspect='auto',\\n cmap = colors)\\ndisplay(fig)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"image\",\"data\":\"data:image/png;base64,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\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390975507,\"submitTime\":1492390875770,\"finishTime\":1492390976059,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"e8fafc2e-ca52-4bf7-9a35-e60be3a4083c\"},{\"version\":\"CommandV1\",\"origId\":1555922344233085,\"guid\":\"93898137-5ceb-4445-89c8-dd3d34e9c5a2\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":70.0,\"command\":\"%md ### ** Part 6: Add interactions between features **\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875778,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"a17a269a-7dd4-46b2-aa21-592c00e75379\"},{\"version\":\"CommandV1\",\"origId\":1555922344233086,\"guid\":\"c29379dc-86e0-44d9-8fd5-c740681750fb\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":71.0,\"command\":\"%md #### ** (6a) Add 2-way interactions **\\n#### So far, we've used the features as they were provided. Now, we will add features that capture the two-way interactions between our existing features. Write a function `twoWayInteractions` that takes in a `LabeledPoint` and generates a new `LabeledPoint` that contains the old features and the two-way interactions between them. Note that a dataset with three features would have nine ( 3^2 ) two-way interactions.\\n#### You might want to use [itertools.product](https://docs.python.org/2/library/itertools.html#itertools.product) to generate tuples for each of the possible 2-way interactions. Remember that you can combine two `DenseVector` or `ndarray` objects using [np.hstack](http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html#numpy.hstack).\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875792,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"db4b96c9-c46f-4f65-b25a-43b336ef4089\"},{\"version\":\"CommandV1\",\"origId\":1555922344233087,\"guid\":\"ddd645ab-7f32-4ae4-aa08-8726d16454cc\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":72.0,\"command\":\"# TODO: Replace with appropriate code\\nimport itertools\\n\\ndef twoWayInteractions(lp):\\n \\\"\\\"\\\"Creates a new `LabeledPoint` that includes two-way interactions.\\n\\n Note:\\n For features [x, y] the two-way interactions would be [x^2, x*y, y*x, y^2] and these\\n would be appended to the original [x, y] feature list.\\n\\n Args:\\n lp (LabeledPoint): The label and features for this observation.\\n\\n Returns:\\n LabeledPoint: The new `LabeledPoint` should have the same label as `lp`. Its features\\n should include the features from `lp` followed by the two-way interaction features.\\n \\\"\\\"\\\"\\n newFeatures = [item[0]*item[1] for item in itertools.product(lp.features, lp.features)]\\n #newFeatures = [reduce(lambda x,y: x*y, f) for f in newFeatures]\\n return LabeledPoint(lp.label, np.hstack((lp.features, newFeatures)))\\n\\nprint twoWayInteractions(LabeledPoint(0.0, [2, 3]))\\n\\n# Transform the existing train, validation, and test sets to include two-way interactions.\\ntrainDataInteract = parsedTrainData.map(lambda lp: twoWayInteractions(lp))\\nvalDataInteract = parsedValData.map(lambda lp: twoWayInteractions(lp))\\ntestDataInteract = parsedTestData.map(lambda lp: twoWayInteractions(lp))\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"(0.0,[2.0,3.0,4.0,6.0,6.0,9.0])\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390976064,\"submitTime\":1492390875809,\"finishTime\":1492390976109,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"2206f5b0-3cb8-4d94-83a5-cad4b56a8070\"},{\"version\":\"CommandV1\",\"origId\":1555922344233088,\"guid\":\"d309ac2a-6b9d-4b0a-bdef-0a728d69c46b\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":73.0,\"command\":\"%md #### ** (6b) Build interaction model **\\n#### Now, let's build the new model. We've done this several times now. To implement this for the new features, we need to change a few variable names. Remember that we should build our model from the training data and evaluate it on the validation data.\\n#### Note that you should re-run your hyperparameter search after changing features, as using the best hyperparameters from your prior model will not necessary lead to the best model. For this exercise, we have already preset the hyperparameters to reasonable values.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875817,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"7e1a502b-b077-4d0b-a6ce-0662ff185954\"},{\"version\":\"CommandV1\",\"origId\":1555922344233089,\"guid\":\"36ee0543-b15f-4a9e-bdfa-69f7d2034299\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":74.0,\"command\":\"# TODO: Replace with appropriate code\\nnumIters = 500\\nalpha = 1.0\\nminiBatchFrac = 1.0\\nreg = 1e-10\\n\\nmodelInteract = LinearRegressionWithSGD.train(trainDataInteract, numIters, alpha,\\n miniBatchFrac, regParam=reg,\\n regType='l2', intercept=True)\\nlabelsAndPredsInteract = valDataInteract.map(lambda lp: (lp.label, modelInteract.predict(lp.features)))\\nrmseValInteract = calcRMSE(labelsAndPredsInteract)\\n\\nprint ('Validation RMSE:\\\\n\\\\tBaseline = {0:.3f}\\\\n\\\\tLR0 = {1:.3f}\\\\n\\\\tLR1 = {2:.3f}\\\\n\\\\tLRGrid = ' +\\n '{3:.3f}\\\\n\\\\tLRInteract = {4:.3f}').format(rmseValBase, rmseValLR0, rmseValLR1,\\n rmseValLRGrid, rmseValInteract)\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"Validation RMSE:\\n\\tBaseline = 21.586\\n\\tLR0 = 19.192\\n\\tLR1 = 19.873\\n\\tLRGrid = 17.483\\n\\tLRInteract = 15.996\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390976120,\"submitTime\":1492390875831,\"finishTime\":1492390979943,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"d8988576-7b20-4a2c-86ae-959d6b808a29\"},{\"version\":\"CommandV1\",\"origId\":1555922344233090,\"guid\":\"8304b5fd-bcd9-4d86-b7c9-91a174a943bc\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":75.0,\"command\":\"%md #### ** (6c) Evaluate interaction model on test data **\\n#### Our final step is to evaluate the new model on the test dataset. Note that we haven't used the test set to evaluate any of our models. Because of this, our evaluation provides us with an unbiased estimate for how our model will perform on new data. If we had changed our model based on viewing its performance on the test set, our estimate of RMSE would likely be overly optimistic.\\n#### We'll also print the RMSE for both the baseline model and our new model. With this information, we can see how much better our model performs than the baseline model.\",\"commandVersion\":1,\"state\":\"finished\",\"results\":null,\"errorSummary\":null,\"error\":null,\"workflows\":[],\"startTime\":0,\"submitTime\":1492390875839,\"finishTime\":0,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"4326d87e-4246-4bd5-a1b5-e1fad711bea2\"},{\"version\":\"CommandV1\",\"origId\":1555922344233091,\"guid\":\"2238aa26-b200-440c-b301-9133a771219d\",\"subtype\":\"command\",\"commandType\":\"auto\",\"position\":76.0,\"command\":\"# TODO: Replace with appropriate code\\nlabelsAndPredsTest = testDataInteract.map(lambda lp: (lp.label, modelInteract.predict(lp.features)))\\nrmseTestInteract = calcRMSE(labelsAndPredsTest)\\n\\nprint ('Test RMSE:\\\\n\\\\tBaseline = {0:.3f}\\\\n\\\\tLRInteract = {1:.3f}'\\n .format(rmseTestBase, rmseTestInteract))\",\"commandVersion\":1,\"state\":\"finished\",\"results\":{\"type\":\"html\",\"data\":\"Test RMSE:\\n\\tBaseline = 22.137\\n\\tLRInteract = 16.525\\n\",\"arguments\":{},\"addedWidgets\":{},\"removedWidgets\":[]},\"errorSummary\":\"Command skipped\",\"error\":null,\"workflows\":[],\"startTime\":1492390979949,\"submitTime\":1492390875856,\"finishTime\":1492390980170,\"collapsed\":false,\"bindings\":{},\"inputWidgets\":{},\"displayType\":\"table\",\"width\":\"auto\",\"height\":\"auto\",\"xColumns\":null,\"yColumns\":null,\"pivotColumns\":null,\"pivotAggregation\":null,\"customPlotOptions\":{},\"commentThread\":[],\"commentsVisible\":false,\"parentHierarchy\":[],\"diffInserts\":[],\"diffDeletes\":[],\"globalVars\":{},\"latestUser\":\"a user\",\"commandTitle\":\"\",\"showCommandTitle\":false,\"hideCommandCode\":false,\"hideCommandResult\":false,\"iPythonMetadata\":{\"collapsed\":false,\"deletable\":true,\"editable\":true},\"streamStates\":{},\"nuid\":\"fc6fc06d-2246-492b-9a29-13229adf4fea\"}],\"dashboards\":[],\"guid\":\"58f7a14f-fb09-473f-94a9-2b169d1d509a\",\"globalVars\":{},\"iPythonMetadata\":{\"nbformat\":4,\"IPythonMetadata\":{\"kernelspec\":{\"display_name\":\"Python 2\",\"language\":\"python\",\"name\":\"python2\"},\"language_info\":{\"mimetype\":\"text/x-python\",\"name\":\"python\",\"pygments_lexer\":\"ipython2\",\"codemirror_mode\":{\"name\":\"ipython\",\"version\":2},\"version\":\"2.7.13\",\"nbconvert_exporter\":\"python\",\"file_extension\":\".py\"},\"name\":\"hw2_linear_reg_student\",\"notebookId\":622372970202767}},\"inputWidgets\":{}}; if (window.mainJsLoadError) { var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js'; var b = document.getElementsByTagName('body')[0]; var c = document.createElement('div'); c.innerHTML = ('Network Error' + 'Please check your network connection and try again.' + 'Could not load a required resource: ' + u + ''); c.style.margin = '30px'; c.style.padding = '20px 50px'; c.style.backgroundColor = '#f5f5f5'; c.style.borderRadius = '5px'; b.appendChild(c); } MathJax.Hub.Config({\"tex2jax\":{\"inlineMath\":[[\"$\",\"$\"],[\"\\\\(\",\"\\\\)\"]],\"skipTags\":[\"script\",\"noscript\",\"style\",\"textarea\",\"pre\",\"code\"],\"processEscapes\":true},\"TeX\":{\"equationNumbers\":{\"autoNumber\":\"AMS\"}}}); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i < all.length; i += 1) { all[i].SourceElement().parentNode.className += ' has-jax'; } });","tags":""},{"title":"","url":"/others/Bit, Bytes and Integers.html","text":"Bit-level manipulationsAndA = 1 and B = 1=&gt; A &amp; B = 1 OrA = 1 or B = 1=&gt; A | B = 1 notA = 0=&gt; ~A = 1 Exclusive-Or(XOR)either A=1 or B=1, but not both =&gt; A^B = 1 Shift Operationsx &lt;&lt; 88 mod 8 lower 3 bits shift, ignore others Encoding IntegersUnsigned:$B2U(X)=\\sum^{w-1}_{i=0}x_i2^i$ Eg.123454 3 2 1 0 i16 8 4 2 1 2^i1 0 1 1 016 4 2 0 = 22 Signed:Eg.123454 3 2 1 0 i-16 8 4 2 1 +-2^i1 0 1 1 0-16 4 2 0 = -10 Numeric RangesTwo’s Complement Values:TMin: 最高位为1，其它都为0 =&gt; $-2^{w-1}$TMax: 最高位为0，其它都为1 =&gt; $2^{w-1}-1$ |TMin| = TMax + 1 Eg.1234567891011smallest:1 0 0 0 0-16 = -16largest0 1 1 1 1 8 4 2 1 = 15all ones1 1 1 1 1-16 8 4 2 1 = -1 Unsigned Values:UMin = 0UMax = $2^w-1$ 1234567smallest:0 0 0 0 0 = 0largest1 1 1 1 116 8 4 2 1 = 32 UMax = 2 * TMax + 1 Conversion看上面提到的两组例子1234567Signed:1 1 1 1 1-16 8 4 2 1 = -1Unsigned:1 1 1 1 116 8 4 2 1 = 32 1234567Signed:1 0 1 1 0-16 4 2 0 = -10Unsigned:1 0 1 1 016 4 2 0 = 22 两个值相差32。 Representing &amp; Manipulating Sets","tags":""},{"title":"","url":"/others/人工智能.html","text":"人工智能 感知感知，基于视觉、听觉及各种传感器的信息处理视觉语音语言 决策识别，负责更高层的语义处理，如推理、规划、记忆、学习等识别推荐预测 反馈行为控制，专门对机器人对行为进行控制生成机器人自动化 框架结构 应用层 技术层deep learning 基础层大数据，计算引擎/深度学习芯片 人工职能技术三架马车 Big Data Algorithm Computing Power","tags":""},{"title":"","url":"/404.html","text":"","tags":""},{"title":"NLP 笔记 - notes","url":"/others/NLP 笔记 - notes.html","text":"形态学(Morphology) 语素(Morphemes)- 词根(Roots) - 词缀(Affixes) § 前缀(Prefixes) § 后缀(Suffixes) determin-ize, iterat-or § 中缀(Infixes) Pennsyl-f\\*\\*kin-vanian § 位缀(Circumfixes) ge-sammel-t - 毗邻性语素(concatenative morphology) 主要指前缀和后缀这一类语素，词是由一定数目的语素毗邻在一起而组成的 - 非毗邻性语素(nonconcatenative morphology) § Umlaut foot::feet tooth : teeth § Ablaut sing, sang, sung § 词根与模式语素(Root-and-pattern)/模板语素(templatic morphology) 通常在阿拉伯语和其它闪美特语系中(Eg. Arabic, Hebrew, Afroasiatic languages) 如在希伯来语中，动词通常由词根和模板组成，词根又通常由3个辅音组成。 § Infixation 单词(words)- 屈折形态学(Inflectional morphology) 屈折把词干(stem)和一个语法语素(grammatical morpheme)结合起来 形成的单词一般和原来的词干术语同一个词类(word class) 会产生诸如“一致关系”之类的句法功能 • Number (singular versus plural) automaton → automata • Case (nomina:ve versus accusa:ve versus…) he, him, his, … - 派生形态学(Derivational morphology) 派生把词干(stem)和一个词缀(suffixes/affixes/infixes)结合起来 形成的单词一般属于不同的词类(word class)，具有不同的含义(meaning) • parse → parser • repulse → repulsive 有限状态自动机(Final-State Automaton)正则表达式 vs 有限状态自动机: § 正则表达式是描述有限状态自动机的一种方法 § 任何正则表达式都可以用有限状态自动机来实现 § 任何有限状态自动机都可以用正则表达式来描述 § 两者彼此对称 形态剖析(Morphological Parsing)- 形态剖析器构成： § 词表(lexicon) 词干和词缀表及其基本信息(如一个词干是名词词干还是动词词干等) § 形态顺序规则(morphotactics) 关于形态顺序的模型，解释在一个词内什么样的语素跟在什么样的语素后面 如英语表示复数的语素要跟在名词后面而不是前面 § 正词法规则(orthographic rule) 当两个语素结合时在拼写上发生什么变换。如 y-&gt;ie - 剖析方法 - Table - Trie - Final-state transducer(FST) ○ 双层形态学(two-level morphology)把一个词表示为词汇层(lexical level)和表层(surface level)之间的对应 § 词汇层(lexical level) 表示组成该词的语素之间的简单毗邻关系 § 表层(surface level) 该层实际拼写的最终情况 § 映射规则 把在表层上的字幕序列(如 cats) 映射为词汇层上的语素和特征的序列(cat+N+PL) =&gt; 有限状态转录机(Final State Transducers) ○ FSA vs FST: § FST 通过 FSA 来实现转录，因此我们通常把 FST 看成具有两层的 FSA § FSA 通过确定符号集合来定义/识别形式语言，而 FST 则定义符号串之间的关系 § FST 具有比 FSA 更多的功能 FSA 主要是来表达正则语言，主要作用是识别(recognize)语言； FST 既能够识别(recognize)语言，也能够产生(generates)语言 FST 可以剖析(parse)输入，也可以把输入转化(transform)成另一种表达方式 ○ 作用： § 作为识别器(recognizer) 符号串的偶对作为输入和输出，如果该符号串偶对也在语言的符号串偶对(pair)中就接收，否则拒绝 § 作为生成器(generator) 输出 yes 或 no 以及输出符号串的偶对 § 作为翻译器(translator) 读一个符号串，输出另一个符号串 § 作为关联器(relater) 计算两个集合之间的关系 拼写错误和噪声信道模型 拼写错误分类：真词(Real-word Errors)，非词(Non-word Errors) 拼写错误模式：- 打字操作错误(typographic error) 插入(insertion)，脱落(deletion)，替代(substitution)，换位(transposition) - 认知错误(cognitive error) § 语音错误: 用语音上等价的字母序列来替代，如 separate 拼成了 seperate § 同音词错误: 如用 piece 来替代 peace 错误检查- 使用词典 - 检查序列(概率分布) 错误改正- 噪声信道模型(Noisy Channel Model) 应用：语音识别、拼写纠错、机器翻译、中文分词、词性标注、音字转换 等众多应用领域 过程： 1. 提出候选更正表(generate candidate words) 2. 用语言模型计算 P(W) (language model probability/prior) 3. 计算错误模型 P(O|W) (channel model probability) 4. 计算 argmaxw∈V P(W|O)=argmaxP(W)*P(O|W) - 分类器(Classifier) 可选特征 p(misspelling|word) • The source letter • The target letter • Surrounding letters • The position in the word • Nearby keys on the keyboard • Homology on the keyboard • Pronunciations • Likely morpheme transformations NLP 笔记 - Spelling, Edit Distance, and Noisy Channels 语言模型应用： Machine Translation，Spell Correction，Speech Recognition，Summarization，QA system,etc. 文本预处理问题标点/大小写/屈折形式/口语语料库 简单的(非平滑的) N 元语法 Full History Model看单词对于给定历史的条件概率(conditioned on every history)$p(W=w) = (\\prod^L_{l=1}p(w_l|history_l))p(stop|history_L)$ N-Gram Model看单词对于固定长度历史的条件概率(conditioned on a fixed-length history(n-1)）$p(W=w) = (\\prod^L_{l=1}p(w_l|history_l))p(stop|history_{L+1})$Bigram 为例，假设 &lt;s&gt; 为 START_SYMBOL，&lt;/s&gt; 为 STOP_SYMBOL$p(w^1_L)=\\prod^L_{l=1}P(w_l|w_{l-1})p(stop|w_{L+1})$&lt;s&gt; 为 START_SYMBOL，&lt;/s&gt; 为 STOP_SYMBOL &lt;s&gt; I am Sam &lt;/s&gt; P(I|&lt;s&gt;)*P(am|I)*P(Sam|am)*P(&lt;/s&gt;|Sam) 对数(Logprob) 解决 underflow 问题；加速运算(加法比乘法快) 归一化(Normalizing) Unknown word 新建一个unknown word来表示未登录词 N-gram 对语料库的敏感性 训练模型的上下文越长，句子连贯性也就越好 N-gram 性能强烈依赖于它们的语料库(特别是语料库的种类和单词的容量) 平滑(Smoothing) 加 1 平滑(add-one smoothing)$P_{Add-1}(w_i|w_{i-1})={c(w_{i-1}w_i)+1 \\over c(w_{i-1})+V}$ Good-Turing smoothing$P^\\star_{GT} (things \\ with \\ zero \\ frequency)={N_1 \\over N_2}$$c^\\star = {(c+1)N_{c+1} \\over N_c}$Nc 是出现过 c 次的单词的个数 Backoff(回退) Linear Interpolation(线性差值)$ p(w_n|w_{n-1}w_{n-2}) = \\lambda_1 p(w_n|w_{n-1}w_{n-2}) + \\lambda_2 p(w_n|w_{n-1}) + \\lambda_3 p(w_n)$$\\sum_i \\lambda_i=1$ 模型评估 $Perplexity = \\sqrt[N] {\\prod^N_{i=1} 1 \\over {P(w_i|w_{i-1})}}$ NLP 笔记 - Language models and smoothing 词性标注(PoS tagging) 特点- 分布特征(Distributional) 相似的环境/相似功能 - 形态特征(Morphological) 相同词缀/句法结构中相似上下文 - 无关于含义(meaning)，也无关于语法(可以是主语/宾语，等等) 分类- 封闭类(closed class) 介词(prepositions)/限定词(determiners)/代词(pronouns)/连接词(conjunctions)/助动词(auxiliary verbs)/小品词(particles)/数词(numerals) - 开放类(open class) 名词/动词/形容词/副词 应用§ POS 有助于模型的泛化，并帮助 reduce model size。 § 提供关于单词及其邻近成分的大量有用信息(区分名词、动词，推断近邻词) § 提供单词发音的信息(语音合成系统) § 分割词干(stemming) § 用于信息检索/信息抽取 § 自动词义排歧算法/局部剖析(parital parsing) 算法- HMM argmaxP(tag|word)=P(word|tag)∗P(tag|previous n tags)/P(word) - Brown Clustering 自底向上的层次聚类算法(hierarchical agglomeretive)，基于 n-gram 模型和马尔科夫链模型，容易 scale 输入：语料库 输出：二叉树，叶子节点是一个个词，中间节点是我们想要的类（中间结点作为根节点的子树上的所有叶子为类中的词） 基本思想： 1. 初始的时候，将每一个词独立的分成一类 2. 然后，将两个类合并，使得合并之后 quality 函数最大 quality 函数，是对于n个连续的词（w）序列能否组成一句话的概率的对数的归一化结果 3. 不断重复上述过程，达到想要的类的数量的时候停止合并 - Feature-based tagger 可用特征 • Word the: the → DT • Lowercased word Importantly: importantly → RB • Prefixes unfathomable: un- → JJ • Suffixes Importantly: -ly → RB • Capitalization Meridian: CAP → NNP • Word shapes 35-year: d-x → JJ • Sliding window 未知词- 均等概率 假定每个未知词在所有可能的标记中都是有歧义的，给每个P(t|w)相同概率 根据上下文相关的 POS trigram 给未知词恰当的标签 - Things-seen-once 在未知词上的标记的概率分布与在训练集中只出现一次的单词的标记的概率分布非常相似 - 使用关于单词拼写的信息 4 类特殊的正词法特征，包括 § 3 个屈折词尾(-ed,-s,-ing) § 32个派生后缀(-ion,-al,-ive,-ly) § 4个大写(captial)值(首字母大写，非首字母大写等)以及连字符(hyph)规则 P(wi)=P(unknown−word|ti)P(captial|ti)P(endings|hyph/ti) NLP 笔记 - Part of speech tags 句法(syntax) 话题- 组成性(Constituency) - 语法关系(Grammatical relation) - 次范畴化和依存关系(Subcategorization and dependency) Chomsky Hierarchy- 0型语法(type 0 grammar) - 上下文有关语法(context-sensitive grammar) - 上下文无关语法(context-free grammar) - 有限状态语法/正则语法(finite state grammar/regular grammar) Chomsky Normal Form(CNF)• Grammar 是 ε-free(ε 表示空串)，且 rules 只有 X → Y Z; X → w 两种形式，且 X,Y,Z∈N, w∈T =&gt; 该语法具有 CNF 范式 • CNF 语法都是二分叉的。 • 任何语法都可以转化成一个弱等价的 CNF 形式，只改变树的结构，且能识别相同的语言。 § 移除 empties 和 unaries § 引入新的 non-terminal 来解决 n-ary 问题 语言结构- 组成结构(Constituency/phrase structure) 通常由上下文无关语法产生 主要构成部分：成分 - 依存结构(Dependency structure) 应用：决定单复数/QA系统 主要构成部分：head 和 dependents 剖析树 Parse tree- 可以得到的信息： § 单词的词性(Part of speech) § 词组(Phrases) § 关系(Useful Relationships) - 两种思路 - 自顶向下(Top-down) - 自底向上(Bottom-up) - 比较 Top-down 不会浪费时间搜索一个不可能以 S 为根的树；但是会产生与输入不一致的根为 S 的树 Bottom-up 相反 两种方法都不能有效利用语法和输入单词中的约束条件 - 歧义(Ambiguity) 来源： 词性标注歧义 介词短语歧义(Prepositional Phrase Attachment) 解决： 基于统计数据，在语料库中，看某个 PP 跟在特定名词/动词后面的概率，取概率大的那种 parse。 PCFG - 算法 - 上下文无关语法(Context-Free Grammar/CFGs) - 概率上下文无关语法(Probabilistic Context-Free Grammar/PCFGs) 五元组 (N,Σ, P, S, D) 产生规则中每条规则都加了一个条件概率A→β[p] D 的功能是给 R 中的每个规则指派一个概率 P(A→β|A) 一个 non-terminal 符号的所有展开，概率之和为1 - Cocke-Kasami-Younger(CKY) Bottom-up，为一个句子建立一个三角形的表格，然后 bottom-up 一层一层向上填充 chart 输入必须是具有 Chomsky 范式(CNF) - Earley Top-down 无需将输入 grammar 转化成 CNF 范式 如果输入有 N 个单词，Earley 算法会创建一个 N+1 大小的 chart，对于句子中每一个单词的位置，chart 包含一个状态表来表示已经生成的部分剖析树，在句子结尾，chart 把对于给定输入的所有可能的剖析结果进行编码，每个可能的子树只表示一次，并且这个子树表示可以被需要它的所有的剖析共享。 关键操作： § 预测(Predictor:for non-terminals) § 扫描(Scanner: for words) § 完成(Completer) - 两个算法的不足： § 一致性(agreement)问题 Number/Person/Tense/Case/Gender § 次范畴化问题(Subcategorization Frames) Direct object/Prepositional phrase/Predicative adjective... § CFG 假设：任何一个 non-terminal 符号的展开与任何其他 non-terminal 符号的展开是独立的，然而这个假设是不成立的 -&gt; 引入 Lexicalized grammars - 评估： 标注每一个成分的起始位置，然后比较两个 tree，看两个 tree 对应成分的起始位置是否相同，计算 precision，recall，F1，和 tagging accuracy。 不足：错误会被继承 NLP 笔记 - Syntax Introduction NLP 笔记 - Constituency Parsing","tags":""},{"title":"无人车","url":"/others/无人车.html","text":"无人车传感器会收集附近对象的数据，比如其大小和速率等。然后会根据其可能的行为方式对这些对象进行分类——比如自行车手、行人或者别的车和对象。 红色盒子：自行车手；黄色盒子：行人；粉红色盒子：车辆 绿色“栅栏”：无人车可能需要放慢速度的地方；红色“栅栏”：无人车可能需要停下来的位置 无人车是如何工作的？ Difficulties让无人车在 highway 上行驶一点都不困难，难点是要让无人车去应对所有的情况，让车能理解人的行为。举个简单的例子，交通员在路上 human hands a stop sign, piece of road, whether to stop or not Mapping is the keyuber, not human beatufully integrated, Common color selection首先需要知道一些颜色的基础，最重要的就是 RGB Color Region Mixedselect -&gt; filter -&gt; lane like Color Region triangulation mask the threshold find region and mask the selection manual process concept Canny Edge goal: identify the boundaries of an object in an image covert to grayscale and then take the gradient trace out the edges with strongest gradient Hough Lines feature extraction technique goal: find imperfect instances of objects within a certain class of shapes by a voting procedure Lane findingWhy are we doing lane finding?keep the car stay in the same lane What are we going to do after lane finding? How are we going to achieve it? Steps for finding lanes Determine the Region of Interest(ROI) by slicing the image(focus the middle part) Grayscale the ROI Equalized the grayscaled ROI with cv2.equalizeHist Apply Gaussian blur to 3 Threshold(4) by using cv2.adaptiveThreshold Skeletonize(5) by using skimage.morphology.skeletonize Apply the cv2.HoughLines on 6 distance to the lane, check if the car is left, right Sobel Edge DetectionSobel Edge Detection refers to computing the gradient magnitude of an image using 3*3 filters“gradient magnitude”: for each a pixel, a number giving the greatest rate of change in light intensity in the direction where intensity is changing fastest Sobel is very fast, less computation edge detection techniques compared to Canny, Harris, and Marr-Hildreth. HarrisHarris Corner Detection looks for corners because corners are translation invariant and rotation invariant while distinguishable, unlike edges. These properties make corners good feature candidates. First it computes the horizontal and vertical derivatives(edges) of an image, then it performs cross correlation on these edge images to highlight corners, and then it performs non-maximum suppression to get rid of the edge features. Probabilistic HoughUse line polar coordinate$p=xcos\\theta + ysin\\theta$ p(rho)=distance from origin to the line. $[-max_dist to max_dist]$max_dist is the diagonal length of the image$\\theta$ = angle from origin to the line. $[-90-90]$ Algorithm Perform Corner or Edge Detection as input image Rho range and Theta range creation Setup Hough accumulator in 2D army with numbers equal from p and theta Find the total points/pixels contributed for potential line lanes Perform Peak finding by applying threshold What we have learned Color Selection Edge Detection Filter and Transformation Camera Calibration Distort and undistort how to define all objectsfeatures -&gt; linear regression classifier Perspective Transform == Bird’s Eye View (smaller than the real world) use many(E.g.6) cameras to form a full Bird’s Eye View Gradient Thresholdstill deal with edges which we end up with color masking and transformationso the best way to do this, like we discussed last week. utilize the sobel operator ??? load image -&gt; perspective transform -&gt; Color mask-&gt;yellow mask &amp; white mask -&gt; combine sobel and color mask -&gt; sobel filter -&gt; a","tags":""},{"title":"卷积神经网络 CNN 笔记","url":"/others/卷积神经网络 CNN 笔记.html","text":"CNN 对模式分类非常适合，其最初是为识别二维形状而特殊设计的，这种二维形状对平移、比例缩放、倾斜或其他形式对变形有高度不变性。 图像识别/分类图片识别／分类的一般过程：detect -&gt; align -&gt; represent -&gt; classify。具体到 CNN 就是检测到图片的位置，剪出来对齐，表达特征，对若干层进行不同的卷积、pooling，最后全连接网络做分类。 传统模型:1Fixed features + unsupervised mid-level features + simple classifier 神经网络：1Low-level features －&gt; Mid-level features -&gt; High-level features -&gt; trainable classifier 李飞飞的 ImageNet 比赛，在 2012 年之前，经典做法是人工选一些原始特征出来(SIFT, Hog, Harr, etc.)，再稍加变换，可能用到一些聚类的算法，做一些中等级别的特征，然后给某个分类器做识别，一般就是 SVM。这种方法每一步都会损失数据，到最后可能就达不到很好的分类效果。 2012 年第一次用了 CNN，正确率提高了 10%，人们意识到深度学习可能是图像识别非常有效的方式。与传统模型不同的是特征是自动选择的。也因为 CNN 需要足够大量的样本，大量的参数，也有人质疑大量参数会过拟合。 注： 把图像像素看成 words of bags，不同的原始图像可能分别是 M1N, M2N, M3*N 等等的 vectors，通过 K-means 的聚类聚比如说 1000 个类，就能把原来的 vectors 转化成长度为 1000 的直方图，也就形成中等级别的特征，维度就一样了，然后再选一个分类器。 深度学习现在看来还可能是过冗余的，可以很多改进空间，如果能把 100M -&gt; 100K 的参数，就可以放到 App 中。 花一天时间做的非监督学习的训练，大多时候往往不如几分钟做的有监督绚练。好数据往往优于好算法，如果能拿到样本，就拿监督学习做。 卷积神经网络传统的神经网络都是采用全连接的方式，即输入层到隐藏层的神经元都是全部连接的，这样做将导致参数量巨大，使得网络训练耗时甚至难以训练，而 CNN 则通过局部连接、权值共享等方法避免了这一困难。 全连接神经网络先来说一个浅层的神经网络，如下图其实就可以看作一个 logistic regression 模型。 一个神经元的组成： 输入：n 维向量 线性加权：$z=\\sum^n_{i=1}w_ix_i+b$ 激活函数：a=h(z)，要求非线性，容易求导 输出值：a(标量) 当然我们可以加 z2, z3, a2, a3… 输入是 x1,x2…xn，输出是 a1,a2…am，如果给一个神经元，就是或 0 或 1 的输出，如果给多个，就从 logistic 回归变成了 softmax 回归。 一个输入，若干个中间层(可能是全连接／非全连接网络)，最后输出层，如果要做分类，就可以给一个或多个全连接网络（可以看作是 softmax）。 卷积网络比如说一张 32*32 的 RGB 图片，做卷积，一张图片就能理解。 123456Input volume: 32*32*3Receptive fields: 5*5, stride 3Number of neurons: 5Output volume: (32-5)/3+1=10, -&gt; 10*10*5Weights for each of 10*10*5 neurons: 5*5*3=75 每一个神经元从上一层的局部接受域得到输入，提取局部特征，每个局部特征相对于其他特征的位置被近似保留下来，原本的精确位置就没那么重要了。每一个计算层都由多个 feature map 组成，每个 feature map 都是平面形式的，平面中单独的神经元在约束下共享相同的权值集。这种结构约束具有平移不变性（强迫 feature map 的执行使用具有小尺度核的卷积，再接着使用一个 sigmoid 函数），另外，权值共享也可以实现自由参数数量的缩减。 padding &amp; stride 如果无法整除，比如说 3232，取 55 的卷积窗口，会有余数，所以我们一般会加上 padding，一般补 0。如上图，55 的图，卷积核 33，取 padding=1，对原始数据上下左右各补 1，可能会有偏移量，就相乘相加再加上偏移值。步长为 2，就是跳着取窗口。 池化 pooling每个卷积层跟着一个实现局部平均和子抽样的计算层，能达到降维的目的，由此 feature map 的分辨率降低。这种操作可以使 feature map 的输出对平移和其他形式的变形的敏感度下降。一张图解释下 2*2 的 max-pooling。 这样 MM 的图像就成了 M/2 M/2 的图像。当然还有 min-pooling 和 avg-pooling。作用: 降低输出规模 增加可解释性 避免丢失过多信息 特点通过局部连接和权值共享减少了神经网络需要训练的参数的个数。 局部连接 权值共享(每个 feature map 共享参数) 池化 权值设置：可以对所有权值做先验处理，按高斯分布做随机处理，然后梯度下降调整权值。 一般架构 可能有多个卷积层或多个输出层，某些卷积层不会跟着 pooling 也是可以的。 规则化：白化、去均值（中心化） 卷积：对原始图像提取特征，可以看作在大量的基上做一个稀疏编码。-&gt; 维度提升，过完备基 非线性映射：稀疏化、边界消除 pooling：特征聚集、降维（并减少参数）、光滑 训练算法训练算法与传统的 BP 算法差不多。主要包括4步，分为两个阶段： 第一阶段，向前传播阶段： a）从样本集中取一个样本(X,Yp)，将 X 输入网络； b）计算相应的实际输出 Op。 在此阶段，信息从输入层经过逐级的变换，传送到输出层。这个过程也是网络在完成训练后正常运行时执行的过程。在此过程中，网络执行的是计算（实际上就是输入与每层的权值矩阵相点乘，得到最后的输出结果）： $$Op=Fn（…（F2（F1（XpW（1））W（2））…）W（n））$$ 第二阶段，向后传播阶段： a）计算实际输出 Op 与相应的理想输出 Yp 的差； b）按极小化误差的方法反向传播调整权矩阵。 CNN 前向传播、反向传播详解 优化提高泛化能力（减少 overfit） 增加神经网络层数。使用卷积层极大地减小了全连接层中的参数的数目，使学习的问题更容易 使用更多强有力的规范化技术（尤其是 dropout 和 regularization）来减小过度拟合 使用修正线性单元而不是 S 型神经元，来加速训练-依据经验，通常是3-5倍 使用 GPU 来计算 利用充分大的数据集，避免过拟合 使用正确的代价函数，避免学习减速 使用好的权重初始化，避免因为神经元饱和引起的学习减速","tags":""},{"title":"works","url":"/works/index.html","text":"项目项目实战–知识图谱初探NLP 笔记 - Question Answering SystemQA system - Question Generation项目实战–搜索引擎实习总结之 sentence embedding项目实战–云计算Twitter Analytics Web Service项目实战–App Recommender System项目实战–云计算Social Networking Timeline 爬虫系列爬虫总结(一)– 爬虫基础 &amp; python实现爬虫总结(二)– scrapy爬虫总结(三)– cloud scrapy爬虫总结(四)– 分布式爬虫爬虫总结(五)– 其他技巧爬虫总结–汇总贴 NLP 系列NLP 笔记 - Question Answering SystemQA system - Question Generation句向量总结笔记（简洁版）词向量总结笔记（简洁版）NLP 笔记 - 再谈词向量 CMU 11411/11611 Natural Language Model 的课程笔记。NLP 笔记 - Words, morphology, and lexiconsNLP 笔记 - Spelling, Edit Distance, and Noisy ChannelsNLP 笔记 - Language models and smoothingNLP 笔记 - Part of speech tagsNLP 笔记 - Syntax IntroductionNLP 笔记 - Constituency ParsingNLP 笔记 - Dependency Parsing and TreebankNLP笔记 - Information ExtractionNLP 笔记 - 平滑方法(Smoothing)小结ParseTree操作若干-Tregex and Stanford CoreNLPNLP 笔记 - Meaning Representation LanguagesNLP 笔记 - Knowledge RepresentationNLP笔记 - Relation ExtractionNLP笔记 - Compositional SemanticsNLP笔记 - NLU之意图分类NLP 笔记 - Machine TranslationNLP 笔记 - Neural Machine TranslationNLP 笔记 - Text SummarizationNLP 笔记 - Sentiment AnalysisNLP 笔记 - Neural Machine TranslationNLP 笔记 - Discourse Analysis 搜索引擎系列CMU 11442/11642 Search engines 的课程笔记。CMU 11642 Search Engines - 大纲梳理Search Engines笔记 - Exact-match retrievalSearch Engines笔记 - Query ProcessingSearch Engines笔记 - Evaluating Search EffectivenessSearch Engines笔记 - Document RepresentationsSearch Engines笔记 - Best-MatchSearch Engines笔记 - Information NeedsSearch Engines笔记 - Pseudo Relevance FeedbackSearch Engines笔记 - Index ConstructionSearch Engines笔记 - CacheSearch Engines笔记 - Learning to RankSearch Engines笔记 - Search logsSearch Engines笔记 - Document StructureSearch Engines笔记 - Authority MetricsSearch Engines笔记 - PersonalizationSearch Engines笔记 - ReDDE Algorithm for Resource SelectionSearch Engines笔记 - Federated SearchSearch Engines笔记 - Diversity 深度学习系列深度学习知识框架神经网络-从线性到非线性神经网络-链式反向梯度传导会议笔记 - Nuts and Bolts of Applying Deep Learning卷积神经网络 CNN 笔记卷积神经网络 CNN 笔记(高级篇)/)卷积神经网络 CNN 笔记 - 目标分类卷积神经网络 CNN 笔记 - 目标探测TensorFlow 实战 MINST实习总结之 sentence embedding递归神经网络 RNN 笔记 机器学习系列CMU 10601 Machine learning 的课程笔记。Hidden-Markov-ModelsBayesian LearningEM算法Graphical Models 分布式系统系列CMU 95702 Distributed Systems 的课程笔记。Distributed Systems笔记－Web Service Design PatternsDistributed Systems笔记－middlewaresDistributed Systems笔记－Cryptographic ProtocolsDistributed Systems笔记－NFS、AFS、GFS","tags":""},{"title":"categories","url":"/categories/index.html","text":"","tags":""}]}