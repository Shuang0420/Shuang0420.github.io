<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />













  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="NLP,Relation Extraction,Information Extraction," />





  <link rel="alternate" href="/atom.xml" title="徐阿衡" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.3" />






<meta name="description" content="这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 NLP笔记 - Information Extraction 和 NLP笔记 - Relation Extraction，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。">
<meta property="og:type" content="article">
<meta property="og:title" content="知识抽取-实体及关系抽取">
<meta property="og:url" content="http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取/index.html">
<meta property="og:site_name" content="徐阿衡">
<meta property="og:description" content="这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 NLP笔记 - Information Extraction 和 NLP笔记 - Relation Extraction，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/general.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/SemEval.png">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/2.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/3.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/2.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/3.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/4.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/5.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/6.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/7.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/8.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/LSTM%2BCRF.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.png">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/5.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DT.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DT2.png">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/7.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/features2.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/CR-CNN.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/CR-CNN_loss.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/PE.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCNN.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCnn_loss.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCNN_loss2.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttBLSM.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/pipeline_perf.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/joint_model.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/entity_detection.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/dp.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/joint_perf.png">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/8.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/6.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/9.jpg">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS_sum.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS_att.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/ed.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/errors.png">
<meta property="og:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/final_loss.png">
<meta property="og:updated_time" content="2020-05-08T06:43:39.907Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="知识抽取-实体及关系抽取">
<meta name="twitter:description" content="这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 NLP笔记 - Information Extraction 和 NLP笔记 - Relation Extraction，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。">
<meta name="twitter:image" content="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/general.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '6294135991397516000',
      author: '阿衡'
    }
  };
</script>

<script async src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6146435155426457",
    enable_page_level_ads: true
  });
</script>




  <link rel="canonical" href="http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取/"/>


  <title> 知识抽取-实体及关系抽取 | 徐阿衡 </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="en">

  










  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">徐阿衡</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Shuang</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-works">
          <a href="/works" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Works
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/aboutme" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input" placeholder="search my blog...">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
         
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                知识抽取-实体及关系抽取
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2018-09-15T19:02:27+08:00" content="2018-09-15">
              2018-09-15
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  , 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/Knowledge-Graph/" itemprop="url" rel="index">
                    <span itemprop="name">Knowledge Graph</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2018/09/15/知识抽取-实体及关系抽取/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/09/15/知识抽取-实体及关系抽取/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这一篇是关于知识抽取，整理并补充了上学时的两篇笔记 <a href="http://www.shuang0420.com/2017/03/18/NLP%20笔记%20-Information%20Extraction/">NLP笔记 - Information Extraction</a> 和 <a href="http://www.shuang0420.com/2017/04/10/NLP笔记%20-%20Relation%20Extraction/">NLP笔记 - Relation Extraction</a>，梳理了知识抽取的基本方法，包括传统机器学习及经典的深度学习方法。</p>
<a id="more"></a>
<p>知识抽取涉及的“知识”通常是 <strong>清楚的、事实性的信息</strong>，这些信息来自不同的来源和结构，而对不同数据源进行的知识抽取的方法各有不同，从结构化数据中获取知识用 D2R，其难点在于复杂表数据的处理，包括嵌套表、多列、外键关联等，从链接数据中获取知识用图映射，难点在于数据对齐，从半结构化数据中获取知识用包装器，难点在于 wrapper 的自动生成、更新和维护，这一篇主要讲从文本中获取知识，也就是我们广义上说的信息抽取。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/general.png">
<p>信息抽取三个最重要/最受关注的子任务：</p>
<ul>
<li><strong>实体抽取</strong><br>也就是命名实体识别，包括实体的检测（find）和分类（classify）</li>
<li><strong>关系抽取</strong><br>通常我们说的<strong>三元组（triple）</strong> 抽取，一个谓词（predicate）带 2 个形参（argument），如 Founding-location(IBM,New York) </li>
<li><strong>事件抽取</strong><br>相当于一种多元关系的抽取</li>
</ul>
<p>篇幅限制，这一篇主要整理实体抽取和关系抽取，下一篇再上事件抽取。</p>
<h1 id="相关竞赛与数据集"><a href="#相关竞赛与数据集" class="headerlink" title="相关竞赛与数据集"></a>相关竞赛与数据集</h1><p>信息抽取相关的会议/数据集有 <strong>MUC、ACE、KBP、SemEval</strong> 等。其中，<strong>ACE(Automated Content Extraction)</strong> 对 MUC 定义的任务进行了融合、分类和细化，<strong><a href="https://tac.nist.gov/2017/KBP/" target="_blank" rel="external">KBP(Knowledge Base Population)</a></strong> 对 ACE 定义的任务进一步修订，分了四个独立任务和一个整合任务，包括</p>
<ul>
<li><strong>Cold Start KB (CSKB)</strong><br>端到端的冷启动知识构建</li>
<li><strong>Entity Discovery and Linking (EDL)</strong><br>实体发现与链接</li>
<li><strong>Slot Filling (SF)</strong><br>槽填充</li>
<li><strong>Event</strong><br>事件抽取</li>
<li><strong>Belief/Sentiment (BeSt)</strong><br>信念和情感</li>
</ul>
<p>至于 SemEval 主要是词义消歧评测，目的是增加人们对词义、多义现象的理解。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/SemEval.png"></p>
<p>ACE 的 17 类关系<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/2.jpg" class="ful-image" alt="2.jpg"></p>
<p>具体的应用实例<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/3.jpg" class="ful-image" alt="3.jpg"></p>
<p>常用的 Freebase relations<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">people/person/nationality,</div><div class="line">people/person/profession,</div><div class="line">biology/organism_higher_classification,</div><div class="line">location/location/contains</div><div class="line">people/person/place-of-birth</div><div class="line">film/film/genre</div></pre></td></tr></table></figure></p>
<p>还有的一些世界范围内知名的高质量大规模开放知识图谱，如包括 DBpedia、Yago、Wikidata、BabelNet、ConceptNet 以及 Microsoft Concept Graph等，中文的有开放知识图谱平台 OpenKG……</p>
<h1 id="实体抽取"><a href="#实体抽取" class="headerlink" title="实体抽取"></a>实体抽取</h1><p>实体抽取或者说命名实体识别（NER）在信息抽取中扮演着重要角色，主要抽取的是文本中的原子信息元素，如<strong>人名、组织/机构名、地理位置、事件/日期、字符值、金额值</strong>等。实体抽取任务有两个关键词：<strong>find &amp; classify</strong>，找到命名实体，并进行分类。<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/2.jpg" class="ful-image" alt="2.jpg"></p>
<p><strong>主要应用：</strong></p>
<ul>
<li>命名实体作为索引和超链接</li>
<li>情感分析的准备步骤，在情感分析的文本中需要识别公司和产品，才能进一步为情感词归类</li>
<li>关系抽取（Relation Extraction）的准备步骤</li>
<li>QA 系统，大多数答案都是命名实体</li>
</ul>
<h2 id="传统机器学习方法"><a href="#传统机器学习方法" class="headerlink" title="传统机器学习方法"></a>传统机器学习方法</h2><p>标准流程：<br><strong>Training:</strong></p>
<ol>
<li>收集代表性的训练文档</li>
<li>为每个 token 标记命名实体(不属于任何实体就标 Others O)</li>
<li>设计适合该文本和类别的特征提取方法</li>
<li>训练一个 sequence classifier 来预测数据的 label</li>
</ol>
<p><strong>Testing:</strong></p>
<ol>
<li>收集测试文档</li>
<li>运行 sequence classifier 给每个 token 做标记</li>
<li>输出命名实体</li>
</ol>
<h3 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h3><p>看一下最常用的两种 sequence labeling 的编码方式，<strong>IO encoding</strong> 简单的为每个 token 标注，如果不是 NE 就标为 O(other)，所以一共需要 C+1 个类别(label)。而 <strong>IOB encoding</strong> 需要 2C+1 个类别(label)，因为它标了 NE boundary，B 代表 begining，NE 开始的位置，I 代表 continue，承接上一个 NE，如果连续出现两个 B，自然就表示上一个 B 已经结束了。<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/3.jpg" class="ful-image" alt="3.jpg"></p>
<p>在 Stanford NER 里，用的其实是 IO encoding，有两个原因，一是 IO encoding 运行速度更快，二是在实践中，两种编码方式的效果差不多。IO encoding 确定 boundary 的依据是，如果有连续的 token 类别不为 O，那么类别相同，同属一个 NE；类别不相同，就分割，相同的 sequence 属同一个 NE。而实际上，两个 NE 是相同类别这样的现象出现的很少，如上面的例子，Sue，Mengqiu Huang 两个同是 PER 类别，并不多见，更重要的是，在实践中，虽然 IOB encoding 能规定 boundary，而实际上它也很少能做对，它也会把 Sue Mengqiu Huang 分为同一个 PER，这主要是因为更多的类别会带来数据的稀疏。</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>Features for sequence labeling:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">• Words</div><div class="line">    Current word (essentially like a learned dictionary)</div><div class="line">    Previous/next word (context)</div><div class="line">• Other kinds of inferred linguistic classification</div><div class="line">    Part of speech tags</div><div class="line">    Dependency relations</div><div class="line">• Label context</div><div class="line">    Previous (and perhaps next) label</div></pre></td></tr></table></figure></p>
<p>再来看两个比较重要的 feature</p>
<p><strong>Word substrings</strong><br>Word substrings (包括前后缀)的作用是很大的，以下面的例子为例，NE 中间有 ‘oxa’ 的十有八九是 drug，NE 中间有 ‘:’ 的则大多都是 movie，而以 field 结尾的 NE 往往是 place。<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/4.jpg" class="ful-image" alt="4.jpg"></p>
<p><strong>Word shapes</strong><br>可以做一个 mapping，把 <strong>单词长度(length)、大写(capitalization)、数字(numerals)、希腊字母(Greek eltters)、单词内部标点(internal punctuation)</strong> 这些字本身的特征都考虑进去。<br>如下表，把所有大写字母映射为 X，小写字母映射为 x，数字映射为 d…<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/5.jpg" class="ful-image" alt="5.jpg"></p>
<h3 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h3><p>NLP 的很多数据都是序列类型，像 sequence of characters, words, phrases, lines, sentences，我们可以把这些任务当做是给每一个 item 打标签，如下图：<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/6.jpg" class="ful-image" alt="6.jpg"></p>
<p>常见的序列模型有 <strong>有向图模型</strong> 如 HMM，假设特征之间相互独立，找到使得 P(X,Y) 最大的参数，生成式模型；<strong>无向图模型</strong> 如 CRF，没有特征独立的假设，找到使得 P(Y|X) 最大的参数，判别式模型。相对而言，CRF 优化的是联合概率（整个序列，实际就是最终目标），而不是每个时刻最优点的拼接，一般而言性能比 HMM 要好，在小数据上拟合也会更好。</p>
<p>整个流程如图所示：<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/7.jpg" class="ful-image" alt="7.jpg"></p>
<p>讨论下最后的 inference<br><img src="http://images.shuang0420.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-Information%20Extraction/8.jpg" class="ful-image" alt="8.jpg"></p>
<p>最基础的是 “decide one sequence at a time and move on”，也就是一个 <strong>greedy inference</strong>，比如在词性标注中，可能模型在位置 2 的时候挑了当前最好的 PoS tag，但是到了位置 4 的时候，其实发现位置 2 应该有更好的选择，然而，greedy inference 并不会 care 这些。因为它是贪婪的，只要当前最好就行了。除了 greedy inference，比较常见的还有 beam inference 和 viterbi inference。</p>
<h4 id="Greedy-Inference"><a href="#Greedy-Inference" class="headerlink" title="Greedy Inference"></a>Greedy Inference</h4><p><strong>优点:</strong></p>
<ol>
<li>速度快，没有额外的内存要求</li>
<li>非常易于实现</li>
<li>有很丰富的特征，表现不错</li>
</ol>
<p><strong>缺点:</strong></p>
<ol>
<li>贪婪</li>
</ol>
<h4 id="Beam-Inference"><a href="#Beam-Inference" class="headerlink" title="Beam Inference"></a>Beam Inference</h4><ul>
<li>在每一个位置，都保留 top k 种可能(当前的完整序列)</li>
<li>在每个状态下，考虑上一步保存的序列来进行推进</li>
</ul>
<p><strong>优点:</strong></p>
<ol>
<li>速度快，没有额外的内存要求</li>
<li>易于实现(不用动态规划)</li>
</ol>
<p><strong>缺点:</strong></p>
<ol>
<li>不精确，不能保证找到全局最优</li>
</ol>
<h4 id="Viterbi-Inference"><a href="#Viterbi-Inference" class="headerlink" title="Viterbi Inference"></a>Viterbi Inference</h4><ul>
<li>动态规划</li>
<li>需要维护一个 fix small window</li>
</ul>
<p><strong>优点:</strong></p>
<ol>
<li>非常精确，能保证找到全局最优序列</li>
</ol>
<p><strong>缺点:</strong></p>
<ol>
<li>难以实现远距离的 state-state interaction</li>
</ol>
<h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><h3 id="LSTM-CRF"><a href="#LSTM-CRF" class="headerlink" title="LSTM+CRF"></a>LSTM+CRF</h3><p>最经典的 <a href="hiheng Huang, Wei Xu, Kai Yu. Bidirectional LSTM-CRF Models for Sequence Tagging. CoRR. 2015">LSTM+CRF</a>，端到端的判别式模型，LSTM 利用过去的输入特征，CRF 利用句子级的标注信息，可以有效地使用过去和未来的标注来预测当前的标注。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/LSTM%2BCRF.png">
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p>评估 IR 系统或者文本分类的任务，我们通常会用到 precision，recall，F1 这种 set-based metrics，见<a href="http://www.shuang0420.com/2016/09/20/Search%20Engines%E7%AC%94%E8%AE%B0%20-%20Evaluating%20Search%20Effectiveness/">信息检索评价的 Unranked Boolean Retrieval Model 部分</a>，但是在这里对 NER 这种 sequence 类型任务的评估，如果用这些 metrics，可能出现 boundary error 之类的问题。因为 NER 的评估是按每个 entity 而不是每个 token 来计算的，我们需要看 entity 的 boundary。</p>
<p>以下面一句话为例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">First Bank of Chicago announced earnings...</div></pre></td></tr></table></figure></p>
<p>正确的 NE 应该是 First Bank of Chicago，类别是 ORG，然而系统识别了 Bank of Chicago，类别 ORG，也就是说，右边界(right boundary)是对的，但是左边界(left boundary)是错误的，这其实是一个常见的错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">正确的标注：</div><div class="line">ORG - (1,4)</div><div class="line"></div><div class="line">系统：</div><div class="line">ORG - (2,4)</div></pre></td></tr></table></figure>
<p>而计算 precision，recall 的时候，我们会发现，对 ORG - (1,4) 而言，系统产生了一个 false negative，对 ORG - (2,4) 而言，系统产生了一个 false positive！所以系统有了 2 个错误。<strong>F1 measure</strong> 对 precision，recall 进行加权平均，结果会更好一些，所以经常用来作为 NER 任务的评估手段。另外，专家提出了别的建议，比如说给出 partial credit，如 MUC scorer metric，然而，对哪种 case 给多少的 credit，也需要精心设计。</p>
<h2 id="其他-实体链接"><a href="#其他-实体链接" class="headerlink" title="其他-实体链接"></a>其他-实体链接</h2><p>实体识别完成之后还需要进行归一化，比如万达集团、大连万达集团、万达集团有限公司这些实体其实是可以融合的。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.png" class="ful-image" alt="%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5.png"></p>
<p>主要步骤如下：</p>
<ol>
<li><strong>实体识别</strong><br>命名实体识别，词典匹配</li>
<li><strong>候选实体生成</strong><br>表层名字扩展，搜索引擎，查询实体引用表</li>
<li><strong>候选实体消歧</strong><br>图方法，概率生成模型，主题模型，深度学习</li>
</ol>
<p>补充一些开源系统：</p>
<ul>
<li><a href="http://acube.di.unipi.it/tagme" target="_blank" rel="external">http://acube.di.unipi.it/tagme</a></li>
<li><a href="https://github.com/parthatalukdar/junto" target="_blank" rel="external">https://github.com/parthatalukdar/junto</a></li>
<li><a href="http://orion.tw.rpi.edu/~zhengj3/wod/wikify.php" target="_blank" rel="external">http://orion.tw.rpi.edu/~zhengj3/wod/wikify.php</a></li>
<li><a href="https://github.com/yahoo/FEL" target="_blank" rel="external">https://github.com/yahoo/FEL</a></li>
<li><a href="https://github.com/yago-naga/aida" target="_blank" rel="external">https://github.com/yago-naga/aida</a></li>
<li><a href="http://www.nzdl.org/wikification/about.html" target="_blank" rel="external">http://www.nzdl.org/wikification/about.html</a></li>
<li><a href="http://aksw.org/Projects/AGDISTIS.html" target="_blank" rel="external">http://aksw.org/Projects/AGDISTIS.html</a></li>
<li><a href="https://github.com/dalab/pboh-entity-linking" target="_blank" rel="external">https://github.com/dalab/pboh-entity-linking</a></li>
</ul>
<h1 id="关系抽取"><a href="#关系抽取" class="headerlink" title="关系抽取"></a>关系抽取</h1><p><strong>关系抽取</strong> 需要从文本中抽取两个或多个实体之间的语义关系，主要方法有下面几类：</p>
<ul>
<li><strong>基于模板的方法(hand-written patterns)</strong><ul>
<li>基于触发词/字符串</li>
<li>基于依存句法</li>
</ul>
</li>
<li><strong>监督学习(supervised machine learning)</strong><ul>
<li>机器学习</li>
<li>深度学习（Pipeline vs Joint Model）</li>
</ul>
</li>
<li><strong>半监督/无监督学习(semi-supervised and unsupervised)</strong><ul>
<li>Bootstrapping</li>
<li>Distant supervision</li>
<li>Unsupervised learning from the web</li>
</ul>
</li>
</ul>
<h2 id="基于模板的方法"><a href="#基于模板的方法" class="headerlink" title="基于模板的方法"></a>基于模板的方法</h2><h3 id="基于触发词-字符串"><a href="#基于触发词-字符串" class="headerlink" title="基于触发词/字符串"></a>基于触发词/字符串</h3><p>首先是基于字符串的 pattern，举一个 IS-A 的关系</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Agar is a substance prepared from a mixture of red algae, **such as** Gelidium, for laboratory or industrial use</div></pre></td></tr></table></figure>
<p>通过 such as 可以判断这是一种 IS-A 的关系，由此可以写的规则是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">“Y such as X ((, X)* (, and|or) X)”</div><div class="line">“such Y as X”</div><div class="line">“X or other Y”</div><div class="line">“X and other Y”</div><div class="line">“Y including X”</div><div class="line">“Y, especially X”</div></pre></td></tr></table></figure></p>
<p>另一个直觉是，更多的关系是在特定实体之间的，所以可以用 NER 标签来帮助关系抽取，如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">•  located-in (ORGANIZATION, LOCATION)</div><div class="line">•  founded (PERSON, ORGANIZATION)</div><div class="line">•  cures (DRUG, DISEASE)</div></pre></td></tr></table></figure></p>
<p>也就是说我们可以把基于字符串的 pattern 和基于 NER 的 pattern 结合起来，就有了下面的例子。<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/5.jpg" class="ful-image" alt="5.jpg"></p>
<p>对应的工具有 Stanford CoreNLP 的 tokensRegex。</p>
<h3 id="基于依存句法"><a href="#基于依存句法" class="headerlink" title="基于依存句法"></a>基于依存句法</h3><p>通常可以以动词为起点构建规则，对节点上的词性和边上的依存关系进行限定。流程为:<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DT.png" class="ful-image" alt="DT.png"><br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DT2.png" class="ful-image" alt="DT2.png"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>手写规则的 <strong>优点</strong> 是：</p>
<ul>
<li>人工规则有高准确率(high-precision)</li>
<li>可以为特定领域定制(tailor)</li>
<li>在小规模数据集上容易实现，构建简单</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>低召回率(low-recall)</li>
<li>特定领域的模板需要专家构建，要考虑周全所有可能的 pattern 很难，也很费时间精力</li>
<li>需要为每条关系来定义 pattern</li>
<li>难以维护</li>
<li>可移植性差</li>
</ul>
<h2 id="监督学习-传统机器学习"><a href="#监督学习-传统机器学习" class="headerlink" title="监督学习-传统机器学习"></a>监督学习-传统机器学习</h2><h3 id="研究综述"><a href="#研究综述" class="headerlink" title="研究综述"></a>研究综述</h3><p>漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025</p>
<blockquote>
<p>Zhou[13] 在 Kambhatla 的基础上加入了基本词组块信息和 WordNet，使用 SVM 作为分类器，在实体关系识别的准确率达到了 55.5%，实验表明实体类别信息的特征有助于提高关系抽取性能； Zelenko[14] 等人使用浅层句法分析树上最小公共子树来表达关系实例，计算两颗子树之间的核函数，通过训练例如 SVM 模型的分类器来对实例进行分。但基于核函数的方法的问题是召回率普遍较低，这是由于相似度计算过程匹配约束比较严格，因此在后续研究对基于核函数改进中，大部分是围绕改进召回率。但随着时间的推移，语料的增多、深度学习在图像和语音领域获得成功，信息抽取逐渐转向了基于神经模型的研究，相关的语料被提出作为测试标准，如 SemEval-2010 task 8[15]。基于神经网络方法的研究有，Hashimoto[16] 等人利用 Word Embedding 方法从标注语料中学习特定的名词对的上下文特征，然后将该特征加入到神经网络分类器中，在 SemEval-2010 task 8 上取得了 F1 值 82.8% 的效果。基于神经网络模型显著的特点是不需要加入太多的特征，一般可用的特征有词向量、位置等，因此有人提出利用基于联合抽取模型，这种模型可以同时抽取实体和其之间的关系。联合抽取模型的优点是可以避免流水线模型存在的错误累积[17-22]。其中比较有代表性的工作是[20]，该方法通过提出全新的全局特征作为算法的软约束，进而同时提高关系抽取和实体抽取的准确率，该方法在 ACE 语料上比传统的流水线方法 F1 提高了 1.5%，；另一项工作是 [22]，利用双层的 LSTM-RNN 模型训练分类模型，第一层 LSTM 输入的是词向量、位置特征和词性来识别实体的类型。训练得到的 LSTM 中隐藏层的分布式表达和实体的分类标签信息作为第二层 RNN 模型的输入，第二层的输入实体之间的依存路径，第二层训练对关系的分类，通过神经网络同时优化 LSTM 和 RNN 的模型参数，实验与另一个采用神经网络的联合抽取模型[21]相比在关系分类上有一定的提升。但无论是流水线方法还是联合抽取方法，都属于有监督学习，因此需要大量的训练语料，尤其是对基于神经网络的方法，需要大量的语料进行模型训练，因此这些方法都不适用于构建大规模的 Knowledge Base。</p>
</blockquote>
<p>[13] Guodong Z, Jian S, Jie Z, et al. ExploringVarious Knowledge in relation Extraction.[c]// acl2005, Meeting of the Association for ComputationalLinguistics, Proceedings of the Conference, 25-30 June, 2005, University of Michigan, USA. DBLP.2005:419-444.<br>[14] Zelenko D, Aone C, Richardella A. KernelMethods for relation Extraction[J]. the Journal ofMachine Learning Research, 2003, 1083-1106.<br>[15] Hendrickx I, Kim S N, Kozareva Z, et al.semEval-2010 task 8: Multi-way classification ofsemantic relations between Pairs of nominals[c]//the Workshop on semantic Evaluations: recentachievements and Future Directions. association forComputational Linguistics, 2009:94-99.<br>[16] Hashimoto K, Stenetorp P, Miwa M, et al. Task-oriented learning of Word Embeddings for semanticRelation Classification[J], Computer Science,2015:268-278.<br>[17] Singh S, Riedel S, Martin B, et al. JointInference of Entities, Relations, and Coreference[C]//the Workshop on automated Knowledge baseConstruction ,San Francisco, CA, USA, October27-november 1. 2013:1-6.<br>[18] Miwa M, Sasaki Y. Modeling Joint Entity andrelation Extraction with table representation[c]//conference on Empirical Methods in naturalLanguage Processing. 2014:944-948.<br>[19] Lu W, Dan R. Joint Mention Extraction andclassification with Mention Hypergraphs[c]//conference on Empirical Methods in naturallanguage Processing. 2015:857-867.<br>[20] Li Q, Ji H. Incremental Joint Extraction of EntityMentions and relations[c]// annual Meeting of theAssociation for Computational Linguistics. 2014:402-412.<br>[21] Kate R J, Mooney R J. Joint Entity andrelation Extraction using card-pyramid Parsing[c]//conference on computational natural languagelearning. 2010:203-212.<br>[22] Miwa M, Bansal M. End-to-End Relation Extraction using lstMs on sequences and tree structures[c]// annual Meeting of the association for computational linguistics. 2016:1105-1116.</p>
<h3 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h3><p>标准流程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">- 预先定义好想提取的关系集合</div><div class="line">- 选择相关的命名实体集合</div><div class="line">- 寻找并标注数据</div><div class="line"> 选择有代表性的语料库</div><div class="line"> 标记命名实体</div><div class="line"> 人工标注实体间的关系</div><div class="line"> 分成训练、开发、测试集</div><div class="line">- 设计特征</div><div class="line">- 选择并训练分类器</div><div class="line">- 评估结果</div></pre></td></tr></table></figure></p>
<p>为了提高 efficiency，通常我们会训练两个分类器，第一个分类器是 yes/no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用 task-specific feature-set。</p>
<p>可以采用的分类器可以是 <strong>MaxEnt、Naive Bayes、SVM</strong> 等。</p>
<h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><p>直接上例子：<br>E.g., <strong>American Airlines</strong>, a unit of AMR, immediately matched the move, spokesman <strong>Tim Wagner</strong> said</p>
<p><strong>Mention 1:</strong> American Airlines<br><strong>Mention 2:</strong> Tim Wagner</p>
<p>用到的特征可以有：<br><strong>Word features</strong></p>
<ul>
<li>Headwords of M1 and M2, and combination<ul>
<li>M1: Airlines,  M2: Wagner, Combination: Airlines-Wagner</li>
</ul>
</li>
<li>Bag of words and bigrams in M1 and M2<ul>
<li>{American, Airlines, Tim, Wagner, American Airlines, Tim Wagner}</li>
</ul>
</li>
<li>Words or bigrams in particular positions left and right of M1/M2<ul>
<li>M2: -1 spokesman</li>
<li>M2: +1 said</li>
</ul>
</li>
<li>Bag of words or bigrams between the two entities<ul>
<li>{a, AMR, of, immediately, matched, move, spokesman, the, unit}</li>
</ul>
</li>
</ul>
<p><strong>Named Entities Type and Mention Level Features</strong></p>
<ul>
<li>Named-entities types<br>M1: ORG<br>M2: PERSON</li>
<li>Concatenation of the two named-entities types<br>ORG-PERSON</li>
<li>Entity Level of M1 and M2 (NAME, NOMINAL, PRONOUN)<br>M1: NAME     [it or he would be PRONOUN]<br>M2: NAME     [the company would be NOMINAL]</li>
</ul>
<p><strong>Parse Features</strong></p>
<ul>
<li>Base syntactic chunk sequence from one to the other<br>NP NP PP VP NP NP</li>
<li>Constituent path through the tree from one to the other<br>NP ↑ NP ↑ S ↑ S ↓ NP</li>
<li>Dependency path<br>Airlines matched Wagner said</li>
</ul>
<p><strong>Gazetteer and trigger word features</strong></p>
<ul>
<li>Trigger list for family: kinship terms<br>parent, wife, husband, grandparent, etc. [from WordNet]</li>
<li>Gazetteer:<br>List of useful geo or geopolitical words<br>  Country name list<br>  Other sub-entities</li>
</ul>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/7.jpg" class="ful-image" alt="7.jpg">
<p>或者从另一个角度考虑，可以分为</p>
<ul>
<li><strong>轻量级</strong><br>实体的特征，包括实体前后的词，实体类型，实体之间的距离等</li>
<li><strong>中等量级</strong><br>考虑 chunk，如 NP，VP，PP 这类短语</li>
<li><strong>重量级</strong><br>考虑实体间的依存关系，实体间树结构的距离，及其他特定的结构信息</li>
</ul>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/features2.png" class="ful-image" alt="features2.png">
<h2 id="监督学习-深度学习"><a href="#监督学习-深度学习" class="headerlink" title="监督学习-深度学习"></a>监督学习-深度学习</h2><p>深度学习方法又分为两大类，pipeline 和 joint model</p>
<ul>
<li><strong>Pipeline</strong><br>把实体识别和关系分类作为两个完全独立的过程，不会相互影响，关系的识别依赖于实体识别的效果</li>
<li><strong>Joint Model</strong><br>实体识别和关系分类的过程共同优化</li>
</ul>
<p>深度学习用到的特征通常有：</p>
<ul>
<li>Position embeddings</li>
<li>Word embeddings</li>
<li>Knowledge embeddings</li>
</ul>
<p>模型通常有 CNN/RNN + attention，损失函数 ranking loss 要优于交叉熵。</p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><h4 id="CR-CNN"><a href="#CR-CNN" class="headerlink" title="CR-CNN"></a>CR-CNN</h4><p><a href="https://arxiv.org/pdf/1504.06580.pdf" target="_blank" rel="external">Santos et. al Computer Science 2015</a><br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/CR-CNN.png" class="ful-image" alt="CR-CNN.png"></p>
<p>输入层 word embedding + position embedding，用 6 个卷积核 + max pooling 生成句子向量表示，与关系（类别）向量做点积求相似度，作为关系分类的结果。<br>损失函数用的是  <strong>pairwise ranking loss function</strong></p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/CR-CNN_loss.png" class="ful-image" alt="CR-CNN_loss.png">
<p>训练时每个样本有两个标签，正确标签 y+ 和错误标签 c-，m+ 和 m- 对应了两个 margin，$\gamma$ 用来缩放，希望 $s(x)_{y+}$ 越大越好，$s(x)_{c-}$ 越小越好。</p>
<p>另外还有一些 tips：</p>
<ul>
<li>负样本选择 $s(x)_c$ 最大的标签，便于更好地将比较类似的两种 label 分开</li>
<li>加了一个 Artifical Class，表示两个实体没有任何关系，可以理解为 Other/拒识，训练时不考虑这一类，损失函数的第一项直接置 0，预测时如果其他 actual classes 的分数都为负，那么就分为 Other，对于整体的 performance 有提升</li>
<li>position feature 是每个 word 与两个 entity 的相对距离，强调了两个实体的作用，认为距离实体近的单词更重要，PE 对效果的提升明显，但实际上只用两个实体间的 word embedding 作为输入代替整个句子的 word embedding+position embedding，也有相近效果，且输入更少实现更简单。</li>
</ul>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/PE.png" class="ful-image" alt="PE.png">
<h4 id="Att-CNN"><a href="#Att-CNN" class="headerlink" title="Att-CNN"></a>Att-CNN</h4><p><a href="http://iiis.tsinghua.edu.cn/~weblt/papers/relation-classification.pdf" target="_blank" rel="external">Relation Classification via Multi-Level Attention CNNs</a></p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCNN.png" class="ful-image" alt="AttCNN.png">
<p>用了两个层面的 Attention，一个是输入层对两个 entity 的注意力，另一个是在卷积后的 pooling 阶段，用 attention pooling 代替 max pooling 来加强相关性强的词的权重。</p>
<p>输入特征还是 word embedding 和 position embedding，另外做了 n-gram 的操作，取每个词前后 k/2 个词作为上下文信息，每个词的 embedding size 就是 $(d_w + 2d_p)*k$。这个滑动窗口的效果其实和卷积一样，但因为输入层后直接接了 attention，所以这里先做了 n-gram。</p>
<p>第一层 input attention 用两个对角矩阵分别对应两个 entity，对角线各元素是输入位置对应词与实体间的相关性分数 $A^j_{i,i}=f(e_j, w_i)$，通过词向量內积衡量相关性，然后 softmax 归一化，每个词对两个实体各有一个权重 $\alpha_1, \alpha_2$，然后进行加权把权重与输入 $z_i$ 融合，有三种融合方法， <strong>求平均、拼接、相减</strong>（类似 transE 操作，把 relation 看做两个权重的差）。这一层的 attention 捕捉的是句中单词与实体的词向量距离，但其实有些线索词如 caused 与实体的相似度不高但很重要。</p>
<p>接着做正常卷积，然后第二层用 attention pooling 代替 max-pooling，bilinear 方法计算相关度，然后归一化，再做 max pooling 得到模型最后的输出 $w^O$。</p>
<p>另外，这篇 paper 还改进了 Santos 提出的 Ranking loss，Ranking loss 里的 distance function 直接用了网络的输出，而这里定义了新的 distance function 来衡量模型输出 $w^O$ 和正确标签对应的向量 relation embedding $W^L_y$ 的距离：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCnn_loss.png" class="ful-image" alt="AttCnn_loss.png"></p>
<p>用了 L2 正则，然后基于这一距离定义了目标函数：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttCNN_loss2.png" class="ful-image" alt="AttCNN_loss2.png"></p>
<p>两个距离分别为网络输出与正例和与负例的距离，负例照例用了所有错误类别中与输出最接近的，margin 设置的 1。</p>
<p><strong>这应该是目前最好的方法，SemEval-2010 Task 8 上的 F1 值到了 88。</strong></p>
<h4 id="Att-BLSTM"><a href="#Att-BLSTM" class="headerlink" title="Att-BLSTM"></a>Att-BLSTM</h4><p><a href="http://www.aclweb.org/anthology/P16-2034" target="_blank" rel="external">Peng Zhou et. al ACL 2016</a></p>
<p>CNN 可以处理文本较短的输入，但是长距离的依赖还是需要 LSTM，这一篇就是中规中矩的 BiLSTM+Attn 来做关系分类任务。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/AttBLSM.png" class="ful-image" alt="AttBLSM.png"></p>
<h4 id="评测"><a href="#评测" class="headerlink" title="评测"></a>评测</h4><p>各方法在 SemEval-2010 Task 8 上的评测：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/pipeline_perf.png" class="ful-image" alt="pipeline_perf.png"></p>
<h3 id="Joint-Model"><a href="#Joint-Model" class="headerlink" title="Joint Model"></a>Joint Model</h3><p>Pipeline 的方法会导致误差的传递，端到端的方法直觉上会更优。</p>
<h4 id="LSTM-RNNs"><a href="#LSTM-RNNs" class="headerlink" title="LSTM-RNNs"></a>LSTM-RNNs</h4><p><a href="https://arxiv.org/pdf/1601.00770.pdf" target="_blank" rel="external">Miwa et. al ACL 2016</a></p>
<p>用端到端的方式进行抽取，实体识别和关系分类的参数共享，不过判断过程并没有进行交互。<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/joint_model.png" class="ful-image" alt="joint_model.png"></p>
<p>三个表示层</p>
<ul>
<li><strong>Embedding layer (word embeddings layer)</strong><br>用到了词向量 $v_w$、词性 POS tags $v_p$、依存句法标签 Dependency types $v_d$、实体标签 entity labels $v_e$</li>
<li><strong>Sequence layer (word sequence based LSTM-RNN layer)</strong><br>负责实体识别<br>BiLSTM 对句子进行编码，输入是 word embedding 和 POS embedding 的拼接，输出是两个方向的隐层单元输出的拼接 $s_t$<br>然后进行实体识别，还是序列标注任务，两层 NN 加一个 softmax 输出标签。打标签的方法用 BILOU(Begin, Inside, Last, Outside, Unit)，解码时考虑到当前标签依赖于上一个标签的问题，输入在 sequence layer 层的输出上还加了上一时刻的 label embedding，用 schedule sampling 的方式来决定用 gold label 还是 predict label<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/entity_detection.png" class="ful-image" alt="entity_detection.png"></li>
<li><p><strong>Dependency layer (dependency subtree based LSTM-RNN layer )</strong><br>负责关系分类<br>用 tree-structured BiLSTM-RNNs 来表示 relation candidate，捕捉了 top-down 和 bottom-up 双向的关系，输入是 sequence layer 的输出 $s_t$，dependency type embedding $v_d$，以及 label embedding $v_e$，输出是 $d_p$<br>关系分类主要还是利用了依存树中两个实体之间的最短路径（shortest path）。主要过程是找到 sequence layer 识别出的所有实体，对每个实体的最后一个单词进行排列组合，再经过 dependency layer 得到每个组合的 $d_p$，然后同样用两层 NN + softmax 对该组合进行分类，输出这对实体的关系类别。<br>$d_p$ 第一项是 bottom-up LSTM-RNN 的 top LSTM unit，代表实体对的最低公共父节点（the lowest common ancestor of the target word pair p），第二、三项分别是两个实体对应的 top-down LSTM-RNN 的 hidden state。</p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/dp.png" class="ful-image" alt="dp.png">
<p>​</p>
</li>
</ul>
<p>不同模型在 SemEval-2010 Task 8 数据集上的效果比较：<br><img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/joint_perf.png" class="ful-image" alt="joint_perf.png"></p>
<p>与我们的直觉相反，joint model 不一定能起正作用。不过上面的比较能得到的另一个结论是：<strong>外部资源可以来优化模型</strong>。</p>
<h2 id="监督学习-评价指标"><a href="#监督学习-评价指标" class="headerlink" title="监督学习-评价指标"></a>监督学习-评价指标</h2><p>最常用的 Precision, Recall, F1</p>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/8.jpg" class="ful-image" alt="8.jpg">
<h2 id="监督学习-小结"><a href="#监督学习-小结" class="headerlink" title="监督学习-小结"></a>监督学习-小结</h2><p>如果测试集和训练集很相似，那么监督学习的准确率会很高，然而，它对不同 genre 的泛化能力有限，模型比较脆弱，也很难扩展新的关系；另一方面，获取这么大的训练集代价也是昂贵的。</p>
<h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><h3 id="研究综述-1"><a href="#研究综述-1" class="headerlink" title="研究综述"></a>研究综述</h3><p>漆桂林,高桓,吴天星.知识图谱研究进展[J].情报工程,2017,3(1):004-025</p>
<blockquote>
<p>Brin[23]等人通过少量的实例学习种子模板，从网络上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，其主要贡献是构建了 DIPRE 系统；Agichtein[24]在 Brin 的基础上对新抽取的实例进行可信度的评分和完善关系描述的模式，设计实现了 Snowball 抽取系统；此后的一些系统都沿着 Bootstrap 的方法，但会加入更合理的对 pattern 描述、更加合理的限制条件和评分策略，或者基于先前系统抽取结果上构建大规模 pattern；如 NELL（Never-EndingLanguage Learner）系统[25-26]，NELL 初始化一个本体和种子 pattern，从大规模的 Web 文本中学习，通过对学习到的内容进行打分来提高准确率，目前已经获得了 280 万个事实。</p>
</blockquote>
<p>[23] brin s. Extracting Patterns and relations fromthe World Wide Web[J]. lecture notes in computerScience, 1998, 1590:172-183.<br>[24] Agichtein E, Gravano L. Snowball : Extractingrelations from large Plain-text collections[c]// acMConference on Digital Libraries. ACM, 2000:85-94.<br>[25] Carlson A, Betteridge J, Kisiel B, et al. Toward anarchitecture for never-Ending language learning.[c]// twenty-Fourth aaai conference on artificialIntelligence, AAAI 2010, Atlanta, Georgia, Usa, July.DBLP, 2010:529-573.<br>[26] Mitchell T, Fredkin E. Never-ending Languagelearning[M]// never-Ending language learning.Alphascript Publishing, 2014.</p>
<h3 id="Seed-based-or-bootstrapping-approaches"><a href="#Seed-based-or-bootstrapping-approaches" class="headerlink" title="Seed-based or bootstrapping approaches"></a>Seed-based or bootstrapping approaches</h3><p>半监督学习主要是利用少量的标注信息进行学习，这方面的工作主要是<strong>基于 Bootstrap 的方法</strong>以及<strong>远程监督方法（distance supervision）</strong>。<strong>基于 Bootstrap 的方法</strong> 主要是利用少量实例作为初始种子(seed tuples)的集合，然后利用 pattern 学习方法进行学习，通过不断迭代从非结构化数据中抽取实例，然后从新学到的实例中学习新的 pattern 并扩充 pattern 集合，寻找和发现新的潜在关系三元组。<strong>远程监督</strong> 方法主要是对知识库与非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。</p>
<h4 id="Relation-Bootstrapping"><a href="#Relation-Bootstrapping" class="headerlink" title="Relation Bootstrapping"></a>Relation Bootstrapping</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">•  Gather a set of seed pairs that have relation R</div><div class="line">•  Iterate:</div><div class="line">1.  Find sentences with these pairs</div><div class="line">2.  Look at the context between or around the pair and generalize the context to create patterns</div><div class="line">3.  Use the patterns for grep for more pairs</div></pre></td></tr></table></figure>
<p>看一个完整的例子<br><img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/6.jpg" class="ful-image" alt="6.jpg"></p>
<p>从 5 对种子开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 $(authoer, book)$ 抽取到了 relation pattern，<strong><em>x, by y</em></strong>, 和 <strong><em>x, one of y’s</em></strong></p>
<p><strong>优点：</strong></p>
<ul>
<li>构建成本低，适合大规模构建</li>
<li>可以发现新的关系（隐含的）</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>对初始给定的种子集敏感</li>
<li>存在语义漂移问题</li>
<li>结果准确率较低</li>
<li>缺乏对每一个结果的置信度的计算</li>
</ul>
<h4 id="Snowball"><a href="#Snowball" class="headerlink" title="Snowball"></a>Snowball</h4><p>对 Dipre 算法的改进。Snowball 也是一种相似的迭代算法，Dipre 的 X,Y 可以是任何字符串，而 Snowball 要求 X,Y 必须是命名实体，并且 Snowball 对每个 pattern 计算了 confidence value<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Group instances w/similar prefix, middle, suffix, extract patterns</div><div class="line"> •  But require that X and Y be named entites</div><div class="line"> •  And compute a confidence for each pattern</div><div class="line"></div><div class="line">ORGANIZATION &#123;&apos;s, in, headquaters&#125; LOCATION</div><div class="line">LOCATION &#123;in, based&#125; ORGANIZATION</div></pre></td></tr></table></figure></p>
<h3 id="Distant-Supervision"><a href="#Distant-Supervision" class="headerlink" title="Distant Supervision"></a>Distant Supervision</h3><p><strong>基本假设：</strong>两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系。</p>
<p><strong>具体步骤：</strong></p>
<ol>
<li>从知识库中抽取存在关系的实体对</li>
<li>从非结构化文本中抽取含有实体对的句子作为训练样例，然后提取特征训练分类器。</li>
</ol>
<img src="http://images.shuang0420.com/images/NLP%E7%AC%94%E8%AE%B0%20-%20Relation%20Extraction/9.jpg" class="ful-image" alt="9.jpg">
<p>Distant Supervision 结合了 bootstrapping 和监督学习的长处，使用一个大的 corpus 来得到海量的 seed example，然后从这些 example 中创建特征，最后与有监督的分类器相结合。</p>
<p>与监督学习相似的是这种方法用大量特征训练了分类器，通过已有的知识进行监督，不需要用迭代的方法来扩充 pattern。<br>与无监督学习相似的是这种方法采用了大量没有标注的数据，对训练语料库中的 genre 并不敏感，适合泛化。</p>
<h4 id="PCNN-Attention"><a href="#PCNN-Attention" class="headerlink" title="PCNN + Attention"></a>PCNN + Attention</h4><p><a href="https://www.semanticscholar.org/paper/Distant-Supervision-for-Relation-Extraction-with-Ji-Liu/b8da823ad81e3b8e5b80d82f86129fdb1d9132e7" target="_blank" rel="external">Kang Liu et.al AI 2017</a></p>
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS.png" class="ful-image" alt="DS.png">
<ol>
<li><strong>PCNN</strong><br>单一池化难以刻画不同上下文对句向量的贡献，而进行分段池化，根据两个实体把句子分成三段然后对不同部分分别进行池化，刻画更为精准。<br>另见 <a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP203.pdf" target="_blank" rel="external">Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks</a></li>
<li><strong>Sentence-level attention</strong><br>远程监督常用的 multi-instance learning，只选取最有可能的一个句子进行训练预测，丢失了大部分信息，句子层面的 attention 对 bag 里所有句子进行加权作为 bag 的特征向量，保留尽可能多的信息，能动态减少噪声句的权重，有利于解决错误标记的问题。<br>另见 <a href="http://www.aclweb.org/anthology/P16-1200" target="_blank" rel="external">Neural Relation Extraction with Selective Attention over Instances</a><br>这里对两个实体向量作差来表示 relation 向量 $v_{relation}$，如果一个实例能表达这种关系，那么这个实例的向量表达应该和 $v_{relation}$ 高度相似，根据这个假设来计算句向量和关系向量的相关性，其中 $[b_i; v_{relation}]$ 表示垂直级联，$b_i$ 是 PCNN 得到的特征输出，softmax 归一化再进行加权，最后再过softmax 进行分类。<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS_sum.png" class="ful-image" alt="DS_sum.png">
<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/DS_att.png" class="ful-image" alt="DS_att.png"></li>
<li><strong>Entity representation</strong><br>引入了实体的背景知识（Freebase 和 Wikipedia 提供的实体描述信息），增强了实体表达（entity representation），D 是 (entity, description) 的集合表示，$e_i$ 是实体表示，$d_i$ 通过另一个传统 CNN 对收集到的实体的描述句抽特征得到<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/ed.png" class="ful-image" alt="ed.png">
希望 $e_i$ 和 $d_i$ 尽可能相似，定义两者间的误差：<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/errors.png" class="ful-image" alt="errors.png">
最后的损失函数是交叉熵和实体描述误差的加权和：<img src="http://images.shuang0420.com/images/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96-%E5%AE%9E%E4%BD%93%E5%8F%8A%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/final_loss.png" class="ful-image" alt="final_loss.png">
</li>
</ol>
<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p><strong>优点：</strong></p>
<ul>
<li>可以利用丰富的知识库信息，减少一定的人工标注</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>假设过于肯定，引入大量噪声，存在语义漂移现象</li>
<li>很难发现新的关系</li>
</ul>
<h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><h3 id="研究综述-2"><a href="#研究综述-2" class="headerlink" title="研究综述"></a>研究综述</h3><blockquote>
<p>Bollegala[27]从搜索引擎摘要中获取和聚合抽取模板，将模板聚类后发现由实体对代表的隐含语义关系; Bollegala[28]使用联合聚类(Co-clustering)算法，利用关系实例和关系模板的对偶性，提高了关系模板聚类效果，同时使用 L1 正则化 Logistics 回归模型，在关系模板聚类结果中筛选出代表性的抽取模板，使得关系抽取在准确率和召回率上都有所提高。</p>
<p>无监督学习一般利用语料中存在的大量冗余信息做聚类，在聚类结果的基础上给定关系，但由于聚类方法本身就存在难以描述关系和低频实例召回率低的问题，因此无监督学习一般难以得很好的抽取效果。</p>
</blockquote>
<p>[27] Bollegala D T, Matsuo Y, Ishizuka M. Measuringthe similarity between implicit semantic relationsfrom the Web[J]. Www Madrid! track semantic/dataWeb, 2009:651-660.<br>[28] Bollegala D T, Matsuo Y, Ishizuka M. RelationalDuality: Unsupervised Extraction of semantic relations between Entities on the Web[c]//International Conference on World Wide Web, WWW 2010, Raleigh, North Carolina, Usa, April. DBLP, 2010:151-160.</p>
<h3 id="Open-IE"><a href="#Open-IE" class="headerlink" title="Open IE"></a>Open IE</h3><p><strong>Open Information Extraction</strong> 从网络中抽取关系，没有训练数据，没有关系列表。过程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1. Use parsed data to train a “trustworthy tuple” classifier</div><div class="line">2. Single-pass extract all relations between NPs, keep if trustworthy</div><div class="line">3. Assessor ranks relations based on text redundancy</div><div class="line"></div><div class="line">E.g.,</div><div class="line">(FCI, specializes in, sobware development)</div><div class="line">(Tesla, invented, coil transformer)</div></pre></td></tr></table></figure></p>
<h2 id="半监督-无监督学习-评价指标"><a href="#半监督-无监督学习-评价指标" class="headerlink" title="半监督/无监督学习-评价指标"></a>半监督/无监督学习-评价指标</h2><p>因为抽取的是新的关系，并不能准确的计算 precision 和 recall，所以我们只能估计，从结果集中随机抽取一个关系的 sample，然后人工来检验准确率</p>
<p>$$\hat P = {\text {Number of correctly extracted relations in the sample} \over \text {Total number of extracted relations in the sample}}$$</p>
<p>也可以计算不同 recall level 上的 precision，比如说分别计算在前 1000，10,000，100,000 个新的关系中的 precision，在各个情况下随机取样。</p>
<p>然而，并没有方法来计算 recall。</p>

      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/wechat.jpg" alt="徐阿衡 wechat" style="width: 200px; max-width: 100%;"/>
    <div>欢迎关注：徐阿衡的微信公众号</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>客官，打个赏呗~</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="http://7xu83c.com1.z0.glb.clouddn.com/1.pic.jpg" alt="徐阿衡 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag">#NLP</a>
          
            <a href="/tags/Relation-Extraction/" rel="tag">#Relation Extraction</a>
          
            <a href="/tags/Information-Extraction/" rel="tag">#Information Extraction</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/06/love99/" rel="next" title="99/100 天纪念日 - 第 1 期">
                <i class="fa fa-chevron-left"></i> 99/100 天纪念日 - 第 1 期
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/10/15/知识抽取-事件抽取/" rel="prev" title="知识抽取-事件抽取">
                知识抽取-事件抽取 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      



    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
     
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xu83c.com1.z0.glb.clouddn.com/2.pic.jpg"
               alt="徐阿衡" />
          <p class="site-author-name" itemprop="name">徐阿衡</p>
          <p class="site-description motion-element" itemprop="description">读万卷书，行万里路 @SYSU @CMU</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/">
              <span class="site-state-item-count">164</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">126</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Shuang0420" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.linkedin.com/in/shuang-xu-7008b894?trk=nav_responsive_tab_profile_pic" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://zhuanlan.zhihu.com/c_136690664" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://starllap.space" title="Star" target="_blank">Star</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://liam0205.me" title="Liam Huang" target="_blank">Liam Huang</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.libinx.com" title="Li Bin" target="_blank">Li Bin</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#相关竞赛与数据集"><span class="nav-number">1.</span> <span class="nav-text">相关竞赛与数据集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实体抽取"><span class="nav-number">2.</span> <span class="nav-text">实体抽取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#传统机器学习方法"><span class="nav-number">2.1.</span> <span class="nav-text">传统机器学习方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#编码方式"><span class="nav-number">2.1.1.</span> <span class="nav-text">编码方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征选择"><span class="nav-number">2.1.2.</span> <span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#序列模型"><span class="nav-number">2.1.3.</span> <span class="nav-text">序列模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Greedy-Inference"><span class="nav-number">2.1.3.1.</span> <span class="nav-text">Greedy Inference</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Beam-Inference"><span class="nav-number">2.1.3.2.</span> <span class="nav-text">Beam Inference</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Viterbi-Inference"><span class="nav-number">2.1.3.3.</span> <span class="nav-text">Viterbi Inference</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习方法"><span class="nav-number">2.2.</span> <span class="nav-text">深度学习方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LSTM-CRF"><span class="nav-number">2.2.1.</span> <span class="nav-text">LSTM+CRF</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评价指标"><span class="nav-number">2.3.</span> <span class="nav-text">评价指标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他-实体链接"><span class="nav-number">2.4.</span> <span class="nav-text">其他-实体链接</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关系抽取"><span class="nav-number">3.</span> <span class="nav-text">关系抽取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基于模板的方法"><span class="nav-number">3.1.</span> <span class="nav-text">基于模板的方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于触发词-字符串"><span class="nav-number">3.1.1.</span> <span class="nav-text">基于触发词/字符串</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于依存句法"><span class="nav-number">3.1.2.</span> <span class="nav-text">基于依存句法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#小结"><span class="nav-number">3.1.3.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习-传统机器学习"><span class="nav-number">3.2.</span> <span class="nav-text">监督学习-传统机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#研究综述"><span class="nav-number">3.2.1.</span> <span class="nav-text">研究综述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类器"><span class="nav-number">3.2.2.</span> <span class="nav-text">分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征"><span class="nav-number">3.2.3.</span> <span class="nav-text">特征</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习-深度学习"><span class="nav-number">3.3.</span> <span class="nav-text">监督学习-深度学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pipeline"><span class="nav-number">3.3.1.</span> <span class="nav-text">Pipeline</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CR-CNN"><span class="nav-number">3.3.1.1.</span> <span class="nav-text">CR-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Att-CNN"><span class="nav-number">3.3.1.2.</span> <span class="nav-text">Att-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Att-BLSTM"><span class="nav-number">3.3.1.3.</span> <span class="nav-text">Att-BLSTM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#评测"><span class="nav-number">3.3.1.4.</span> <span class="nav-text">评测</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Joint-Model"><span class="nav-number">3.3.2.</span> <span class="nav-text">Joint Model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LSTM-RNNs"><span class="nav-number">3.3.2.1.</span> <span class="nav-text">LSTM-RNNs</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习-评价指标"><span class="nav-number">3.4.</span> <span class="nav-text">监督学习-评价指标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习-小结"><span class="nav-number">3.5.</span> <span class="nav-text">监督学习-小结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#半监督学习"><span class="nav-number">3.6.</span> <span class="nav-text">半监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#研究综述-1"><span class="nav-number">3.6.1.</span> <span class="nav-text">研究综述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Seed-based-or-bootstrapping-approaches"><span class="nav-number">3.6.2.</span> <span class="nav-text">Seed-based or bootstrapping approaches</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Relation-Bootstrapping"><span class="nav-number">3.6.2.1.</span> <span class="nav-text">Relation Bootstrapping</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Snowball"><span class="nav-number">3.6.2.2.</span> <span class="nav-text">Snowball</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distant-Supervision"><span class="nav-number">3.6.3.</span> <span class="nav-text">Distant Supervision</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PCNN-Attention"><span class="nav-number">3.6.3.1.</span> <span class="nav-text">PCNN + Attention</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小结-1"><span class="nav-number">3.6.3.2.</span> <span class="nav-text">小结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无监督学习"><span class="nav-number">3.7.</span> <span class="nav-text">无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#研究综述-2"><span class="nav-number">3.7.1.</span> <span class="nav-text">研究综述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Open-IE"><span class="nav-number">3.7.2.</span> <span class="nav-text">Open IE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#半监督-无监督学习-评价指标"><span class="nav-number">3.8.</span> <span class="nav-text">半监督/无监督学习-评价指标</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <!-- Other code may be here -->
<div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">徐阿衡</span>
  <a href="http://www.miitbeian.gov.cn/">粤ICP备17129486号</a>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>


<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'httpshuang0420githubio';
      var disqus_identifier = '2018/09/15/知识抽取-实体及关系抽取/';
      var disqus_title = "知识抽取-实体及关系抽取";
      var disqus_url = 'http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
